{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import expon\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dill\n",
    "import pickle\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import classification_module as classmod\n",
    "import features_extraction_funcs as feex\n",
    "import feats_extr_module as feex_module\n",
    "%aimport\n",
    "\n",
    "pipe_names = [#'V0001_PCA_80','V0001_PCA_70','V0001_PCA_5components',\n",
    "              #'V001_PCA_80',\n",
    "              'V001_PCA_70',\n",
    "              'V001_PCA_5components',\n",
    "              #'V01_PCA_90',\n",
    "              'V01_PCA_85',\n",
    "              'V01_PCA_80',\n",
    "              'V01_PCA_5components',\n",
    "              #'V09_PCA_95',\n",
    "              'V09_PCA_90',\n",
    "              'V09_PCA_80',\n",
    "              'V09_PCA_5components'\n",
    "            ]\n",
    "pipes = [\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 0.70, whiten = True, svd_solver = 'full')),\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "    #              PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "                  PCA(n_components = 0.70, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "    #              PCA(n_components = 0.90, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 0.85, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "    #              PCA(n_components = 0.95, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 0.90, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "       ]\n",
    "\n",
    "\n",
    "#pipe_names = ['V09_PCA_5components']\n",
    "#pipes = [make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "#                  PCA(n_components = 5, whiten = True, svd_solver = 'full'))]\n",
    "model_names_v1 = ['LogisticRegression',\n",
    "                  'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier',\n",
    "                    'SVC', 'MLPClassifier']\n",
    "\n",
    "model_names_v1 = ['LogisticRegression',\n",
    "                  'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier',\n",
    "                  'MLPClassifier']\n",
    "\n",
    "models_v1 = [LogisticRegression(),\n",
    "             RandomForestClassifier(), DecisionTreeClassifier(), KNeighborsClassifier(), SVC(probability=True),\n",
    "               MLPClassifier()]\n",
    "\n",
    "models_v1 = [LogisticRegression(),\n",
    "             RandomForestClassifier(), DecisionTreeClassifier(), KNeighborsClassifier(),\n",
    "             MLPClassifier()]\n",
    "##{'C': expon(scale=0.2), 'degree': [2,3,4,5,6,7,8], 'kernel': ['rbf', 'poly', 'linear', 'sigmoid'],\n",
    "##    'coef0': [0.0, 0.5, 0.75, 1.0], 'shrinking': [True, False], 'tol': np.arange(1e-5,0.7,0.00001)},\n",
    "models_params_v1 = [\n",
    "    {'penalty': ['l2'], 'tol': expon(scale=0.2), 'C': expon(scale=0.2),\n",
    "     'class_weight': ['balanced', None], 'solver': ['newton-cg', 'saga', 'liblinear']},\n",
    "    {'n_estimators': [100,150,200,250,300,350], 'max_depth': np.arange(5,105,5),\n",
    "     'min_samples_leaf': [10, 50, 150, 200, 250, 125, 75], 'max_features': ['sqrt', 'log2']},\n",
    "    {'criterion': ['gini', 'entropy'], 'max_depth': [None, 20],\n",
    "     'min_samples_split': np.arange(0.01,1,0.01),\n",
    "    'max_features': ['sqrt', 'log2', 0.5], 'class_weight': ['balanced', None]},\n",
    "    {'n_neighbors': [3,4,5,6,7,8], 'weights': ['uniform', 'distance'],\n",
    "     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "    {'hidden_layer_sizes': [(100,),(100,100,),(100,100,50,),(200,50,),(200,50,50,),(200,50,50,50)],\n",
    "     'solver': ['adam','sgd','lbfgs'], 'activation': ['relu', 'identity', 'tanh', 'logistic'],\n",
    "    'alpha': np.arange(0.0001,0.05,0.0001)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('features_extracted_dataset_splitted.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_bench = classmod.ModelsBenchmark(model_names_v1, models_v1, models_params_v1)\n",
    "mlp_bench.fitTransformators(names=pipe_names,\n",
    "                             transformators=pipes,\n",
    "                             X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 89\n",
      "Finding best parameters for LogisticRegression_V001_PCA_70:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V001_PCA_70...\n",
      "\n",
      "Finding best parameters for RandomForestClassifier_V001_PCA_70:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V001_PCA_70...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V001_PCA_70:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTreeClassifier_V001_PCA_70...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V001_PCA_70:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V001_PCA_70...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V001_PCA_70:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.5min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V001_PCA_70...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for LogisticRegression_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V001_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for RandomForestClassifier_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V001_PCA_5components...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTreeClassifier_V001_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V001_PCA_5components...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.6min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V001_PCA_5components...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 90\n",
      "Finding best parameters for LogisticRegression_V01_PCA_85:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V01_PCA_85...\n",
      "\n",
      "Finding best parameters for RandomForestClassifier_V01_PCA_85:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V01_PCA_85...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V01_PCA_85:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTreeClassifier_V01_PCA_85...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V01_PCA_85:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V01_PCA_85...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V01_PCA_85:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V01_PCA_85...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 66\n",
      "Finding best parameters for LogisticRegression_V01_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V01_PCA_80...\n",
      "\n",
      "Finding best parameters for RandomForestClassifier_V01_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V01_PCA_80...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V01_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Error occured!\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 790, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 201, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n",
      "    raise TransportableException(text, e_type)\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 04:25:36 2018\n",
      "PID: 18428 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.84333783, -0.18074621,  1.3881462 , ....        0.19763274, -0.31561387]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 04:25:36 2018\n",
      "PID: 18428 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.84333783, -0.18074621,  1.3881462 , ....        0.19763274, -0.31561387]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py\", line 155, in findBestParams\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError\n",
      "___________________________________________________________________________\n",
      "Multiprocessing exception:\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n",
      "    188         sys.exit(msg)\n",
      "    189     main_globals = sys.modules[\"__main__\"].__dict__\n",
      "    190     if alter_argv:\n",
      "    191         sys.argv[0] = mod_spec.origin\n",
      "    192     return _run_code(code, main_globals, None,\n",
      "--> 193                      \"__main__\", mod_spec)\n",
      "        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n",
      "    194 \n",
      "    195 def run_module(mod_name, init_globals=None,\n",
      "    196                run_name=None, alter_sys=False):\n",
      "    197     \"\"\"Execute a module's code without importing it\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n",
      "     80                        __cached__ = cached,\n",
      "     81                        __doc__ = None,\n",
      "     82                        __loader__ = loader,\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "        code = <code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n",
      "        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n",
      "     86     return run_globals\n",
      "     87 \n",
      "     88 def _run_module_code(code, init_globals=None,\n",
      "     89                     mod_name=None, mod_spec=None,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n",
      "     11     # This is added back by InteractiveShellApp.init_path()\n",
      "     12     if sys.path[0] == '':\n",
      "     13         del sys.path[0]\n",
      "     14 \n",
      "     15     from ipykernel import kernelapp as app\n",
      "---> 16     app.launch_new_instance()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n",
      "    653 \n",
      "    654         If a global instance already exists, this reinitializes and starts it\n",
      "    655         \"\"\"\n",
      "    656         app = cls.instance(**kwargs)\n",
      "    657         app.initialize(argv)\n",
      "--> 658         app.start()\n",
      "        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n",
      "    659 \n",
      "    660 #-----------------------------------------------------------------------------\n",
      "    661 # utility functions, for convenience\n",
      "    662 #-----------------------------------------------------------------------------\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n",
      "    481         if self.poller is not None:\n",
      "    482             self.poller.start()\n",
      "    483         self.kernel.start()\n",
      "    484         self.io_loop = ioloop.IOLoop.current()\n",
      "    485         try:\n",
      "--> 486             self.io_loop.start()\n",
      "        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "    487         except KeyboardInterrupt:\n",
      "    488             pass\n",
      "    489 \n",
      "    490 launch_new_instance = IPKernelApp.launch_instance\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n",
      "    127         except (RuntimeError, AssertionError):\n",
      "    128             old_loop = None\n",
      "    129         try:\n",
      "    130             self._setup_logging()\n",
      "    131             asyncio.set_event_loop(self.asyncio_loop)\n",
      "--> 132             self.asyncio_loop.run_forever()\n",
      "        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n",
      "    133         finally:\n",
      "    134             asyncio.set_event_loop(old_loop)\n",
      "    135 \n",
      "    136     def stop(self):\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n",
      "    418                                    finalizer=self._asyncgen_finalizer_hook)\n",
      "    419         try:\n",
      "    420             events._set_running_loop(self)\n",
      "    421             while True:\n",
      "--> 422                 self._run_once()\n",
      "        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n",
      "    423                 if self._stopping:\n",
      "    424                     break\n",
      "    425         finally:\n",
      "    426             self._stopping = False\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "   1429                         logger.warning('Executing %s took %.3f seconds',\n",
      "   1430                                        _format_handle(handle), dt)\n",
      "   1431                 finally:\n",
      "   1432                     self._current_handle = None\n",
      "   1433             else:\n",
      "-> 1434                 handle._run()\n",
      "        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>>\n",
      "   1435         handle = None  # Needed to break cycles when an exception occurs.\n",
      "   1436 \n",
      "   1437     def _set_coroutine_wrapper(self, enabled):\n",
      "   1438         try:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>)\n",
      "    140             self._callback = None\n",
      "    141             self._args = None\n",
      "    142 \n",
      "    143     def _run(self):\n",
      "    144         try:\n",
      "--> 145             self._callback(*self._args)\n",
      "        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>),)\n",
      "    146         except Exception as exc:\n",
      "    147             cb = _format_callback_source(self._callback, self._args)\n",
      "    148             msg = 'Exception in callback {}'.format(cb)\n",
      "    149             context = {\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>))\n",
      "    753         \"\"\"Runs a callback with error handling.\n",
      "    754 \n",
      "    755         For use in subclasses.\n",
      "    756         \"\"\"\n",
      "    757         try:\n",
      "--> 758             ret = callback()\n",
      "        ret = undefined\n",
      "        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>)\n",
      "    759             if ret is not None:\n",
      "    760                 from tornado import gen\n",
      "    761                 # Functions that return Futures typically swallow all\n",
      "    762                 # exceptions and store them in the Future.  If a Future\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ()\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n",
      "    531             return\n",
      "    532 \n",
      "    533         if state & self.socket.events:\n",
      "    534             # events still exist that haven't been processed\n",
      "    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n",
      "--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "    537 \n",
      "    538     def _init_io_state(self):\n",
      "    539         \"\"\"initialize the ioloop event handler\"\"\"\n",
      "    540         with stack_context.NullContext():\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n",
      "    445             return\n",
      "    446         zmq_events = self.socket.EVENTS\n",
      "    447         try:\n",
      "    448             # dispatch events:\n",
      "    449             if zmq_events & zmq.POLLIN and self.receiving():\n",
      "--> 450                 self._handle_recv()\n",
      "        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "    451                 if not self.socket:\n",
      "    452                     return\n",
      "    453             if zmq_events & zmq.POLLOUT and self.sending():\n",
      "    454                 self._handle_send()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n",
      "    475             else:\n",
      "    476                 raise\n",
      "    477         else:\n",
      "    478             if self._recv_callback:\n",
      "    479                 callback = self._recv_callback\n",
      "--> 480                 self._run_callback(callback, msg)\n",
      "        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    481         \n",
      "    482 \n",
      "    483     def _handle_send(self):\n",
      "    484         \"\"\"Handle a send event.\"\"\"\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    427         close our socket.\"\"\"\n",
      "    428         try:\n",
      "    429             # Use a NullContext to ensure that all StackContexts are run\n",
      "    430             # inside our blanket exception handler rather than outside.\n",
      "    431             with stack_context.NullContext():\n",
      "--> 432                 callback(*args, **kwargs)\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    433         except:\n",
      "    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n",
      "    435                           exc_info=True)\n",
      "    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n",
      "    278         if self.control_stream:\n",
      "    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n",
      "    280 \n",
      "    281         def make_dispatcher(stream):\n",
      "    282             def dispatcher(msg):\n",
      "--> 283                 return self.dispatch_shell(stream, msg)\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    284             return dispatcher\n",
      "    285 \n",
      "    286         for s in self.shell_streams:\n",
      "    287             s.on_recv(make_dispatcher(s), copy=False)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n",
      "    229         else:\n",
      "    230             self.log.debug(\"%s: %s\", msg_type, msg)\n",
      "    231             self.pre_handler_hook()\n",
      "    232             try:\n",
      "--> 233                 handler(stream, idents, msg)\n",
      "        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n",
      "        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n",
      "        idents = [b'ea4df705f78d4ef197094a57a76c451a']\n",
      "        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}}\n",
      "    234             except Exception:\n",
      "    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "    236             finally:\n",
      "    237                 self.post_handler_hook()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'ea4df705f78d4ef197094a57a76c451a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    394         if not silent:\n",
      "    395             self.execution_count += 1\n",
      "    396             self._publish_execute_input(code, parent, self.execution_count)\n",
      "    397 \n",
      "    398         reply_content = self.do_execute(code, silent, store_history,\n",
      "--> 399                                         user_expressions, allow_stdin)\n",
      "        user_expressions = {}\n",
      "        allow_stdin = True\n",
      "    400 \n",
      "    401         # Flush output before sending the reply.\n",
      "    402         sys.stdout.flush()\n",
      "    403         sys.stderr.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n",
      "    203 \n",
      "    204         self._forward_input(allow_stdin)\n",
      "    205 \n",
      "    206         reply_content = {}\n",
      "    207         try:\n",
      "--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "        res = undefined\n",
      "        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "    209         finally:\n",
      "    210             self._restore_input()\n",
      "    211 \n",
      "    212         if res.error_before_exec is not None:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",), **kwargs={'silent': False, 'store_history': True})\n",
      "    532             )\n",
      "    533         self.payload_manager.write_payload(payload)\n",
      "    534 \n",
      "    535     def run_cell(self, *args, **kwargs):\n",
      "    536         self._last_traceback = None\n",
      "--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        args = (\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",)\n",
      "        kwargs = {'silent': False, 'store_history': True}\n",
      "    538 \n",
      "    539     def _showtraceback(self, etype, evalue, stb):\n",
      "    540         # try to preserve ordering of tracebacks and print statements\n",
      "    541         sys.stdout.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2657         -------\n",
      "   2658         result : :class:`ExecutionResult`\n",
      "   2659         \"\"\"\n",
      "   2660         try:\n",
      "   2661             result = self._run_cell(\n",
      "-> 2662                 raw_cell, store_history, silent, shell_futures)\n",
      "        raw_cell = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "        shell_futures = True\n",
      "   2663         finally:\n",
      "   2664             self.events.trigger('post_execute')\n",
      "   2665             if not silent:\n",
      "   2666                 self.events.trigger('post_run_cell', result)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2780                 self.displayhook.exec_result = result\n",
      "   2781 \n",
      "   2782                 # Execute the user code\n",
      "   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n",
      "   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n",
      "-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n",
      "        interactivity = 'last_expr'\n",
      "        compiler = <IPython.core.compilerop.CachingCompiler object>\n",
      "   2786                 \n",
      "   2787                 self.last_execution_succeeded = not has_raised\n",
      "   2788                 self.last_execution_result = result\n",
      "   2789 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-0017af1c5de4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n",
      "   2897         try:\n",
      "   2898             for i, node in enumerate(to_run_exec):\n",
      "   2899                 mod = ast.Module([node])\n",
      "   2900                 code = compiler(mod, cell_name, \"exec\")\n",
      "-> 2901                 if self.run_code(code, result):\n",
      "        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        result = <ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>\n",
      "   2902                     return True\n",
      "   2903 \n",
      "   2904             for i, node in enumerate(to_run_interactive):\n",
      "   2905                 mod = ast.Interactive([node])\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2956         outflag = True  # happens in more places, so it's easier as default\n",
      "   2957         try:\n",
      "   2958             try:\n",
      "   2959                 self.hooks.pre_run_code_hook()\n",
      "   2960                 #rprint('Running code', repr(code_obj)) # dbg\n",
      "-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "        code_obj = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "   2962             finally:\n",
      "   2963                 # Reset our crash handler in place\n",
      "   2964                 sys.excepthook = old_excepthook\n",
      "   2965         except SystemExit as e:\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\<ipython-input-4-0017af1c5de4> in <module>()\n",
      "      1 y_labels = np.unique(y_train)\n",
      "      2 score_dict = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='weighted'),\n",
      "      3              'Log_Loss': make_scorer(log_loss,normalize=True,greater_is_better=False, needs_proba=True)} \n",
      "      4 mlp_bench.runBenchmarkOnLoaded(X_train, y_train,  prio_score='Log_Loss', folds=3, iters=30, randomized=True,\n",
      "      5                                     verbosity=3, print_shapes=True,\n",
      "----> 6                                scoring=score_dict)\n",
      "      7 rootDir = '''D:/PROGRAMMING_PROJS/FoodMachineLearning/FoodMLrepo/FoodML/foodml_src/'''\n",
      "      8 mlp_bench.saveToPickles(rootDir,'randomized_results_much_more')\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmarkOnLoaded(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    207                                                                                             model)\n",
      "    208         return default_model_results, model\n",
      "    209 \n",
      "    210     def fitModels(self, X, y, models):\n",
      "    211         for model_name in models:\n",
      "--> 212             models[model_name].fit(X, y)\n",
      "    213 \n",
      "    214     def runBenchmarkOnLoaded(self, X_train, y_train, prio_score, folds=4, iters=20, randomized=True,\n",
      "    215                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    216         self.runBenchmark(X_train, y_train, self.model_names, self.models,\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmark(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, model_names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], model_params=[{'C': <scipy.stats._distn_infrastructure.rv_frozen object>, 'class_weight': ['balanced', None], 'penalty': ['l2'], 'solver': ['newton-cg', 'saga', 'liblinear'], 'tol': <scipy.stats._distn_infrastructure.rv_frozen object>}, {'max_depth': array([  5,  10,  15,  20,  25,  30,  35,  40,  ...,  65,\n",
      "        70,  75,  80,  85,  90,  95, 100]), 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [10, 50, 150, 200, 250, 125, 75], 'n_estimators': [100, 150, 200, 250, 300, 350]}, {'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, {'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'n_neighbors': [3, 4, 5, 6, 7, 8], 'weights': ['uniform', 'distance']}, {'activation': ['relu', 'identity', 'tanh', 'logistic'], 'alpha': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0..., 0.0495, 0.0496,\n",
      "       0.0497, 0.0498, 0.0499]), 'hidden_layer_sizes': [(100,), (100, 100), (100, 100, 50), (200, 50), (200, 50, 50), (200, 50, 50, 50)], 'solver': ['adam', 'sgd', 'lbfgs']}], transformators={'V001_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V001_PCA_70': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_85': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_90': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])}, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    219 \n",
      "    220     def runBenchmark(self, X_train, y_train, model_names, models, model_params, transformators, prio_score,\n",
      "    221                      folds=4, iters=20, randomized=True,\n",
      "    222                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    223         '''search best parameters for set of models'''\n",
      "--> 224 \n",
      "        transf_name = 'V01_PCA_80'\n",
      "        transformer = Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])\n",
      "        transformators.items = <built-in method items of dict object>\n",
      "    225         #models are not included in pipelines with transformators,\n",
      "    226         #because we want to avoid waiting for the same transformator to fit multiple times to the same dataset\n",
      "    227         for transf_name, transformer in transformators.items():\n",
      "    228             X_transf = transformer.transform(X_train)\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in findBestParams(self=<classification_module.ModelsBenchmark object>, X_train=array([[ 0.71989925, -0.78191795, -0.99183779, ....  0.22929229,\n",
      "         0.19763274, -0.31561387]]), y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], params={'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, transf_postfix='V01_PCA_80', prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3)\n",
      "    150                                                    scoring=scoring, n_jobs=n_jobs,\n",
      "    151                                                    verbose=verbosity, cv=folds, refit=prio_score)\n",
      "    152                 else:\n",
      "    153                     model_scanner = GridSearchCV(model, params, scoring=scoring,\n",
      "    154                                              n_jobs=n_jobs, verbose=verbosity, cv=folds, refit=prio_score)\n",
      "--> 155 \n",
      "        model_scanner.fit = <bound method BaseSearchCV.fit of RandomizedSear...oba=True, normalize=True)},\n",
      "          verbose=3)>\n",
      "        X_train = array([[ 0.71989925, -0.78191795, -0.99183779, ....  0.22929229,\n",
      "         0.19763274, -0.31561387]])\n",
      "        y_train = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "    156                 #get search results and store them\n",
      "    157                 model_scanner.fit(X_train, y_train)\n",
      "    158                 model_info = \\\n",
      "    159                     model_scanner.cv_results_, model_scanner.best_params_, \\\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n",
      "  ...roba=True, normalize=True)},\n",
      "          verbose=3), X=array([[ 0.71989925, -0.78191795, -0.99183779, ....  0.22929229,\n",
      "         0.19763274, -0.31561387]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, groups=None, **fit_params={})\n",
      "    634                                   return_train_score=self.return_train_score,\n",
      "    635                                   return_n_test_samples=True,\n",
      "    636                                   return_times=True, return_parameters=False,\n",
      "    637                                   error_score=self.error_score)\n",
      "    638           for parameters, (train, test) in product(candidate_params,\n",
      "--> 639                                                    cv.split(X, y, groups)))\n",
      "        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n",
      "        X = array([[ 0.71989925, -0.78191795, -0.99183779, ....  0.22929229,\n",
      "         0.19763274, -0.31561387]])\n",
      "        y = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "        groups = None\n",
      "    640 \n",
      "    641         # if one choose to see train score, \"out\" will contain train score info\n",
      "    642         if self.return_train_score:\n",
      "    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n",
      "    784             if pre_dispatch == \"all\" or n_jobs == 1:\n",
      "    785                 # The iterable was consumed all at once by the above for loop.\n",
      "    786                 # No need to wait for async callbacks to trigger to\n",
      "    787                 # consumption.\n",
      "    788                 self._iterating = False\n",
      "--> 789             self.retrieve()\n",
      "        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n",
      "    790             # Make sure that we get a last message telling us we are done\n",
      "    791             elapsed_time = time.time() - self._start_time\n",
      "    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n",
      "    793                         (len(self._output), len(self._output),\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                         Fri Oct  5 04:25:36 2018\n",
      "PID: 18428 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.71989925, -0.78191795, -0.99183779, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': None, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.84333784, -0.18074621,  1.38814614, ... 0.22929229,\n",
      "          0.19763274, -0.31561387]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.84333783, -0.18074621,  1.3881462 , ....        0.19763274, -0.31561387]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V01_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V01_PCA_80...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V01_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  5.3min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V01_PCA_80...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for LogisticRegression_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   15.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V01_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for RandomForestClassifier_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V01_PCA_5components...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTreeClassifier_V01_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   39.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V01_PCA_5components...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.9min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V01_PCA_5components...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 79\n",
      "Finding best parameters for LogisticRegression_V09_PCA_90:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V09_PCA_90...\n",
      "\n",
      "Finding best parameters for RandomForestClassifier_V09_PCA_90:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V09_PCA_90...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V09_PCA_90:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DecisionTreeClassifier_V09_PCA_90...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V09_PCA_90:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V09_PCA_90...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V09_PCA_90:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V09_PCA_90...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 38\n",
      "Finding best parameters for LogisticRegression_V09_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V09_PCA_80...\n",
      "\n",
      "Finding best parameters for RandomForestClassifier_V09_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V09_PCA_80...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V09_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Error occured!\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 790, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 201, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n",
      "    raise TransportableException(text, e_type)\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 05:10:04 2018\n",
      "PID: 13424 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , ....        0.08829915,  0.137329  ]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 05:10:04 2018\n",
      "PID: 13424 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , ....        0.08829915,  0.137329  ]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py\", line 155, in findBestParams\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError\n",
      "___________________________________________________________________________\n",
      "Multiprocessing exception:\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n",
      "    188         sys.exit(msg)\n",
      "    189     main_globals = sys.modules[\"__main__\"].__dict__\n",
      "    190     if alter_argv:\n",
      "    191         sys.argv[0] = mod_spec.origin\n",
      "    192     return _run_code(code, main_globals, None,\n",
      "--> 193                      \"__main__\", mod_spec)\n",
      "        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n",
      "    194 \n",
      "    195 def run_module(mod_name, init_globals=None,\n",
      "    196                run_name=None, alter_sys=False):\n",
      "    197     \"\"\"Execute a module's code without importing it\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n",
      "     80                        __cached__ = cached,\n",
      "     81                        __doc__ = None,\n",
      "     82                        __loader__ = loader,\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "        code = <code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n",
      "        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n",
      "     86     return run_globals\n",
      "     87 \n",
      "     88 def _run_module_code(code, init_globals=None,\n",
      "     89                     mod_name=None, mod_spec=None,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n",
      "     11     # This is added back by InteractiveShellApp.init_path()\n",
      "     12     if sys.path[0] == '':\n",
      "     13         del sys.path[0]\n",
      "     14 \n",
      "     15     from ipykernel import kernelapp as app\n",
      "---> 16     app.launch_new_instance()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n",
      "    653 \n",
      "    654         If a global instance already exists, this reinitializes and starts it\n",
      "    655         \"\"\"\n",
      "    656         app = cls.instance(**kwargs)\n",
      "    657         app.initialize(argv)\n",
      "--> 658         app.start()\n",
      "        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n",
      "    659 \n",
      "    660 #-----------------------------------------------------------------------------\n",
      "    661 # utility functions, for convenience\n",
      "    662 #-----------------------------------------------------------------------------\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n",
      "    481         if self.poller is not None:\n",
      "    482             self.poller.start()\n",
      "    483         self.kernel.start()\n",
      "    484         self.io_loop = ioloop.IOLoop.current()\n",
      "    485         try:\n",
      "--> 486             self.io_loop.start()\n",
      "        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "    487         except KeyboardInterrupt:\n",
      "    488             pass\n",
      "    489 \n",
      "    490 launch_new_instance = IPKernelApp.launch_instance\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n",
      "    127         except (RuntimeError, AssertionError):\n",
      "    128             old_loop = None\n",
      "    129         try:\n",
      "    130             self._setup_logging()\n",
      "    131             asyncio.set_event_loop(self.asyncio_loop)\n",
      "--> 132             self.asyncio_loop.run_forever()\n",
      "        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n",
      "    133         finally:\n",
      "    134             asyncio.set_event_loop(old_loop)\n",
      "    135 \n",
      "    136     def stop(self):\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n",
      "    418                                    finalizer=self._asyncgen_finalizer_hook)\n",
      "    419         try:\n",
      "    420             events._set_running_loop(self)\n",
      "    421             while True:\n",
      "--> 422                 self._run_once()\n",
      "        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n",
      "    423                 if self._stopping:\n",
      "    424                     break\n",
      "    425         finally:\n",
      "    426             self._stopping = False\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "   1429                         logger.warning('Executing %s took %.3f seconds',\n",
      "   1430                                        _format_handle(handle), dt)\n",
      "   1431                 finally:\n",
      "   1432                     self._current_handle = None\n",
      "   1433             else:\n",
      "-> 1434                 handle._run()\n",
      "        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>>\n",
      "   1435         handle = None  # Needed to break cycles when an exception occurs.\n",
      "   1436 \n",
      "   1437     def _set_coroutine_wrapper(self, enabled):\n",
      "   1438         try:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>)\n",
      "    140             self._callback = None\n",
      "    141             self._args = None\n",
      "    142 \n",
      "    143     def _run(self):\n",
      "    144         try:\n",
      "--> 145             self._callback(*self._args)\n",
      "        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>),)\n",
      "    146         except Exception as exc:\n",
      "    147             cb = _format_callback_source(self._callback, self._args)\n",
      "    148             msg = 'Exception in callback {}'.format(cb)\n",
      "    149             context = {\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>))\n",
      "    753         \"\"\"Runs a callback with error handling.\n",
      "    754 \n",
      "    755         For use in subclasses.\n",
      "    756         \"\"\"\n",
      "    757         try:\n",
      "--> 758             ret = callback()\n",
      "        ret = undefined\n",
      "        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>)\n",
      "    759             if ret is not None:\n",
      "    760                 from tornado import gen\n",
      "    761                 # Functions that return Futures typically swallow all\n",
      "    762                 # exceptions and store them in the Future.  If a Future\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ()\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n",
      "    531             return\n",
      "    532 \n",
      "    533         if state & self.socket.events:\n",
      "    534             # events still exist that haven't been processed\n",
      "    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n",
      "--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "    537 \n",
      "    538     def _init_io_state(self):\n",
      "    539         \"\"\"initialize the ioloop event handler\"\"\"\n",
      "    540         with stack_context.NullContext():\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n",
      "    445             return\n",
      "    446         zmq_events = self.socket.EVENTS\n",
      "    447         try:\n",
      "    448             # dispatch events:\n",
      "    449             if zmq_events & zmq.POLLIN and self.receiving():\n",
      "--> 450                 self._handle_recv()\n",
      "        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "    451                 if not self.socket:\n",
      "    452                     return\n",
      "    453             if zmq_events & zmq.POLLOUT and self.sending():\n",
      "    454                 self._handle_send()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n",
      "    475             else:\n",
      "    476                 raise\n",
      "    477         else:\n",
      "    478             if self._recv_callback:\n",
      "    479                 callback = self._recv_callback\n",
      "--> 480                 self._run_callback(callback, msg)\n",
      "        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    481         \n",
      "    482 \n",
      "    483     def _handle_send(self):\n",
      "    484         \"\"\"Handle a send event.\"\"\"\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    427         close our socket.\"\"\"\n",
      "    428         try:\n",
      "    429             # Use a NullContext to ensure that all StackContexts are run\n",
      "    430             # inside our blanket exception handler rather than outside.\n",
      "    431             with stack_context.NullContext():\n",
      "--> 432                 callback(*args, **kwargs)\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    433         except:\n",
      "    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n",
      "    435                           exc_info=True)\n",
      "    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n",
      "    278         if self.control_stream:\n",
      "    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n",
      "    280 \n",
      "    281         def make_dispatcher(stream):\n",
      "    282             def dispatcher(msg):\n",
      "--> 283                 return self.dispatch_shell(stream, msg)\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    284             return dispatcher\n",
      "    285 \n",
      "    286         for s in self.shell_streams:\n",
      "    287             s.on_recv(make_dispatcher(s), copy=False)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n",
      "    229         else:\n",
      "    230             self.log.debug(\"%s: %s\", msg_type, msg)\n",
      "    231             self.pre_handler_hook()\n",
      "    232             try:\n",
      "--> 233                 handler(stream, idents, msg)\n",
      "        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n",
      "        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n",
      "        idents = [b'ea4df705f78d4ef197094a57a76c451a']\n",
      "        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}}\n",
      "    234             except Exception:\n",
      "    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "    236             finally:\n",
      "    237                 self.post_handler_hook()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'ea4df705f78d4ef197094a57a76c451a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    394         if not silent:\n",
      "    395             self.execution_count += 1\n",
      "    396             self._publish_execute_input(code, parent, self.execution_count)\n",
      "    397 \n",
      "    398         reply_content = self.do_execute(code, silent, store_history,\n",
      "--> 399                                         user_expressions, allow_stdin)\n",
      "        user_expressions = {}\n",
      "        allow_stdin = True\n",
      "    400 \n",
      "    401         # Flush output before sending the reply.\n",
      "    402         sys.stdout.flush()\n",
      "    403         sys.stderr.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n",
      "    203 \n",
      "    204         self._forward_input(allow_stdin)\n",
      "    205 \n",
      "    206         reply_content = {}\n",
      "    207         try:\n",
      "--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "        res = undefined\n",
      "        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "    209         finally:\n",
      "    210             self._restore_input()\n",
      "    211 \n",
      "    212         if res.error_before_exec is not None:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",), **kwargs={'silent': False, 'store_history': True})\n",
      "    532             )\n",
      "    533         self.payload_manager.write_payload(payload)\n",
      "    534 \n",
      "    535     def run_cell(self, *args, **kwargs):\n",
      "    536         self._last_traceback = None\n",
      "--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        args = (\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",)\n",
      "        kwargs = {'silent': False, 'store_history': True}\n",
      "    538 \n",
      "    539     def _showtraceback(self, etype, evalue, stb):\n",
      "    540         # try to preserve ordering of tracebacks and print statements\n",
      "    541         sys.stdout.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2657         -------\n",
      "   2658         result : :class:`ExecutionResult`\n",
      "   2659         \"\"\"\n",
      "   2660         try:\n",
      "   2661             result = self._run_cell(\n",
      "-> 2662                 raw_cell, store_history, silent, shell_futures)\n",
      "        raw_cell = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "        shell_futures = True\n",
      "   2663         finally:\n",
      "   2664             self.events.trigger('post_execute')\n",
      "   2665             if not silent:\n",
      "   2666                 self.events.trigger('post_run_cell', result)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2780                 self.displayhook.exec_result = result\n",
      "   2781 \n",
      "   2782                 # Execute the user code\n",
      "   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n",
      "   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n",
      "-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n",
      "        interactivity = 'last_expr'\n",
      "        compiler = <IPython.core.compilerop.CachingCompiler object>\n",
      "   2786                 \n",
      "   2787                 self.last_execution_succeeded = not has_raised\n",
      "   2788                 self.last_execution_result = result\n",
      "   2789 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-0017af1c5de4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n",
      "   2897         try:\n",
      "   2898             for i, node in enumerate(to_run_exec):\n",
      "   2899                 mod = ast.Module([node])\n",
      "   2900                 code = compiler(mod, cell_name, \"exec\")\n",
      "-> 2901                 if self.run_code(code, result):\n",
      "        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        result = <ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>\n",
      "   2902                     return True\n",
      "   2903 \n",
      "   2904             for i, node in enumerate(to_run_interactive):\n",
      "   2905                 mod = ast.Interactive([node])\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2956         outflag = True  # happens in more places, so it's easier as default\n",
      "   2957         try:\n",
      "   2958             try:\n",
      "   2959                 self.hooks.pre_run_code_hook()\n",
      "   2960                 #rprint('Running code', repr(code_obj)) # dbg\n",
      "-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "        code_obj = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "   2962             finally:\n",
      "   2963                 # Reset our crash handler in place\n",
      "   2964                 sys.excepthook = old_excepthook\n",
      "   2965         except SystemExit as e:\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\<ipython-input-4-0017af1c5de4> in <module>()\n",
      "      1 y_labels = np.unique(y_train)\n",
      "      2 score_dict = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='weighted'),\n",
      "      3              'Log_Loss': make_scorer(log_loss,normalize=True,greater_is_better=False, needs_proba=True)} \n",
      "      4 mlp_bench.runBenchmarkOnLoaded(X_train, y_train,  prio_score='Log_Loss', folds=3, iters=30, randomized=True,\n",
      "      5                                     verbosity=3, print_shapes=True,\n",
      "----> 6                                scoring=score_dict)\n",
      "      7 rootDir = '''D:/PROGRAMMING_PROJS/FoodMachineLearning/FoodMLrepo/FoodML/foodml_src/'''\n",
      "      8 mlp_bench.saveToPickles(rootDir,'randomized_results_much_more')\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmarkOnLoaded(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    207                                                                                             model)\n",
      "    208         return default_model_results, model\n",
      "    209 \n",
      "    210     def fitModels(self, X, y, models):\n",
      "    211         for model_name in models:\n",
      "--> 212             models[model_name].fit(X, y)\n",
      "    213 \n",
      "    214     def runBenchmarkOnLoaded(self, X_train, y_train, prio_score, folds=4, iters=20, randomized=True,\n",
      "    215                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    216         self.runBenchmark(X_train, y_train, self.model_names, self.models,\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmark(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, model_names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], model_params=[{'C': <scipy.stats._distn_infrastructure.rv_frozen object>, 'class_weight': ['balanced', None], 'penalty': ['l2'], 'solver': ['newton-cg', 'saga', 'liblinear'], 'tol': <scipy.stats._distn_infrastructure.rv_frozen object>}, {'max_depth': array([  5,  10,  15,  20,  25,  30,  35,  40,  ...,  65,\n",
      "        70,  75,  80,  85,  90,  95, 100]), 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [10, 50, 150, 200, 250, 125, 75], 'n_estimators': [100, 150, 200, 250, 300, 350]}, {'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, {'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'n_neighbors': [3, 4, 5, 6, 7, 8], 'weights': ['uniform', 'distance']}, {'activation': ['relu', 'identity', 'tanh', 'logistic'], 'alpha': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0..., 0.0495, 0.0496,\n",
      "       0.0497, 0.0498, 0.0499]), 'hidden_layer_sizes': [(100,), (100, 100), (100, 100, 50), (200, 50), (200, 50, 50), (200, 50, 50, 50)], 'solver': ['adam', 'sgd', 'lbfgs']}], transformators={'V001_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V001_PCA_70': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_85': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_90': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])}, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    219 \n",
      "    220     def runBenchmark(self, X_train, y_train, model_names, models, model_params, transformators, prio_score,\n",
      "    221                      folds=4, iters=20, randomized=True,\n",
      "    222                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    223         '''search best parameters for set of models'''\n",
      "--> 224 \n",
      "        transf_name = 'V09_PCA_80'\n",
      "        transformer = Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])\n",
      "        transformators.items = <built-in method items of dict object>\n",
      "    225         #models are not included in pipelines with transformators,\n",
      "    226         #because we want to avoid waiting for the same transformator to fit multiple times to the same dataset\n",
      "    227         for transf_name, transformer in transformators.items():\n",
      "    228             X_transf = transformer.transform(X_train)\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in findBestParams(self=<classification_module.ModelsBenchmark object>, X_train=array([[ 0.64428542, -0.73095584, -1.13630558, ....  0.04064016,\n",
      "         0.08829915,  0.13732899]]), y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], params={'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, transf_postfix='V09_PCA_80', prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3)\n",
      "    150                                                    scoring=scoring, n_jobs=n_jobs,\n",
      "    151                                                    verbose=verbosity, cv=folds, refit=prio_score)\n",
      "    152                 else:\n",
      "    153                     model_scanner = GridSearchCV(model, params, scoring=scoring,\n",
      "    154                                              n_jobs=n_jobs, verbose=verbosity, cv=folds, refit=prio_score)\n",
      "--> 155 \n",
      "        model_scanner.fit = <bound method BaseSearchCV.fit of RandomizedSear...oba=True, normalize=True)},\n",
      "          verbose=3)>\n",
      "        X_train = array([[ 0.64428542, -0.73095584, -1.13630558, ....  0.04064016,\n",
      "         0.08829915,  0.13732899]])\n",
      "        y_train = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "    156                 #get search results and store them\n",
      "    157                 model_scanner.fit(X_train, y_train)\n",
      "    158                 model_info = \\\n",
      "    159                     model_scanner.cv_results_, model_scanner.best_params_, \\\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n",
      "  ...roba=True, normalize=True)},\n",
      "          verbose=3), X=array([[ 0.64428542, -0.73095584, -1.13630558, ....  0.04064016,\n",
      "         0.08829915,  0.13732899]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, groups=None, **fit_params={})\n",
      "    634                                   return_train_score=self.return_train_score,\n",
      "    635                                   return_n_test_samples=True,\n",
      "    636                                   return_times=True, return_parameters=False,\n",
      "    637                                   error_score=self.error_score)\n",
      "    638           for parameters, (train, test) in product(candidate_params,\n",
      "--> 639                                                    cv.split(X, y, groups)))\n",
      "        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n",
      "        X = array([[ 0.64428542, -0.73095584, -1.13630558, ....  0.04064016,\n",
      "         0.08829915,  0.13732899]])\n",
      "        y = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "        groups = None\n",
      "    640 \n",
      "    641         # if one choose to see train score, \"out\" will contain train score info\n",
      "    642         if self.return_train_score:\n",
      "    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n",
      "    784             if pre_dispatch == \"all\" or n_jobs == 1:\n",
      "    785                 # The iterable was consumed all at once by the above for loop.\n",
      "    786                 # No need to wait for async callbacks to trigger to\n",
      "    787                 # consumption.\n",
      "    788                 self._iterating = False\n",
      "--> 789             self.retrieve()\n",
      "        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n",
      "    790             # Make sure that we get a last message telling us we are done\n",
      "    791             elapsed_time = time.time() - self._start_time\n",
      "    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n",
      "    793                         (len(self._output), len(self._output),\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                         Fri Oct  5 05:10:04 2018\n",
      "PID: 13424 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[ 0.64428542, -0.73095584, -1.13630558, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=memmap([[-0.73433723, -0.13099279,  1.46872225, ... 0.04064016,\n",
      "          0.08829915,  0.13732899]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , ....        0.08829915,  0.137329  ]], dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V09_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V09_PCA_80...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V09_PCA_80:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.5min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V09_PCA_80...\n",
      "\n",
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for LogisticRegression_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression_V09_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for RandomForestClassifier_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RandomForestClassifier_V09_PCA_5components...\n",
      "\n",
      "Finding best parameters for DecisionTreeClassifier_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Error occured!\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 790, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 201, in fit\n",
      "    % self.min_samples_split)\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n",
      "    raise TransportableException(text, e_type)\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 05:20:50 2018\n",
      "PID: 20468 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , -... -1.9802066 ,  0.01082953]],\n",
      "      dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 699, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\multiprocessing\\pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n",
      "___________________________________________________________________________\n",
      "ValueError                                         Fri Oct  5 05:20:50 2018\n",
      "PID: 20468 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , -... -1.9802066 ,  0.01082953]],\n",
      "      dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py\", line 155, in findBestParams\n",
      "  File \"C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.externals.joblib.my_exceptions.JoblibValueError: JoblibValueError\n",
      "___________________________________________________________________________\n",
      "Multiprocessing exception:\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n",
      "    188         sys.exit(msg)\n",
      "    189     main_globals = sys.modules[\"__main__\"].__dict__\n",
      "    190     if alter_argv:\n",
      "    191         sys.argv[0] = mod_spec.origin\n",
      "    192     return _run_code(code, main_globals, None,\n",
      "--> 193                      \"__main__\", mod_spec)\n",
      "        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n",
      "    194 \n",
      "    195 def run_module(mod_name, init_globals=None,\n",
      "    196                run_name=None, alter_sys=False):\n",
      "    197     \"\"\"Execute a module's code without importing it\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n",
      "     80                        __cached__ = cached,\n",
      "     81                        __doc__ = None,\n",
      "     82                        __loader__ = loader,\n",
      "     83                        __package__ = pkg_name,\n",
      "     84                        __spec__ = mod_spec)\n",
      "---> 85     exec(code, run_globals)\n",
      "        code = <code object <module> at 0x000001C6CD698AE0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n",
      "        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lenv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...nv\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n",
      "     86     return run_globals\n",
      "     87 \n",
      "     88 def _run_module_code(code, init_globals=None,\n",
      "     89                     mod_name=None, mod_spec=None,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n",
      "     11     # This is added back by InteractiveShellApp.init_path()\n",
      "     12     if sys.path[0] == '':\n",
      "     13         del sys.path[0]\n",
      "     14 \n",
      "     15     from ipykernel import kernelapp as app\n",
      "---> 16     app.launch_new_instance()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n",
      "    653 \n",
      "    654         If a global instance already exists, this reinitializes and starts it\n",
      "    655         \"\"\"\n",
      "    656         app = cls.instance(**kwargs)\n",
      "    657         app.initialize(argv)\n",
      "--> 658         app.start()\n",
      "        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n",
      "    659 \n",
      "    660 #-----------------------------------------------------------------------------\n",
      "    661 # utility functions, for convenience\n",
      "    662 #-----------------------------------------------------------------------------\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n",
      "    481         if self.poller is not None:\n",
      "    482             self.poller.start()\n",
      "    483         self.kernel.start()\n",
      "    484         self.io_loop = ioloop.IOLoop.current()\n",
      "    485         try:\n",
      "--> 486             self.io_loop.start()\n",
      "        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "    487         except KeyboardInterrupt:\n",
      "    488             pass\n",
      "    489 \n",
      "    490 launch_new_instance = IPKernelApp.launch_instance\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n",
      "    127         except (RuntimeError, AssertionError):\n",
      "    128             old_loop = None\n",
      "    129         try:\n",
      "    130             self._setup_logging()\n",
      "    131             asyncio.set_event_loop(self.asyncio_loop)\n",
      "--> 132             self.asyncio_loop.run_forever()\n",
      "        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n",
      "    133         finally:\n",
      "    134             asyncio.set_event_loop(old_loop)\n",
      "    135 \n",
      "    136     def stop(self):\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n",
      "    418                                    finalizer=self._asyncgen_finalizer_hook)\n",
      "    419         try:\n",
      "    420             events._set_running_loop(self)\n",
      "    421             while True:\n",
      "--> 422                 self._run_once()\n",
      "        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n",
      "    423                 if self._stopping:\n",
      "    424                     break\n",
      "    425         finally:\n",
      "    426             self._stopping = False\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n",
      "   1429                         logger.warning('Executing %s took %.3f seconds',\n",
      "   1430                                        _format_handle(handle), dt)\n",
      "   1431                 finally:\n",
      "   1432                     self._current_handle = None\n",
      "   1433             else:\n",
      "-> 1434                 handle._run()\n",
      "        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>>\n",
      "   1435         handle = None  # Needed to break cycles when an exception occurs.\n",
      "   1436 \n",
      "   1437     def _set_coroutine_wrapper(self, enabled):\n",
      "   1438         try:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...01C6D50419D8>))>)\n",
      "    140             self._callback = None\n",
      "    141             self._args = None\n",
      "    142 \n",
      "    143     def _run(self):\n",
      "    144         try:\n",
      "--> 145             self._callback(*self._args)\n",
      "        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n",
      "        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>),)\n",
      "    146         except Exception as exc:\n",
      "    147             cb = _format_callback_source(self._callback, self._args)\n",
      "    148             msg = 'Exception in callback {}'.format(cb)\n",
      "    149             context = {\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>))\n",
      "    753         \"\"\"Runs a callback with error handling.\n",
      "    754 \n",
      "    755         For use in subclasses.\n",
      "    756         \"\"\"\n",
      "    757         try:\n",
      "--> 758             ret = callback()\n",
      "        ret = undefined\n",
      "        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C6D50419D8>)\n",
      "    759             if ret is not None:\n",
      "    760                 from tornado import gen\n",
      "    761                 # Functions that return Futures typically swallow all\n",
      "    762                 # exceptions and store them in the Future.  If a Future\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ()\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n",
      "    531             return\n",
      "    532 \n",
      "    533         if state & self.socket.events:\n",
      "    534             # events still exist that haven't been processed\n",
      "    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n",
      "--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "    537 \n",
      "    538     def _init_io_state(self):\n",
      "    539         \"\"\"initialize the ioloop event handler\"\"\"\n",
      "    540         with stack_context.NullContext():\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n",
      "    445             return\n",
      "    446         zmq_events = self.socket.EVENTS\n",
      "    447         try:\n",
      "    448             # dispatch events:\n",
      "    449             if zmq_events & zmq.POLLIN and self.receiving():\n",
      "--> 450                 self._handle_recv()\n",
      "        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "    451                 if not self.socket:\n",
      "    452                     return\n",
      "    453             if zmq_events & zmq.POLLOUT and self.sending():\n",
      "    454                 self._handle_send()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n",
      "    475             else:\n",
      "    476                 raise\n",
      "    477         else:\n",
      "    478             if self._recv_callback:\n",
      "    479                 callback = self._recv_callback\n",
      "--> 480                 self._run_callback(callback, msg)\n",
      "        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    481         \n",
      "    482 \n",
      "    483     def _handle_send(self):\n",
      "    484         \"\"\"Handle a send event.\"\"\"\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    427         close our socket.\"\"\"\n",
      "    428         try:\n",
      "    429             # Use a NullContext to ensure that all StackContexts are run\n",
      "    430             # inside our blanket exception handler rather than outside.\n",
      "    431             with stack_context.NullContext():\n",
      "--> 432                 callback(*args, **kwargs)\n",
      "        callback = <function wrap.<locals>.null_wrapper>\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    433         except:\n",
      "    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n",
      "    435                           exc_info=True)\n",
      "    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n",
      "    295         # Fast path when there are no active contexts.\n",
      "    296         def null_wrapper(*args, **kwargs):\n",
      "    297             try:\n",
      "    298                 current_state = _state.contexts\n",
      "    299                 _state.contexts = cap_contexts[0]\n",
      "--> 300                 return fn(*args, **kwargs)\n",
      "        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n",
      "        kwargs = {}\n",
      "    301             finally:\n",
      "    302                 _state.contexts = current_state\n",
      "    303         null_wrapper._wrapped = True\n",
      "    304         return null_wrapper\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n",
      "    278         if self.control_stream:\n",
      "    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n",
      "    280 \n",
      "    281         def make_dispatcher(stream):\n",
      "    282             def dispatcher(msg):\n",
      "--> 283                 return self.dispatch_shell(stream, msg)\n",
      "        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n",
      "    284             return dispatcher\n",
      "    285 \n",
      "    286         for s in self.shell_streams:\n",
      "    287             s.on_recv(make_dispatcher(s), copy=False)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n",
      "    229         else:\n",
      "    230             self.log.debug(\"%s: %s\", msg_type, msg)\n",
      "    231             self.pre_handler_hook()\n",
      "    232             try:\n",
      "--> 233                 handler(stream, idents, msg)\n",
      "        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n",
      "        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n",
      "        idents = [b'ea4df705f78d4ef197094a57a76c451a']\n",
      "        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}}\n",
      "    234             except Exception:\n",
      "    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n",
      "    236             finally:\n",
      "    237                 self.post_handler_hook()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'ea4df705f78d4ef197094a57a76c451a'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 10, 5, 1, 30, 43, 462328, tzinfo=tzutc()), 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'session': 'ea4df705f78d4ef197094a57a76c451a', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '5b3a3c3e20b94c3a8f55dfc62c6ac062', 'msg_type': 'execute_request', 'parent_header': {}})\n",
      "    394         if not silent:\n",
      "    395             self.execution_count += 1\n",
      "    396             self._publish_execute_input(code, parent, self.execution_count)\n",
      "    397 \n",
      "    398         reply_content = self.do_execute(code, silent, store_history,\n",
      "--> 399                                         user_expressions, allow_stdin)\n",
      "        user_expressions = {}\n",
      "        allow_stdin = True\n",
      "    400 \n",
      "    401         # Flush output before sending the reply.\n",
      "    402         sys.stdout.flush()\n",
      "    403         sys.stderr.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n",
      "    203 \n",
      "    204         self._forward_input(allow_stdin)\n",
      "    205 \n",
      "    206         reply_content = {}\n",
      "    207         try:\n",
      "--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "        res = undefined\n",
      "        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "    209         finally:\n",
      "    210             self._restore_input()\n",
      "    211 \n",
      "    212         if res.error_before_exec is not None:\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",), **kwargs={'silent': False, 'store_history': True})\n",
      "    532             )\n",
      "    533         self.payload_manager.write_payload(payload)\n",
      "    534 \n",
      "    535     def run_cell(self, *args, **kwargs):\n",
      "    536         self._last_traceback = None\n",
      "--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        args = (\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\",)\n",
      "        kwargs = {'silent': False, 'store_history': True}\n",
      "    538 \n",
      "    539     def _showtraceback(self, etype, evalue, stb):\n",
      "    540         # try to preserve ordering of tracebacks and print statements\n",
      "    541         sys.stdout.flush()\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2657         -------\n",
      "   2658         result : :class:`ExecutionResult`\n",
      "   2659         \"\"\"\n",
      "   2660         try:\n",
      "   2661             result = self._run_cell(\n",
      "-> 2662                 raw_cell, store_history, silent, shell_futures)\n",
      "        raw_cell = \"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\"\n",
      "        store_history = True\n",
      "        silent = False\n",
      "        shell_futures = True\n",
      "   2663         finally:\n",
      "   2664             self.events.trigger('post_execute')\n",
      "   2665             if not silent:\n",
      "   2666                 self.events.trigger('post_run_cell', result)\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"y_labels = np.unique(y_train)\\nscore_dict = {'Acc...ToPickles(rootDir,'randomized_results_much_more')\", store_history=True, silent=False, shell_futures=True)\n",
      "   2780                 self.displayhook.exec_result = result\n",
      "   2781 \n",
      "   2782                 # Execute the user code\n",
      "   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n",
      "   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n",
      "-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n",
      "        interactivity = 'last_expr'\n",
      "        compiler = <IPython.core.compilerop.CachingCompiler object>\n",
      "   2786                 \n",
      "   2787                 self.last_execution_succeeded = not has_raised\n",
      "   2788                 self.last_execution_result = result\n",
      "   2789 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-0017af1c5de4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n",
      "   2897         try:\n",
      "   2898             for i, node in enumerate(to_run_exec):\n",
      "   2899                 mod = ast.Module([node])\n",
      "   2900                 code = compiler(mod, cell_name, \"exec\")\n",
      "-> 2901                 if self.run_code(code, result):\n",
      "        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n",
      "        code = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        result = <ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>\n",
      "   2902                     return True\n",
      "   2903 \n",
      "   2904             for i, node in enumerate(to_run_interactive):\n",
      "   2905                 mod = ast.Interactive([node])\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>, result=<ExecutionResult object at 1c6cfa4f978, executio...rue silent=False shell_futures=True> result=None>)\n",
      "   2956         outflag = True  # happens in more places, so it's easier as default\n",
      "   2957         try:\n",
      "   2958             try:\n",
      "   2959                 self.hooks.pre_run_code_hook()\n",
      "   2960                 #rprint('Running code', repr(code_obj)) # dbg\n",
      "-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "        code_obj = <code object <module> at 0x000001C6D2DA19C0, file \"<ipython-input-4-0017af1c5de4>\", line 4>\n",
      "        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', 'import features_extraction_funcs as feex\\nimport feats_extr_module as feex_module', 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', \"input_path ='''D:/PROGRAMMING_PROJS/FoodMachineL...oodMLrepo/FoodML/dataframes/Features_dataframe'''\", 'import pandas as pd\\nfeatDF = pd.read_pickle(output_path)\\nfeatDF.head()', 'inDF = pd.read_pickle(input_path)\\ninDF.head()', 'print(featDF.shape)\\nprint(inDF.shape)', \"featDF = pd.concat([featDF,inDF['Path']],axis=1)\\nfeatDF.head()\", 'featDF.isna().sum().sort_values(ascending=False)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF.loc[5024,'Path']\", 'featDF = featDF.drop(5024)', 'featDF.isna().sum(axis=1).sort_values(ascending=False)', \"featDF['ProdName'].value_counts()\", \"X_train, y_train, X_val, y_val = feex_module.spl...DF,label_column='ProdName',cols_to_drop=['Path'])\", \"featDF.to_pickle(\\n    '''D:/PROGRAMMING_PROJS/Fo...o/FoodML/dataframes/Features_dataframe_backup''')\", 'dd = pd.DataFrame({A: [1,22,3,4], B: [33,44,525,...1,2,32,4], B1: [33,44,55,1], C1: [44,66,727,88]})', \"dd = pd.DataFrame({'A': [1,22,3,4], 'B': [33,44,...32,4], 'B1': [33,44,55,1], 'C1': [44,66,727,88]})\", \"ee = pd.concat(ee,dd[['A','B']])\\nee.head()\", \"cli = ['A','B']\\nee = pd.concat(ee,dd.loc[:,cli])\\nee.head()\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {4:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...  BREAD  \n",
      "4     BREAD  \n",
      "\n",
      "[5 rows x 16681 columns], 5:    FullSize2D  Height  Width     Ratio ProdName ...PROJS/FoodMachineLearning/FOODM...  BREAD_4.png  , 7:    RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-3  R...hineLearning/FOODM...  \n",
      "\n",
      "[5 rows x 16682 columns], 8: Cluster: 4 cspace: RGB; sortCH1; CH1    1\n",
      "Cluste...                    0\n",
      "Length: 16682, dtype: int64, 9: 5024     30\n",
      "10403     0\n",
      "3464      0\n",
      "3471      0\n",
      "...31      0\n",
      "0         0\n",
      "Length: 10404, dtype: int64, 10: 'D:/PROGRAMMING_PROJS/FoodMachineLearning/FOODMLENV_dataset/PLUM/PLUM_5024.png', 12: 10403    0\n",
      "3454     0\n",
      "3472     0\n",
      "3471     0\n",
      "3470...6931     0\n",
      "0        0\n",
      "Length: 10403, dtype: int64, 13: APPLE          593\n",
      "ORANGE         516\n",
      "ONION     ...0\n",
      "PLUM           249\n",
      "Name: ProdName, dtype: int64, 21:    A1  B1   C1   A    B\n",
      "0   1  33   44   1   33\n",
      "...4\n",
      "2  32  55  727   3  525\n",
      "3   4   1   88   4    1, 24:    A1  B1   C1   A    B   A    B\n",
      "0   1  33   44 ... 3  525   3  525\n",
      "3   4   1   88   4    1   4    1, ...}, ...}\n",
      "   2962             finally:\n",
      "   2963                 # Reset our crash handler in place\n",
      "   2964                 sys.excepthook = old_excepthook\n",
      "   2965         except SystemExit as e:\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\<ipython-input-4-0017af1c5de4> in <module>()\n",
      "      1 y_labels = np.unique(y_train)\n",
      "      2 score_dict = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='weighted'),\n",
      "      3              'Log_Loss': make_scorer(log_loss,normalize=True,greater_is_better=False, needs_proba=True)} \n",
      "      4 mlp_bench.runBenchmarkOnLoaded(X_train, y_train,  prio_score='Log_Loss', folds=3, iters=30, randomized=True,\n",
      "      5                                     verbosity=3, print_shapes=True,\n",
      "----> 6                                scoring=score_dict)\n",
      "      7 rootDir = '''D:/PROGRAMMING_PROJS/FoodMachineLearning/FoodMLrepo/FoodML/foodml_src/'''\n",
      "      8 mlp_bench.saveToPickles(rootDir,'randomized_results_much_more')\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmarkOnLoaded(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    207                                                                                             model)\n",
      "    208         return default_model_results, model\n",
      "    209 \n",
      "    210     def fitModels(self, X, y, models):\n",
      "    211         for model_name in models:\n",
      "--> 212             models[model_name].fit(X, y)\n",
      "    213 \n",
      "    214     def runBenchmarkOnLoaded(self, X_train, y_train, prio_score, folds=4, iters=20, randomized=True,\n",
      "    215                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    216         self.runBenchmark(X_train, y_train, self.model_names, self.models,\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in runBenchmark(self=<classification_module.ModelsBenchmark object>, X_train=       RGB-CH1-0  RGB-CH1-1  RGB-CH1-2  RGB-CH1-...          0.104585  \n",
      "\n",
      "[8322 rows x 16680 columns], y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, model_names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], model_params=[{'C': <scipy.stats._distn_infrastructure.rv_frozen object>, 'class_weight': ['balanced', None], 'penalty': ['l2'], 'solver': ['newton-cg', 'saga', 'liblinear'], 'tol': <scipy.stats._distn_infrastructure.rv_frozen object>}, {'max_depth': array([  5,  10,  15,  20,  25,  30,  35,  40,  ...,  65,\n",
      "        70,  75,  80,  85,  90,  95, 100]), 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [10, 50, 150, 200, 250, 125, 75], 'n_estimators': [100, 150, 200, 250, 300, 350]}, {'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, {'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'n_neighbors': [3, 4, 5, 6, 7, 8], 'weights': ['uniform', 'distance']}, {'activation': ['relu', 'identity', 'tanh', 'logistic'], 'alpha': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0..., 0.0495, 0.0496,\n",
      "       0.0497, 0.0498, 0.0499]), 'hidden_layer_sizes': [(100,), (100, 100), (100, 100, 50), (200, 50), (200, 50, 50), (200, 50, 50, 50)], 'solver': ['adam', 'sgd', 'lbfgs']}], transformators={'V001_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V001_PCA_70': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V01_PCA_85': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_5components': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_80': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))]), 'V09_PCA_90': Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])}, prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3, reset=False, print_shapes=True)\n",
      "    219 \n",
      "    220     def runBenchmark(self, X_train, y_train, model_names, models, model_params, transformators, prio_score,\n",
      "    221                      folds=4, iters=20, randomized=True,\n",
      "    222                      scoring=None, n_jobs=-1, verbosity=0, reset=False, print_shapes=False):\n",
      "    223         '''search best parameters for set of models'''\n",
      "--> 224 \n",
      "        transf_name = 'V09_PCA_5components'\n",
      "        transformer = Pipeline(memory=None,\n",
      "     steps=[('variancethre...ne,\n",
      "  svd_solver='full', tol=0.0, whiten=True))])\n",
      "        transformators.items = <built-in method items of dict object>\n",
      "    225         #models are not included in pipelines with transformators,\n",
      "    226         #because we want to avoid waiting for the same transformator to fit multiple times to the same dataset\n",
      "    227         for transf_name, transformer in transformators.items():\n",
      "    228             X_transf = transformer.transform(X_train)\n",
      "\n",
      "...........................................................................\n",
      "D:\\PROGRAMMING_PROJS\\FooDMachineLearning\\FoodMLrepo\\FoodML\\foodml_src\\classification_module.py in findBestParams(self=<classification_module.ModelsBenchmark object>, X_train=array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y_train=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, names=['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'MLPClassifier'], models=[LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n",
      "          verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n",
      "            warm_start=False), DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size...n_neighbors=5, p=2,\n",
      "           weights='uniform'), MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n",
      "       verbose=False, warm_start=False)], params={'class_weight': ['balanced', None], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 20], 'max_features': ['sqrt', 'log2', 0.5], 'min_samples_split': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,...0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99])}, transf_postfix='V09_PCA_5components', prio_score='Log_Loss', folds=3, iters=30, randomized=True, scoring={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, n_jobs=-1, verbosity=3)\n",
      "    150                                                    scoring=scoring, n_jobs=n_jobs,\n",
      "    151                                                    verbose=verbosity, cv=folds, refit=prio_score)\n",
      "    152                 else:\n",
      "    153                     model_scanner = GridSearchCV(model, params, scoring=scoring,\n",
      "    154                                              n_jobs=n_jobs, verbose=verbosity, cv=folds, refit=prio_score)\n",
      "--> 155 \n",
      "        model_scanner.fit = <bound method BaseSearchCV.fit of RandomizedSear...oba=True, normalize=True)},\n",
      "          verbose=3)>\n",
      "        X_train = array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]])\n",
      "        y_train = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "    156                 #get search results and store them\n",
      "    157                 model_scanner.fit(X_train, y_train)\n",
      "    158                 model_info = \\\n",
      "    159                     model_scanner.cv_results_, model_scanner.best_params_, \\\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n",
      "  ...roba=True, normalize=True)},\n",
      "          verbose=3), X=array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, groups=None, **fit_params={})\n",
      "    634                                   return_train_score=self.return_train_score,\n",
      "    635                                   return_n_test_samples=True,\n",
      "    636                                   return_times=True, return_parameters=False,\n",
      "    637                                   error_score=self.error_score)\n",
      "    638           for parameters, (train, test) in product(candidate_params,\n",
      "--> 639                                                    cv.split(X, y, groups)))\n",
      "        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n",
      "        X = array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]])\n",
      "        y = 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object\n",
      "        groups = None\n",
      "    640 \n",
      "    641         # if one choose to see train score, \"out\" will contain train score info\n",
      "    642         if self.return_train_score:\n",
      "    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n",
      "    784             if pre_dispatch == \"all\" or n_jobs == 1:\n",
      "    785                 # The iterable was consumed all at once by the above for loop.\n",
      "    786                 # No need to wait for async callbacks to trigger to\n",
      "    787                 # consumption.\n",
      "    788                 self._iterating = False\n",
      "--> 789             self.retrieve()\n",
      "        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n",
      "    790             # Make sure that we get a last message telling us we are done\n",
      "    791             elapsed_time = time.time() - self._start_time\n",
      "    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n",
      "    793                         (len(self._output), len(self._output),\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Sub-process traceback:\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                         Fri Oct  5 05:20:50 2018\n",
      "PID: 20468 Python 3.6.6: C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\python.exe\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        self.items = [(<function _fit_and_score>, (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n",
      "    126     def __init__(self, iterator_slice):\n",
      "    127         self.items = list(iterator_slice)\n",
      "    128         self._size = len(self.items)\n",
      "    129 \n",
      "    130     def __call__(self):\n",
      "--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "        func = <function _fit_and_score>\n",
      "        args = (DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), 2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, array([2228, 2298, 2311, ..., 8319, 8320, 8321]), array([   0,    1,    2, ..., 3209, 3223, 3230]), 3, {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0})\n",
      "        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n",
      "    132 \n",
      "    133     def __len__(self):\n",
      "    134         return self._size\n",
      "    135 \n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[ 0.64428542, -0.73095584, -1.13630558, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=2987          BANANA\n",
      "3249        DOUGHNUT\n",
      "4012  ... PEAR\n",
      "Name: ProdName, Length: 8322, dtype: object, scorer={'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average=weighted), 'Log_Loss': make_scorer(log_loss, greater_is_better=False, needs_proba=True, normalize=True)}, train=array([2228, 2298, 2311, ..., 8319, 8320, 8321]), test=array([   0,    1,    2, ..., 3209, 3223, 3230]), verbose=3, parameters={'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.5, 'min_samples_split': 0.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n",
      "    453 \n",
      "    454     try:\n",
      "    455         if y_train is None:\n",
      "    456             estimator.fit(X_train, **fit_params)\n",
      "    457         else:\n",
      "--> 458             estimator.fit(X_train, y_train, **fit_params)\n",
      "        estimator.fit = <bound method DecisionTreeClassifier.fit of Deci... random_state=None,\n",
      "            splitter='best')>\n",
      "        X_train = array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]])\n",
      "        y_train = 6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object\n",
      "        fit_params = {}\n",
      "    459 \n",
      "    460     except Exception as e:\n",
      "    461         # Note fit time as time until error\n",
      "    462         fit_time = time.time() - start_time\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.73433723, -0.13099279,  1.46872225, -...5744146,  0.05706253, -1.98020667,  0.01082953]]), y=6620            QIWI\n",
      "5211            QIWI\n",
      "5219  ... PEAR\n",
      "Name: ProdName, Length: 5533, dtype: object, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    785 \n",
      "    786         super(DecisionTreeClassifier, self).fit(\n",
      "    787             X, y,\n",
      "    788             sample_weight=sample_weight,\n",
      "    789             check_input=check_input,\n",
      "--> 790             X_idx_sorted=X_idx_sorted)\n",
      "        X_idx_sorted = None\n",
      "    791         return self\n",
      "    792 \n",
      "    793     def predict_proba(self, X, check_input=True):\n",
      "    794         \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "...........................................................................\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight='balanced', ..., random_state=None,\n",
      "            splitter='best'), X=array([[-0.7343372 , -0.13099279,  1.4687222 , -... -1.9802066 ,  0.01082953]],\n",
      "      dtype=float32), y=array([[32.],\n",
      "       [32.],\n",
      "       [32.],\n",
      "       ...,\n",
      "       [16.],\n",
      "       [35.],\n",
      "       [28.]]), sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      "    196         else:  # float\n",
      "    197             if not 0. < self.min_samples_split <= 1.:\n",
      "    198                 raise ValueError(\"min_samples_split must be an integer \"\n",
      "    199                                  \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "    200                                  \"got the float %s\"\n",
      "--> 201                                  % self.min_samples_split)\n",
      "        self.min_samples_split = 0.0\n",
      "    202             min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "    203             min_samples_split = max(2, min_samples_split)\n",
      "    204 \n",
      "    205         min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 0.0\n",
      "___________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for KNeighborsClassifier_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   35.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KNeighborsClassifier_V09_PCA_5components...\n",
      "\n",
      "Finding best parameters for MLPClassifier_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  4.0min finished\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier_V09_PCA_5components...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_labels = np.unique(y_train)\n",
    "score_dict = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='weighted'),\n",
    "             'Log_Loss': make_scorer(log_loss,normalize=True,greater_is_better=False, needs_proba=True)} \n",
    "mlp_bench.runBenchmarkOnLoaded(X_train, y_train,  prio_score='Log_Loss', folds=3, iters=30, randomized=True,\n",
    "                                    verbosity=3, print_shapes=True,\n",
    "                               scoring=score_dict)\n",
    "rootDir = '''D:/PROGRAMMING_PROJS/FoodMachineLearning/FoodMLrepo/FoodML/foodml_src/'''\n",
    "mlp_bench.saveToPickles(rootDir,'randomized_results_much_more')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_F1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_Log_Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_Log_Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_Log_Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_Log_Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_Log_Loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_V001_PCA_70': ({'mean_fit_time': array([2.53256464, 6.14291334, 2.39559706, 0.74168444, 0.76761548,\n",
       "          1.72040153, 1.38529563, 4.39126269, 3.04053919, 5.33341074,\n",
       "          2.7742509 , 5.43680064, 1.09208067, 2.67086053, 5.24697502,\n",
       "          1.39360833, 3.95576048, 3.68182453, 4.84637904, 5.54418127,\n",
       "          3.63062859, 1.43217142, 5.56379366, 3.94711614, 2.48103436,\n",
       "          1.91853809, 5.92848587, 0.81980824, 1.07146883, 2.70676525]),\n",
       "   'std_fit_time': array([0.20410313, 0.12796058, 0.24522868, 0.00896976, 0.03410913,\n",
       "          0.03002244, 0.12139547, 0.25678791, 0.04219096, 0.00490791,\n",
       "          0.02497147, 0.46500178, 0.01835442, 0.20219266, 0.13593811,\n",
       "          0.02896666, 0.0372494 , 0.07864088, 0.28623913, 0.03518537,\n",
       "          0.25463021, 0.12926866, 0.1769907 , 0.16596978, 0.2567767 ,\n",
       "          0.03184426, 0.16601789, 0.03403636, 0.01861032, 0.07277668]),\n",
       "   'mean_score_time': array([0.05485304, 0.04022622, 0.06183441, 0.0322473 , 0.04255239,\n",
       "          0.05983933, 0.03823113, 0.03390932, 0.03324397, 0.03291241,\n",
       "          0.03424199, 0.03723423, 0.03224794, 0.03291194, 0.03191487,\n",
       "          0.03424279, 0.03557134, 0.03424263, 0.03490631, 0.04122289,\n",
       "          0.0598398 , 0.03291217, 0.03257998, 0.03224699, 0.03557197,\n",
       "          0.04355065, 0.03257974, 0.04421512, 0.0561831 , 0.03357728]),\n",
       "   'std_score_time': array([0.01634826, 0.00384878, 0.04302082, 0.00047002, 0.00577693,\n",
       "          0.03526135, 0.00658305, 0.00215505, 0.0012443 , 0.00081439,\n",
       "          0.00124424, 0.00329088, 0.00094049, 0.00141012, 0.000814  ,\n",
       "          0.00169447, 0.00204959, 0.00261791, 0.0029348 , 0.00577881,\n",
       "          0.03667141, 0.00215494, 0.00124352, 0.00188048, 0.00658205,\n",
       "          0.01129447, 0.00188048, 0.02023258, 0.03220748, 0.00658213]),\n",
       "   'param_C': masked_array(data=[0.11888458671945079, 0.19818487379444166,\n",
       "                      0.15262214305716224, 0.08168540785279634,\n",
       "                      0.37078840859599965, 0.0675533159354475,\n",
       "                      0.015831687955549827, 0.21722369544783005,\n",
       "                      0.5784855152772371, 0.02863612939925386,\n",
       "                      0.2318182484954568, 0.4546229691182355,\n",
       "                      0.7974882070154842, 0.18444605335287959,\n",
       "                      0.14075721638102495, 0.5046110431473106,\n",
       "                      0.11348561350910442, 0.10212744615118743,\n",
       "                      0.09561722860806694, 0.43300844862919385,\n",
       "                      0.09898799745215514, 0.08736655681479871,\n",
       "                      0.16105478247027252, 0.16745383697667598,\n",
       "                      0.28918800056416427, 0.49369948229990224,\n",
       "                      0.05039223753489763, 0.06793850632322022,\n",
       "                      0.030554288128957614, 0.07813533945643869],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', None, None, None, 'balanced',\n",
       "                      'balanced', None, None, 'balanced', 'balanced', None,\n",
       "                      None, None, None, 'balanced', 'balanced', None,\n",
       "                      'balanced', None, None, 'balanced', None, None,\n",
       "                      'balanced', None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['liblinear', 'newton-cg', 'liblinear', 'saga', 'saga',\n",
       "                      'liblinear', 'saga', 'newton-cg', 'liblinear',\n",
       "                      'newton-cg', 'liblinear', 'newton-cg', 'saga',\n",
       "                      'liblinear', 'newton-cg', 'saga', 'newton-cg',\n",
       "                      'liblinear', 'newton-cg', 'liblinear', 'saga',\n",
       "                      'liblinear', 'newton-cg', 'newton-cg', 'saga',\n",
       "                      'liblinear', 'saga', 'saga', 'saga', 'newton-cg'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.15844783254877817, 0.24232689728835194,\n",
       "                      0.35889868683081616, 0.26545250962167016,\n",
       "                      0.26352922086303426, 0.28238433145891473,\n",
       "                      0.13022515998302014, 0.2206899943124342,\n",
       "                      0.33426636046938873, 0.053527991304425204,\n",
       "                      0.3604110190968004, 0.22473909055263924,\n",
       "                      0.18343402972464584, 0.1679061502242495,\n",
       "                      0.2771469771440015, 0.13036342678173227,\n",
       "                      0.3853369848685954, 0.0249298180334461,\n",
       "                      0.11175747781186224, 0.025901539001063525,\n",
       "                      0.027479072997078982, 0.6340754645325195,\n",
       "                      0.24145169209457348, 0.21494866860760045,\n",
       "                      0.0643413233537857, 0.9283636092787133,\n",
       "                      0.020325055733560686, 0.3171881483117204,\n",
       "                      0.10823035776058071, 0.4669864213231443],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.11888458671945079,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.15844783254877817},\n",
       "    {'C': 0.19818487379444166,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.24232689728835194},\n",
       "    {'C': 0.15262214305716224,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.35889868683081616},\n",
       "    {'C': 0.08168540785279634,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.26545250962167016},\n",
       "    {'C': 0.37078840859599965,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.26352922086303426},\n",
       "    {'C': 0.0675533159354475,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.28238433145891473},\n",
       "    {'C': 0.015831687955549827,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.13022515998302014},\n",
       "    {'C': 0.21722369544783005,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.2206899943124342},\n",
       "    {'C': 0.5784855152772371,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.33426636046938873},\n",
       "    {'C': 0.02863612939925386,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.053527991304425204},\n",
       "    {'C': 0.2318182484954568,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3604110190968004},\n",
       "    {'C': 0.4546229691182355,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.22473909055263924},\n",
       "    {'C': 0.7974882070154842,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.18343402972464584},\n",
       "    {'C': 0.18444605335287959,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.1679061502242495},\n",
       "    {'C': 0.14075721638102495,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.2771469771440015},\n",
       "    {'C': 0.5046110431473106,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.13036342678173227},\n",
       "    {'C': 0.11348561350910442,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3853369848685954},\n",
       "    {'C': 0.10212744615118743,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.0249298180334461},\n",
       "    {'C': 0.09561722860806694,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.11175747781186224},\n",
       "    {'C': 0.43300844862919385,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.025901539001063525},\n",
       "    {'C': 0.09898799745215514,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.027479072997078982},\n",
       "    {'C': 0.08736655681479871,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.6340754645325195},\n",
       "    {'C': 0.16105478247027252,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.24145169209457348},\n",
       "    {'C': 0.16745383697667598,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.21494866860760045},\n",
       "    {'C': 0.28918800056416427,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0643413233537857},\n",
       "    {'C': 0.49369948229990224,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.9283636092787133},\n",
       "    {'C': 0.05039223753489763,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.020325055733560686},\n",
       "    {'C': 0.06793850632322022,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.3171881483117204},\n",
       "    {'C': 0.030554288128957614,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.10823035776058071},\n",
       "    {'C': 0.07813533945643869,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.4669864213231443}],\n",
       "   'split0_test_Accuracy': array([0.64897813, 0.63320186, 0.65292219, 0.56615274, 0.57619218,\n",
       "          0.63356042, 0.56149157, 0.67837935, 0.66977411, 0.61957691,\n",
       "          0.65722481, 0.68411617, 0.55647185, 0.65579061, 0.630692  ,\n",
       "          0.57117246, 0.67192542, 0.65471495, 0.66977411, 0.67515238,\n",
       "          0.59949803, 0.63965579, 0.63105056, 0.67658659, 0.59053424,\n",
       "          0.64037289, 0.61061312, 0.54930082, 0.57798494, 0.66583005]),\n",
       "   'split1_test_Accuracy': array([0.64177489, 0.63564214, 0.64249639, 0.56673882, 0.56926407,\n",
       "          0.62662338, 0.5523088 , 0.68326118, 0.65909091, 0.61580087,\n",
       "          0.64790765, 0.68759019, 0.55627706, 0.6461039 , 0.63311688,\n",
       "          0.56565657, 0.67027417, 0.64357864, 0.66810967, 0.66594517,\n",
       "          0.60064935, 0.62481962, 0.63455988, 0.67929293, 0.58441558,\n",
       "          0.63528139, 0.61075036, 0.5523088 , 0.57756133, 0.66414141]),\n",
       "   'split2_test_Accuracy': array([0.64795364, 0.63600145, 0.6461427 , 0.56791018, 0.57406737,\n",
       "          0.62948207, 0.54726548, 0.67656646, 0.66751177, 0.61535675,\n",
       "          0.65085114, 0.68562115, 0.53965954, 0.65266208, 0.63056863,\n",
       "          0.55161173, 0.67004708, 0.65157552, 0.66533865, 0.67040927,\n",
       "          0.59000362, 0.63274176, 0.63310395, 0.67366896, 0.56609924,\n",
       "          0.63926114, 0.59905831, 0.52444766, 0.57660268, 0.66497646]),\n",
       "   'mean_test_Accuracy': array([0.64623888, 0.63494352, 0.64720019, 0.56693103, 0.57317952,\n",
       "          0.62989666, 0.55371305, 0.67940399, 0.66546503, 0.61691901,\n",
       "          0.65200673, 0.68577265, 0.55082913, 0.65152608, 0.63145878,\n",
       "          0.56284547, 0.67075222, 0.64996395, 0.66774814, 0.6705119 ,\n",
       "          0.59673155, 0.63242009, 0.63290075, 0.67652007, 0.58038933,\n",
       "          0.6383081 , 0.60682528, 0.5420572 , 0.57738524, 0.66498438]),\n",
       "   'std_test_Accuracy': array([0.00318243, 0.00124518, 0.00432594, 0.00073033, 0.00289997,\n",
       "          0.00285035, 0.00589292, 0.00282469, 0.00459849, 0.00189571,\n",
       "          0.00389423, 0.00142392, 0.00787075, 0.0040393 , 0.0011729 ,\n",
       "          0.00823034, 0.00083807, 0.00469119, 0.00182901, 0.00376391,\n",
       "          0.00476395, 0.00606814, 0.00144148, 0.00229335, 0.01037504,\n",
       "          0.00218669, 0.00547307, 0.01246884, 0.00057796, 0.00069021]),\n",
       "   'rank_test_Accuracy': array([13, 15, 12, 26, 25, 19, 28,  2,  7, 20,  9,  1, 29, 10, 18, 27,  4,\n",
       "          11,  6,  5, 22, 17, 16,  3, 23, 14, 21, 30, 24,  8]),\n",
       "   'split0_train_Accuracy': array([0.72185071, 0.72474245, 0.72185071, 0.61413338, 0.61575999,\n",
       "          0.69528285, 0.59298753, 0.77354057, 0.74715344, 0.69040304,\n",
       "          0.72853786, 0.78655341, 0.59190313, 0.72781493, 0.71624797,\n",
       "          0.59967468, 0.75962407, 0.72492319, 0.75420206, 0.76034701,\n",
       "          0.65154527, 0.69980119, 0.71913971, 0.76956443, 0.62443521,\n",
       "          0.71245256, 0.66094343, 0.57220314, 0.62624254, 0.74896078]),\n",
       "   'split1_train_Accuracy': array([0.73063063, 0.71171171, 0.73171171, 0.62648649, 0.62684685,\n",
       "          0.69981982, 0.62036036, 0.78504505, 0.76126126, 0.68846847,\n",
       "          0.7418018 , 0.79585586, 0.61963964, 0.74126126, 0.70828829,\n",
       "          0.62972973, 0.77027027, 0.73369369, 0.76540541, 0.76990991,\n",
       "          0.6645045 , 0.70666667, 0.70900901, 0.77963964, 0.65009009,\n",
       "          0.72      , 0.68576577, 0.60036036, 0.63585586, 0.75927928]),\n",
       "   'split2_train_Accuracy': array([0.72307139, 0.72522928, 0.7254091 , 0.6149973 , 0.62560691,\n",
       "          0.69322064, 0.59899299, 0.77665887, 0.75472037, 0.69447941,\n",
       "          0.73386082, 0.79086495, 0.59144039, 0.73242223, 0.71965474,\n",
       "          0.59899299, 0.76209315, 0.72594857, 0.75831685, 0.76461068,\n",
       "          0.65923395, 0.70167236, 0.72145298, 0.77090451, 0.62524726,\n",
       "          0.71138284, 0.65977342, 0.57201942, 0.63172091, 0.75184319]),\n",
       "   'mean_train_Accuracy': array([0.72518424, 0.72056115, 0.72632384, 0.61853906, 0.62273791,\n",
       "          0.69610777, 0.60411363, 0.77841483, 0.75437836, 0.69111697,\n",
       "          0.73473349, 0.79109141, 0.60099438, 0.73383281, 0.71473033,\n",
       "          0.6094658 , 0.76399583, 0.72818848, 0.75930811, 0.76495587,\n",
       "          0.65842791, 0.70271341, 0.7165339 , 0.77336953, 0.63325752,\n",
       "          0.7146118 , 0.66882754, 0.58152764, 0.6312731 , 0.75336108]),\n",
       "   'std_train_Accuracy': array([0.00388328, 0.00626065, 0.00407737, 0.00563074, 0.00496004,\n",
       "          0.00275653, 0.01174688, 0.00485803, 0.00576457, 0.00250535,\n",
       "          0.00545003, 0.00380108, 0.01318554, 0.00557932, 0.0047628 ,\n",
       "          0.01433147, 0.00454976, 0.00391521, 0.00462714, 0.00391166,\n",
       "          0.0053212 , 0.00289787, 0.00540406, 0.00446726, 0.01190704,\n",
       "          0.00383498, 0.01198666, 0.01331695, 0.00393737, 0.00434709]),\n",
       "   'split0_test_F1': array([0.6422926 , 0.63679436, 0.64606286, 0.55794309, 0.56920224,\n",
       "          0.62549293, 0.53921671, 0.67440323, 0.6638068 , 0.62166471,\n",
       "          0.65141846, 0.67980513, 0.53192923, 0.65002311, 0.6344826 ,\n",
       "          0.54943065, 0.66759419, 0.64751577, 0.66499017, 0.67082205,\n",
       "          0.59796062, 0.63121449, 0.63477611, 0.67230207, 0.57363419,\n",
       "          0.6328154 , 0.59723016, 0.52607304, 0.57315209, 0.66101597]),\n",
       "   'split1_test_F1': array([0.63511892, 0.63680135, 0.63598237, 0.56405833, 0.56253233,\n",
       "          0.61812542, 0.52664876, 0.67823678, 0.65241775, 0.61585824,\n",
       "          0.64222433, 0.68251548, 0.52997845, 0.6402619 , 0.63449068,\n",
       "          0.54378399, 0.66453334, 0.6347104 , 0.66221215, 0.66089245,\n",
       "          0.59800585, 0.61432032, 0.63585539, 0.67362472, 0.56660039,\n",
       "          0.62832401, 0.59860022, 0.52657494, 0.57213017, 0.65807044]),\n",
       "   'split2_test_F1': array([0.64122098, 0.63981403, 0.63984878, 0.5634562 , 0.56864215,\n",
       "          0.62145935, 0.52295685, 0.67258702, 0.66153837, 0.61742614,\n",
       "          0.64561392, 0.68254947, 0.51564311, 0.6471663 , 0.6337199 ,\n",
       "          0.52783519, 0.66570945, 0.64295544, 0.66052464, 0.66566473,\n",
       "          0.58805766, 0.62336892, 0.63634409, 0.66956818, 0.54654051,\n",
       "          0.63242446, 0.58554842, 0.49284058, 0.57211361, 0.65999078]),\n",
       "   'mean_test_F1': array([0.63954757, 0.63779853, 0.64064347, 0.56180913, 0.56679472,\n",
       "          0.62170064, 0.52963586, 0.67507759, 0.65926059, 0.61832438,\n",
       "          0.64643018, 0.68161842, 0.52587617, 0.64582391, 0.63423225,\n",
       "          0.54038504, 0.66594934, 0.64173741, 0.6625833 , 0.66580352,\n",
       "          0.59469017, 0.62298423, 0.63565582, 0.67183561, 0.56230238,\n",
       "          0.63118965, 0.59381085, 0.51521465, 0.57246716, 0.65969471]),\n",
       "   'std_test_F1': array([0.00316027, 0.00142017, 0.00415802, 0.00275575, 0.003021  ,\n",
       "          0.00301608, 0.00696672, 0.00235262, 0.0049239 , 0.00245619,\n",
       "          0.00380163, 0.00128747, 0.0072544 , 0.00410024, 0.00036103,\n",
       "          0.00913912, 0.00126241, 0.00530377, 0.00184212, 0.00405965,\n",
       "          0.00467345, 0.00691038, 0.00065558, 0.00168666, 0.01147223,\n",
       "          0.00203149, 0.00584877, 0.01576661, 0.00048633, 0.00122185]),\n",
       "   'rank_test_F1': array([13, 14, 12, 26, 24, 19, 28,  2,  8, 20,  9,  1, 29, 10, 16, 27,  4,\n",
       "          11,  6,  5, 21, 18, 15,  3, 25, 17, 22, 30, 23,  7]),\n",
       "   'split0_train_F1': array([0.71581054, 0.72473029, 0.71598856, 0.60627303, 0.60968904,\n",
       "          0.68848616, 0.57039866, 0.77096848, 0.74292542, 0.68956146,\n",
       "          0.72305397, 0.7842719 , 0.56850001, 0.7222769 , 0.71633195,\n",
       "          0.57838478, 0.75654456, 0.71911593, 0.75096816, 0.75627402,\n",
       "          0.6482148 , 0.69313438, 0.71911686, 0.76678408, 0.60782985,\n",
       "          0.70615028, 0.65084462, 0.54869786, 0.62027386, 0.74565438]),\n",
       "   'split1_train_F1': array([0.7244645 , 0.71119811, 0.72592387, 0.62360052, 0.62085903,\n",
       "          0.69255628, 0.60086579, 0.78224097, 0.75670385, 0.68676054,\n",
       "          0.73633857, 0.79339406, 0.60135868, 0.73575988, 0.70804413,\n",
       "          0.61230135, 0.76687556, 0.72729466, 0.76181336, 0.76607568,\n",
       "          0.6611094 , 0.6989621 , 0.70875104, 0.77679029, 0.63760161,\n",
       "          0.71316457, 0.67728759, 0.57863837, 0.62997627, 0.75512291]),\n",
       "   'split2_train_F1': array([0.71890123, 0.72595731, 0.72108896, 0.60955393, 0.62055423,\n",
       "          0.6876084 , 0.57829208, 0.77372965, 0.75095397, 0.69453463,\n",
       "          0.72965967, 0.78810041, 0.57064344, 0.72841134, 0.72022376,\n",
       "          0.57810057, 0.75920663, 0.72072966, 0.75529014, 0.76125284,\n",
       "          0.65749622, 0.69557741, 0.72224239, 0.76789342, 0.61010632,\n",
       "          0.70679927, 0.65019657, 0.54360691, 0.62799853, 0.74848685]),\n",
       "   'mean_train_F1': array([0.71972543, 0.72062857, 0.72100046, 0.6131425 , 0.6170341 ,\n",
       "          0.68955028, 0.58318551, 0.77564637, 0.75019442, 0.69028554,\n",
       "          0.72968407, 0.78858879, 0.58016738, 0.72881604, 0.71486661,\n",
       "          0.58959556, 0.76087558, 0.72238008, 0.75602389, 0.76120085,\n",
       "          0.65560681, 0.6958913 , 0.71670343, 0.77048926, 0.6185126 ,\n",
       "          0.7087047 , 0.65944293, 0.55698105, 0.62608289, 0.74975471]),\n",
       "   'std_train_F1': array([0.00358071, 0.00668713, 0.00405655, 0.00751527, 0.00519523,\n",
       "          0.00215556, 0.01291048, 0.00479741, 0.0056506 , 0.00321479,\n",
       "          0.00542344, 0.00374008, 0.01501004, 0.00551184, 0.00507913,\n",
       "          0.01605583, 0.00437961, 0.00353703, 0.00445783, 0.00400168,\n",
       "          0.00543109, 0.00238949, 0.00576614, 0.00447846, 0.01352993,\n",
       "          0.00316471, 0.01262085, 0.01545443, 0.0041862 , 0.00396812]),\n",
       "   'split0_test_Log_Loss': array([-1.48823511, -1.49048086, -1.46165096, -2.72159492, -2.70604185,\n",
       "          -1.6878812 , -2.69969394, -1.15361729, -1.29308763, -1.69425355,\n",
       "          -1.38792238, -1.13023158, -2.75523062, -1.40632852, -1.51355128,\n",
       "          -2.62636225, -1.19586584, -1.49545241, -1.20953492, -1.24303002,\n",
       "          -2.1781963 , -1.63303786, -1.50377158, -1.16727442, -2.30550389,\n",
       "          -1.48521528, -1.8895907 , -2.88517114, -2.59872241, -1.23059072]),\n",
       "   'split1_test_Log_Loss': array([-1.51666313, -1.50321307, -1.48353308, -2.57199169, -2.55788329,\n",
       "          -1.71112309, -2.51150722, -1.1945564 , -1.33072158, -1.71078629,\n",
       "          -1.41852186, -1.16409693, -2.50852577, -1.43688881, -1.52794708,\n",
       "          -2.39674244, -1.24039577, -1.52945833, -1.2543655 , -1.27550643,\n",
       "          -2.06793181, -1.66355288, -1.51765466, -1.20998351, -2.12538919,\n",
       "          -1.51514111, -1.78246565, -2.68165956, -2.45223291, -1.27483411]),\n",
       "   'split2_test_Log_Loss': array([-1.53087217, -1.54437181, -1.4982411 , -2.72077678, -2.71204284,\n",
       "          -1.72098549, -2.71226683, -1.22289316, -1.34870024, -1.72779125,\n",
       "          -1.43890722, -1.20614263, -2.74834564, -1.45494559, -1.56385325,\n",
       "          -2.62543919, -1.25801391, -1.53746974, -1.26962873, -1.30516459,\n",
       "          -2.20107973, -1.66864659, -1.55545694, -1.23404107, -2.32424637,\n",
       "          -1.52538031, -1.91979542, -2.92127615, -2.59960794, -1.28839306]),\n",
       "   'mean_test_Log_Loss': array([-1.51185003, -1.51260134, -1.4810793 , -2.6714917 , -2.65868223,\n",
       "          -1.70660596, -2.64118158, -1.19023756, -1.3240739 , -1.71088733,\n",
       "          -1.41503015, -1.16669699, -2.67077072, -1.43263768, -1.53503516,\n",
       "          -2.54957125, -1.23131739, -1.52071969, -1.24440507, -1.27446215,\n",
       "          -2.14906003, -1.65501615, -1.52554365, -1.20365177, -2.25172716,\n",
       "          -1.50850896, -1.86392915, -2.82936146, -2.55022157, -1.26450504]),\n",
       "   'std_test_Log_Loss': array([0.01773861, 0.02298311, 0.01504067, 0.07031988, 0.0712792 ,\n",
       "          0.0138889 , 0.09178772, 0.02845069, 0.02318847, 0.01369419,\n",
       "          0.0209637 , 0.03105017, 0.11469693, 0.02007722, 0.02114117,\n",
       "          0.10800851, 0.02617461, 0.01823409, 0.02552706, 0.02538131,\n",
       "          0.05809166, 0.01574165, 0.02182803, 0.02762674, 0.0896135 ,\n",
       "          0.01705669, 0.05887843, 0.10542043, 0.06925193, 0.02470477]),\n",
       "   'rank_test_Log_Loss': array([13, 14, 11, 29, 27, 19, 26,  2,  8, 20,  9,  1, 28, 10, 17, 24,  4,\n",
       "          15,  5,  7, 22, 18, 16,  3, 23, 12, 21, 30, 25,  6]),\n",
       "   'split0_train_Log_Loss': array([-1.33809025, -1.288729  , -1.30855036, -2.68156878, -2.66535336,\n",
       "          -1.56619009, -2.65516537, -0.90174242, -1.0986868 , -1.57416586,\n",
       "          -1.22018869, -0.83789371, -2.71241453, -1.240651  , -1.3289054 ,\n",
       "          -2.5790774 , -0.97763223, -1.34953409, -0.99895117, -1.02800152,\n",
       "          -2.10684683, -1.50752304, -1.31252875, -0.92912962, -2.23661739,\n",
       "          -1.33328755, -1.78965624, -2.84902218, -2.55434157, -1.02992556]),\n",
       "   'split1_train_Log_Loss': array([-1.32353213, -1.26756627, -1.28593462, -2.51443577, -2.50032298,\n",
       "          -1.5508037 , -2.43333177, -0.88911026, -1.08148008, -1.55884128,\n",
       "          -1.20663213, -0.82768688, -2.4285815 , -1.22488702, -1.30842216,\n",
       "          -2.30604032, -0.96326363, -1.33451657, -0.98418147, -1.01300707,\n",
       "          -1.96742816, -1.49385191, -1.29184741, -0.91552415, -2.01119734,\n",
       "          -1.3202205 , -1.62857231, -2.6162945 , -2.38934884, -1.01509011]),\n",
       "   'split2_train_Log_Loss': array([-1.31423279, -1.26746413, -1.2746305 , -2.66492786, -2.6587518 ,\n",
       "          -1.54284376, -2.64317722, -0.87615465, -1.07345545, -1.55672088,\n",
       "          -1.1984798 , -0.81306585, -2.68396652, -1.21590061, -1.30777334,\n",
       "          -2.54801397, -0.95182129, -1.32592784, -0.97345004, -1.00088379,\n",
       "          -2.10037261, -1.48709072, -1.29119205, -0.90365984, -2.21947636,\n",
       "          -1.31110864, -1.77176158, -2.86752215, -2.53464278, -1.00481938]),\n",
       "   'mean_train_Log_Loss': array([-1.32528506, -1.27458647, -1.28970516, -2.6203108 , -2.60814271,\n",
       "          -1.55327918, -2.57722479, -0.88900244, -1.08454078, -1.56324267,\n",
       "          -1.20843354, -0.82621548, -2.60832085, -1.22714621, -1.31503364,\n",
       "          -2.47771056, -0.96423905, -1.3366595 , -0.98552756, -1.01396413,\n",
       "          -2.05821587, -1.49615522, -1.29852274, -0.91610453, -2.1557637 ,\n",
       "          -1.3215389 , -1.72999671, -2.77761294, -2.49277773, -1.01661168]),\n",
       "   'std_train_Log_Loss': array([0.00981832, 0.01000037, 0.01410206, 0.07517257, 0.07628768,\n",
       "          0.0096905 , 0.10186537, 0.01044644, 0.01052556, 0.00777222,\n",
       "          0.00895369, 0.01018919, 0.12762444, 0.01022981, 0.0098124 ,\n",
       "          0.12204982, 0.01055982, 0.00975561, 0.01045421, 0.01109143,\n",
       "          0.06425099, 0.00849898, 0.00990736, 0.01040609, 0.10246309,\n",
       "          0.00910237, 0.072089  , 0.11431912, 0.07357609, 0.01030587])},\n",
       "  {'C': 0.4546229691182355,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.22473909055263924},\n",
       "  11,\n",
       "  -1.1666969914408678),\n",
       " 'RandomForestClassifier_V001_PCA_70': ({'mean_fit_time': array([17.80174836,  2.79353301,  2.60769598,  6.55082393,  8.77487914,\n",
       "           7.51158857,  2.73236338, 17.85228213,  6.4494276 ,  3.26161464,\n",
       "           5.38427575,  3.35636171,  3.11168281,  3.73667804,  7.11099275,\n",
       "           7.38027287,  3.87663857,  2.87165809,  4.12730185,  6.21571883,\n",
       "           7.78186552,  7.55048434,  1.46342166,  5.06911651, 10.02221092,\n",
       "           6.82675203,  1.32313005,  6.36797825,  3.05416973,  4.87895846]),\n",
       "   'std_fit_time': array([0.1218973 , 0.02330477, 0.03903063, 0.05395051, 0.02036294,\n",
       "          0.0979395 , 0.04824659, 0.10133026, 0.08161241, 0.03989573,\n",
       "          0.04473056, 0.03139442, 0.05941164, 0.04109239, 0.06069794,\n",
       "          0.14982603, 0.05093894, 0.09474218, 0.03437895, 0.02283509,\n",
       "          0.13528628, 0.10519931, 0.00702065, 0.03634726, 0.08058525,\n",
       "          0.02136058, 0.03389284, 0.06030353, 0.00577742, 0.03142272]),\n",
       "   'mean_score_time': array([0.87931673, 0.31549025, 0.3085084 , 0.51728423, 0.62599421,\n",
       "          0.60870671, 0.3716739 , 0.89294664, 0.46309622, 0.28557022,\n",
       "          0.56449095, 0.37732546, 0.21209947, 0.44148731, 0.52592778,\n",
       "          0.6801819 , 0.37034361, 0.29321678, 0.48370854, 0.39893484,\n",
       "          0.36303051, 0.63862705, 0.20079708, 0.35970505, 0.45777655,\n",
       "          0.38929319, 0.1944801 , 0.44946575, 0.21708647, 0.23503915]),\n",
       "   'std_score_time': array([0.02337995, 0.05991919, 0.01537087, 0.0180687 , 0.00729859,\n",
       "          0.00943786, 0.01631323, 0.00823741, 0.03181415, 0.00600241,\n",
       "          0.01976269, 0.03056066, 0.01532815, 0.01018106, 0.01316436,\n",
       "          0.01763495, 0.00658244, 0.03624431, 0.00646342, 0.02571192,\n",
       "          0.00495314, 0.02360557, 0.00773985, 0.00878326, 0.00917716,\n",
       "          0.01140992, 0.01797102, 0.0130373 , 0.02775053, 0.00678074]),\n",
       "   'param_n_estimators': masked_array(data=[350, 150, 150, 300, 250, 350, 200, 350, 250, 150, 300,\n",
       "                      200, 100, 250, 300, 350, 200, 150, 250, 200, 150, 350,\n",
       "                      100, 200, 200, 200, 100, 250, 100, 100],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[10, 10, 150, 150, 10, 200, 250, 10, 125, 75, 125, 150,\n",
       "                      75, 200, 150, 75, 250, 250, 150, 75, 10, 75, 200, 125,\n",
       "                      10, 50, 250, 125, 75, 10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['sqrt', 'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                      'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2',\n",
       "                      'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
       "                      'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
       "                      'sqrt', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[85, 5, 85, 5, 30, 35, 40, 35, 30, 70, 20, 80, 85, 75,\n",
       "                      25, 10, 75, 100, 70, 45, 55, 90, 35, 95, 35, 55, 75,\n",
       "                      100, 100, 75],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 75}],\n",
       "   'split0_test_Accuracy': array([0.71244174, 0.47328792, 0.46002151, 0.42380782, 0.70813912,\n",
       "          0.4327716 , 0.37719613, 0.71817856, 0.47866619, 0.54392255,\n",
       "          0.47723198, 0.46109717, 0.52276802, 0.41556113, 0.46253137,\n",
       "          0.54069559, 0.39117963, 0.39404805, 0.46253137, 0.53531732,\n",
       "          0.71100753, 0.54141269, 0.40803155, 0.47794909, 0.71029043,\n",
       "          0.56292578, 0.37253496, 0.48010039, 0.52169236, 0.70025099]),\n",
       "   'split1_test_Accuracy': array([0.70021645, 0.45634921, 0.4462482 , 0.42532468, 0.69011544,\n",
       "          0.42099567, 0.38275613, 0.69805195, 0.46825397, 0.52380952,\n",
       "          0.47222222, 0.4469697 , 0.52236652, 0.42388167, 0.4541847 ,\n",
       "          0.52236652, 0.3997114 , 0.39033189, 0.45995671, 0.51334776,\n",
       "          0.69805195, 0.52128427, 0.42424242, 0.46572872, 0.69949495,\n",
       "          0.55411255, 0.37265512, 0.46464646, 0.51226551, 0.69083694]),\n",
       "   'split2_test_Accuracy': array([0.70155741, 0.45454545, 0.44549076, 0.41687794, 0.70083303,\n",
       "          0.41687794, 0.37884824, 0.70626585, 0.46251358, 0.52299891,\n",
       "          0.47301702, 0.44404201, 0.5088736 , 0.41542919, 0.44766389,\n",
       "          0.5204636 , 0.40021731, 0.39949294, 0.44911264, 0.51792829,\n",
       "          0.69684897, 0.5291561 , 0.41325607, 0.47011952, 0.70735241,\n",
       "          0.55776892, 0.37739949, 0.45997827, 0.51430641, 0.69177834]),\n",
       "   'mean_test_Accuracy': array([0.70475847, 0.46142754, 0.45061283, 0.42201394, 0.69971161,\n",
       "          0.42357606, 0.37959625, 0.70752223, 0.46983898, 0.53028118,\n",
       "          0.47416486, 0.450733  , 0.51802451, 0.41828887, 0.45481855,\n",
       "          0.52787791, 0.39701995, 0.39461668, 0.45722182, 0.52223023,\n",
       "          0.70199471, 0.53064167, 0.41516462, 0.47128094, 0.70571978,\n",
       "          0.55827926, 0.3741889 , 0.46827686, 0.5161019 , 0.69430425]),\n",
       "   'std_test_Accuracy': array([0.00548226, 0.00845264, 0.00668707, 0.00367166, 0.00740897,\n",
       "          0.006741  , 0.00233283, 0.00827373, 0.00668983, 0.00969069,\n",
       "          0.00220156, 0.0074545 , 0.00645003, 0.00395294, 0.00608715,\n",
       "          0.00913326, 0.00415161, 0.00375667, 0.00581001, 0.00947733,\n",
       "          0.00641766, 0.0082933 , 0.00676088, 0.00506136, 0.00455987,\n",
       "          0.00362008, 0.00226279, 0.00860748, 0.00405538, 0.00423945]),\n",
       "   'rank_test_Accuracy': array([ 3, 18, 22, 24,  5, 23, 29,  1, 16,  9, 14, 21, 12, 25, 20, 10, 27,\n",
       "          28, 19, 11,  4,  8, 26, 15,  2,  7, 30, 17, 13,  6]),\n",
       "   'split0_train_Accuracy': array([0.94740647, 0.55684077, 0.51328393, 0.46087114, 0.95572022,\n",
       "          0.46538948, 0.4194831 , 0.94957528, 0.52991144, 0.63130309,\n",
       "          0.54961142, 0.50713898, 0.61322971, 0.45707573, 0.50840412,\n",
       "          0.63817097, 0.42472438, 0.43358034, 0.51997108, 0.62262787,\n",
       "          0.94523766, 0.63925538, 0.45056931, 0.53406832, 0.94559913,\n",
       "          0.68642689, 0.41080788, 0.53840593, 0.61485632, 0.94252666]),\n",
       "   'split1_train_Accuracy': array([0.9409009 , 0.54486486, 0.51711712, 0.47495495, 0.95585586,\n",
       "          0.47225225, 0.43009009, 0.94342342, 0.54054054, 0.6381982 ,\n",
       "          0.55387387, 0.52396396, 0.62198198, 0.47441441, 0.52198198,\n",
       "          0.63927928, 0.4409009 , 0.4409009 , 0.52846847, 0.62126126,\n",
       "          0.94144144, 0.64558559, 0.47243243, 0.54072072, 0.9381982 ,\n",
       "          0.69027027, 0.42612613, 0.53675676, 0.61621622, 0.93747748]),\n",
       "   'split2_train_Accuracy': array([0.94839058, 0.54558533, 0.51123899, 0.46916022, 0.95774141,\n",
       "          0.46772163, 0.42096745, 0.94317569, 0.54180903, 0.63585686,\n",
       "          0.55115986, 0.51411617, 0.61517713, 0.47185758, 0.50656357,\n",
       "          0.63639633, 0.44056824, 0.43445423, 0.51843194, 0.62614638,\n",
       "          0.9417371 , 0.63262003, 0.4621471 , 0.54648445, 0.94623269,\n",
       "          0.68566805, 0.4243841 , 0.54037044, 0.6187736 , 0.93993886]),\n",
       "   'mean_train_Accuracy': array([0.94556598, 0.54909699, 0.51388001, 0.46832877, 0.95643916,\n",
       "          0.46845446, 0.42351355, 0.94539146, 0.53742034, 0.63511938,\n",
       "          0.55154839, 0.51507304, 0.61679627, 0.46778257, 0.51231656,\n",
       "          0.63794886, 0.43539784, 0.43631182, 0.5222905 , 0.62334517,\n",
       "          0.9428054 , 0.63915366, 0.46171628, 0.54042449, 0.94334334,\n",
       "          0.68745507, 0.42043937, 0.53851104, 0.61661538, 0.939981  ]),\n",
       "   'std_train_Accuracy': array([0.00332309, 0.00548358, 0.00243647, 0.00577968, 0.00092249,\n",
       "          0.00284923, 0.00468963, 0.00296013, 0.00533479, 0.00286281,\n",
       "          0.00176169, 0.00690201, 0.00375205, 0.0076425 , 0.00687567,\n",
       "          0.00118739, 0.0075485 , 0.00326452, 0.00441345, 0.00205783,\n",
       "          0.0017241 , 0.00529365, 0.00893078, 0.00507319, 0.00364735,\n",
       "          0.00201461, 0.00684752, 0.00147715, 0.00162394, 0.00206153]),\n",
       "   'split0_test_F1': array([0.70748085, 0.44568687, 0.43603406, 0.38097216, 0.7031385 ,\n",
       "          0.38790638, 0.35296237, 0.7134728 , 0.44337809, 0.52063733,\n",
       "          0.45093435, 0.43432873, 0.49698241, 0.3900798 , 0.42308425,\n",
       "          0.51777358, 0.34127329, 0.3535057 , 0.43436122, 0.51087637,\n",
       "          0.7061525 , 0.51777617, 0.37512519, 0.44577499, 0.70567231,\n",
       "          0.54218668, 0.35429534, 0.44404759, 0.49412458, 0.69478281]),\n",
       "   'split1_test_F1': array([0.69379109, 0.42782729, 0.41158638, 0.38090495, 0.68139362,\n",
       "          0.37418114, 0.35601123, 0.69106502, 0.42675367, 0.49599104,\n",
       "          0.44114412, 0.41890984, 0.49357451, 0.3919752 , 0.4109679 ,\n",
       "          0.49501447, 0.35641679, 0.35216096, 0.43050944, 0.48281521,\n",
       "          0.69076475, 0.49745708, 0.39855307, 0.42490265, 0.69267697,\n",
       "          0.5304471 , 0.35086502, 0.42472524, 0.48140481, 0.68519627]),\n",
       "   'split2_test_F1': array([0.69885423, 0.42779988, 0.41019158, 0.36903019, 0.6988931 ,\n",
       "          0.36970128, 0.35115696, 0.70464495, 0.41559246, 0.50048119,\n",
       "          0.43858866, 0.40998766, 0.47721003, 0.38425981, 0.40219561,\n",
       "          0.49465842, 0.35920796, 0.35647966, 0.41622478, 0.49088193,\n",
       "          0.6949925 , 0.50428603, 0.37698277, 0.42758557, 0.70516998,\n",
       "          0.53806647, 0.34707786, 0.41689227, 0.4864653 , 0.68911316]),\n",
       "   'mean_test_F1': array([0.70005882, 0.43380358, 0.41931692, 0.37698777, 0.69448693,\n",
       "          0.37729467, 0.35337894, 0.7030801 , 0.42862214, 0.5057406 ,\n",
       "          0.44357735, 0.42111714, 0.48928735, 0.38878024, 0.41211813,\n",
       "          0.50252374, 0.35226769, 0.35404445, 0.42706107, 0.49489582,\n",
       "          0.69732438, 0.50653238, 0.38354515, 0.43278783, 0.70117699,\n",
       "          0.53690934, 0.35075817, 0.4286021 , 0.48734658, 0.68970858]),\n",
       "   'std_test_F1': array([0.00565935, 0.00843686, 0.01188239, 0.00560716, 0.00941433,\n",
       "          0.00775228, 0.00200104, 0.00922475, 0.01142193, 0.01073359,\n",
       "          0.00532619, 0.01006054, 0.0086232 , 0.00327805, 0.00856783,\n",
       "          0.010828  , 0.00788828, 0.00180178, 0.00779611, 0.01181285,\n",
       "          0.00650044, 0.0084544 , 0.01063355, 0.00928523, 0.00601068,\n",
       "          0.00486704, 0.00294799, 0.01142147, 0.00523583, 0.00394065]),\n",
       "   'rank_test_F1': array([ 3, 15, 21, 26,  5, 25, 28,  1, 17,  9, 14, 20, 12, 23, 22, 10, 29,\n",
       "          27, 19, 11,  4,  8, 24, 16,  2,  7, 30, 18, 13,  6]),\n",
       "   'split0_train_F1': array([0.94706612, 0.53567702, 0.48858494, 0.41434296, 0.95548245,\n",
       "          0.42075439, 0.39277816, 0.94931105, 0.49412661, 0.61548889,\n",
       "          0.5256407 , 0.47673069, 0.59442074, 0.42638494, 0.46965446,\n",
       "          0.62240157, 0.3717096 , 0.38875057, 0.49354068, 0.60309706,\n",
       "          0.94489925, 0.62479838, 0.414832  , 0.50488233, 0.94523823,\n",
       "          0.67492456, 0.38579536, 0.50943706, 0.59454289, 0.94231847]),\n",
       "   'split1_train_F1': array([0.94042411, 0.52347769, 0.48779139, 0.43315121, 0.95549159,\n",
       "          0.43194226, 0.40495353, 0.94288175, 0.50673498, 0.62407102,\n",
       "          0.53114998, 0.49632994, 0.6035427 , 0.44682734, 0.48504949,\n",
       "          0.62376467, 0.39579196, 0.40562589, 0.5011637 , 0.6033339 ,\n",
       "          0.94093709, 0.63191086, 0.44830707, 0.51094625, 0.93764271,\n",
       "          0.68003073, 0.40602351, 0.50453231, 0.5975932 , 0.93700438]),\n",
       "   'split2_train_F1': array([0.94818959, 0.52376318, 0.47876602, 0.42188158, 0.9576075 ,\n",
       "          0.42640499, 0.39346584, 0.94289095, 0.50694262, 0.61853027,\n",
       "          0.5232648 , 0.48687291, 0.59104679, 0.43857132, 0.4675209 ,\n",
       "          0.61714733, 0.40104431, 0.39361747, 0.49010683, 0.60558751,\n",
       "          0.94145304, 0.61554719, 0.42626438, 0.5140072 , 0.94604745,\n",
       "          0.67167523, 0.39770708, 0.50540036, 0.59917404, 0.93967362]),\n",
       "   'mean_train_F1': array([0.94522661, 0.5276393 , 0.48504745, 0.42312525, 0.95619385,\n",
       "          0.42636721, 0.39706584, 0.94502792, 0.5026014 , 0.61936339,\n",
       "          0.52668516, 0.48664452, 0.59633674, 0.4372612 , 0.47407495,\n",
       "          0.62110452, 0.38951529, 0.39599797, 0.49493707, 0.60400616,\n",
       "          0.9424298 , 0.62408548, 0.42980115, 0.50994526, 0.94297613,\n",
       "          0.6755435 , 0.39650865, 0.50645658, 0.59710337, 0.93966549]),\n",
       "   'std_train_F1': array([0.00342671, 0.00568472, 0.00445344, 0.00772863, 0.00099961,\n",
       "          0.00456751, 0.0055845 , 0.00302863, 0.00599318, 0.00355282,\n",
       "          0.00330275, 0.00800299, 0.00527827, 0.00839683, 0.0078089 ,\n",
       "          0.00285296, 0.01277181, 0.00709198, 0.00462068, 0.00112236,\n",
       "          0.00175883, 0.00669943, 0.01389308, 0.00379186, 0.00378574,\n",
       "          0.00343908, 0.00830147, 0.00213711, 0.00192212, 0.00216948]),\n",
       "   'split0_test_Log_Loss': array([-1.70968419, -2.73440418, -2.79921623, -2.76703589, -1.84538141,\n",
       "          -2.77865631, -2.9691439 , -1.70440266, -2.60765804, -2.52276163,\n",
       "          -2.72530312, -2.78791193, -2.4174867 , -2.89159741, -2.66807737,\n",
       "          -2.54804029, -2.84491769, -2.86998521, -2.78856799, -2.42252136,\n",
       "          -1.72268536, -2.54017965, -2.87913797, -2.61607488, -1.71615836,\n",
       "          -2.27792969, -2.9724125 , -2.61856395, -2.43483096, -1.71316827]),\n",
       "   'split1_test_Log_Loss': array([-1.71867553, -2.74517142, -2.7895015 , -2.78716696, -1.85992181,\n",
       "          -2.78918867, -2.95824061, -1.71257757, -2.61017037, -2.5572201 ,\n",
       "          -2.73244551, -2.79744387, -2.40339818, -2.88329189, -2.68332177,\n",
       "          -2.54187479, -2.86306372, -2.87280183, -2.78773274, -2.42929834,\n",
       "          -1.71699422, -2.53942731, -2.8856657 , -2.62398387, -1.71586631,\n",
       "          -2.2619735 , -2.96898388, -2.61106436, -2.42023112, -1.7317504 ]),\n",
       "   'split2_test_Log_Loss': array([-1.71937473, -2.75384635, -2.77803374, -2.78207177, -1.84050961,\n",
       "          -2.77317688, -2.95871996, -1.70718949, -2.59836426, -2.53456505,\n",
       "          -2.71545465, -2.79390151, -2.40476661, -2.8802241 , -2.67971028,\n",
       "          -2.54529841, -2.86566188, -2.85591149, -2.79080603, -2.40789482,\n",
       "          -1.71200178, -2.53990799, -2.87671557, -2.59265795, -1.71929347,\n",
       "          -2.27026907, -2.96088442, -2.6059102 , -2.41270598, -1.70344262]),\n",
       "   'mean_test_Log_Loss': array([-1.71589419, -2.74444102, -2.78895258, -2.77872988, -1.84860839,\n",
       "          -2.78034665, -2.96205373, -1.70805026, -2.60541147, -2.53815554,\n",
       "          -2.72441476, -2.79307412, -2.40857375, -2.88505756, -2.67701464,\n",
       "          -2.54507693, -2.85784433, -2.86625415, -2.78903229, -2.41992606,\n",
       "          -1.71724518, -2.53983892, -2.88050863, -2.61094025, -1.71710122,\n",
       "          -2.27007322, -2.96744577, -2.61186774, -2.42262742, -1.71613116]),\n",
       "   'std_test_Log_Loss': array([0.00441815, 0.00795533, 0.00865786, 0.00855838, 0.00823921,\n",
       "          0.00663732, 0.00503764, 0.00339588, 0.00507068, 0.01430944,\n",
       "          0.00695575, 0.00393932, 0.00635253, 0.00480864, 0.00651384,\n",
       "          0.00252482, 0.00923853, 0.00737804, 0.00129561, 0.00891853,\n",
       "          0.00436589, 0.00031133, 0.00377646, 0.01328152, 0.00154932,\n",
       "          0.00652315, 0.00483099, 0.00519784, 0.00919136, 0.01173109]),\n",
       "   'rank_test_Log_Loss': array([ 2, 19, 22, 20,  6, 21, 29,  1, 14, 11, 18, 24,  8, 28, 17, 13, 25,\n",
       "          26, 23,  9,  5, 12, 27, 15,  4,  7, 30, 16, 10,  3]),\n",
       "   'split0_train_Log_Loss': array([-1.23589549, -2.62223583, -2.718777  , -2.71120753, -1.34558103,\n",
       "          -2.71983124, -2.91764223, -1.2318026 , -2.52115712, -2.38807511,\n",
       "          -2.63243201, -2.70764043, -2.29107896, -2.82986735, -2.5931538 ,\n",
       "          -2.41525805, -2.79873694, -2.82146105, -2.70882309, -2.29415582,\n",
       "          -1.24368509, -2.40400858, -2.81670922, -2.52905378, -1.23991061,\n",
       "          -2.10237303, -2.92001765, -2.5316893 , -2.30637053, -1.2390015 ]),\n",
       "   'split1_train_Log_Loss': array([-1.23133422, -2.63769254, -2.70949296, -2.72873249, -1.34366993,\n",
       "          -2.73058316, -2.90692488, -1.22778645, -2.52411481, -2.41926676,\n",
       "          -2.64039864, -2.71725976, -2.27710849, -2.82123097, -2.60962633,\n",
       "          -2.40847067, -2.81536482, -2.82391641, -2.70778758, -2.29869385,\n",
       "          -1.2328112 , -2.40241084, -2.82213214, -2.53627707, -1.23225112,\n",
       "          -2.09063711, -2.91710315, -2.52455125, -2.29147199, -1.23766931]),\n",
       "   'split2_train_Log_Loss': array([-1.23456619, -2.63497819, -2.70300787, -2.72731238, -1.33423715,\n",
       "          -2.72072277, -2.90882174, -1.2287236 , -2.51856684, -2.40425897,\n",
       "          -2.6293045 , -2.71706293, -2.28277569, -2.82025743, -2.60949566,\n",
       "          -2.41592433, -2.8203396 , -2.80888586, -2.71384917, -2.28586345,\n",
       "          -1.23093717, -2.40822047, -2.81659424, -2.51263367, -1.23288929,\n",
       "          -2.10215272, -2.91228968, -2.52528017, -2.28851774, -1.22646234]),\n",
       "   'mean_train_Log_Loss': array([-1.23393197, -2.63163552, -2.71042595, -2.72241747, -1.3411627 ,\n",
       "          -2.72371239, -2.91112962, -1.22943755, -2.52127959, -2.40386695,\n",
       "          -2.63404505, -2.7139877 , -2.28365438, -2.82378525, -2.60409193,\n",
       "          -2.41321768, -2.81148045, -2.81808777, -2.71015328, -2.29290437,\n",
       "          -1.23581115, -2.40487996, -2.81847853, -2.52598817, -1.23501701,\n",
       "          -2.09838762, -2.91647016, -2.52717357, -2.29545342, -1.23437772]),\n",
       "   'std_train_Log_Loss': array([0.00191537, 0.00673833, 0.00647143, 0.0079478 , 0.00495887,\n",
       "          0.00487198, 0.00466977, 0.00171555, 0.00226661, 0.01273695,\n",
       "          0.00467057, 0.00448892, 0.00573717, 0.00431902, 0.00773461,\n",
       "          0.00336765, 0.00923706, 0.00658349, 0.00264736, 0.00531221,\n",
       "          0.00562004, 0.0024505 , 0.00258392, 0.00989279, 0.00347009,\n",
       "          0.00548118, 0.00318652, 0.00320693, 0.00781321, 0.00562338])},\n",
       "  {'n_estimators': 350,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 35},\n",
       "  7,\n",
       "  -1.7080502555349546),\n",
       " 'DecisionTreeClassifier_V001_PCA_70': ({'mean_fit_time': array([0.56581807, 0.13663411, 0.74866557, 0.0641617 , 0.17453321,\n",
       "          0.06482585, 0.35139306, 0.11735272, 0.11136905, 0.73137824,\n",
       "          0.75298691, 0.09042438, 0.04089022, 0.1815145 , 0.07180754,\n",
       "          0.32380064, 0.2991999 , 0.4364996 , 0.08743286, 0.08876252,\n",
       "          0.06416202, 0.84806633, 0.26329573, 0.27326934, 0.07945418,\n",
       "          0.57645957, 0.05684749, 1.06581791, 0.06017184, 0.34441249]),\n",
       "   'std_fit_time': array([0.01934337, 0.00850221, 0.0768247 , 0.00329093, 0.01020311,\n",
       "          0.00141051, 0.0041784 , 0.03482898, 0.00367156, 0.00409847,\n",
       "          0.00960048, 0.01716505, 0.00746321, 0.01626587, 0.00354968,\n",
       "          0.00261825, 0.02001304, 0.11448185, 0.00248782, 0.00081459,\n",
       "          0.00204928, 0.07338527, 0.03150694, 0.02399139, 0.00678062,\n",
       "          0.00430848, 0.00244328, 0.04043293, 0.01262455, 0.00542193]),\n",
       "   'mean_score_time': array([0.04887048, 0.03191519, 0.04521235, 0.02759266, 0.03989379,\n",
       "          0.02958806, 0.02958806, 0.02892303, 0.03025262, 0.04355017,\n",
       "          0.03258006, 0.03091764, 0.03656904, 0.03058537, 0.02825761,\n",
       "          0.0262634 , 0.02825824, 0.02925547, 0.02892296, 0.03025238,\n",
       "          0.03025301, 0.02792557, 0.03690139, 0.0511965 , 0.05817771,\n",
       "          0.03158204, 0.0309178 , 0.0285902 , 0.0339098 , 0.02659591]),\n",
       "   'std_score_time': array([0.01000598, 0.0085015 , 0.00248861, 0.00047086, 0.00924988,\n",
       "          0.00169536, 0.00204852, 0.00215424, 0.00204941, 0.00577666,\n",
       "          0.00517164, 0.00215454, 0.01011658, 0.00047008, 0.00124426,\n",
       "          0.00093999, 0.00094032, 0.00124411, 0.0008143 , 0.00047042,\n",
       "          0.00261732, 0.00162879, 0.00776837, 0.01750904, 0.03996246,\n",
       "          0.00285971, 0.0008141 , 0.00204893, 0.0008143 , 0.00094016]),\n",
       "   'param_min_samples_split': masked_array(data=[0.61, 0.39, 0.41000000000000003, 0.08, 0.3, 0.76, 0.76,\n",
       "                      0.74, 0.39, 0.43, 0.47000000000000003, 0.79, 0.84,\n",
       "                      0.31, 0.1, 0.78, 0.16, 0.6, 0.6900000000000001, 0.97,\n",
       "                      0.91, 0.35000000000000003, 0.18, 0.07, 0.18, 0.68,\n",
       "                      0.19, 0.21, 0.49, 0.84],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=[0.5, 0.5, 0.5, 'log2', 0.5, 0.5, 0.5, 'sqrt', 'log2',\n",
       "                      0.5, 0.5, 'log2', 'sqrt', 'sqrt', 'sqrt', 0.5, 'sqrt',\n",
       "                      0.5, 'sqrt', 'sqrt', 0.5, 0.5, 'sqrt', 0.5, 'sqrt',\n",
       "                      0.5, 'sqrt', 0.5, 'sqrt', 0.5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[20, None, 20, 20, None, 20, None, 20, None, None, 20,\n",
       "                      20, 20, 20, 20, 20, None, None, 20, 20, None, 20, 20,\n",
       "                      20, 20, 20, 20, None, None, 20],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_criterion': masked_array(data=['entropy', 'gini', 'entropy', 'gini', 'gini', 'gini',\n",
       "                      'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                      'entropy', 'gini', 'entropy', 'gini', 'entropy',\n",
       "                      'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                      'entropy', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                      'gini', 'entropy', 'gini', 'entropy'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, 'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', 'balanced', None, 'balanced',\n",
       "                      'balanced', 'balanced', None, None, None, None,\n",
       "                      'balanced', None, None, None, None, 'balanced',\n",
       "                      'balanced', 'balanced', 'balanced', None, 'balanced',\n",
       "                      'balanced', 'balanced', 'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'min_samples_split': 0.61,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.39,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.41000000000000003,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.08,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.3,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.76,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.76,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.74,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.39,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.43,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.47000000000000003,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.79,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.84,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.31,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.1,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.78,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.16,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.6,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.6900000000000001,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.97,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.91,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.35000000000000003,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.18,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.07,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.18,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.68,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.19,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.21,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.49,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.84,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'}],\n",
       "   'split0_test_Accuracy': array([0.08784511, 0.09178917, 0.09286483, 0.15883829, 0.09465758,\n",
       "          0.04697024, 0.04804589, 0.04732879, 0.06525636, 0.07959842,\n",
       "          0.0731445 , 0.0376479 , 0.07673001, 0.0856938 , 0.18788096,\n",
       "          0.06704912, 0.10684833, 0.0627465 , 0.06023664, 0.05593403,\n",
       "          0.06740767, 0.0731445 , 0.10792399, 0.22194335, 0.11473646,\n",
       "          0.08784511, 0.08856221, 0.1366081 , 0.06884188, 0.04625314]),\n",
       "   'split1_test_Accuracy': array([0.07972583, 0.10209235, 0.08549784, 0.12229437, 0.11760462,\n",
       "          0.04689755, 0.04689755, 0.03787879, 0.07251082, 0.08116883,\n",
       "          0.08044733, 0.0494228 , 0.06601732, 0.09307359, 0.16125541,\n",
       "          0.06782107, 0.09920635, 0.07792208, 0.06313131, 0.07251082,\n",
       "          0.06168831, 0.11075036, 0.11435786, 0.22186147, 0.13672439,\n",
       "          0.08008658, 0.13095238, 0.13961039, 0.06637807, 0.04329004]),\n",
       "   'split2_test_Accuracy': array([0.0818544 , 0.09960159, 0.08801159, 0.16551974, 0.10141253,\n",
       "          0.04599783, 0.04780876, 0.04889533, 0.05939877, 0.07787034,\n",
       "          0.08221659, 0.0496197 , 0.07207534, 0.10068816, 0.16008693,\n",
       "          0.07062658, 0.0876494 , 0.06664252, 0.05903658, 0.05613908,\n",
       "          0.06700471, 0.09416878, 0.12097066, 0.23650851, 0.10938066,\n",
       "          0.08438971, 0.10503441, 0.10901847, 0.07388627, 0.04780876]),\n",
       "   'mean_test_Accuracy': array([0.08315309, 0.09781303, 0.08880077, 0.14888248, 0.10454218,\n",
       "          0.04662341, 0.04758472, 0.04470079, 0.06572939, 0.07954819,\n",
       "          0.07858688, 0.04554194, 0.0716174 , 0.09312665, 0.16979092,\n",
       "          0.06849315, 0.09793319, 0.06909397, 0.06080269, 0.06152367,\n",
       "          0.0653689 , 0.092646  , 0.11439558, 0.22674838, 0.12028359,\n",
       "          0.0841144 , 0.10814708, 0.1284547 , 0.06969478, 0.04578226]),\n",
       "   'std_test_Accuracy': array([0.0034424 , 0.0043957 , 0.00306199, 0.01898748, 0.00963477,\n",
       "          0.0004418 , 0.0004952 , 0.00486352, 0.00535626, 0.00134525,\n",
       "          0.00393071, 0.00560515, 0.00439041, 0.00612256, 0.01285234,\n",
       "          0.00153602, 0.00789071, 0.00643866, 0.00171709, 0.00776534,\n",
       "          0.00260636, 0.01540784, 0.00532724, 0.0068773 , 0.01182312,\n",
       "          0.00317703, 0.01746417, 0.01375008, 0.00312038, 0.00187235]),\n",
       "   'rank_test_Accuracy': array([15, 10, 13,  3,  8, 27, 26, 30, 22, 16, 17, 29, 18, 11,  2, 21,  9,\n",
       "          20, 25, 24, 23, 12,  6,  1,  5, 14,  7,  4, 19, 28]),\n",
       "   'split0_train_Accuracy': array([0.08621001, 0.09831918, 0.0957889 , 0.17422736, 0.10030725,\n",
       "          0.04717152, 0.04825592, 0.04735225, 0.06885957, 0.08151093,\n",
       "          0.07536599, 0.03885776, 0.07464305, 0.09831918, 0.20748238,\n",
       "          0.06416049, 0.12271824, 0.06651003, 0.06090728, 0.05602747,\n",
       "          0.0663293 , 0.07446232, 0.11422375, 0.24543647, 0.1219953 ,\n",
       "          0.08621001, 0.09940358, 0.13844207, 0.07157058, 0.04699078]),\n",
       "   'split1_train_Accuracy': array([0.08144144, 0.10306306, 0.08414414, 0.14684685, 0.11189189,\n",
       "          0.04738739, 0.04738739, 0.03657658, 0.07855856, 0.07873874,\n",
       "          0.08108108, 0.05297297, 0.06612613, 0.09567568, 0.18594595,\n",
       "          0.07027027, 0.09657658, 0.07963964, 0.0645045 , 0.07531532,\n",
       "          0.06522523, 0.11279279, 0.11855856, 0.25891892, 0.14576577,\n",
       "          0.08540541, 0.13855856, 0.14036036, 0.07081081, 0.04504505]),\n",
       "   'split2_train_Accuracy': array([0.08056105, 0.09980219, 0.08883294, 0.18899479, 0.10951268,\n",
       "          0.046934  , 0.0476533 , 0.05394713, 0.06347779, 0.08217946,\n",
       "          0.08577594, 0.04783312, 0.07121021, 0.10339867, 0.17892465,\n",
       "          0.0703111 , 0.09566625, 0.06401726, 0.06096026, 0.05592519,\n",
       "          0.06689444, 0.09566625, 0.131631  , 0.27602949, 0.12731523,\n",
       "          0.08487682, 0.11167056, 0.11976263, 0.07570581, 0.0476533 ]),\n",
       "   'mean_train_Accuracy': array([0.0827375 , 0.10039481, 0.08958866, 0.170023  , 0.10723727,\n",
       "          0.0471643 , 0.04776554, 0.04595865, 0.07029864, 0.08080971,\n",
       "          0.080741  , 0.04655462, 0.0706598 , 0.09913117, 0.19078433,\n",
       "          0.06824729, 0.10498702, 0.07005564, 0.06212402, 0.06242266,\n",
       "          0.06614966, 0.09430712, 0.1214711 , 0.26012829, 0.1316921 ,\n",
       "          0.08549741, 0.11654423, 0.13285502, 0.07269573, 0.04656304]),\n",
       "   'std_train_Accuracy': array([0.0024816 , 0.0019815 , 0.00478389, 0.01746176, 0.0049956 ,\n",
       "          0.00018516, 0.00036335, 0.00715964, 0.00624022, 0.00148962,\n",
       "          0.00425664, 0.00583299, 0.00349874, 0.00320475, 0.01215026,\n",
       "          0.00288985, 0.01254337, 0.00685289, 0.0016834 , 0.00911658,\n",
       "          0.00069319, 0.01567783, 0.00739889, 0.01251879, 0.01018582,\n",
       "          0.00054815, 0.01635222, 0.00929078, 0.00215093, 0.00110694]),\n",
       "   'split0_test_F1': array([0.01797419, 0.02024088, 0.02394863, 0.11064775, 0.02700192,\n",
       "          0.0052436 , 0.00479541, 0.00475288, 0.0114737 , 0.0154747 ,\n",
       "          0.0132066 , 0.00417961, 0.02077424, 0.02992973, 0.13405936,\n",
       "          0.01138125, 0.05430085, 0.01017589, 0.00930214, 0.00592578,\n",
       "          0.01188682, 0.01252569, 0.03190996, 0.15497728, 0.05288171,\n",
       "          0.01797419, 0.0351045 , 0.04632182, 0.01864077, 0.00420902]),\n",
       "   'split1_test_F1': array([0.01614464, 0.03104304, 0.01671315, 0.07999052, 0.03787868,\n",
       "          0.00500006, 0.00479796, 0.0039391 , 0.01899803, 0.01734042,\n",
       "          0.01693074, 0.00894962, 0.01756915, 0.02691115, 0.10452006,\n",
       "          0.009211  , 0.03627895, 0.01719877, 0.01203915, 0.0116911 ,\n",
       "          0.01009136, 0.02928661, 0.04633828, 0.17362701, 0.07038446,\n",
       "          0.01549169, 0.05676346, 0.04766222, 0.01449464, 0.00496275]),\n",
       "   'split2_test_F1': array([0.01675388, 0.02415454, 0.01954625, 0.11845262, 0.03886999,\n",
       "          0.00442148, 0.00520189, 0.0061777 , 0.01585399, 0.01355783,\n",
       "          0.01534155, 0.00536622, 0.01013004, 0.02335264, 0.11259677,\n",
       "          0.01306295, 0.03574898, 0.01093876, 0.00954492, 0.00596815,\n",
       "          0.01209045, 0.02167696, 0.0508436 , 0.18959284, 0.05948621,\n",
       "          0.01682342, 0.03072319, 0.03771025, 0.0153248 , 0.00520189]),\n",
       "   'mean_test_F1': array([0.01695991, 0.02513744, 0.02007796, 0.10302547, 0.03456238,\n",
       "          0.00488972, 0.00493112, 0.00495453, 0.01543326, 0.0154602 ,\n",
       "          0.0151554 , 0.00616215, 0.0161752 , 0.02674218, 0.11709936,\n",
       "          0.01121629, 0.04214291, 0.01276826, 0.01029437, 0.00786022,\n",
       "          0.01135632, 0.02114476, 0.04299757, 0.17267382, 0.06090293,\n",
       "          0.01676549, 0.04086536, 0.04391123, 0.01615958, 0.00478949]),\n",
       "   'std_test_F1': array([0.00076174, 0.0044691 , 0.00298095, 0.01658836, 0.00538294,\n",
       "          0.00034462, 0.00019079, 0.00092382, 0.00308963, 0.00154218,\n",
       "          0.00152779, 0.00202868, 0.00445645, 0.00268819, 0.01248332,\n",
       "          0.00157478, 0.00863456, 0.00314661, 0.00123706, 0.00270743,\n",
       "          0.00089784, 0.00686085, 0.0080834 , 0.01415016, 0.00722312,\n",
       "          0.00101548, 0.01137711, 0.00440356, 0.0017938 , 0.00042349]),\n",
       "   'rank_test_F1': array([14, 11, 13,  3,  9, 29, 28, 27, 19, 18, 20, 26, 16, 10,  2, 23,  7,\n",
       "          21, 24, 25, 22, 12,  6,  1,  4, 15,  8,  5, 17, 30]),\n",
       "   'split0_train_F1': array([0.0177829 , 0.02218333, 0.02616692, 0.121313  , 0.02841315,\n",
       "          0.00534098, 0.00479506, 0.00478701, 0.01256851, 0.01637404,\n",
       "          0.01408335, 0.00439923, 0.01981678, 0.03418121, 0.14802801,\n",
       "          0.01094164, 0.06148747, 0.01079298, 0.00958134, 0.00594507,\n",
       "          0.01165302, 0.01295823, 0.033989  , 0.17484726, 0.05497537,\n",
       "          0.0177829 , 0.04336189, 0.04712712, 0.01985061, 0.00428199]),\n",
       "   'split1_train_F1': array([0.01654795, 0.03402316, 0.01611726, 0.09696285, 0.03469608,\n",
       "          0.0051346 , 0.00494539, 0.00369132, 0.02042235, 0.01548543,\n",
       "          0.01724735, 0.00968111, 0.01881798, 0.02701129, 0.12398872,\n",
       "          0.00954031, 0.03518484, 0.0172957 , 0.01223486, 0.01216962,\n",
       "          0.01069111, 0.02958453, 0.04810662, 0.20275891, 0.075484  ,\n",
       "          0.01656063, 0.06178363, 0.04696952, 0.01790411, 0.00507027]),\n",
       "   'split2_train_F1': array([0.01641799, 0.02462482, 0.01954517, 0.13336769, 0.04479054,\n",
       "          0.00450415, 0.00512493, 0.00752983, 0.01760369, 0.01437025,\n",
       "          0.0166411 , 0.00517193, 0.00997498, 0.02403235, 0.12712699,\n",
       "          0.01296071, 0.03866907, 0.01041181, 0.00978485, 0.00592396,\n",
       "          0.01200236, 0.02285411, 0.05543273, 0.22405304, 0.06755534,\n",
       "          0.01681293, 0.03319184, 0.04208463, 0.01616582, 0.00512493]),\n",
       "   'mean_train_F1': array([0.01691628, 0.02694377, 0.02060978, 0.11721451, 0.03596659,\n",
       "          0.00499324, 0.00495513, 0.00533605, 0.01686485, 0.01540991,\n",
       "          0.0159906 , 0.00641742, 0.01620325, 0.02840828, 0.13304791,\n",
       "          0.01114755, 0.0451138 , 0.0128335 , 0.01053368, 0.00801288,\n",
       "          0.01144883, 0.02179896, 0.04584278, 0.20055307, 0.0660049 ,\n",
       "          0.01705215, 0.04611245, 0.04539376, 0.01797351, 0.00482573]),\n",
       "   'std_train_F1': array([0.00061508, 0.00510415, 0.00417125, 0.01514213, 0.00674613,\n",
       "          0.00035596, 0.00013484, 0.00161444, 0.0032486 , 0.00081979,\n",
       "          0.00137115, 0.00232924, 0.00442289, 0.00425938, 0.01066973,\n",
       "          0.00140394, 0.01166499, 0.00315909, 0.00120578, 0.00293927,\n",
       "          0.00055444, 0.00682854, 0.00889952, 0.02014864, 0.00844409,\n",
       "          0.00052688, 0.01183348, 0.00234079, 0.00150511, 0.00038513]),\n",
       "   'split0_test_Log_Loss': array([-3.20293747, -3.04924245, -3.11771583, -3.54085127, -3.12051541,\n",
       "          -3.37828258, -3.41795749, -3.37993035, -3.48725339, -3.22783764,\n",
       "          -3.23143653, -3.6064685 , -3.42415115, -3.42713568, -3.18490042,\n",
       "          -3.35469483, -3.53954311, -3.39607978, -3.54084296, -3.56096108,\n",
       "          -3.34698334, -3.35072082, -3.25181386, -3.10773389, -3.3185053 ,\n",
       "          -3.20293747, -3.42645408, -2.9144626 , -3.36609015, -3.421774  ]),\n",
       "   'split1_test_Log_Loss': array([-3.20119099, -3.08771344, -3.12731453, -3.91225851, -3.09274703,\n",
       "          -3.3984875 , -3.39596418, -3.58548249, -3.32900631, -3.21740235,\n",
       "          -3.15845336, -3.58395282, -3.50220112, -3.1408615 , -3.38022918,\n",
       "          -3.40790054, -3.54263359, -3.23493913, -3.55840642, -3.47622666,\n",
       "          -3.3788488 , -3.02681462, -3.39350238, -3.15877631, -3.24835134,\n",
       "          -3.21407073, -3.29728534, -2.98755213, -3.35887111, -3.53969727]),\n",
       "   'split2_test_Log_Loss': array([-3.19770315, -3.02879794, -3.18017344, -3.34731709, -3.18105452,\n",
       "          -3.4278748 , -3.36044795, -3.54459609, -3.51024717, -3.14771791,\n",
       "          -3.09302627, -3.58993545, -3.40316625, -3.17835627, -3.52107619,\n",
       "          -3.38962311, -3.39615529, -3.36743707, -3.58505684, -3.52620264,\n",
       "          -3.36733775, -2.94786872, -3.39833997, -3.05369464, -3.41124239,\n",
       "          -3.12932878, -3.0937931 , -3.13703895, -3.38163442, -3.36044795]),\n",
       "   'mean_test_Log_Loss': array([-3.20061914, -3.05527397, -3.14163473, -3.60035536, -3.13135109,\n",
       "          -3.40146597, -3.39155166, -3.50302968, -3.44217107, -3.1977803 ,\n",
       "          -3.16120581, -3.5934835 , -3.44318686, -3.24924191, -3.3614965 ,\n",
       "          -3.38400548, -3.49300058, -3.33290213, -3.56136212, -3.52120479,\n",
       "          -3.36435051, -3.1091752 , -3.34762246, -3.1068071 , -3.325905  ,\n",
       "          -3.18222464, -3.27306154, -3.01265264, -3.36884268, -3.4407072 ]),\n",
       "   'std_test_Log_Loss': array([0.00217513, 0.0243983 , 0.0274372 , 0.23416634, 0.0368153 ,\n",
       "          0.02035844, 0.02368826, 0.08897307, 0.08052551, 0.03553202,\n",
       "          0.05654868, 0.00953625, 0.0425779 , 0.12722209, 0.13790311,\n",
       "          0.02210379, 0.0682511 , 0.07021373, 0.01817371, 0.03481161,\n",
       "          0.01319319, 0.1744859 , 0.06805043, 0.04284635, 0.06661738,\n",
       "          0.03754838, 0.13690561, 0.0925967 , 0.00948402, 0.07430508]),\n",
       "   'rank_test_Log_Loss': array([10,  2,  6, 30,  5, 21, 20, 26, 23,  9,  7, 29, 24, 11, 16, 19, 25,\n",
       "          14, 28, 27, 17,  4, 15,  3, 13,  8, 12,  1, 18, 22]),\n",
       "   'split0_train_Log_Loss': array([-3.18390683, -2.95529226, -3.01544558, -2.81153446, -2.9790032 ,\n",
       "          -3.37497501, -3.4067254 , -3.36258565, -3.43073638, -3.16337623,\n",
       "          -3.16419797, -3.57920656, -3.40992317, -3.35750806, -2.59925444,\n",
       "          -3.337121  , -3.07866102, -3.36115059, -3.52695587, -3.54690247,\n",
       "          -3.34026081, -3.30990714, -3.03508366, -2.42773664, -3.04943183,\n",
       "          -3.18390683, -3.24096332, -2.79023661, -3.32626161, -3.38700443]),\n",
       "   'split1_train_Log_Loss': array([-3.16308627, -2.90819366, -3.03115252, -3.03672998, -2.87828214,\n",
       "          -3.3616537 , -3.35995898, -3.58322272, -3.25907257, -3.07845677,\n",
       "          -3.10134872, -3.54903987, -3.47162338, -3.07580021, -2.76520703,\n",
       "          -3.37422348, -3.23566944, -3.18343162, -3.55383262, -3.44770941,\n",
       "          -3.36189927, -2.90442033, -3.16834479, -2.40460424, -2.92725778,\n",
       "          -3.12521603, -2.98367788, -2.80189403, -3.25327393, -3.4757947 ]),\n",
       "   'split2_train_Log_Loss': array([-3.16475619, -2.95788006, -3.11741316, -2.69999642, -2.95984293,\n",
       "          -3.39301844, -3.37123354, -3.4813919 , -3.48466389, -3.07800772,\n",
       "          -3.03201411, -3.58206197, -3.39434545, -3.10714732, -2.81982066,\n",
       "          -3.38138656, -3.18514468, -3.36661159, -3.56542948, -3.52495267,\n",
       "          -3.34843914, -2.94202463, -3.05107096, -2.36523071, -3.09121245,\n",
       "          -3.1425902 , -2.94173599, -2.93306196, -3.335421  , -3.37123354]),\n",
       "   'mean_train_Log_Loss': array([-3.1705831 , -2.94045533, -3.05467042, -2.84942029, -2.93904275,\n",
       "          -3.37654905, -3.37930597, -3.47573342, -3.39149095, -3.10661357,\n",
       "          -3.09918693, -3.5701028 , -3.42529733, -3.18015186, -2.72809404,\n",
       "          -3.36424368, -3.16649172, -3.30373126, -3.54873932, -3.50652152,\n",
       "          -3.35019974, -3.05211736, -3.08483314, -2.39919053, -3.02263402,\n",
       "          -3.15057102, -3.05545906, -2.84173087, -3.30498551, -3.41134422]),\n",
       "   'std_train_Log_Loss': array([0.00944594, 0.02283689, 0.04482682, 0.14005683, 0.0436705 ,\n",
       "          0.01285289, 0.01992733, 0.09016353, 0.09618736, 0.04013768,\n",
       "          0.05398548, 0.01493929, 0.03336908, 0.12606103, 0.09379195,\n",
       "          0.0194003 , 0.06544138, 0.08509391, 0.0161144 , 0.04254093,\n",
       "          0.00892116, 0.18293022, 0.05941126, 0.02580348, 0.06956472,\n",
       "          0.02461602, 0.13228417, 0.06475595, 0.03675631, 0.04602593])},\n",
       "  {'min_samples_split': 0.21,\n",
       "   'max_features': 0.5,\n",
       "   'max_depth': None,\n",
       "   'criterion': 'entropy',\n",
       "   'class_weight': 'balanced'},\n",
       "  27,\n",
       "  -3.0126526371290887),\n",
       " 'KNeighborsClassifier_V001_PCA_70': ({'mean_fit_time': array([0.04223021, 0.02227553, 0.04554558, 0.04886921, 0.02194095,\n",
       "          0.02360455, 0.04621037, 0.05019959, 0.02327029, 0.02160875,\n",
       "          0.0232722 , 0.05618294, 0.04654225, 0.04454732, 0.04654264,\n",
       "          0.05119578, 0.04920268, 0.04953496, 0.02194158, 0.04222075,\n",
       "          0.05551847, 0.04554423, 0.04853725, 0.04787207, 0.02260582,\n",
       "          0.04687341, 0.02526601, 0.05152901, 0.02360415, 0.04753844]),\n",
       "   'std_fit_time': array([4.63694260e-04, 4.69461150e-04, 4.70021816e-04, 8.14004101e-04,\n",
       "          8.13809542e-04, 9.39762738e-04, 1.69574747e-03, 4.01718222e-03,\n",
       "          4.70078102e-04, 9.40774101e-04, 1.24383669e-03, 8.31803492e-03,\n",
       "          1.24383659e-03, 9.40380565e-04, 3.08319220e-03, 1.24472861e-03,\n",
       "          1.10560392e-02, 1.69551328e-03, 9.79807218e-07, 1.87997427e-03,\n",
       "          1.01164443e-02, 4.69741492e-04, 1.24400648e-03, 1.41090798e-03,\n",
       "          4.70471261e-04, 4.95388967e-03, 1.87986184e-03, 4.01672184e-03,\n",
       "          4.70696165e-04, 3.84876938e-03]),\n",
       "   'mean_score_time': array([ 9.93709699,  1.40258249, 10.27021503, 12.70803308,  1.37299712,\n",
       "           1.36169378, 11.9843003 , 12.20238368,  1.33609557,  1.35138822,\n",
       "           1.34407306, 11.99992537, 12.38788819, 10.10199833, 10.27686405,\n",
       "          12.54480211,  9.86496536, 12.60065214,  1.03822478, 10.13856681,\n",
       "          12.24327477, 12.22698553, 12.2452693 , 12.01687988,  1.47771684,\n",
       "          10.25791526,  1.47671962, 12.66980139,  1.41122754,  9.46802664]),\n",
       "   'std_score_time': array([0.16408208, 0.01875438, 0.13031207, 0.3440137 , 0.05125939,\n",
       "          0.04047464, 0.04641871, 0.03495906, 0.02778652, 0.02973086,\n",
       "          0.02047707, 0.03386066, 0.10243303, 0.00960066, 0.05312695,\n",
       "          0.01885904, 0.13806083, 0.18311227, 0.01412723, 0.02034669,\n",
       "          0.06832066, 0.08842101, 0.16024704, 0.12074831, 0.06412732,\n",
       "          0.07451905, 0.12405817, 0.22914763, 0.08117544, 0.34201125]),\n",
       "   'param_weights': masked_array(data=['distance', 'distance', 'uniform', 'distance',\n",
       "                      'distance', 'uniform', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'distance'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[7, 6, 7, 5, 5, 6, 6, 5, 5, 8, 4, 6, 7, 3, 8, 4, 4, 4,\n",
       "                      3, 3, 7, 3, 8, 5, 7, 5, 8, 8, 4, 5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['ball_tree', 'brute', 'ball_tree', 'auto', 'brute',\n",
       "                      'brute', 'kd_tree', 'kd_tree', 'brute', 'brute',\n",
       "                      'brute', 'kd_tree', 'kd_tree', 'ball_tree',\n",
       "                      'ball_tree', 'kd_tree', 'ball_tree', 'auto', 'brute',\n",
       "                      'ball_tree', 'auto', 'auto', 'auto', 'auto', 'brute',\n",
       "                      'ball_tree', 'brute', 'kd_tree', 'brute', 'ball_tree'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'distance',\n",
       "     'n_neighbors': 7,\n",
       "     'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'}],\n",
       "   'split0_test_Accuracy': array([0.72176407, 0.73001076, 0.67479383, 0.73359627, 0.73359627,\n",
       "          0.68698458, 0.73001076, 0.69451416, 0.69451416, 0.66260308,\n",
       "          0.69774113, 0.68698458, 0.67479383, 0.71423449, 0.71853711,\n",
       "          0.69774113, 0.69774113, 0.69774113, 0.71423449, 0.74757978,\n",
       "          0.72176407, 0.71423449, 0.66260308, 0.69451416, 0.72176407,\n",
       "          0.69451416, 0.71853711, 0.71853711, 0.74291861, 0.73359627]),\n",
       "   'split1_test_Accuracy': array([0.71897547, 0.73124098, 0.67424242, 0.73629149, 0.73629149,\n",
       "          0.67965368, 0.73124098, 0.69155844, 0.69155844, 0.67352092,\n",
       "          0.71103896, 0.67965368, 0.67424242, 0.72113997, 0.72294372,\n",
       "          0.71103896, 0.71103896, 0.71103896, 0.72113997, 0.75901876,\n",
       "          0.71897547, 0.72113997, 0.67352092, 0.69155844, 0.71897547,\n",
       "          0.69155844, 0.72294372, 0.72294372, 0.754329  , 0.73629149]),\n",
       "   'split2_test_Accuracy': array([0.70952553, 0.70952553, 0.6667874 , 0.72075335, 0.72075335,\n",
       "          0.67149583, 0.70952553, 0.67801521, 0.67801521, 0.66388989,\n",
       "          0.69177834, 0.67149583, 0.6667874 , 0.70336834, 0.7048171 ,\n",
       "          0.69177834, 0.69177834, 0.69177834, 0.70336834, 0.74139804,\n",
       "          0.70952553, 0.70336834, 0.66388989, 0.67801521, 0.70952553,\n",
       "          0.67801521, 0.7048171 , 0.7048171 , 0.73524085, 0.72075335]),\n",
       "   'mean_test_Accuracy': array([0.71677481, 0.72362413, 0.67195386, 0.73023312, 0.73023312,\n",
       "          0.67940399, 0.72362413, 0.68805576, 0.68805576, 0.66666667,\n",
       "          0.70019226, 0.67940399, 0.67195386, 0.71292958, 0.71545302,\n",
       "          0.70019226, 0.70019226, 0.70019226, 0.71292958, 0.7493391 ,\n",
       "          0.71677481, 0.71292958, 0.66666667, 0.68805576, 0.71677481,\n",
       "          0.68805576, 0.71545302, 0.71545302, 0.74417207, 0.73023312]),\n",
       "   'std_test_Accuracy': array([0.00523362, 0.00994691, 0.00364738, 0.00676989, 0.00676989,\n",
       "          0.00632678, 0.00994691, 0.0071772 , 0.0071772 , 0.00487248,\n",
       "          0.00804299, 0.00632678, 0.00364738, 0.0073044 , 0.0077077 ,\n",
       "          0.00804299, 0.00804299, 0.00804299, 0.0073044 , 0.00729166,\n",
       "          0.00523362, 0.0073044 , 0.00487248, 0.0071772 , 0.00523362,\n",
       "          0.0071772 , 0.0077077 , 0.0077077 , 0.00783287, 0.00676989]),\n",
       "   'rank_test_Accuracy': array([ 8,  6, 27,  3,  3, 25,  6, 21, 21, 29, 17, 25, 27, 14, 11, 17, 17,\n",
       "          17, 14,  1,  8, 14, 29, 21,  8, 21, 11, 11,  2,  3]),\n",
       "   'split0_train_Accuracy': array([1.        , 1.        , 0.77390204, 1.        , 1.        ,\n",
       "          0.79125249, 1.        , 0.80968733, 0.80968733, 0.76125068,\n",
       "          0.83426712, 0.79125249, 0.77390204, 0.8630038 , 1.        ,\n",
       "          0.83426712, 0.83426712, 0.83426712, 0.8630038 , 1.        ,\n",
       "          1.        , 0.8630038 , 0.76125068, 0.80968733, 1.        ,\n",
       "          0.80968733, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'split1_train_Accuracy': array([1.        , 1.        , 0.78666667, 1.        , 1.        ,\n",
       "          0.80216216, 1.        , 0.82342342, 0.82342342, 0.77333333,\n",
       "          0.83765766, 0.80216216, 0.78666667, 0.86936937, 1.        ,\n",
       "          0.83765766, 0.83765766, 0.83765766, 0.86936937, 1.        ,\n",
       "          1.        , 0.86936937, 0.77333333, 0.82342342, 1.        ,\n",
       "          0.82342342, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'split2_train_Accuracy': array([1.        , 1.        , 0.78097464, 1.        , 1.        ,\n",
       "          0.79931667, 1.        , 0.8207157 , 0.8207157 , 0.76820716,\n",
       "          0.84175508, 0.79931667, 0.78097464, 0.87052688, 1.        ,\n",
       "          0.84175508, 0.84175508, 0.84175508, 0.87052688, 1.        ,\n",
       "          1.        , 0.87052688, 0.76820716, 0.8207157 , 1.        ,\n",
       "          0.8207157 , 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'mean_train_Accuracy': array([1.        , 1.        , 0.78051445, 1.        , 1.        ,\n",
       "          0.79757711, 1.        , 0.81794215, 0.81794215, 0.76759706,\n",
       "          0.83789329, 0.79757711, 0.78051445, 0.86763335, 1.        ,\n",
       "          0.83789329, 0.83789329, 0.83789329, 0.86763335, 1.        ,\n",
       "          1.        , 0.86763335, 0.76759706, 0.81794215, 1.        ,\n",
       "          0.81794215, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'std_train_Accuracy': array([0.        , 0.        , 0.00522129, 0.        , 0.        ,\n",
       "          0.00462059, 0.        , 0.00594079, 0.00594079, 0.00495155,\n",
       "          0.00306148, 0.00462059, 0.00522129, 0.00330752, 0.        ,\n",
       "          0.00306148, 0.00306148, 0.00306148, 0.00330752, 0.        ,\n",
       "          0.        , 0.00330752, 0.00495155, 0.00594079, 0.        ,\n",
       "          0.00594079, 0.        , 0.        , 0.        , 0.        ]),\n",
       "   'split0_test_F1': array([0.71983895, 0.72812212, 0.67246198, 0.73232226, 0.73232226,\n",
       "          0.68480045, 0.72812212, 0.69368201, 0.69368201, 0.66055962,\n",
       "          0.69717254, 0.68480045, 0.67246198, 0.71348156, 0.71617761,\n",
       "          0.69717254, 0.69717254, 0.69717254, 0.71348156, 0.74633313,\n",
       "          0.71983895, 0.71348156, 0.66055962, 0.69368201, 0.71983895,\n",
       "          0.69368201, 0.71617761, 0.71617761, 0.74172464, 0.73232226]),\n",
       "   'split1_test_F1': array([0.71727149, 0.73016384, 0.67303149, 0.73597631, 0.73597631,\n",
       "          0.67899945, 0.73016384, 0.69127921, 0.69127921, 0.67275318,\n",
       "          0.71078344, 0.67899945, 0.67303149, 0.72208439, 0.7215907 ,\n",
       "          0.71078344, 0.71078344, 0.71078344, 0.72208439, 0.75876637,\n",
       "          0.71727149, 0.72208439, 0.67275318, 0.69127921, 0.71727149,\n",
       "          0.69127921, 0.7215907 , 0.7215907 , 0.75401414, 0.73597631]),\n",
       "   'split2_test_F1': array([0.71005479, 0.71008646, 0.6685067 , 0.72085906, 0.72085906,\n",
       "          0.67395399, 0.71008646, 0.67948866, 0.67948866, 0.66576608,\n",
       "          0.69250837, 0.67395399, 0.6685067 , 0.70414803, 0.70499006,\n",
       "          0.69250837, 0.69250837, 0.69250837, 0.70414803, 0.74194278,\n",
       "          0.71005479, 0.70414803, 0.66576608, 0.67948866, 0.71005479,\n",
       "          0.67948866, 0.70499006, 0.70499006, 0.73543859, 0.72085906]),\n",
       "   'mean_test_F1': array([0.71573764, 0.72281849, 0.67133943, 0.72973624, 0.72973624,\n",
       "          0.67926963, 0.72281849, 0.68817271, 0.68817271, 0.66634856,\n",
       "          0.7001588 , 0.67926963, 0.67133943, 0.71325051, 0.71426897,\n",
       "          0.7001588 , 0.7001588 , 0.7001588 , 0.71325051, 0.74901796,\n",
       "          0.71573764, 0.71325051, 0.66634856, 0.68817271, 0.71573764,\n",
       "          0.68817271, 0.71426897, 0.71426897, 0.74373265, 0.72973624]),\n",
       "   'std_test_F1': array([0.00413949, 0.00901001, 0.00200953, 0.00643089, 0.00643089,\n",
       "          0.0044329 , 0.00901001, 0.00619729, 0.00619729, 0.00500068,\n",
       "          0.00774645, 0.0044329 , 0.00200953, 0.00731441, 0.00690233,\n",
       "          0.00774645, 0.00774645, 0.00774645, 0.00731441, 0.00711884,\n",
       "          0.00413949, 0.00731441, 0.00500068, 0.00619729, 0.00413949,\n",
       "          0.00619729, 0.00690233, 0.00690233, 0.00770618, 0.00643089]),\n",
       "   'rank_test_F1': array([ 8,  6, 27,  3,  3, 25,  6, 21, 21, 29, 17, 25, 27, 14, 11, 17, 17,\n",
       "          17, 14,  1,  8, 14, 29, 21,  8, 21, 11, 11,  2,  3]),\n",
       "   'split0_train_F1': array([1.        , 1.        , 0.77309251, 1.        , 1.        ,\n",
       "          0.79100267, 1.        , 0.80959216, 0.80959216, 0.76089551,\n",
       "          0.83438631, 0.79100267, 0.77309251, 0.86298171, 1.        ,\n",
       "          0.83438631, 0.83438631, 0.83438631, 0.86298171, 1.        ,\n",
       "          1.        , 0.86298171, 0.76089551, 0.80959216, 1.        ,\n",
       "          0.80959216, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'split1_train_F1': array([1.        , 1.        , 0.78626368, 1.        , 1.        ,\n",
       "          0.80190185, 1.        , 0.82300729, 0.82300729, 0.7731855 ,\n",
       "          0.83720127, 0.80190185, 0.78626368, 0.86948797, 1.        ,\n",
       "          0.83720127, 0.83720127, 0.83720127, 0.86948797, 1.        ,\n",
       "          1.        , 0.86948797, 0.7731855 , 0.82300729, 1.        ,\n",
       "          0.82300729, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'split2_train_F1': array([1.        , 1.        , 0.78069205, 1.        , 1.        ,\n",
       "          0.79884932, 1.        , 0.82038273, 0.82038273, 0.76817662,\n",
       "          0.84163386, 0.79884932, 0.78069205, 0.87067412, 1.        ,\n",
       "          0.84163386, 0.84163386, 0.84163386, 0.87067412, 1.        ,\n",
       "          1.        , 0.87067412, 0.76817662, 0.82038273, 1.        ,\n",
       "          0.82038273, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'mean_train_F1': array([1.        , 1.        , 0.78001608, 1.        , 1.        ,\n",
       "          0.79725128, 1.        , 0.81766073, 0.81766073, 0.76741921,\n",
       "          0.83774048, 0.79725128, 0.78001608, 0.8677146 , 1.        ,\n",
       "          0.83774048, 0.83774048, 0.83774048, 0.8677146 , 1.        ,\n",
       "          1.        , 0.8677146 , 0.76741921, 0.81766073, 1.        ,\n",
       "          0.81766073, 1.        , 1.        , 1.        , 1.        ]),\n",
       "   'std_train_F1': array([0.        , 0.        , 0.00539831, 0.        , 0.        ,\n",
       "          0.00459081, 0.        , 0.00580508, 0.00580508, 0.00504587,\n",
       "          0.00298327, 0.00459081, 0.00539831, 0.00338151, 0.        ,\n",
       "          0.00298327, 0.00298327, 0.00298327, 0.00338151, 0.        ,\n",
       "          0.        , 0.00338151, 0.00504587, 0.00580508, 0.        ,\n",
       "          0.00580508, 0.        , 0.        , 0.        , 0.        ]),\n",
       "   'split0_test_Log_Loss': array([-2.96668585, -3.17010475, -3.02448005, -3.51830632, -3.51830632,\n",
       "          -3.2224641 , -3.17010475, -3.56347982, -3.56347982, -2.81881941,\n",
       "          -4.05695199, -3.2224641 , -3.02448005, -4.82473881, -2.75716622,\n",
       "          -4.05695199, -4.05695199, -4.05695199, -4.82473881, -4.79533566,\n",
       "          -2.96668585, -4.82473881, -2.81881941, -3.56347982, -2.96668585,\n",
       "          -3.56347982, -2.75716622, -2.75716622, -4.01888642, -3.51830632]),\n",
       "   'split1_test_Log_Loss': array([-3.29547234, -3.57076217, -3.35365993, -3.93805729, -3.93805729,\n",
       "          -3.62391188, -3.57076217, -3.98535752, -3.98535752, -3.00691645,\n",
       "          -4.36794664, -3.62391188, -3.35365993, -4.93339892, -2.94540196,\n",
       "          -4.36794664, -4.36794664, -4.36794664, -4.93339892, -4.90349929,\n",
       "          -3.29547234, -4.93339892, -3.00691645, -3.98535752, -3.29547234,\n",
       "          -3.98535752, -2.94540196, -2.94540196, -4.32835713, -3.93805729]),\n",
       "   'split2_test_Log_Loss': array([-3.27384287, -3.52840632, -3.33183322, -3.9296557 , -3.9296557 ,\n",
       "          -3.58127378, -3.52840632, -3.97548516, -3.97548516, -3.23116951,\n",
       "          -4.41441824, -3.58127378, -3.33183322, -5.04010473, -3.16901678,\n",
       "          -4.41441824, -4.41441824, -4.41441824, -5.04010473, -5.01017144,\n",
       "          -3.27384287, -5.04010473, -3.23116951, -3.97548516, -3.27384287,\n",
       "          -3.97548516, -3.16901678, -3.16901678, -4.37569989, -3.9296557 ]),\n",
       "   'mean_test_Log_Loss': array([-3.17810818, -3.42243508, -3.2360985 , -3.79459631, -3.79459631,\n",
       "          -3.47522627, -3.42243508, -3.84069584, -3.84069584, -3.01827911,\n",
       "          -4.27913914, -3.47522627, -3.2360985 , -4.93238494, -2.95650639,\n",
       "          -4.27913914, -4.27913914, -4.27913914, -4.93238494, -4.90264054,\n",
       "          -3.17810818, -4.93238494, -3.01827911, -3.84069584, -3.17810818,\n",
       "          -3.84069584, -2.95650639, -2.95650639, -4.24034939, -3.79459631]),\n",
       "   'std_test_Log_Loss': array([0.15036367, 0.17997891, 0.1505074 , 0.19618928, 0.19618928,\n",
       "          0.18029515, 0.17997891, 0.19685799, 0.19685799, 0.16856081,\n",
       "          0.15888133, 0.18029515, 0.1505074 , 0.08794042, 0.16834847,\n",
       "          0.15888133, 0.15888133, 0.15888133, 0.08794042, 0.08772313,\n",
       "          0.15036367, 0.08794042, 0.16856081, 0.19685799, 0.15036367,\n",
       "          0.19685799, 0.16834847, 0.16834847, 0.15841374, 0.19618928]),\n",
       "   'rank_test_Log_Loss': array([ 6, 11,  9, 15, 15, 13, 11, 18, 18,  4, 23, 13,  9, 28,  1, 23, 23,\n",
       "          23, 28, 27,  6, 28,  4, 18,  6, 18,  1,  1, 22, 15]),\n",
       "   'split0_train_Log_Loss': array([-3.77251697e-14, -2.43239319e-08, -6.08870735e-01, -3.77251697e-14,\n",
       "          -1.83822920e-08, -5.45535377e-01, -3.77251697e-14, -4.74836850e-01,\n",
       "          -4.74836850e-01, -6.63414288e-01, -3.92393466e-01, -5.45535377e-01,\n",
       "          -6.08870735e-01, -2.91148990e-01, -3.77251697e-14, -3.92393466e-01,\n",
       "          -3.92393466e-01, -3.92393466e-01, -2.91148990e-01, -3.77251697e-14,\n",
       "          -3.77251697e-14, -2.91148990e-01, -6.63414288e-01, -4.74836850e-01,\n",
       "          -3.04744273e-08, -4.74836850e-01, -3.67200163e-08, -3.77251697e-14,\n",
       "          -1.28268065e-08, -3.77251697e-14]),\n",
       "   'split1_train_Log_Loss': array([-3.77252183e-14, -2.39161270e-08, -6.00687829e-01, -3.77252183e-14,\n",
       "          -1.79883388e-08, -5.40690386e-01, -3.77252183e-14, -4.70454487e-01,\n",
       "          -4.70454487e-01, -6.53434226e-01, -3.87710544e-01, -5.40690386e-01,\n",
       "          -6.00687829e-01, -2.86748391e-01, -3.77252183e-14, -3.87710544e-01,\n",
       "          -3.87710544e-01, -3.87710544e-01, -2.86748391e-01, -3.77252183e-14,\n",
       "          -3.77252183e-14, -2.86748391e-01, -6.53434226e-01, -4.70454487e-01,\n",
       "          -2.98808183e-08, -4.70454487e-01, -3.60765307e-08, -3.77252183e-14,\n",
       "          -1.24843971e-08, -3.77252183e-14]),\n",
       "   'split2_train_Log_Loss': array([-3.77251228e-14, -2.42340113e-08, -5.97664550e-01, -3.77251228e-14,\n",
       "          -1.84381106e-08, -5.35156799e-01, -3.77251228e-14, -4.64852806e-01,\n",
       "          -4.64852806e-01, -6.52037467e-01, -3.80855175e-01, -5.35156799e-01,\n",
       "          -5.97664550e-01, -2.83398711e-01, -3.77251228e-14, -3.80855175e-01,\n",
       "          -3.80855175e-01, -3.80855175e-01, -2.83398711e-01, -3.77251228e-14,\n",
       "          -3.77251228e-14, -2.83398711e-01, -6.52037467e-01, -4.64852806e-01,\n",
       "          -3.02995734e-08, -4.64852806e-01, -3.64412820e-08, -3.77251228e-14,\n",
       "          -1.28531702e-08, -3.77251228e-14]),\n",
       "   'mean_train_Log_Loss': array([-3.77251703e-14, -2.41580234e-08, -6.02407705e-01, -3.77251703e-14,\n",
       "          -1.82695805e-08, -5.40460854e-01, -3.77251703e-14, -4.70048048e-01,\n",
       "          -4.70048048e-01, -6.56295327e-01, -3.86986395e-01, -5.40460854e-01,\n",
       "          -6.02407705e-01, -2.87098697e-01, -3.77251703e-14, -3.86986395e-01,\n",
       "          -3.86986395e-01, -3.86986395e-01, -2.87098697e-01, -3.77251703e-14,\n",
       "          -3.77251703e-14, -2.87098697e-01, -6.56295327e-01, -4.70048048e-01,\n",
       "          -3.02182730e-08, -4.70048048e-01, -3.64126097e-08, -3.77251703e-14,\n",
       "          -1.27214579e-08, -3.77251703e-14]),\n",
       "   'std_train_Log_Loss': array([3.89952081e-20, 1.74941569e-10, 4.73378786e-03, 3.89952081e-20,\n",
       "          2.00169236e-10, 4.24014415e-03, 3.89952081e-20, 4.08608844e-03,\n",
       "          4.08608844e-03, 5.06605930e-03, 4.73823697e-03, 4.24014415e-03,\n",
       "          4.73378786e-03, 3.17371932e-03, 3.89952081e-20, 4.73823697e-03,\n",
       "          4.73823697e-03, 4.73823697e-03, 3.17371932e-03, 3.89952081e-20,\n",
       "          3.89952081e-20, 3.17371932e-03, 5.06605930e-03, 4.08608844e-03,\n",
       "          2.49065211e-10, 4.08608844e-03, 2.63483094e-10, 3.89952081e-20,\n",
       "          1.67972485e-10, 3.89952081e-20])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "  14,\n",
       "  -2.956506386759135),\n",
       " 'MLPClassifier_V001_PCA_70': ({'mean_fit_time': array([ 4.43148422, 19.27414743,  2.11966785, 25.19598715, 31.82726113,\n",
       "           8.94775041,  3.0455269 , 10.94275093,  8.39123686,  3.36700106,\n",
       "           7.59104403, 14.98361786,  4.67716479, 11.09667357, 13.79412921,\n",
       "          10.77154136,  7.06544749, 13.72498051, 12.40417886, 12.34334095,\n",
       "           6.350027  , 18.25986083, 35.37045813, 13.06408087,  6.78752462,\n",
       "           1.04254651,  5.498969  , 10.95272438, 14.44605366, 12.12459207]),\n",
       "   'std_fit_time': array([0.2524429 , 0.27316134, 0.04994814, 0.54127853, 1.23319071,\n",
       "          0.37528092, 0.17425393, 0.43271066, 0.86106039, 0.25965857,\n",
       "          0.59130448, 0.88175961, 0.19231436, 0.34534302, 1.53468398,\n",
       "          1.14175142, 1.75982451, 0.16239392, 1.76610179, 0.04442539,\n",
       "          0.86922848, 1.6245915 , 1.76365136, 0.57783336, 1.09190306,\n",
       "          0.07757119, 0.94029361, 0.56081213, 0.29599217, 2.59834901]),\n",
       "   'mean_score_time': array([0.0561831 , 0.06017311, 0.05285764, 0.06515884, 0.08011961,\n",
       "          0.07347004, 0.06549096, 0.05252624, 0.05219475, 0.05551799,\n",
       "          0.06482601, 0.06183426, 0.05618342, 0.04188848, 0.05252735,\n",
       "          0.04621037, 0.06416114, 0.06416178, 0.04554534, 0.04920165,\n",
       "          0.05053115, 0.05917501, 0.083776  , 0.06482697, 0.05119658,\n",
       "          0.04554574, 0.05950673, 0.04122313, 0.05352362, 0.0458769 ]),\n",
       "   'std_score_time': array([2.04962780e-03, 2.85907636e-03, 8.14880337e-04, 2.85994482e-03,\n",
       "          1.88109815e-03, 2.85846670e-03, 2.35010828e-03, 6.11134491e-03,\n",
       "          3.29138790e-03, 4.17873151e-03, 2.15453530e-03, 2.82052331e-03,\n",
       "          1.24360311e-03, 7.01885292e-07, 2.35100748e-03, 3.38915621e-03,\n",
       "          4.90892486e-03, 4.63032342e-03, 4.69347345e-04, 1.24383659e-03,\n",
       "          4.69685125e-04, 1.69496800e-03, 6.46349532e-03, 8.13322715e-04,\n",
       "          1.24400648e-03, 6.58238241e-03, 4.69572088e-04, 4.69628375e-04,\n",
       "          2.35005208e-03, 3.54961287e-03]),\n",
       "   'param_solver': masked_array(data=['adam', 'adam', 'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd',\n",
       "                      'sgd', 'lbfgs', 'lbfgs', 'lbfgs', 'adam', 'lbfgs',\n",
       "                      'sgd', 'adam', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
       "                      'adam', 'adam', 'adam', 'lbfgs', 'adam', 'lbfgs',\n",
       "                      'adam', 'adam', 'adam', 'sgd'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50, 50, 50), (100, 100), (100, 100, 50),\n",
       "                      (200, 50, 50, 50), (200, 50, 50, 50),\n",
       "                      (200, 50, 50, 50), (100, 100, 50), (100,), (100,),\n",
       "                      (100,), (100, 100, 50), (100, 100, 50), (100, 100),\n",
       "                      (100,), (100, 100), (100,), (200, 50, 50, 50),\n",
       "                      (200, 50, 50), (100,), (100, 100), (200, 50),\n",
       "                      (200, 50), (200, 50, 50, 50), (200, 50, 50, 50),\n",
       "                      (100, 100, 50), (100,), (200, 50, 50, 50), (100,),\n",
       "                      (100, 100, 50), (100, 100)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0115, 0.0256, 0.034100000000000005, 0.0219, 0.0103,\n",
       "                      0.031400000000000004, 0.0107, 0.00030000000000000003,\n",
       "                      0.0213, 0.0081, 0.0352, 0.0291, 0.0198, 0.0286, 0.0396,\n",
       "                      0.0268, 0.016900000000000002, 0.0369, 0.0304, 0.0093,\n",
       "                      0.0156, 0.042600000000000006, 0.01, 0.0442, 0.0233,\n",
       "                      0.0027, 0.037000000000000005, 0.033400000000000006,\n",
       "                      0.0146, 0.0133],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['identity', 'logistic', 'tanh', 'tanh', 'logistic',\n",
       "                      'relu', 'logistic', 'logistic', 'identity', 'logistic',\n",
       "                      'relu', 'relu', 'logistic', 'relu', 'relu', 'logistic',\n",
       "                      'identity', 'identity', 'logistic', 'tanh', 'identity',\n",
       "                      'relu', 'logistic', 'identity', 'identity', 'tanh',\n",
       "                      'identity', 'relu', 'tanh', 'tanh'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0115,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0256,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.034100000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0219,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0103,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.031400000000000004,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0107,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.00030000000000000003,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0213,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0081,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0352,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0291,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0198,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0286,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0396,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0268,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.016900000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0369,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0304,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0093,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0156,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.042600000000000006,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.01,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0442,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0233,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0027,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.037000000000000005,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.033400000000000006,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0146,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0133,\n",
       "     'activation': 'tanh'}],\n",
       "   'split0_test_Accuracy': array([0.68734313, 0.77554679, 0.69630692, 0.65937612, 0.63571172,\n",
       "          0.72176407, 0.05593403, 0.44065973, 0.66116888, 0.72248118,\n",
       "          0.73610613, 0.75690212, 0.74220151, 0.67228397, 0.76980997,\n",
       "          0.44711366, 0.68877734, 0.66654715, 0.43635712, 0.78092506,\n",
       "          0.70670491, 0.78092506, 0.60882037, 0.6676228 , 0.69164575,\n",
       "          0.69989243, 0.69343851, 0.776981  , 0.7658659 , 0.68375762]),\n",
       "   'split1_test_Accuracy': array([0.68037518, 0.76767677, 0.6991342 , 0.67568543, 0.62987013,\n",
       "          0.74062049, 0.05591631, 0.44300144, 0.65692641, 0.70815296,\n",
       "          0.73773449, 0.75757576, 0.72330447, 0.67496392, 0.76443001,\n",
       "          0.44336219, 0.69480519, 0.66161616, 0.46969697, 0.77056277,\n",
       "          0.69011544, 0.79292929, 0.58513709, 0.66197691, 0.69516595,\n",
       "          0.69227994, 0.67929293, 0.76587302, 0.75937951, 0.67207792]),\n",
       "   'split2_test_Accuracy': array([0.67584209, 0.76711336, 0.70626585, 0.66533865, 0.63093082,\n",
       "          0.75371242, 0.05613908, 0.43752264, 0.66714958, 0.72328866,\n",
       "          0.74429555, 0.75805867, 0.69250272, 0.65555958, 0.77725462,\n",
       "          0.42919232, 0.67946396, 0.67656646, 0.4270192 , 0.76457805,\n",
       "          0.69358928, 0.79427744, 0.65592177, 0.67294459, 0.68199928,\n",
       "          0.69938428, 0.69141615, 0.77797899, 0.75660992, 0.6841724 ]),\n",
       "   'mean_test_Accuracy': array([0.68120644, 0.77012737, 0.70055275, 0.66678683, 0.63217976,\n",
       "          0.73864456, 0.05599615, 0.44039894, 0.66173997, 0.71797645,\n",
       "          0.73936554, 0.75751021, 0.71941841, 0.66762797, 0.77048786,\n",
       "          0.43991829, 0.68769527, 0.66822879, 0.44436434, 0.77204999,\n",
       "          0.69682769, 0.78935352, 0.61655852, 0.66750781, 0.68961788,\n",
       "          0.69718818, 0.68805576, 0.77361211, 0.76063446, 0.68000481]),\n",
       "   'std_test_Accuracy': array([0.00473267, 0.00385451, 0.00418815, 0.00674366, 0.00254462,\n",
       "          0.01311957, 0.00010097, 0.00224134, 0.00418762, 0.00695033,\n",
       "          0.00353698, 0.00047451, 0.02047784, 0.00857392, 0.00525063,\n",
       "          0.00771173, 0.00630155, 0.006211  , 0.0183047 , 0.006757  ,\n",
       "          0.00715418, 0.0060092 , 0.02937687, 0.00447221, 0.00555771,\n",
       "          0.00347497, 0.00624771, 0.00548457, 0.00388204, 0.00560468]),\n",
       "   'rank_test_Accuracy': array([18,  5, 12, 23, 25,  9, 30, 28, 24, 11,  8,  7, 10, 21,  4, 29, 17,\n",
       "          20, 27,  3, 14,  1, 26, 22, 15, 13, 16,  2,  6, 19]),\n",
       "   'split0_train_Accuracy': array([0.8223387 , 0.99186698, 1.        , 0.79414423, 0.97469727,\n",
       "          1.        , 0.05602747, 0.46466655, 0.88378818, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.77823965, 1.        ,\n",
       "          0.45273812, 0.81637448, 0.88161937, 0.45490692, 1.        ,\n",
       "          0.85378637, 0.99584312, 0.96240737, 0.87529369, 0.84005061,\n",
       "          1.        , 0.80806073, 1.        , 1.        , 0.78510754]),\n",
       "   'split1_train_Accuracy': array([0.8218018 , 0.99333333, 1.        , 0.8045045 , 0.9772973 ,\n",
       "          1.        , 0.05603604, 0.47009009, 0.89531532, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78774775, 0.99981982,\n",
       "          0.46486486, 0.81207207, 0.89333333, 0.48648649, 1.        ,\n",
       "          0.85279279, 1.        , 0.9381982 , 0.8818018 , 0.83333333,\n",
       "          1.        , 0.82630631, 1.        , 1.        , 0.78954955]),\n",
       "   'split2_train_Accuracy': array([0.81208416, 0.99262723, 1.        , 0.79841755, 0.97536414,\n",
       "          1.        , 0.05592519, 0.47167776, 0.8940838 , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.7843913 , 1.        ,\n",
       "          0.46646287, 0.82647006, 0.89156627, 0.46754181, 1.        ,\n",
       "          0.85074627, 0.99748247, 0.99082899, 0.88635138, 0.84085596,\n",
       "          1.        , 0.82287358, 1.        , 1.        , 0.78888689]),\n",
       "   'mean_train_Accuracy': array([0.81874155, 0.99260918, 1.        , 0.79902209, 0.97578624,\n",
       "          1.        , 0.05599623, 0.46881146, 0.89106243, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78345957, 0.99993994,\n",
       "          0.46135528, 0.81830554, 0.88883966, 0.46964507, 1.        ,\n",
       "          0.85244181, 0.9977752 , 0.96381152, 0.88114896, 0.83807997,\n",
       "          1.        , 0.81908021, 1.        , 1.        , 0.78784799]),\n",
       "   'std_train_Accuracy': array([4.71258841e-03, 5.98772248e-04, 0.00000000e+00, 4.25111350e-03,\n",
       "          1.10262015e-03, 0.00000000e+00, 5.03546264e-05, 3.00171379e-03,\n",
       "          5.16818505e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 3.93717819e-03, 8.49377515e-05, 6.12808091e-03,\n",
       "          6.03447014e-03, 5.15622587e-03, 1.29778018e-02, 0.00000000e+00,\n",
       "          1.26568797e-03, 1.70961485e-03, 2.15093579e-02, 4.53782216e-03,\n",
       "          3.37244178e-03, 0.00000000e+00, 7.91696846e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.95658757e-03]),\n",
       "   'split0_test_F1': array([0.68403303, 0.77391889, 0.69469257, 0.65280523, 0.63722483,\n",
       "          0.7222553 , 0.00592578, 0.40915447, 0.65928381, 0.72218119,\n",
       "          0.73597131, 0.7561168 , 0.74171519, 0.66891154, 0.76900809,\n",
       "          0.4047925 , 0.68579987, 0.66342032, 0.40304839, 0.77892411,\n",
       "          0.70653997, 0.78068805, 0.60593111, 0.66603161, 0.69188113,\n",
       "          0.69985457, 0.69198221, 0.77655189, 0.7652167 , 0.67970652]),\n",
       "   'split1_test_F1': array([0.67452548, 0.76628266, 0.69849172, 0.66763138, 0.62717796,\n",
       "          0.74065399, 0.00592212, 0.40661194, 0.65362644, 0.70767411,\n",
       "          0.73553827, 0.75712771, 0.72189761, 0.66988909, 0.76358607,\n",
       "          0.39792976, 0.69250337, 0.65950369, 0.42890508, 0.77016746,\n",
       "          0.68735215, 0.79151475, 0.58493372, 0.65933742, 0.69357827,\n",
       "          0.69045773, 0.67688981, 0.76454636, 0.75766224, 0.66549617]),\n",
       "   'split2_test_F1': array([0.67460529, 0.76616522, 0.70438458, 0.6599046 , 0.62791141,\n",
       "          0.75366846, 0.00596815, 0.40266523, 0.66478647, 0.72230288,\n",
       "          0.74289183, 0.75669232, 0.69123135, 0.65252935, 0.77609839,\n",
       "          0.38936481, 0.67823216, 0.67555867, 0.38475685, 0.76345065,\n",
       "          0.69241449, 0.79352726, 0.65521951, 0.67163481, 0.67955269,\n",
       "          0.6991154 , 0.69068583, 0.77680839, 0.75397388, 0.68065259]),\n",
       "   'mean_test_F1': array([0.67773828, 0.76880287, 0.69917357, 0.66009908, 0.63078836,\n",
       "          0.73880576, 0.00593862, 0.40615463, 0.659225  , 0.71738936,\n",
       "          0.7381231 , 0.75664447, 0.71836501, 0.66380202, 0.76955441,\n",
       "          0.3973881 , 0.68552201, 0.66614287, 0.40559247, 0.77087368,\n",
       "          0.69546222, 0.78855403, 0.6152895 , 0.6656608 , 0.68835621,\n",
       "          0.69647931, 0.68652494, 0.77263803, 0.75897032, 0.67528703]),\n",
       "   'std_test_F1': array([4.46924485e-03, 3.63256705e-03, 3.98663801e-03, 6.06135542e-03,\n",
       "          4.57951120e-03, 1.28928546e-02, 2.08604460e-05, 2.66930403e-03,\n",
       "          4.55008128e-03, 6.86618222e-03, 3.36481637e-03, 4.14559990e-04,\n",
       "          2.07640259e-02, 7.95302352e-03, 5.11593641e-03, 6.31100030e-03,\n",
       "          5.82164648e-03, 6.82498180e-03, 1.80894240e-02, 6.33775473e-03,\n",
       "          8.13123774e-03, 5.64460905e-03, 2.94153925e-02, 5.02049624e-03,\n",
       "          6.24183126e-03, 4.26629157e-03, 6.82992225e-03, 5.71953957e-03,\n",
       "          4.68278747e-03, 6.93021406e-03]),\n",
       "   'rank_test_F1': array([18,  5, 12, 23, 25,  8, 30, 27, 24, 11,  9,  7, 10, 22,  4, 29, 17,\n",
       "          20, 28,  3, 14,  1, 26, 21, 15, 13, 16,  2,  6, 19]),\n",
       "   'split0_train_F1': array([0.82144445, 0.99183876, 1.        , 0.78930045, 0.97418131,\n",
       "          1.        , 0.00594507, 0.42984252, 0.88339707, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.77552108, 1.        ,\n",
       "          0.41138839, 0.81476819, 0.88138895, 0.42307064, 1.        ,\n",
       "          0.85320549, 0.99584785, 0.96132723, 0.8746474 , 0.84072694,\n",
       "          1.        , 0.80726691, 1.        , 1.        , 0.78158567]),\n",
       "   'split1_train_F1': array([0.81934358, 0.99331887, 1.        , 0.79964284, 0.97700472,\n",
       "          1.        , 0.00594684, 0.43617223, 0.89488531, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78500368, 0.99982002,\n",
       "          0.42501204, 0.81108462, 0.8928271 , 0.45132089, 1.        ,\n",
       "          0.85176336, 1.        , 0.93769033, 0.88154658, 0.83339289,\n",
       "          1.        , 0.82393476, 1.        , 1.        , 0.78665465]),\n",
       "   'split2_train_F1': array([0.81080454, 0.99259537, 1.        , 0.79485189, 0.97521971,\n",
       "          1.        , 0.00592396, 0.43504093, 0.89354528, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78282193, 1.        ,\n",
       "          0.42388111, 0.8257441 , 0.89115274, 0.42756333, 1.        ,\n",
       "          0.84996744, 0.99744694, 0.99079759, 0.88570875, 0.83905995,\n",
       "          1.        , 0.82185231, 1.        , 1.        , 0.78641313]),\n",
       "   'mean_train_F1': array([0.81719752, 0.99258433, 1.        , 0.79459839, 0.97546858,\n",
       "          1.        , 0.00593862, 0.43368523, 0.89060922, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78111556, 0.99994001,\n",
       "          0.42009385, 0.81719897, 0.88845626, 0.43398495, 1.        ,\n",
       "          0.85164543, 0.99776493, 0.96327172, 0.88063424, 0.8377266 ,\n",
       "          1.        , 0.81768466, 1.        , 1.        , 0.78488448]),\n",
       "   'std_train_F1': array([4.60116835e-03, 6.04302932e-04, 0.00000000e+00, 4.22607006e-03,\n",
       "          1.16600555e-03, 0.00000000e+00, 1.03944448e-05, 2.75617542e-03,\n",
       "          5.12901835e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.05493060e-03, 8.48434234e-05, 6.17297738e-03,\n",
       "          6.22664170e-03, 5.04387569e-03, 1.23948111e-02, 0.00000000e+00,\n",
       "          1.32455662e-03, 1.70995738e-03, 2.17245048e-02, 4.56162776e-03,\n",
       "          3.13905055e-03, 0.00000000e+00, 7.41535808e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 2.33469561e-03]),\n",
       "   'split0_test_Log_Loss': array([-1.15025701, -0.77579551, -1.79009485, -1.18004467, -1.54565385,\n",
       "          -3.53363261, -3.61198841, -2.70777984, -2.65325427, -1.80792617,\n",
       "          -2.97914266, -1.40791629, -1.34194456, -1.13316131, -1.13338291,\n",
       "          -2.70048277, -1.17010963, -2.28031241, -2.70685112, -0.94966429,\n",
       "          -1.19263842, -0.99126709, -1.62459043, -2.13334273, -1.18422042,\n",
       "          -2.45984991, -1.11157987, -0.97003234, -1.00735241, -1.09888223]),\n",
       "   'split1_test_Log_Loss': array([-1.2040452 , -0.81880319, -1.7568755 , -1.17518638, -1.62892029,\n",
       "          -3.19702724, -3.61173521, -2.7197487 , -2.69872067, -2.11473809,\n",
       "          -3.1973259 , -1.50159152, -1.60876322, -1.14836515, -1.21125712,\n",
       "          -2.73707606, -1.17951778, -2.45909427, -2.70549732, -1.05552109,\n",
       "          -1.19791126, -0.97366895, -1.66182616, -2.22974058, -1.18840531,\n",
       "          -2.58758487, -1.22065109, -1.10293743, -1.02977252, -1.14785028]),\n",
       "   'split2_test_Log_Loss': array([-1.21192309, -0.83755714, -1.77984633, -1.19747609, -1.53907288,\n",
       "          -2.89549694, -3.61185899, -2.73141179, -2.81425217, -2.01410024,\n",
       "          -2.95752134, -1.48303789, -1.87124484, -1.18530496, -1.13925167,\n",
       "          -2.69908541, -1.21311707, -2.37056055, -2.72007723, -1.02402993,\n",
       "          -1.23773739, -0.99172175, -1.53656983, -2.39683254, -1.30006251,\n",
       "          -2.42183374, -1.23086766, -1.02926563, -1.06322956, -1.13047014]),\n",
       "   'mean_test_Log_Loss': array([-1.18863251, -0.8106118 , -1.77562955, -1.18420966, -1.57120594,\n",
       "          -3.20979667, -3.61186113, -2.71960698, -2.72181328, -1.97852569,\n",
       "          -3.04464464, -1.46404204, -1.60642659, -1.15552536, -1.16126935,\n",
       "          -2.71220814, -1.18751205, -2.36980513, -2.71078822, -1.00959683,\n",
       "          -1.20935731, -0.98555611, -1.60779069, -2.25287052, -1.22404745,\n",
       "          -2.48978486, -1.18748698, -1.033954  , -1.03335882, -1.1256731 ]),\n",
       "   'std_test_Log_Loss': array([2.74343521e-02, 2.58742359e-02, 1.38988599e-02, 9.55641496e-03,\n",
       "          4.08765561e-02, 2.60717663e-01, 1.03498153e-04, 9.64983827e-03,\n",
       "          6.77336476e-02, 1.27882281e-01, 1.08264132e-01, 4.05595525e-02,\n",
       "          2.16128440e-01, 2.18842082e-02, 3.54087574e-02, 1.75840319e-02,\n",
       "          1.84471219e-02, 7.30744444e-02, 6.56859513e-03, 4.44454223e-02,\n",
       "          2.01130569e-02, 8.40300236e-03, 5.24408364e-02, 1.08822015e-01,\n",
       "          5.35892559e-02, 7.08392758e-02, 5.40529819e-02, 5.44219121e-02,\n",
       "          2.29559157e-02, 2.02978503e-02]),\n",
       "   'rank_test_Log_Loss': array([12,  1, 19,  9, 16, 29, 30, 26, 27, 20, 28, 15, 17,  7,  8, 25, 11,\n",
       "          22, 24,  3, 13,  2, 18, 21, 14, 23, 10,  5,  4,  6]),\n",
       "   'split0_train_Log_Loss': array([-5.85841344e-01, -1.33324498e-01, -2.21997017e-03, -8.42457041e-01,\n",
       "          -1.84175650e-01, -1.74271348e-04, -3.61176687e+00, -2.67422121e+00,\n",
       "          -3.72665549e-01, -2.71538598e-03, -3.43895492e-04, -4.87593564e-03,\n",
       "          -4.35049205e-03, -8.59865440e-01, -8.58050519e-03, -2.66416960e+00,\n",
       "          -5.93330823e-01, -3.88876670e-01, -2.66843968e+00, -7.81818850e-03,\n",
       "          -4.87121078e-01, -2.59172387e-02, -2.55724043e-01, -4.12544517e-01,\n",
       "          -5.26332694e-01, -8.92279089e-04, -6.30521071e-01, -1.90460852e-02,\n",
       "          -7.40226255e-03, -8.39509532e-01]),\n",
       "   'split1_train_Log_Loss': array([-5.95933051e-01, -1.22910032e-01, -1.65606416e-03, -8.42202091e-01,\n",
       "          -1.83570335e-01, -8.44946299e-05, -3.61154874e+00, -2.67142001e+00,\n",
       "          -3.54255655e-01, -5.00804993e-03, -1.69153891e-04, -4.75105231e-03,\n",
       "          -3.54140479e-03, -8.10380416e-01, -9.35999727e-03, -2.68884566e+00,\n",
       "          -6.22590161e-01, -3.67098482e-01, -2.65913285e+00, -8.08890929e-03,\n",
       "          -5.04956355e-01, -8.42908698e-03, -3.30292463e-01, -3.88508599e-01,\n",
       "          -5.55117857e-01, -1.13246065e-03, -5.61428265e-01, -1.89862708e-02,\n",
       "          -7.70551629e-03, -8.25988592e-01]),\n",
       "   'split2_train_Log_Loss': array([-6.11333989e-01, -1.22977526e-01, -1.90724517e-03, -8.31718166e-01,\n",
       "          -1.96313235e-01, -1.02277621e-04, -3.61211851e+00, -2.68217731e+00,\n",
       "          -3.48387308e-01, -4.97470446e-03, -1.91902482e-04, -5.11936732e-03,\n",
       "          -4.50509618e-03, -8.17720425e-01, -8.16078465e-03, -2.64144223e+00,\n",
       "          -5.70668573e-01, -3.68422041e-01, -2.66367759e+00, -8.58478237e-03,\n",
       "          -4.93676781e-01, -1.96438910e-02, -1.09781445e-01, -3.80039438e-01,\n",
       "          -5.13317124e-01, -9.28771565e-04, -5.78263825e-01, -2.13630921e-02,\n",
       "          -7.48267471e-03, -8.24933339e-01]),\n",
       "   'mean_train_Log_Loss': array([-5.97702795e-01, -1.26404019e-01, -1.92775983e-03, -8.38792433e-01,\n",
       "          -1.88019740e-01, -1.20347866e-04, -3.61181137e+00, -2.67593951e+00,\n",
       "          -3.58436171e-01, -4.23271346e-03, -2.34983955e-04, -4.91545176e-03,\n",
       "          -4.13233101e-03, -8.29322094e-01, -8.70042904e-03, -2.66481916e+00,\n",
       "          -5.95529852e-01, -3.74799064e-01, -2.66375004e+00, -8.16396006e-03,\n",
       "          -4.95251404e-01, -1.79967389e-02, -2.31932650e-01, -3.93697518e-01,\n",
       "          -5.31589225e-01, -9.84503769e-04, -5.90071054e-01, -1.97984827e-02,\n",
       "          -7.53015118e-03, -8.30143821e-01]),\n",
       "   'std_train_Log_Loss': array([1.04822941e-02, 4.89359552e-03, 2.30670234e-04, 5.00334436e-03,\n",
       "          5.86959085e-03, 3.88146461e-05, 2.34728524e-04, 4.55662576e-03,\n",
       "          1.03429773e-02, 1.07299891e-03, 7.75700400e-05, 1.52938176e-04,\n",
       "          4.22588023e-04, 2.18042950e-02, 4.96866192e-04, 1.93578204e-02,\n",
       "          2.12538567e-02, 9.96902491e-03, 3.79984289e-03, 3.17428211e-04,\n",
       "          7.36586061e-03, 7.23388762e-03, 9.15816580e-02, 1.37680476e-02,\n",
       "          1.74651778e-02, 1.05676723e-04, 2.94166843e-02, 1.10661538e-03,\n",
       "          1.28273718e-04, 6.63655500e-03])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (100, 100),\n",
       "   'alpha': 0.0256,\n",
       "   'activation': 'logistic'},\n",
       "  1,\n",
       "  -0.8106117996946764),\n",
       " 'LogisticRegression_V001_PCA_5components': ({'mean_fit_time': array([0.08808788, 0.37166246, 0.09474579, 1.06083051, 0.3846391 ,\n",
       "          0.15126173, 0.49800181, 0.09142192, 0.08709995, 0.26595505,\n",
       "          0.90557893, 0.40325459, 0.12234028, 0.12433386, 0.61269538,\n",
       "          0.64361238, 0.9338371 , 0.16588839, 0.22506428, 0.90524554,\n",
       "          0.15159456, 0.30318912, 0.10339014, 1.58343363, 0.61369284,\n",
       "          0.69979636, 0.10604914, 0.09374849, 0.2795856 , 0.25930643]),\n",
       "   'std_fit_time': array([0.00633553, 0.02514246, 0.00081439, 0.06188983, 0.0179579 ,\n",
       "          0.00188054, 0.01502221, 0.00047058, 0.00124409, 0.00338997,\n",
       "          0.03571926, 0.01965069, 0.00093982, 0.00204901, 0.01267679,\n",
       "          0.01448339, 0.1002722 , 0.00204919, 0.00401723, 0.03206411,\n",
       "          0.00924972, 0.00776865, 0.00094077, 0.07526369, 0.07456393,\n",
       "          0.01264993, 0.00367221, 0.00814286, 0.00409902, 0.0135531 ]),\n",
       "   'mean_score_time': array([0.04753931, 0.04255319, 0.03091749, 0.02892296, 0.05252576,\n",
       "          0.03191503, 0.03125079, 0.03490766, 0.03291186, 0.02925555,\n",
       "          0.02726054, 0.04421536, 0.03523858, 0.02692811, 0.02593056,\n",
       "          0.02659607, 0.02792533, 0.02692795, 0.02726102, 0.03457459,\n",
       "          0.03158251, 0.02859028, 0.0289224 , 0.02759329, 0.02726054,\n",
       "          0.02858957, 0.03989331, 0.06050515, 0.06116978, 0.02726022]),\n",
       "   'std_score_time': array([0.00971492, 0.01647546, 0.00162898, 0.00081488, 0.03338974,\n",
       "          0.00495312, 0.00248797, 0.00709943, 0.00705195, 0.0016955 ,\n",
       "          0.00094004, 0.01592278, 0.00823841, 0.00081391, 0.00081439,\n",
       "          0.00046985, 0.00162898, 0.0008143 , 0.00047002, 0.00893272,\n",
       "          0.00600285, 0.00094049, 0.00081439, 0.00046963, 0.00124407,\n",
       "          0.00094066, 0.00826405, 0.01550083, 0.01726149, 0.00261713]),\n",
       "   'param_C': masked_array(data=[0.04219053876216633, 0.14231511704299413,\n",
       "                      0.19420459781331556, 0.16866316341611232,\n",
       "                      0.7660040363639158, 0.3833625948600509,\n",
       "                      0.23943401396545128, 0.17922324196544484,\n",
       "                      0.040281647271330316, 0.044588367669404,\n",
       "                      0.1413007916543674, 0.14394677090731528,\n",
       "                      0.7130393891268539, 0.041554121894364054,\n",
       "                      0.03480539797349576, 0.06770223201817653,\n",
       "                      0.24841271959794853, 0.19702850998598953,\n",
       "                      0.15659655636064024, 0.286166551762709,\n",
       "                      0.21644761235254706, 0.04602272233210524,\n",
       "                      0.0785006094050491, 0.3931095080209061,\n",
       "                      0.017907045039305607, 0.3926555469145107,\n",
       "                      0.09891825441141623, 0.01779361358095786,\n",
       "                      0.1744142793092784, 0.11610566430446485],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, 'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', None, None, None, 'balanced', 'balanced',\n",
       "                      'balanced', None, None, 'balanced', None, 'balanced',\n",
       "                      'balanced', None, None, 'balanced', None, None,\n",
       "                      'balanced', None, None, None, None, None, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'saga',\n",
       "                      'liblinear', 'saga', 'liblinear', 'liblinear', 'saga',\n",
       "                      'newton-cg', 'saga', 'liblinear', 'liblinear',\n",
       "                      'newton-cg', 'newton-cg', 'newton-cg', 'liblinear',\n",
       "                      'saga', 'newton-cg', 'liblinear', 'saga', 'liblinear',\n",
       "                      'saga', 'newton-cg', 'newton-cg', 'liblinear',\n",
       "                      'liblinear', 'saga', 'saga'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.3980198197895368, 0.22246504304290965,\n",
       "                      0.3581491532324251, 0.03165185623127775,\n",
       "                      0.2724224691717941, 0.01075869643289191,\n",
       "                      0.013393951211086143, 0.3254802384604989,\n",
       "                      0.4757060098686903, 0.7178816555109343,\n",
       "                      0.04419290455153522, 0.14514164914506408,\n",
       "                      0.08241576055353439, 0.0031687432630299038,\n",
       "                      1.0164502291479869, 0.3043393063474857,\n",
       "                      0.03512579834022294, 0.00034485971413466605,\n",
       "                      0.37011564045538276, 0.14129906108219156,\n",
       "                      0.002693913923378261, 0.10301959720520176,\n",
       "                      0.1083110431338683, 0.01737327325557254,\n",
       "                      0.6277344182163872, 0.469574405665668,\n",
       "                      0.13094583543414873, 0.03798670798054655,\n",
       "                      0.14861123262384704, 0.14229555919043255],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.04219053876216633,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3980198197895368},\n",
       "    {'C': 0.14231511704299413,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.22246504304290965},\n",
       "    {'C': 0.19420459781331556,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3581491532324251},\n",
       "    {'C': 0.16866316341611232,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.03165185623127775},\n",
       "    {'C': 0.7660040363639158,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.2724224691717941},\n",
       "    {'C': 0.3833625948600509,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.01075869643289191},\n",
       "    {'C': 0.23943401396545128,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.013393951211086143},\n",
       "    {'C': 0.17922324196544484,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3254802384604989},\n",
       "    {'C': 0.040281647271330316,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.4757060098686903},\n",
       "    {'C': 0.044588367669404,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.7178816555109343},\n",
       "    {'C': 0.1413007916543674,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.04419290455153522},\n",
       "    {'C': 0.14394677090731528,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.14514164914506408},\n",
       "    {'C': 0.7130393891268539,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.08241576055353439},\n",
       "    {'C': 0.041554121894364054,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.0031687432630299038},\n",
       "    {'C': 0.03480539797349576,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 1.0164502291479869},\n",
       "    {'C': 0.06770223201817653,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3043393063474857},\n",
       "    {'C': 0.24841271959794853,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.03512579834022294},\n",
       "    {'C': 0.19702850998598953,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.00034485971413466605},\n",
       "    {'C': 0.15659655636064024,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.37011564045538276},\n",
       "    {'C': 0.286166551762709,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.14129906108219156},\n",
       "    {'C': 0.21644761235254706,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.002693913923378261},\n",
       "    {'C': 0.04602272233210524,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.10301959720520176},\n",
       "    {'C': 0.0785006094050491,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.1083110431338683},\n",
       "    {'C': 0.3931095080209061,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.01737327325557254},\n",
       "    {'C': 0.017907045039305607,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.6277344182163872},\n",
       "    {'C': 0.3926555469145107,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.469574405665668},\n",
       "    {'C': 0.09891825441141623,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.13094583543414873},\n",
       "    {'C': 0.01779361358095786,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.03798670798054655},\n",
       "    {'C': 0.1744142793092784,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.14861123262384704},\n",
       "    {'C': 0.11610566430446485,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.14229555919043255}],\n",
       "   'split0_test_Accuracy': array([0.24202223, 0.25493008, 0.271782  , 0.26783793, 0.2215848 ,\n",
       "          0.27859448, 0.27214055, 0.25385443, 0.24094658, 0.22947293,\n",
       "          0.26138401, 0.25062747, 0.27034779, 0.24453209, 0.26030835,\n",
       "          0.26210111, 0.25959125, 0.27500896, 0.271782  , 0.27214055,\n",
       "          0.27536752, 0.25098602, 0.24847616, 0.25708139, 0.23843672,\n",
       "          0.271782  , 0.24991036, 0.23054858, 0.27680172, 0.26138401]),\n",
       "   'split1_test_Accuracy': array([0.23809524, 0.22979798, 0.26046176, 0.24025974, 0.22979798,\n",
       "          0.26875902, 0.26551227, 0.26046176, 0.23881674, 0.20021645,\n",
       "          0.25180375, 0.23340548, 0.26551227, 0.23773449, 0.24314574,\n",
       "          0.26154401, 0.251443  , 0.26587302, 0.26551227, 0.26587302,\n",
       "          0.26623377, 0.25901876, 0.252886  , 0.2492785 , 0.23629149,\n",
       "          0.26695527, 0.25468975, 0.22655123, 0.26118326, 0.26010101]),\n",
       "   'split2_test_Accuracy': array([0.23831945, 0.22600507, 0.25280695, 0.2310757 , 0.24701195,\n",
       "          0.26258602, 0.2662079 , 0.25172039, 0.2368707 , 0.21477725,\n",
       "          0.24882289, 0.24302789, 0.26548352, 0.23904382, 0.24737414,\n",
       "          0.25389352, 0.24701195, 0.26403477, 0.26186164, 0.26874321,\n",
       "          0.26512133, 0.25063383, 0.25172039, 0.24882289, 0.23433539,\n",
       "          0.27019196, 0.2542557 , 0.22310757, 0.26584571, 0.26874321]),\n",
       "   'mean_test_Accuracy': array([0.2394857 , 0.23696227, 0.26171593, 0.24645518, 0.23275655,\n",
       "          0.27000721, 0.26796443, 0.25534727, 0.23888488, 0.2148522 ,\n",
       "          0.25402547, 0.24236962, 0.26712329, 0.24044701, 0.25030041,\n",
       "          0.2591925 , 0.25270368, 0.26832492, 0.26640231, 0.26892574,\n",
       "          0.26892574, 0.25354482, 0.25102139, 0.25174237, 0.23636145,\n",
       "          0.26964672, 0.252944  , 0.22674838, 0.26796443, 0.26339822]),\n",
       "   'std_test_Accuracy': array([0.00180319, 0.01285011, 0.00779836, 0.01563618, 0.01059078,\n",
       "          0.00659578, 0.00297848, 0.00371808, 0.00166495, 0.01195795,\n",
       "          0.00536387, 0.00705431, 0.00228935, 0.00294903, 0.00731154,\n",
       "          0.00374072, 0.00521304, 0.00480433, 0.00409919, 0.00256492,\n",
       "          0.00459594, 0.00387124, 0.0018685 , 0.00379513, 0.00167537,\n",
       "          0.00200986, 0.00216107, 0.00304148, 0.00655589, 0.00380253]),\n",
       "   'rank_test_Accuracy': array([24, 26, 11, 21, 28,  1,  6, 13, 25, 30, 14, 22,  8, 23, 20, 12, 17,\n",
       "           5,  9,  3,  3, 15, 19, 18, 27,  2, 16, 29,  6, 10]),\n",
       "   'split0_train_Accuracy': array([0.24254473, 0.25465389, 0.27091993, 0.26206398, 0.22157961,\n",
       "          0.28393277, 0.27941442, 0.26314838, 0.24091813, 0.22826676,\n",
       "          0.25591903, 0.24706308, 0.27543828, 0.24543647, 0.25429243,\n",
       "          0.270197  , 0.25718417, 0.28049883, 0.28158323, 0.27869149,\n",
       "          0.28067956, 0.25772637, 0.26043738, 0.25085849, 0.23694198,\n",
       "          0.27923369, 0.26332912, 0.23043557, 0.28031809, 0.27399241]),\n",
       "   'split1_train_Accuracy': array([0.24774775, 0.23009009, 0.26126126, 0.25369369, 0.23297297,\n",
       "          0.27603604, 0.27567568, 0.2590991 , 0.24756757, 0.21333333,\n",
       "          0.25675676, 0.2436036 , 0.27441441, 0.24756757, 0.25567568,\n",
       "          0.26684685, 0.25657658, 0.27027027, 0.26900901, 0.27603604,\n",
       "          0.27153153, 0.26486486, 0.25531532, 0.25405405, 0.24234234,\n",
       "          0.27783784, 0.25855856, 0.23783784, 0.26990991, 0.26864865]),\n",
       "   'split2_train_Accuracy': array([0.24024456, 0.23413055, 0.26524006, 0.24384104, 0.24977522,\n",
       "          0.27189354, 0.27566984, 0.26056465, 0.23844632, 0.21237188,\n",
       "          0.25391117, 0.2382665 , 0.27261284, 0.24168315, 0.25409099,\n",
       "          0.26272253, 0.25355152, 0.26739795, 0.26883654, 0.27674879,\n",
       "          0.26973566, 0.26092429, 0.25301205, 0.25463046, 0.23646826,\n",
       "          0.27728826, 0.25606905, 0.22513936, 0.27207337, 0.27135407]),\n",
       "   'mean_train_Accuracy': array([0.24351235, 0.23962485, 0.26580709, 0.25319957, 0.23477594,\n",
       "          0.27728745, 0.27691998, 0.26093738, 0.24231067, 0.21799066,\n",
       "          0.25552899, 0.24297773, 0.27415518, 0.24489573, 0.25468636,\n",
       "          0.26658879, 0.25577075, 0.27272235, 0.27314293, 0.27715877,\n",
       "          0.27398225, 0.26117184, 0.25625491, 0.253181  , 0.2385842 ,\n",
       "          0.27811993, 0.25931891, 0.23113759, 0.27410046, 0.27133171]),\n",
       "   'std_train_Accuracy': array([0.00313865, 0.0107544 , 0.00396347, 0.00744769, 0.01158119,\n",
       "          0.00499401, 0.00176384, 0.00167399, 0.00385172, 0.0072769 ,\n",
       "          0.001194  , 0.00361835, 0.00116796, 0.00243254, 0.00070437,\n",
       "          0.00305689, 0.00158872, 0.00562244, 0.00596861, 0.00112218,\n",
       "          0.00479213, 0.00291953, 0.00310333, 0.00165904, 0.00266444,\n",
       "          0.00081888, 0.00301228, 0.00520784, 0.00448437, 0.00218164]),\n",
       "   'split0_test_F1': array([0.19090255, 0.20679657, 0.21201648, 0.23098604, 0.1815456 ,\n",
       "          0.22679877, 0.2337889 , 0.2102346 , 0.18947821, 0.1826032 ,\n",
       "          0.2277471 , 0.2034757 , 0.23036968, 0.19500704, 0.23067869,\n",
       "          0.22404765, 0.2249932 , 0.2193302 , 0.22932694, 0.23400057,\n",
       "          0.22031126, 0.21204433, 0.20391132, 0.22106269, 0.19329846,\n",
       "          0.23393855, 0.2055541 , 0.17769454, 0.23936476, 0.22058825]),\n",
       "   'split1_test_F1': array([0.18751528, 0.20097568, 0.2047176 , 0.20923579, 0.17809527,\n",
       "          0.21947278, 0.23041122, 0.2176265 , 0.18864988, 0.1777838 ,\n",
       "          0.21929574, 0.19544197, 0.22835898, 0.18863292, 0.21327187,\n",
       "          0.22459687, 0.21782462, 0.2138751 , 0.23410987, 0.23064178,\n",
       "          0.21471554, 0.2199596 , 0.20745699, 0.214735  , 0.19495427,\n",
       "          0.23143798, 0.21085322, 0.17045329, 0.22044957, 0.22360086]),\n",
       "   'split2_test_F1': array([0.18884099, 0.19381691, 0.19700758, 0.19034242, 0.2072325 ,\n",
       "          0.21114211, 0.23021303, 0.20658239, 0.18902075, 0.17691725,\n",
       "          0.21483624, 0.205869  , 0.22686841, 0.19190292, 0.21817382,\n",
       "          0.21721122, 0.21284846, 0.21050167, 0.2203106 , 0.23392445,\n",
       "          0.2118556 , 0.21395887, 0.20668982, 0.21232728, 0.19366579,\n",
       "          0.23528449, 0.20969036, 0.16968489, 0.22826255, 0.22871871]),\n",
       "   'mean_test_F1': array([0.18909031, 0.20055139, 0.20460575, 0.2102568 , 0.18891849,\n",
       "          0.2191641 , 0.23147745, 0.21148509, 0.18905053, 0.17911146,\n",
       "          0.22064856, 0.20159375, 0.22853831, 0.19185401, 0.22073184,\n",
       "          0.22196246, 0.21857612, 0.21458409, 0.22792874, 0.23285652,\n",
       "          0.21564202, 0.21531604, 0.20601418, 0.21605682, 0.19397187,\n",
       "          0.23355217, 0.20869149, 0.17262516, 0.22938085, 0.22428918]),\n",
       "   'std_test_F1': array([0.00139556, 0.00530829, 0.00612889, 0.01661115, 0.0129813 ,\n",
       "          0.00639659, 0.00164307, 0.00458932, 0.00033921, 0.0025041 ,\n",
       "          0.00535771, 0.00445609, 0.00143523, 0.00260549, 0.00733936,\n",
       "          0.00335535, 0.00498726, 0.00363949, 0.0057128 , 0.00156552,\n",
       "          0.00351412, 0.00337354, 0.00152539, 0.00368712, 0.0007103 ,\n",
       "          0.00159202, 0.00227737, 0.00361275, 0.00777115, 0.00335525]),\n",
       "   'rank_test_F1': array([26, 23, 21, 18, 28, 11,  3, 17, 27, 29, 10, 22,  5, 25,  9,  8, 12,\n",
       "          16,  6,  2, 14, 15, 20, 13, 24,  1, 19, 30,  4,  7]),\n",
       "   'split0_train_F1': array([0.19503934, 0.20486442, 0.21000631, 0.22465007, 0.18060606,\n",
       "          0.23285127, 0.24211764, 0.21977602, 0.19305776, 0.18178943,\n",
       "          0.22242276, 0.20048244, 0.23657261, 0.19802022, 0.22501319,\n",
       "          0.23212447, 0.22238664, 0.22507106, 0.24045811, 0.24196901,\n",
       "          0.22598077, 0.21762709, 0.21536515, 0.21346925, 0.19553393,\n",
       "          0.24338334, 0.21888365, 0.17846152, 0.24480027, 0.23148196]),\n",
       "   'split1_train_F1': array([0.1970824 , 0.19918751, 0.20119685, 0.22173141, 0.18154898,\n",
       "          0.22549797, 0.23814703, 0.2132763 , 0.19725204, 0.18872646,\n",
       "          0.22386827, 0.20268206, 0.23486682, 0.19835363, 0.22748945,\n",
       "          0.22908708, 0.22307718, 0.21604648, 0.23571239, 0.23986926,\n",
       "          0.21804232, 0.22754012, 0.20847058, 0.22056024, 0.19923456,\n",
       "          0.24179805, 0.21280088, 0.18175118, 0.22717292, 0.22979375]),\n",
       "   'split2_train_F1': array([0.19087172, 0.20147405, 0.20902963, 0.20314412, 0.21641184,\n",
       "          0.22149158, 0.24023033, 0.21453452, 0.18874369, 0.1722624 ,\n",
       "          0.22245426, 0.20345129, 0.23396398, 0.19330812, 0.22522742,\n",
       "          0.22511435, 0.22075032, 0.21496564, 0.22880132, 0.24231589,\n",
       "          0.21740888, 0.22343883, 0.20806068, 0.21917766, 0.1932415 ,\n",
       "          0.24338031, 0.21126615, 0.16993244, 0.23723629, 0.23393231]),\n",
       "   'mean_train_F1': array([0.19433115, 0.20184199, 0.20674426, 0.21650853, 0.19285562,\n",
       "          0.22661361, 0.240165  , 0.21586228, 0.19301783, 0.1809261 ,\n",
       "          0.2229151 , 0.20220526, 0.23513447, 0.19656066, 0.22591002,\n",
       "          0.2287753 , 0.22207138, 0.21869439, 0.2349906 , 0.24138472,\n",
       "          0.22047732, 0.22286868, 0.21063214, 0.21773572, 0.19600333,\n",
       "          0.2428539 , 0.21431689, 0.17671505, 0.23640316, 0.231736  ]),\n",
       "   'std_train_F1': array([0.00258448, 0.00233215, 0.00394283, 0.00952489, 0.0166612 ,\n",
       "          0.0047042 , 0.00162165, 0.0028147 , 0.00347364, 0.00674909,\n",
       "          0.00067412, 0.00125805, 0.00108165, 0.00230392, 0.00112024,\n",
       "          0.00287035, 0.00097575, 0.00453052, 0.00478616, 0.00108091,\n",
       "          0.00390011, 0.00406701, 0.00335092, 0.0030692 , 0.00246906,\n",
       "          0.0007466 , 0.00328941, 0.00498052, 0.00722041, 0.00169908]),\n",
       "   'split0_test_Log_Loss': array([-2.86308431, -2.70961607, -2.66750238, -2.71549739, -2.70076005,\n",
       "          -2.54852679, -2.48763426, -2.65980282, -2.8730173 , -2.74244792,\n",
       "          -2.71944583, -2.71109617, -2.50870371, -2.84682119, -2.7564369 ,\n",
       "          -2.55619923, -2.71301284, -2.60652731, -2.4971723 , -2.4822456 ,\n",
       "          -2.59671712, -2.56503758, -2.72569145, -2.71697621, -2.72088117,\n",
       "          -2.47525897, -2.68943701, -3.04593611, -2.48834871, -2.50548402]),\n",
       "   'split1_test_Log_Loss': array([-2.87989069, -2.71909651, -2.69247796, -2.7565555 , -2.72301072,\n",
       "          -2.57672663, -2.52016858, -2.682955  , -2.89080654, -2.76394391,\n",
       "          -2.73485002, -2.73393995, -2.53955394, -2.8639232 , -2.77082452,\n",
       "          -2.58449961, -2.72859645, -2.63194023, -2.5269684 , -2.516008  ,\n",
       "          -2.62256039, -2.59829179, -2.74649194, -2.72056989, -2.74201174,\n",
       "          -2.50986616, -2.71187049, -3.05779442, -2.52755491, -2.53520639]),\n",
       "   'split2_test_Log_Loss': array([-2.8684029 , -2.72042865, -2.67340248, -2.72224282, -2.71905117,\n",
       "          -2.5532302 , -2.49262939, -2.66697245, -2.88008217, -2.75322378,\n",
       "          -2.72534269, -2.72277667, -2.51249925, -2.85172847, -2.76126186,\n",
       "          -2.56230042, -2.71911678, -2.61110108, -2.49269782, -2.48831644,\n",
       "          -2.60130111, -2.57777429, -2.73100902, -2.71871146, -2.72788111,\n",
       "          -2.48155456, -2.69472721, -3.04975967, -2.49925573, -2.50757498]),\n",
       "   'mean_test_Log_Loss': array([-2.87044695, -2.71636124, -2.67777905, -2.7314115 , -2.71424006,\n",
       "          -2.55948041, -2.50012845, -2.66989333, -2.88128669, -2.7531832 ,\n",
       "          -2.72653327, -2.72258053, -2.52023895, -2.85414585, -2.7628301 ,\n",
       "          -2.56765009, -2.72022874, -2.61650962, -2.50561267, -2.49550575,\n",
       "          -2.60684617, -2.58034   , -2.73438416, -2.71874894, -2.730242  ,\n",
       "          -2.48887508, -2.69866458, -3.05115458, -2.50502665, -2.51607805]),\n",
       "   'std_test_Log_Loss': array([0.00701855, 0.00481961, 0.01066377, 0.01798207, 0.00970567,\n",
       "          0.0123387 , 0.01430895, 0.00968409, 0.00732026, 0.00878598,\n",
       "          0.00635171, 0.00933784, 0.01373807, 0.00719455, 0.00598349,\n",
       "          0.01216577, 0.00641741, 0.01106395, 0.0152028 , 0.01469995,\n",
       "          0.01126225, 0.01371151, 0.00882803, 0.00146906, 0.00879533,\n",
       "          0.01505598, 0.00957965, 0.00494544, 0.01653241, 0.0135454 ]),\n",
       "   'rank_test_Log_Loss': array([28, 17, 14, 23, 16,  8,  3, 13, 29, 25, 21, 20,  7, 27, 26,  9, 19,\n",
       "          12,  5,  2, 11, 10, 24, 18, 22,  1, 15, 30,  4,  6]),\n",
       "   'split0_train_Log_Loss': array([-2.86616996, -2.70971819, -2.66867293, -2.71661972, -2.69948671,\n",
       "          -2.5470053 , -2.48610597, -2.66182827, -2.87580786, -2.74203842,\n",
       "          -2.720812  , -2.71438686, -2.50765573, -2.84938436, -2.75806536,\n",
       "          -2.55607931, -2.71426879, -2.60591229, -2.49279118, -2.48059074,\n",
       "          -2.59595871, -2.56665192, -2.72697061, -2.71843961, -2.72354982,\n",
       "          -2.47337134, -2.69023038, -3.04949882, -2.48806913, -2.50127243]),\n",
       "   'split1_train_Log_Loss': array([-2.8538538 , -2.68833414, -2.65686919, -2.73996776, -2.68643918,\n",
       "          -2.53115036, -2.46845937, -2.64712854, -2.86545964, -2.73000956,\n",
       "          -2.70260827, -2.69901103, -2.49035649, -2.83707646, -2.74081904,\n",
       "          -2.54004358, -2.69596383, -2.5909484 , -2.47223305, -2.46370498,\n",
       "          -2.58085715, -2.55492695, -2.71366631, -2.68864144, -2.70913641,\n",
       "          -2.45666193, -2.67697405, -3.03897642, -2.47371787, -2.48683992]),\n",
       "   'split2_train_Log_Loss': array([-2.8629945 , -2.7169672 , -2.66699622, -2.71866036, -2.71597517,\n",
       "          -2.5464546 , -2.48546847, -2.66028571, -2.87422008, -2.74976042,\n",
       "          -2.72182783, -2.7193396 , -2.50530954, -2.84651885, -2.75907277,\n",
       "          -2.55547064, -2.71529783, -2.60519309, -2.48962415, -2.48065348,\n",
       "          -2.59527767, -2.56929959, -2.72583627, -2.71045612, -2.72085352,\n",
       "          -2.47376353, -2.68957482, -3.04508078, -2.49381662, -2.50223223]),\n",
       "   'mean_train_Log_Loss': array([-2.86100609, -2.70500651, -2.66417945, -2.72508262, -2.70063369,\n",
       "          -2.54153676, -2.48001127, -2.65641417, -2.87182919, -2.7406028 ,\n",
       "          -2.7150827 , -2.7109125 , -2.50110725, -2.84432656, -2.75265239,\n",
       "          -2.55053118, -2.70851015, -2.60068459, -2.4848828 , -2.47498306,\n",
       "          -2.59069784, -2.56362615, -2.72215773, -2.70584572, -2.71784658,\n",
       "          -2.46793227, -2.68559308, -3.04451867, -2.48520121, -2.49678152]),\n",
       "   'std_train_Log_Loss': array([0.00522094, 0.01215491, 0.00521426, 0.01055831, 0.01208526,\n",
       "          0.00734773, 0.00817257, 0.00659607, 0.00455036, 0.0081269 ,\n",
       "          0.0088305 , 0.0086551 , 0.00766204, 0.00525838, 0.00837755,\n",
       "          0.00742001, 0.00888153, 0.00689078, 0.00903768, 0.00797485,\n",
       "          0.00696397, 0.00624551, 0.00602217, 0.0125943 , 0.00625662,\n",
       "          0.00797094, 0.00610045, 0.0043141 , 0.00845217, 0.00704069])},\n",
       "  {'C': 0.3926555469145107,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.469574405665668},\n",
       "  25,\n",
       "  -2.4888750755215905),\n",
       " 'RandomForestClassifier_V001_PCA_5components': ({'mean_fit_time': array([1.97339161, 1.90557313, 1.25398151, 2.17219281, 1.25664067,\n",
       "          1.28290375, 0.6283195 , 1.56648056, 1.12964749, 1.42053564,\n",
       "          1.46740945, 1.35105491, 3.07976739, 2.33475804, 1.63762275,\n",
       "          0.52958425, 3.4577566 , 1.34906069, 2.53322911, 0.60305429,\n",
       "          4.17883062, 1.91621105, 1.99234017, 0.84873184, 1.43283661,\n",
       "          0.87831783, 2.07179507, 3.61234411, 0.90059225, 2.84273473]),\n",
       "   'std_fit_time': array([0.03986295, 0.06909953, 0.01726243, 0.029665  , 0.01547265,\n",
       "          0.02158073, 0.01148718, 0.02176509, 0.01343813, 0.00490815,\n",
       "          0.01129353, 0.02448925, 0.08095495, 0.02550623, 0.0423133 ,\n",
       "          0.01904508, 0.06201251, 0.03189727, 0.05015251, 0.00803436,\n",
       "          0.04518609, 0.04154168, 0.05631374, 0.00814452, 0.01246498,\n",
       "          0.02471829, 0.00943814, 0.05457781, 0.01345487, 0.01832445]),\n",
       "   'mean_score_time': array([0.39261738, 0.57845426, 0.35305619, 0.55784241, 0.30352267,\n",
       "          0.33975919, 0.18018611, 0.40957149, 0.27493199, 0.41090266,\n",
       "          0.41888038, 0.36070339, 0.68949016, 0.56382624, 0.49002465,\n",
       "          0.17785819, 0.70910509, 0.40026331, 0.54155199, 0.18783124,\n",
       "          0.88230793, 0.58743064, 0.47872225, 0.20179478, 0.41189893,\n",
       "          0.21775214, 0.49401339, 0.68450419, 0.26928099, 0.5445447 ]),\n",
       "   'std_score_time': array([0.02578088, 0.05360295, 0.04054579, 0.02162645, 0.02001867,\n",
       "          0.00285993, 0.00782473, 0.03573053, 0.00577747, 0.02077809,\n",
       "          0.01710116, 0.02282054, 0.06139607, 0.02450241, 0.02631654,\n",
       "          0.0004703 , 0.02543917, 0.03554588, 0.01232264, 0.01105503,\n",
       "          0.02588243, 0.02724013, 0.02639968, 0.00870654, 0.02115659,\n",
       "          0.0198193 , 0.01882356, 0.02292194, 0.00162888, 0.04029755]),\n",
       "   'param_n_estimators': masked_array(data=[150, 350, 200, 350, 150, 200, 100, 250, 150, 250, 250,\n",
       "                      200, 350, 300, 300, 100, 300, 250, 300, 100, 350, 350,\n",
       "                      250, 100, 250, 100, 300, 300, 150, 250],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[10, 250, 150, 150, 50, 150, 150, 150, 75, 200, 200,\n",
       "                      125, 50, 75, 250, 250, 10, 250, 50, 200, 10, 250, 75,\n",
       "                      50, 200, 50, 125, 10, 200, 10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                      'log2', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                      'sqrt', 'log2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[80, 80, 75, 40, 65, 30, 30, 10, 100, 65, 90, 5, 10, 10,\n",
       "                      100, 55, 70, 55, 65, 10, 35, 100, 100, 75, 20, 45, 70,\n",
       "                      20, 20, 40],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40}],\n",
       "   'split0_test_Accuracy': array([0.54499821, 0.29293654, 0.31875224, 0.32341341, 0.39368949,\n",
       "          0.31695948, 0.31875224, 0.31946934, 0.37038365, 0.30441018,\n",
       "          0.31122266, 0.31516673, 0.39010398, 0.36679814, 0.28935102,\n",
       "          0.29150233, 0.54643241, 0.29221943, 0.39763356, 0.30512729,\n",
       "          0.54786662, 0.28791682, 0.37038365, 0.39691646, 0.30763715,\n",
       "          0.40157763, 0.33560416, 0.54786662, 0.30978845, 0.55324489]),\n",
       "   'split1_test_Accuracy': array([0.53391053, 0.29545455, 0.32106782, 0.32215007, 0.38888889,\n",
       "          0.31854257, 0.32539683, 0.31709957, 0.35750361, 0.30808081,\n",
       "          0.30627706, 0.30627706, 0.38708514, 0.35894661, 0.29076479,\n",
       "          0.28968254, 0.53391053, 0.28860029, 0.39177489, 0.30266955,\n",
       "          0.53571429, 0.29040404, 0.35606061, 0.39069264, 0.30808081,\n",
       "          0.38275613, 0.32647908, 0.53643579, 0.3037518 , 0.53246753]),\n",
       "   'split2_test_Accuracy': array([0.53567548, 0.29373415, 0.31944947, 0.32415791, 0.39406012,\n",
       "          0.32777979, 0.32089823, 0.32524448, 0.35530605, 0.29771822,\n",
       "          0.30351322, 0.31256791, 0.39116262, 0.35856574, 0.28975009,\n",
       "          0.29119884, 0.53929736, 0.2893879 , 0.39659544, 0.29735603,\n",
       "          0.53821079, 0.29156103, 0.36001449, 0.38717856, 0.29083665,\n",
       "          0.38283231, 0.33285042, 0.53857298, 0.29916697, 0.54002173]),\n",
       "   'mean_test_Accuracy': array([0.53821197, 0.29403989, 0.31975487, 0.32323961, 0.39221341,\n",
       "          0.32107666, 0.32167748, 0.32059601, 0.36109108, 0.30341264,\n",
       "          0.30701754, 0.31134343, 0.38944965, 0.36145157, 0.28995434,\n",
       "          0.29079548, 0.53989426, 0.2900745 , 0.39533766, 0.30173035,\n",
       "          0.54061524, 0.28995434, 0.36217255, 0.39161259, 0.30221101,\n",
       "          0.38908916, 0.33165105, 0.54097573, 0.30425379, 0.54193703]),\n",
       "   'std_test_Accuracy': array([0.00487151, 0.00105148, 0.00097059, 0.00082784, 0.00235439,\n",
       "          0.00476729, 0.00277075, 0.00341563, 0.00665806, 0.00428373,\n",
       "          0.0031911 , 0.00373446, 0.00172606, 0.00379911, 0.00059549,\n",
       "          0.00079625, 0.00513525, 0.00155634, 0.00255333, 0.00324181,\n",
       "          0.00524796, 0.00152155, 0.00604845, 0.00402895, 0.00801668,\n",
       "          0.00886657, 0.00382419, 0.00496936, 0.00435142, 0.00859878]),\n",
       "   'rank_test_Accuracy': array([ 5, 26, 19, 15,  7, 17, 16, 18, 13, 23, 21, 20,  9, 12, 29, 27,  4,\n",
       "          28,  6, 25,  3, 29, 11,  8, 24, 10, 14,  2, 22,  1]),\n",
       "   'split0_train_Accuracy': array([0.71444063, 0.31429604, 0.34664739, 0.34447858, 0.45165371,\n",
       "          0.33996024, 0.33887584, 0.34429785, 0.40737394, 0.31935659,\n",
       "          0.32568227, 0.33580336, 0.4462317 , 0.41297669, 0.30778963,\n",
       "          0.31013917, 0.72022411, 0.31068137, 0.45093078, 0.31935659,\n",
       "          0.72022411, 0.30652449, 0.40881981, 0.45111151, 0.32026026,\n",
       "          0.45237665, 0.3665281 , 0.71570577, 0.32893548, 0.71895897]),\n",
       "   'split1_train_Accuracy': array([0.71855856, 0.31171171, 0.35243243, 0.34468468, 0.45891892,\n",
       "          0.34756757, 0.35351351, 0.34774775, 0.41207207, 0.32468468,\n",
       "          0.32684685, 0.33369369, 0.44900901, 0.41189189, 0.30936937,\n",
       "          0.30576577, 0.72342342, 0.30612613, 0.46018018, 0.3227027 ,\n",
       "          0.72162162, 0.30486486, 0.40846847, 0.45891892, 0.32468468,\n",
       "          0.45621622, 0.36612613, 0.72378378, 0.32702703, 0.72018018]),\n",
       "   'split2_train_Accuracy': array([0.71821615, 0.31361266, 0.34813882, 0.35245459, 0.44937961,\n",
       "          0.35533177, 0.35083618, 0.34759935, 0.40046754, 0.32548103,\n",
       "          0.32817839, 0.32638015, 0.44991908, 0.40262543, 0.30893724,\n",
       "          0.3116346 , 0.71713721, 0.31037583, 0.45207696, 0.32170473,\n",
       "          0.72037403, 0.31271354, 0.40280525, 0.44884014, 0.31936702,\n",
       "          0.45171732, 0.36054666, 0.71659773, 0.32350297, 0.72235209]),\n",
       "   'mean_train_Accuracy': array([0.71707178, 0.3132068 , 0.34907288, 0.34720595, 0.45331741,\n",
       "          0.34761986, 0.34774184, 0.34654832, 0.40663785, 0.3231741 ,\n",
       "          0.3269025 , 0.33195907, 0.4483866 , 0.40916467, 0.30869875,\n",
       "          0.30917984, 0.72026158, 0.30906111, 0.45439597, 0.32125467,\n",
       "          0.72073992, 0.3080343 , 0.40669784, 0.45295686, 0.32143732,\n",
       "          0.45343673, 0.3644003 , 0.71869576, 0.32648849, 0.72049708]),\n",
       "   'std_train_Accuracy': array([0.00186575, 0.00109338, 0.00245235, 0.0037123 , 0.00406821,\n",
       "          0.00627551, 0.00636378, 0.00159247, 0.00476604, 0.0027189 ,\n",
       "          0.00101979, 0.00403782, 0.00156838, 0.0046451 , 0.00066661,\n",
       "          0.00249012, 0.00256647, 0.00207909, 0.00411673, 0.00140262,\n",
       "          0.00062645, 0.00337738, 0.00275621, 0.00431659, 0.00232501,\n",
       "          0.00198374, 0.00272987, 0.00361616, 0.00225027, 0.00140324]),\n",
       "   'split0_test_F1': array([0.5374783 , 0.2342214 , 0.26837922, 0.27455657, 0.37032392,\n",
       "          0.26409063, 0.26909424, 0.26847587, 0.34021002, 0.24607133,\n",
       "          0.25389321, 0.26156239, 0.36683819, 0.33802574, 0.22827522,\n",
       "          0.23040752, 0.53882978, 0.23172431, 0.3740445 , 0.24834433,\n",
       "          0.54023061, 0.22767656, 0.34236473, 0.3728308 , 0.24865341,\n",
       "          0.38026126, 0.29293581, 0.53931689, 0.25324674, 0.54576893]),\n",
       "   'split1_test_F1': array([0.52361435, 0.23826502, 0.27601944, 0.27303724, 0.36188813,\n",
       "          0.26862227, 0.28168605, 0.26859401, 0.3236136 , 0.2493028 ,\n",
       "          0.25223146, 0.25414263, 0.36084786, 0.32684535, 0.23073909,\n",
       "          0.22704201, 0.52328302, 0.22845165, 0.36489809, 0.2469306 ,\n",
       "          0.5251666 , 0.23106237, 0.3232741 , 0.36545841, 0.25213793,\n",
       "          0.35582818, 0.28168227, 0.52615051, 0.24462621, 0.52175428]),\n",
       "   'split2_test_F1': array([0.52737851, 0.23009695, 0.26578553, 0.27203739, 0.36366481,\n",
       "          0.27688083, 0.26954982, 0.27273022, 0.31467657, 0.23869172,\n",
       "          0.24466161, 0.25483181, 0.35808725, 0.31731169, 0.22790837,\n",
       "          0.22950822, 0.53035321, 0.22819656, 0.36594132, 0.23994587,\n",
       "          0.52897991, 0.22825242, 0.31681646, 0.35326167, 0.23045554,\n",
       "          0.3486128 , 0.28379567, 0.52960926, 0.2394279 , 0.53101238]),\n",
       "   'mean_test_F1': array([0.52950949, 0.23419992, 0.27006361, 0.2732147 , 0.36530472,\n",
       "          0.26984351, 0.27343963, 0.26992669, 0.32621061, 0.24469937,\n",
       "          0.25027691, 0.25685791, 0.36193954, 0.32742931, 0.22897421,\n",
       "          0.22898813, 0.53083898, 0.2294638 , 0.36830949, 0.24508706,\n",
       "          0.53148024, 0.2289954 , 0.32752959, 0.36388264, 0.24377655,\n",
       "          0.36162273, 0.2861549 , 0.53171055, 0.24579061, 0.53287402]),\n",
       "   'std_test_F1': array([0.0058621 , 0.00333012, 0.00434032, 0.00103624, 0.00363639,\n",
       "          0.00529329, 0.00583091, 0.00197602, 0.01058605, 0.00443439,\n",
       "          0.00401454, 0.00335187, 0.0036555 , 0.00846795, 0.00125625,\n",
       "          0.00142354, 0.00636355, 0.00160827, 0.00409387, 0.00366839,\n",
       "          0.00640413, 0.00147958, 0.01085665, 0.00806763, 0.00949372,\n",
       "          0.01355594, 0.00489079, 0.00558139, 0.00570215, 0.00990264]),\n",
       "   'rank_test_F1': array([ 5, 26, 17, 16,  7, 19, 15, 18, 13, 24, 21, 20,  9, 12, 30, 29,  4,\n",
       "          27,  6, 23,  3, 28, 11,  8, 25, 10, 14,  2, 22,  1]),\n",
       "   'split0_train_F1': array([0.71116128, 0.25181826, 0.29519809, 0.29207182, 0.42628614,\n",
       "          0.28573876, 0.28773548, 0.29127759, 0.37351383, 0.25742306,\n",
       "          0.26562768, 0.2746916 , 0.42013422, 0.37953108, 0.24439657,\n",
       "          0.2456985 , 0.71696842, 0.24806812, 0.4254011 , 0.25923044,\n",
       "          0.71724989, 0.24456476, 0.37717524, 0.42466759, 0.256673  ,\n",
       "          0.42887829, 0.32314223, 0.71169944, 0.27066423, 0.71563594]),\n",
       "   'split1_train_F1': array([0.71496119, 0.25132327, 0.30592892, 0.29412727, 0.43665785,\n",
       "          0.2951539 , 0.30787322, 0.29599026, 0.381848  , 0.26266043,\n",
       "          0.26710483, 0.2752765 , 0.42580716, 0.38071305, 0.24462296,\n",
       "          0.23664128, 0.7201448 , 0.24133557, 0.43790963, 0.26368564,\n",
       "          0.71795748, 0.24020222, 0.37603917, 0.43960987, 0.26643771,\n",
       "          0.4356448 , 0.32154218, 0.72043211, 0.26503425, 0.71689416]),\n",
       "   'split2_train_F1': array([0.71499244, 0.25103849, 0.29279843, 0.29863556, 0.42231846,\n",
       "          0.3044214 , 0.29661237, 0.29466747, 0.36016136, 0.26620453,\n",
       "          0.26888765, 0.26740214, 0.42058357, 0.3642084 , 0.2465691 ,\n",
       "          0.24980456, 0.71353391, 0.24821132, 0.42328742, 0.26491455,\n",
       "          0.71709488, 0.24974832, 0.36421177, 0.41889889, 0.259861  ,\n",
       "          0.42220044, 0.3087117 , 0.71309549, 0.26429055, 0.71893852]),\n",
       "   'mean_train_F1': array([0.71370497, 0.25139334, 0.29797514, 0.29494488, 0.42842081,\n",
       "          0.29510469, 0.29740702, 0.29397844, 0.37184106, 0.26209601,\n",
       "          0.26720672, 0.27245675, 0.42217498, 0.37481751, 0.24519621,\n",
       "          0.24404811, 0.71688238, 0.24587167, 0.42886605, 0.26261021,\n",
       "          0.71743409, 0.24483844, 0.37247539, 0.42772545, 0.26099057,\n",
       "          0.42890784, 0.3177987 , 0.71507568, 0.26666301, 0.71715621]),\n",
       "   'std_train_F1': array([0.0017987 , 0.00032217, 0.00570885, 0.0027413 , 0.0060455 ,\n",
       "          0.00762723, 0.00824038, 0.00198467, 0.00893219, 0.00360717,\n",
       "          0.00133283, 0.00358212, 0.00257488, 0.00751727, 0.00097517,\n",
       "          0.00549914, 0.00269957, 0.00320804, 0.00645273, 0.00244195,\n",
       "          0.00037547, 0.00390198, 0.00586164, 0.00872731, 0.00406566,\n",
       "          0.00548868, 0.0064586 , 0.00383021, 0.00284553, 0.00136095]),\n",
       "   'split0_test_Log_Loss': array([-1.61585606, -2.57665444, -2.3906851 , -2.38993058, -2.03687695,\n",
       "          -2.39274578, -2.39431534, -2.39163463, -2.1614753 , -2.49572045,\n",
       "          -2.49973761, -2.4189104 , -2.03772129, -2.16363094, -2.58050274,\n",
       "          -2.58006074, -1.60721984, -2.58433127, -2.02936623, -2.49369029,\n",
       "          -1.59508696, -2.57692594, -2.16145548, -2.0388519 , -2.49673974,\n",
       "          -2.03460397, -2.33162139, -1.59556999, -2.49297529, -1.61539526]),\n",
       "   'split1_test_Log_Loss': array([-1.62029488, -2.58478851, -2.39447047, -2.39639926, -2.0520291 ,\n",
       "          -2.39914345, -2.40730125, -2.39859555, -2.1739727 , -2.50575356,\n",
       "          -2.49961192, -2.42072833, -2.05277609, -2.17436637, -2.58672531,\n",
       "          -2.59413877, -1.60904245, -2.59273637, -2.04677002, -2.50618026,\n",
       "          -1.6086057 , -2.58254149, -2.16996469, -2.05277597, -2.5002604 ,\n",
       "          -2.05053413, -2.34064395, -1.61711398, -2.50959095, -1.60816923]),\n",
       "   'split2_test_Log_Loss': array([-1.60801596, -2.56575448, -2.38185753, -2.3866078 , -2.02974474,\n",
       "          -2.38674441, -2.38350599, -2.38914121, -2.15776706, -2.49097747,\n",
       "          -2.48906022, -2.42295133, -2.03880603, -2.15814883, -2.56630449,\n",
       "          -2.57503124, -1.60474152, -2.57205497, -2.02907389, -2.49139527,\n",
       "          -1.59798954, -2.56919137, -2.15526236, -2.02779684, -2.4860994 ,\n",
       "          -2.03691415, -2.32207716, -1.59330103, -2.49200054, -1.60459087]),\n",
       "   'mean_test_Log_Loss': array([-1.61473348, -2.57574755, -2.38901724, -2.39098285, -2.03955776,\n",
       "          -2.39288572, -2.39505463, -2.39312602, -2.16440781, -2.49748883,\n",
       "          -2.49615329, -2.4208566 , -2.04309582, -2.16538803, -2.57786486,\n",
       "          -2.58308139, -1.6070047 , -2.58305803, -2.03506632, -2.49708919,\n",
       "          -1.60055295, -2.57623033, -2.16223514, -2.03982216, -2.49438229,\n",
       "          -2.04067665, -2.33146024, -1.60199336, -2.49818646, -1.60940373]),\n",
       "   'std_test_Log_Loss': array([0.0050691 , 0.00778675, 0.00527681, 0.00406124, 0.00928246,\n",
       "          0.005056  , 0.0097154 , 0.00399728, 0.00692725, 0.00615358,\n",
       "          0.0049982 , 0.00165247, 0.0068556 , 0.00672847, 0.00853352,\n",
       "          0.00807986, 0.00176011, 0.00848003, 0.00827215, 0.00649286,\n",
       "          0.00581317, 0.00546514, 0.00601957, 0.01020714, 0.00601109,\n",
       "          0.0070301 , 0.00757046, 0.01072619, 0.00806966, 0.00449705]),\n",
       "   'rank_test_Log_Loss': array([ 5, 26, 15, 16,  7, 17, 19, 18, 12, 24, 22, 20, 10, 13, 28, 30,  3,\n",
       "          29,  6, 23,  1, 27, 11,  8, 21,  9, 14,  2, 25,  4]),\n",
       "   'split0_train_Log_Loss': array([-1.20906025, -2.53812733, -2.33418502, -2.33311886, -1.90254912,\n",
       "          -2.33797966, -2.33986513, -2.3340478 , -2.06373766, -2.45118262,\n",
       "          -2.45608202, -2.37080462, -1.91207352, -2.06496293, -2.5416472 ,\n",
       "          -2.54242858, -1.20713829, -2.54585181, -1.90028586, -2.45031823,\n",
       "          -1.20787214, -2.53795335, -2.06290344, -1.90584002, -2.45305212,\n",
       "          -1.90492481, -2.26401214, -1.20833625, -2.44710341, -1.20933134]),\n",
       "   'split1_train_Log_Loss': array([-1.20029441, -2.53937403, -2.32774979, -2.32885372, -1.89815606,\n",
       "          -2.33426509, -2.33907451, -2.33182465, -2.06172391, -2.45191169,\n",
       "          -2.44760963, -2.35981505, -1.90627106, -2.06067105, -2.54214754,\n",
       "          -2.54746013, -1.19917465, -2.54610567, -1.89550496, -2.4536561 ,\n",
       "          -1.19890455, -2.53793393, -2.05691871, -1.89972936, -2.44783181,\n",
       "          -1.89748761, -2.26222842, -1.19904538, -2.45564379, -1.19859886]),\n",
       "   'split2_train_Log_Loss': array([-1.19925914, -2.53665476, -2.33072614, -2.33654993, -1.89891053,\n",
       "          -2.33597242, -2.33328447, -2.33757796, -2.06008965, -2.45445134,\n",
       "          -2.44877783, -2.37704075, -1.91228813, -2.06571708, -2.53586626,\n",
       "          -2.5463409 , -1.1980515 , -2.54319447, -1.89670737, -2.45164883,\n",
       "          -1.19986862, -2.53961654, -2.06122136, -1.89573431, -2.44774211,\n",
       "          -1.89886713, -2.26310139, -1.19871213, -2.45510331, -1.19753808]),\n",
       "   'mean_train_Log_Loss': array([-1.20287127, -2.53805204, -2.33088698, -2.33284083, -1.89987191,\n",
       "          -2.33607239, -2.33740804, -2.33448347, -2.06185041, -2.45251522,\n",
       "          -2.45082316, -2.36922014, -1.9102109 , -2.06378369, -2.539887  ,\n",
       "          -2.54540987, -1.20145482, -2.54505065, -1.8974994 , -2.45187439,\n",
       "          -1.2022151 , -2.53850127, -2.06034784, -1.90043456, -2.44954201,\n",
       "          -1.90042652, -2.26311398, -1.20203125, -2.45261684, -1.20182276]),\n",
       "   'std_train_Log_Loss': array([0.00439663, 0.00111141, 0.00262963, 0.00314811, 0.00191797,\n",
       "          0.00151811, 0.00293361, 0.0023689 , 0.00149198, 0.00140103,\n",
       "          0.00374903, 0.00712105, 0.00278727, 0.0022224 , 0.00285042,\n",
       "          0.00215704, 0.0040449 , 0.0013166 , 0.00203056, 0.00137198,\n",
       "          0.00401944, 0.00078865, 0.00252013, 0.00415567, 0.00248229,\n",
       "          0.00323024, 0.00072825, 0.00446038, 0.00390482, 0.005327  ])},\n",
       "  {'n_estimators': 350,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 35},\n",
       "  20,\n",
       "  -1.6005529493828803),\n",
       " 'DecisionTreeClassifier_V001_PCA_5components': ({'mean_fit_time': array([0.02559789, 0.00897177, 0.05884194, 0.02160875, 0.04953392,\n",
       "          0.03656785, 0.03557118, 0.01961358, 0.01230065, 0.02027869,\n",
       "          0.03523827, 0.06283164, 0.01229946, 0.01462666, 0.00764585,\n",
       "          0.03258014, 0.01761913, 0.00997305, 0.02592985, 0.02593001,\n",
       "          0.04155548, 0.00698098, 0.0159568 , 0.02892176, 0.02958719,\n",
       "          0.08676831, 0.01097043, 0.02825737, 0.05551783, 0.03224746]),\n",
       "   'std_fit_time': array([4.70246599e-04, 8.10988693e-04, 2.93682304e-03, 1.69584060e-03,\n",
       "          1.69535747e-03, 4.69796871e-04, 9.40492896e-04, 4.70583653e-04,\n",
       "          1.88064859e-03, 4.70527507e-04, 3.29099453e-03, 1.41073933e-03,\n",
       "          1.69503008e-03, 4.70302724e-04, 4.70021816e-04, 2.61805990e-03,\n",
       "          9.40380565e-04, 2.15475595e-03, 8.13809386e-04, 8.14101394e-04,\n",
       "          3.67194344e-03, 4.05233662e-07, 8.15075222e-04, 3.54979151e-03,\n",
       "          1.69513918e-03, 2.93655310e-03, 4.05233662e-07, 9.39706155e-04,\n",
       "          5.42204036e-03, 3.38991986e-03]),\n",
       "   'mean_score_time': array([0.02991994, 0.03025309, 0.04055874, 0.03457435, 0.02659575,\n",
       "          0.02593152, 0.02593136, 0.02925507, 0.03224691, 0.02493318,\n",
       "          0.02958798, 0.02825832, 0.02726118, 0.0289228 , 0.03191479,\n",
       "          0.03257926, 0.0272611 , 0.02825769, 0.02692835, 0.02925595,\n",
       "          0.02559876, 0.02626292, 0.02659535, 0.02460138, 0.02626348,\n",
       "          0.02559829, 0.02659583, 0.03723399, 0.04687508, 0.02626284]),\n",
       "   'std_score_time': array([0.0008142 , 0.00658157, 0.01105604, 0.01084395, 0.00094061,\n",
       "          0.00081478, 0.00081381, 0.00169508, 0.00497581, 0.00081439,\n",
       "          0.00463025, 0.00124407, 0.00204937, 0.00215417, 0.00850177,\n",
       "          0.00523435, 0.00124418, 0.00248823, 0.0008142 , 0.00329195,\n",
       "          0.00308327, 0.00094032, 0.00248801, 0.0004703 , 0.00124401,\n",
       "          0.00094038, 0.00047019, 0.01739575, 0.00705229, 0.00204915]),\n",
       "   'param_min_samples_split': masked_array(data=[0.8300000000000001, 0.63, 0.11, 0.64, 0.28, 0.62, 0.52,\n",
       "                      0.81, 0.42, 0.8300000000000001, 0.4, 0.07, 0.38,\n",
       "                      0.9400000000000001, 0.8, 0.49, 0.43, 0.77, 0.99, 0.71,\n",
       "                      0.52, 0.79, 0.54, 0.68, 0.44, 0.01, 0.36, 0.62, 0.25,\n",
       "                      0.55],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'log2', 'sqrt', 'sqrt', 0.5, 'log2', 'log2',\n",
       "                      0.5, 'sqrt', 0.5, 'log2', 'log2', 0.5, 'log2', 'sqrt',\n",
       "                      0.5, 'log2', 0.5, 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'log2', 0.5, 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                      0.5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[None, None, None, 20, None, None, None, None, 20, 20,\n",
       "                      None, 20, None, None, 20, None, 20, 20, 20, None, None,\n",
       "                      20, 20, None, None, 20, 20, 20, None, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_criterion': masked_array(data=['entropy', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                      'entropy', 'entropy', 'entropy', 'gini', 'entropy',\n",
       "                      'entropy', 'entropy', 'gini', 'gini', 'gini',\n",
       "                      'entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                      'entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                      'entropy', 'gini', 'entropy', 'entropy', 'entropy'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=['balanced', None, None, None, 'balanced', 'balanced',\n",
       "                      'balanced', None, None, None, None, None, None,\n",
       "                      'balanced', None, None, 'balanced', None, 'balanced',\n",
       "                      'balanced', 'balanced', None, 'balanced', 'balanced',\n",
       "                      None, 'balanced', None, None, 'balanced', None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'min_samples_split': 0.8300000000000001,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.63,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.11,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.64,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.28,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.62,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.52,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.81,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.42,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.8300000000000001,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.4,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.07,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.38,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.9400000000000001,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.8,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.49,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.43,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.77,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.99,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.71,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.52,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.79,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.54,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.68,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.44,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.01,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.36,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.62,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.25,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.55,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None}],\n",
       "   'split0_test_Accuracy': array([0.04625314, 0.08246683, 0.18214414, 0.0627465 , 0.12119039,\n",
       "          0.06669057, 0.06669057, 0.06704912, 0.11330226, 0.06704912,\n",
       "          0.09322338, 0.23592686, 0.12370025, 0.04589459, 0.06740767,\n",
       "          0.07601291, 0.07995697, 0.06740767, 0.04625314, 0.04804589,\n",
       "          0.06669057, 0.06704912, 0.07135174, 0.04625314, 0.07995697,\n",
       "          0.34994622, 0.10541413, 0.07278594, 0.11617067, 0.08533525]),\n",
       "   'split1_test_Accuracy': array([0.0465368 , 0.08585859, 0.15909091, 0.06168831, 0.10714286,\n",
       "          0.07070707, 0.06818182, 0.06421356, 0.0995671 , 0.06782107,\n",
       "          0.08766234, 0.21500722, 0.0952381 , 0.04401154, 0.06168831,\n",
       "          0.07287157, 0.08766234, 0.09415584, 0.04329004, 0.0465368 ,\n",
       "          0.06854257, 0.06493506, 0.06926407, 0.0465368 , 0.06998557,\n",
       "          0.37049062, 0.1046176 , 0.08549784, 0.10750361, 0.07720058]),\n",
       "   'split2_test_Accuracy': array([0.04780876, 0.08040565, 0.17783412, 0.06664252, 0.09489315,\n",
       "          0.06990221, 0.05831221, 0.06664252, 0.10105034, 0.0673669 ,\n",
       "          0.11046722, 0.21803694, 0.11191597, 0.04780876, 0.06302064,\n",
       "          0.08438971, 0.08801159, 0.06700471, 0.04780876, 0.04563564,\n",
       "          0.06084752, 0.06700471, 0.06591815, 0.06990221, 0.09308222,\n",
       "          0.35747917, 0.09923941, 0.08438971, 0.13654473, 0.08438971]),\n",
       "   'mean_test_Accuracy': array([0.04686373, 0.08291276, 0.17303533, 0.06368661, 0.10778659,\n",
       "          0.06909397, 0.06440759, 0.06596972, 0.10466234, 0.06741168,\n",
       "          0.09709205, 0.22302331, 0.11031002, 0.04590243, 0.0640471 ,\n",
       "          0.07774573, 0.08519587, 0.07618361, 0.04578226, 0.04674357,\n",
       "          0.0653689 , 0.06633021, 0.06885364, 0.0541937 , 0.08099015,\n",
       "          0.35928863, 0.10310022, 0.08086998, 0.12004326, 0.08231194]),\n",
       "   'std_test_Accuracy': array([0.00067591, 0.00224557, 0.01001076, 0.00212723, 0.01074723,\n",
       "          0.00173762, 0.00433798, 0.00125217, 0.00616387, 0.00031709,\n",
       "          0.00969467, 0.00924411, 0.01168808, 0.00154812, 0.00244698,\n",
       "          0.00485437, 0.00372221, 0.01270248, 0.00187235, 0.00099494,\n",
       "          0.00327456, 0.00098615, 0.00223751, 0.01106918, 0.00944492,\n",
       "          0.00849324, 0.00273983, 0.00575723, 0.01215497, 0.0036329 ]),\n",
       "   'rank_test_Accuracy': array([27, 11,  3, 25,  6, 17, 23, 21,  7, 19,  9,  2,  5, 29, 24, 15, 10,\n",
       "          16, 30, 28, 22, 20, 18, 26, 13,  1,  8, 14,  4, 12]),\n",
       "   'split0_train_Accuracy': array([0.04699078, 0.0824146 , 0.19212001, 0.06651003, 0.12560998,\n",
       "          0.06922104, 0.06831737, 0.06416049, 0.10988614, 0.06416049,\n",
       "          0.0930779 , 0.24923188, 0.12814025, 0.04536418, 0.0663293 ,\n",
       "          0.07392012, 0.0797036 , 0.0663293 , 0.04699078, 0.04825592,\n",
       "          0.06922104, 0.07157058, 0.07102838, 0.04699078, 0.08512561,\n",
       "          0.4333996 , 0.10374119, 0.07500452, 0.11458522, 0.08386047]),\n",
       "   'split1_train_Accuracy': array([0.04666667, 0.08900901, 0.17657658, 0.06522523, 0.10864865,\n",
       "          0.06990991, 0.06972973, 0.06720721, 0.09801802, 0.07027027,\n",
       "          0.08846847, 0.23387387, 0.10594595, 0.04522523, 0.06522523,\n",
       "          0.07585586, 0.08918919, 0.09747748, 0.04504505, 0.04666667,\n",
       "          0.06846847, 0.06738739, 0.06900901, 0.04666667, 0.07405405,\n",
       "          0.44936937, 0.11351351, 0.08882883, 0.11207207, 0.08432432]),\n",
       "   'split2_train_Accuracy': array([0.0476533 , 0.08038123, 0.18270095, 0.06401726, 0.09584607,\n",
       "          0.06869268, 0.0627585 , 0.06401726, 0.09872325, 0.06635497,\n",
       "          0.11364862, 0.22729725, 0.11436792, 0.04747348, 0.06491638,\n",
       "          0.08487682, 0.09045136, 0.06689444, 0.0476533 , 0.04549541,\n",
       "          0.06149973, 0.06689444, 0.06851286, 0.06869268, 0.09674519,\n",
       "          0.43481388, 0.10321885, 0.08487682, 0.14026254, 0.08487682]),\n",
       "   'mean_train_Accuracy': array([0.04710358, 0.08393495, 0.18379918, 0.06525084, 0.1100349 ,\n",
       "          0.06927454, 0.0669352 , 0.06512832, 0.10220914, 0.06692858,\n",
       "          0.09839833, 0.236801  , 0.11615137, 0.04602096, 0.0654903 ,\n",
       "          0.0782176 , 0.08644805, 0.07690041, 0.04656304, 0.046806  ,\n",
       "          0.06639641, 0.06861747, 0.06951675, 0.05411671, 0.08530828,\n",
       "          0.43919428, 0.10682452, 0.08290339, 0.12230661, 0.08435387]),\n",
       "   'std_train_Accuracy': array([0.00041061, 0.00368268, 0.00639292, 0.00101783, 0.01219054,\n",
       "          0.00049837, 0.00300913, 0.00147116, 0.00543609, 0.00252707,\n",
       "          0.01094655, 0.00919087, 0.00914813, 0.00102865, 0.00060651,\n",
       "          0.00477464, 0.0047968 , 0.01455202, 0.00110694, 0.00113127,\n",
       "          0.00347608, 0.00209784, 0.00108791, 0.01030762, 0.00926452,\n",
       "          0.007218  , 0.00473464, 0.0058137 , 0.01273815, 0.00041545]),\n",
       "   'split0_test_F1': array([0.00420902, 0.0172303 , 0.10701621, 0.01017589, 0.03607613,\n",
       "          0.0091428 , 0.01025503, 0.01138125, 0.03910857, 0.01138125,\n",
       "          0.02226945, 0.16426898, 0.04290992, 0.0051423 , 0.01188682,\n",
       "          0.01384532, 0.01694   , 0.01188682, 0.00420902, 0.00479541,\n",
       "          0.0091428 , 0.01005187, 0.01023571, 0.00420902, 0.01718254,\n",
       "          0.33231265, 0.03250604, 0.01366136, 0.0305268 , 0.01946879]),\n",
       "   'split1_test_F1': array([0.00437838, 0.01790153, 0.08757115, 0.01009136, 0.02884547,\n",
       "          0.00988747, 0.01051133, 0.01100221, 0.02940098, 0.009211  ,\n",
       "          0.01730998, 0.15439339, 0.035352  , 0.0049437 , 0.01009136,\n",
       "          0.01580054, 0.0199218 , 0.02522262, 0.00496275, 0.00437838,\n",
       "          0.0094688 , 0.01133028, 0.00974657, 0.00437838, 0.01500533,\n",
       "          0.35528023, 0.03687422, 0.01770162, 0.0278078 , 0.0170578 ]),\n",
       "   'split2_test_F1': array([0.00520189, 0.0172157 , 0.09968485, 0.01093876, 0.02110861,\n",
       "          0.00977431, 0.00917152, 0.01093876, 0.02348642, 0.01190919,\n",
       "          0.03193053, 0.15406461, 0.03579309, 0.00551452, 0.01038723,\n",
       "          0.01682342, 0.01903502, 0.01209045, 0.00520189, 0.00426862,\n",
       "          0.00948592, 0.01209045, 0.01002796, 0.00977431, 0.024712  ,\n",
       "          0.33740827, 0.02421578, 0.01682342, 0.04879385, 0.01682342]),\n",
       "   'mean_test_F1': array([0.00459484, 0.01744904, 0.09810686, 0.01040083, 0.02870186,\n",
       "          0.00960036, 0.00998093, 0.01110819, 0.03069206, 0.01083351,\n",
       "          0.02382275, 0.15759397, 0.03803127, 0.00519964, 0.01079124,\n",
       "          0.01548464, 0.01862828, 0.01639644, 0.00478949, 0.00448173,\n",
       "          0.00936522, 0.01115404, 0.01000385, 0.00611184, 0.01895538,\n",
       "          0.34165357, 0.03121058, 0.01605622, 0.0356816 , 0.01778804]),\n",
       "   'std_test_F1': array([0.0004333 , 0.00031984, 0.00802507, 0.00038061, 0.00611233,\n",
       "          0.00032812, 0.00057986, 0.00019559, 0.00644372, 0.00116675,\n",
       "          0.00606188, 0.00474099, 0.00346839, 0.00023625, 0.00078713,\n",
       "          0.00123633, 0.00125198, 0.00623823, 0.00042349, 0.00022716,\n",
       "          0.00015807, 0.00084165, 0.00020065, 0.00258159, 0.00415271,\n",
       "          0.00985249, 0.0052421 , 0.00173758, 0.00930579, 0.00119711]),\n",
       "   'rank_test_F1': array([29, 13,  3, 21,  8, 24, 23, 18,  7, 19,  9,  2,  4, 27, 20, 16, 11,\n",
       "          14, 28, 30, 25, 17, 22, 26, 10,  1,  6, 15,  5, 12]),\n",
       "   'split0_train_F1': array([0.00428199, 0.01734241, 0.11286027, 0.01079298, 0.03795284,\n",
       "          0.00957132, 0.01042185, 0.01094164, 0.03777873, 0.01094164,\n",
       "          0.02307183, 0.17274639, 0.04454494, 0.00513348, 0.01165302,\n",
       "          0.01347909, 0.01651222, 0.01165302, 0.00428199, 0.00479506,\n",
       "          0.00957132, 0.01076903, 0.01026758, 0.00428199, 0.01828755,\n",
       "          0.41476772, 0.03251107, 0.01423829, 0.02973026, 0.01916089]),\n",
       "   'split1_train_F1': array([0.00436228, 0.01852728, 0.09976271, 0.01069111, 0.02899787,\n",
       "          0.00973171, 0.01069716, 0.01163421, 0.02936686, 0.00954031,\n",
       "          0.01733632, 0.1710617 , 0.04103086, 0.00504975, 0.01069111,\n",
       "          0.01634472, 0.02008219, 0.02635352, 0.00507027, 0.00436228,\n",
       "          0.00951284, 0.01190849, 0.00975463, 0.00436228, 0.01597996,\n",
       "          0.43443077, 0.04212064, 0.01834736, 0.02929827, 0.0187988 ]),\n",
       "   'split2_train_F1': array([0.00512493, 0.01711891, 0.10094478, 0.01041181, 0.02146958,\n",
       "          0.00951299, 0.01059485, 0.01041181, 0.02290088, 0.01164046,\n",
       "          0.03286972, 0.16037293, 0.03722779, 0.00539138, 0.01063528,\n",
       "          0.01681293, 0.01960423, 0.01200236, 0.00512493, 0.00424366,\n",
       "          0.00997549, 0.01200236, 0.01052761, 0.00951299, 0.02576125,\n",
       "          0.41108031, 0.02581683, 0.01681293, 0.05107867, 0.01681293]),\n",
       "   'mean_train_F1': array([0.00458973, 0.01766287, 0.10452259, 0.01063197, 0.02947343,\n",
       "          0.00960534, 0.01057129, 0.01099589, 0.03001549, 0.01070747,\n",
       "          0.02442596, 0.16806034, 0.04093453, 0.00519154, 0.01099314,\n",
       "          0.01554558, 0.01873288, 0.01666963, 0.00482573, 0.004467  ,\n",
       "          0.00968655, 0.01155996, 0.01018327, 0.00605242, 0.02000959,\n",
       "          0.42009293, 0.03348285, 0.01646619, 0.0367024 , 0.01825754]),\n",
       "   'std_train_F1': array([3.79860069e-04, 6.18004452e-04, 5.91534877e-03, 1.61133177e-04,\n",
       "          6.73766034e-03, 9.24762921e-05, 1.13624781e-04, 5.00513682e-04,\n",
       "          6.09114636e-03, 8.73225082e-04, 6.41336457e-03, 5.47915577e-03,\n",
       "          2.98799067e-03, 1.45382953e-04, 4.67161440e-04, 1.47368204e-03,\n",
       "          1.58232058e-03, 6.84902633e-03, 3.85131301e-04, 2.36977261e-04,\n",
       "          2.05701918e-04, 5.60585419e-04, 3.21149252e-04, 2.44721124e-03,\n",
       "          4.17472294e-03, 1.02495327e-02, 6.69137929e-03, 1.69534187e-03,\n",
       "          1.01670883e-02, 1.03213109e-03]),\n",
       "   'split0_test_Log_Loss': array([-3.421774  , -3.24747743, -2.96413313, -3.39607978, -2.99314023,\n",
       "          -3.19166096, -3.22830178, -3.35469483, -3.02558121, -3.35469483,\n",
       "          -3.16240573, -2.90467979, -2.97055801, -3.48901139, -3.34698334,\n",
       "          -3.23948844, -3.13837684, -3.34698334, -3.421774  , -3.41795749,\n",
       "          -3.19166096, -3.39717678, -3.22275541, -3.421774  , -3.29649424,\n",
       "          -5.43842564, -3.13952967, -3.21878713, -3.09799317, -3.32045209]),\n",
       "   'split1_test_Log_Loss': array([-3.40456397, -3.22989527, -3.0484869 , -3.3788488 , -3.1192191 ,\n",
       "          -3.25455539, -3.27799002, -3.37104237, -3.12480844, -3.40790054,\n",
       "          -3.17458255, -2.95923779, -3.14396125, -3.50129754, -3.3788488 ,\n",
       "          -3.27088908, -3.17334493, -3.27257728, -3.53969727, -3.40456397,\n",
       "          -3.23890085, -3.37333317, -3.21363931, -3.40456397, -3.30010238,\n",
       "          -5.35384434, -3.00669726, -3.25364377, -3.12175827, -3.33060373]),\n",
       "   'split2_test_Log_Loss': array([-3.36044795, -3.19842809, -2.85679271, -3.36743707, -3.02357991,\n",
       "          -3.15271504, -3.24650859, -3.36743707, -3.03447301, -3.33645948,\n",
       "          -3.00613854, -3.10678376, -3.13806803, -3.3932986 , -3.37321057,\n",
       "          -3.12932878, -3.20133284, -3.36733775, -3.36044795, -3.39927472,\n",
       "          -3.33832986, -3.36733775, -3.27308335, -3.15271504, -3.13195958,\n",
       "          -5.10949847, -2.97837346, -3.12932878, -2.94710605, -3.12932878]),\n",
       "   'mean_test_Log_Loss': array([-3.39569524, -3.22534778, -2.95661832, -3.38083743, -3.04523523,\n",
       "          -3.19968952, -3.25089308, -3.36436759, -3.06158315, -3.36636732,\n",
       "          -3.11461679, -2.98990495, -3.08389242, -3.46134907, -3.36629894,\n",
       "          -3.21339997, -3.17091145, -3.32895221, -3.4407072 , -3.4072978 ,\n",
       "          -3.25605675, -3.37933491, -3.23641626, -3.32677545, -3.24310822,\n",
       "          -5.30112364, -3.04181713, -3.20071793, -3.05584916, -3.26042432]),\n",
       "   'std_test_Log_Loss': array([0.02581296, 0.02028388, 0.07833471, 0.01177944, 0.05374318,\n",
       "          0.04190927, 0.02054243, 0.00702297, 0.04483012, 0.0302822 ,\n",
       "          0.07659812, 0.08532103, 0.08050062, 0.04821216, 0.01390494,\n",
       "          0.06061283, 0.02576345, 0.04069916, 0.07430508, 0.00786935,\n",
       "          0.06110237, 0.01290098, 0.02610375, 0.12284849, 0.07833176,\n",
       "          0.13937882, 0.07032809, 0.05228102, 0.0772361 , 0.09246606]),\n",
       "   'rank_test_Log_Loss': array([26, 13,  1, 25,  4, 10, 16, 21,  6, 23,  8,  2,  7, 29, 22, 12,  9,\n",
       "          20, 28, 27, 17, 24, 14, 19, 15, 30,  3, 11,  5, 18]),\n",
       "   'split0_train_Log_Loss': array([-3.38700443, -3.22394664, -2.6136788 , -3.36115059, -2.84789205,\n",
       "          -3.15732988, -3.2090794 , -3.337121  , -2.99960558, -3.337121  ,\n",
       "          -3.06278906, -2.33622634, -2.9202304 , -3.47733943, -3.34026081,\n",
       "          -3.19653614, -3.12167496, -3.34026081, -3.38700443, -3.4067254 ,\n",
       "          -3.15732988, -3.39647416, -3.20971939, -3.38700443, -3.25845133,\n",
       "          -1.553534  , -3.02098793, -3.1694904 , -2.89906234, -3.27497985]),\n",
       "   'split1_train_Log_Loss': array([-3.38778386, -3.17596274, -2.61994523, -3.36189927, -2.96655985,\n",
       "          -3.18968944, -3.2013369 , -3.33435218, -3.03442228, -3.37422348,\n",
       "          -3.13032764, -2.3597054 , -3.01234861, -3.47612477, -3.36189927,\n",
       "          -3.22091854, -3.1140251 , -3.24613245, -3.4757947 , -3.38778386,\n",
       "          -3.1505555 , -3.33603429, -3.15159646, -3.38778386, -3.28411883,\n",
       "          -1.51299716, -2.91432991, -3.17604907, -2.95536203, -3.27401048]),\n",
       "   'split2_train_Log_Loss': array([-3.37123354, -3.16661342, -2.60253413, -3.36661159, -2.96029842,\n",
       "          -3.16740646, -3.20872564, -3.36661159, -2.99949799, -3.34578939,\n",
       "          -2.95194119, -2.38632304, -2.98531633, -3.37393977, -3.3668623 ,\n",
       "          -3.1425902 , -3.10395428, -3.34843914, -3.37123354, -3.39258774,\n",
       "          -3.32396851, -3.34843914, -3.22170583, -3.16740646, -3.08748693,\n",
       "          -1.54459432, -2.90645356, -3.1425902 , -2.81106232, -3.1425902 ]),\n",
       "   'mean_train_Log_Loss': array([-3.38200727, -3.18884094, -2.61205272, -3.36322048, -2.92491677,\n",
       "          -3.17147526, -3.20638065, -3.34602826, -3.01117528, -3.35237796,\n",
       "          -3.04835263, -2.3607516 , -2.97263178, -3.44246799, -3.3563408 ,\n",
       "          -3.18668163, -3.11321812, -3.3116108 , -3.41134422, -3.395699  ,\n",
       "          -3.21061797, -3.36031586, -3.19434056, -3.31406491, -3.21001903,\n",
       "          -1.53704183, -2.94725713, -3.16270989, -2.88849556, -3.23052685]),\n",
       "   'std_train_Log_Loss': array([0.00762483, 0.02511521, 0.00720045, 0.00241728, 0.05452465,\n",
       "          0.01352039, 0.00356939, 0.01459844, 0.01643817, 0.0158473 ,\n",
       "          0.07353793, 0.02046527, 0.03866191, 0.0484593 , 0.01154938,\n",
       "          0.03272783, 0.00725691, 0.04642041, 0.04602593, 0.00803971,\n",
       "          0.08019864, 0.0260645 , 0.03061821, 0.10370368, 0.08727463,\n",
       "          0.01738944, 0.05223461, 0.01447654, 0.05938206, 0.06218186])},\n",
       "  {'min_samples_split': 0.11,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None,\n",
       "   'criterion': 'entropy',\n",
       "   'class_weight': None},\n",
       "  2,\n",
       "  -2.95661831943423),\n",
       " 'KNeighborsClassifier_V001_PCA_5components': ({'mean_fit_time': array([0.00730435, 0.00698042, 0.00897574, 0.0066483 , 0.00930762,\n",
       "          0.00698153, 0.01063824, 0.0066479 , 0.00997345, 0.010638  ,\n",
       "          0.0066487 , 0.00897702, 0.01063816, 0.01329692, 0.00631595,\n",
       "          0.00864347, 0.00964014, 0.00598351, 0.00664918, 0.01396251,\n",
       "          0.00797884, 0.01196647, 0.00731413, 0.00731333, 0.00565108,\n",
       "          0.00930731, 0.01196782, 0.0079778 , 0.00930794, 0.00831056]),\n",
       "   'std_fit_time': array([4.57770971e-04, 8.14782742e-04, 3.37174788e-07, 4.70021816e-04,\n",
       "          1.24387907e-03, 8.14782819e-04, 1.24407017e-03, 4.70078344e-04,\n",
       "          8.13517879e-04, 9.40717840e-04, 1.24411268e-03, 8.13809712e-04,\n",
       "          1.24417637e-03, 3.29125142e-03, 4.70021655e-04, 1.69531061e-03,\n",
       "          1.24309330e-03, 8.14004147e-04, 9.40436806e-04, 3.54992547e-03,\n",
       "          8.14685398e-04, 3.54988085e-03, 4.69909424e-04, 9.40268092e-04,\n",
       "          4.70246599e-04, 9.39649944e-04, 2.44259619e-03, 2.97360213e-07,\n",
       "          4.70134086e-04, 2.61802973e-03]),\n",
       "   'mean_score_time': array([0.3105042 , 0.28656777, 0.11735344, 0.2792538 , 0.11103702,\n",
       "          1.18084367, 0.13264585, 1.00498056, 0.13031785, 0.13729914,\n",
       "          1.28955356, 0.31382513, 0.1253314 , 0.13397511, 1.2426788 ,\n",
       "          0.29055802, 0.11203408, 1.27492563, 1.23636206, 0.14527814,\n",
       "          0.31715131, 0.1303184 , 0.32346916, 1.2962025 , 1.22273207,\n",
       "          0.13031832, 0.10970712, 0.30119499, 0.11236691, 0.23603559]),\n",
       "   'std_score_time': array([0.01836057, 0.03940286, 0.01050224, 0.00570009, 0.0096464 ,\n",
       "          0.02484663, 0.010956  , 0.05642557, 0.0179399 , 0.00915237,\n",
       "          0.02419581, 0.03139467, 0.00611153, 0.01169693, 0.02621043,\n",
       "          0.02001851, 0.01368254, 0.01262425, 0.02874906, 0.00692579,\n",
       "          0.00709862, 0.02075004, 0.0115533 , 0.04427659, 0.06691842,\n",
       "          0.01716505, 0.0024425 , 0.02877878, 0.01792136, 0.00204928]),\n",
       "   'param_weights': masked_array(data=['distance', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'uniform', 'distance',\n",
       "                      'distance', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'distance', 'distance', 'distance',\n",
       "                      'distance', 'uniform', 'uniform', 'uniform',\n",
       "                      'distance', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'uniform',\n",
       "                      'uniform'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[7, 4, 6, 5, 5, 4, 8, 3, 6, 8, 7, 6, 4, 7, 5, 4, 3, 4,\n",
       "                      7, 6, 8, 6, 6, 6, 8, 5, 5, 5, 3, 3],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['ball_tree', 'ball_tree', 'auto', 'ball_tree', 'auto',\n",
       "                      'brute', 'kd_tree', 'brute', 'kd_tree', 'auto',\n",
       "                      'brute', 'ball_tree', 'kd_tree', 'auto', 'brute',\n",
       "                      'ball_tree', 'auto', 'brute', 'brute', 'kd_tree',\n",
       "                      'ball_tree', 'auto', 'ball_tree', 'brute', 'brute',\n",
       "                      'kd_tree', 'auto', 'ball_tree', 'auto', 'ball_tree'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'distance',\n",
       "     'n_neighbors': 7,\n",
       "     'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'ball_tree'}],\n",
       "   'split0_test_Accuracy': array([0.60380065, 0.56615274, 0.55252779, 0.56256723, 0.56256723,\n",
       "          0.56615274, 0.59268555, 0.56902115, 0.59985658, 0.59268555,\n",
       "          0.60380065, 0.59985658, 0.56615274, 0.5546791 , 0.60272499,\n",
       "          0.60953747, 0.61240588, 0.60953747, 0.5546791 , 0.55252779,\n",
       "          0.54607386, 0.59985658, 0.55252779, 0.59985658, 0.54607386,\n",
       "          0.60272499, 0.60272499, 0.60272499, 0.56902115, 0.56902115]),\n",
       "   'split1_test_Accuracy': array([0.59199134, 0.56637807, 0.54617605, 0.55663781, 0.55663781,\n",
       "          0.56637807, 0.59126984, 0.56421356, 0.5959596 , 0.59126984,\n",
       "          0.59199134, 0.5959596 , 0.56637807, 0.54834055, 0.59848485,\n",
       "          0.60281385, 0.59920635, 0.60281385, 0.54834055, 0.54617605,\n",
       "          0.54220779, 0.5959596 , 0.54617605, 0.5959596 , 0.54220779,\n",
       "          0.59848485, 0.59848485, 0.59848485, 0.56421356, 0.56421356]),\n",
       "   'split2_test_Accuracy': array([0.590728  , 0.5613908 , 0.54545455, 0.55885549, 0.55885549,\n",
       "          0.5613908 , 0.59000362, 0.57406737, 0.59145237, 0.59000362,\n",
       "          0.590728  , 0.59145237, 0.5613908 , 0.54545455, 0.59724737,\n",
       "          0.60268019, 0.60485331, 0.60268019, 0.54545455, 0.54545455,\n",
       "          0.54328142, 0.59145237, 0.54545455, 0.59145237, 0.54328142,\n",
       "          0.59724737, 0.59724737, 0.59724737, 0.57406737, 0.57406737]),\n",
       "   'mean_test_Accuracy': array([0.59552992, 0.56464792, 0.54806537, 0.55936073, 0.55936073,\n",
       "          0.56464792, 0.5913242 , 0.56909397, 0.59577025, 0.5913242 ,\n",
       "          0.59552992, 0.59577025, 0.56464792, 0.54950733, 0.59949531,\n",
       "          0.60502283, 0.60550348, 0.60502283, 0.54950733, 0.54806537,\n",
       "          0.54385965, 0.59577025, 0.54806537, 0.59577025, 0.54385965,\n",
       "          0.59949531, 0.59949531, 0.59949531, 0.56909397, 0.56909397]),\n",
       "   'std_test_Accuracy': array([0.00589457, 0.00229689, 0.00318184, 0.00244951, 0.00244951,\n",
       "          0.00229689, 0.00109575, 0.00401768, 0.00343419, 0.00109575,\n",
       "          0.00589457, 0.00343419, 0.00229689, 0.00385574, 0.00234784,\n",
       "          0.00320575, 0.00541439, 0.00320575, 0.00385574, 0.00318184,\n",
       "          0.00163184, 0.00343419, 0.00318184, 0.00343419, 0.00163184,\n",
       "          0.00234784, 0.00234784, 0.00234784, 0.00401768, 0.00401768]),\n",
       "   'rank_test_Accuracy': array([12, 19, 26, 22, 22, 19, 14, 16,  8, 14, 12,  8, 19, 24,  4,  2,  1,\n",
       "           2, 24, 26, 29,  8, 26,  8, 29,  4,  4,  4, 16, 16]),\n",
       "   'split0_train_Accuracy': array([1.        , 0.73251401, 0.69040304, 0.71317549, 0.71317549,\n",
       "          0.73251401, 1.        , 0.77299837, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73251401, 0.67449846, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67449846, 0.69040304,\n",
       "          0.66112416, 1.        , 0.69040304, 1.        , 0.66112416,\n",
       "          1.        , 1.        , 1.        , 0.77299837, 0.77299837]),\n",
       "   'split1_train_Accuracy': array([1.        , 0.73711712, 0.68720721, 0.70936937, 0.70936937,\n",
       "          0.73711712, 1.        , 0.76846847, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73711712, 0.67261261, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67261261, 0.68720721,\n",
       "          0.66216216, 1.        , 0.68720721, 1.        , 0.66216216,\n",
       "          1.        , 1.        , 1.        , 0.76846847, 0.76846847]),\n",
       "   'split2_train_Accuracy': array([1.        , 0.73727747, 0.68494875, 0.70526884, 0.70526884,\n",
       "          0.73727747, 1.        , 0.77575976, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73727747, 0.67290056, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67290056, 0.68494875,\n",
       "          0.6595936 , 1.        , 0.68494875, 1.        , 0.6595936 ,\n",
       "          1.        , 1.        , 1.        , 0.77575976, 0.77575976]),\n",
       "   'mean_train_Accuracy': array([1.        , 0.7356362 , 0.68751966, 0.70927123, 0.70927123,\n",
       "          0.7356362 , 1.        , 0.77240887, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.7356362 , 0.67333721, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67333721, 0.68751966,\n",
       "          0.66095997, 1.        , 0.68751966, 1.        , 0.66095997,\n",
       "          1.        , 1.        , 1.        , 0.77240887, 0.77240887]),\n",
       "   'std_train_Accuracy': array([0.        , 0.00220869, 0.00223764, 0.00322862, 0.00322862,\n",
       "          0.00220869, 0.        , 0.0030057 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.00220869, 0.0008295 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.0008295 , 0.00223764,\n",
       "          0.00105502, 0.        , 0.00223764, 0.        , 0.00105502,\n",
       "          0.        , 0.        , 0.        , 0.0030057 , 0.0030057 ]),\n",
       "   'split0_test_F1': array([0.59901906, 0.56108368, 0.54761113, 0.55721097, 0.55721097,\n",
       "          0.56108368, 0.58728517, 0.56532698, 0.59526328, 0.58728517,\n",
       "          0.59901906, 0.59526328, 0.56108368, 0.54902975, 0.59806466,\n",
       "          0.60495391, 0.60913848, 0.60495391, 0.54902975, 0.54761113,\n",
       "          0.53983944, 0.59526328, 0.54761113, 0.59526328, 0.53983944,\n",
       "          0.59806466, 0.59806466, 0.59806466, 0.56532698, 0.56532698]),\n",
       "   'split1_test_F1': array([0.58607136, 0.56093802, 0.53986695, 0.55121467, 0.55121467,\n",
       "          0.56093802, 0.5846577 , 0.5594837 , 0.59032913, 0.5846577 ,\n",
       "          0.58607136, 0.59032913, 0.56093802, 0.54147483, 0.59358835,\n",
       "          0.59782941, 0.59499369, 0.59782941, 0.54147483, 0.53986695,\n",
       "          0.5341538 , 0.59032913, 0.53986695, 0.59032913, 0.5341538 ,\n",
       "          0.59358835, 0.59358835, 0.59358835, 0.5594837 , 0.5594837 ]),\n",
       "   'split2_test_F1': array([0.58682842, 0.55835808, 0.54362669, 0.55599973, 0.55599973,\n",
       "          0.55835808, 0.58522551, 0.56941197, 0.58777413, 0.58522551,\n",
       "          0.58682842, 0.58777413, 0.55835808, 0.54310878, 0.59470624,\n",
       "          0.59934603, 0.60223673, 0.59934603, 0.54310878, 0.54362669,\n",
       "          0.5406936 , 0.58777413, 0.54362669, 0.58777413, 0.5406936 ,\n",
       "          0.59470624, 0.59470624, 0.59470624, 0.56941197, 0.56941197]),\n",
       "   'mean_test_F1': array([0.59066177, 0.56013089, 0.54370968, 0.55481179, 0.55481179,\n",
       "          0.56013089, 0.58572664, 0.5647359 , 0.59113507, 0.58572664,\n",
       "          0.59066177, 0.59113507, 0.56013089, 0.54454885, 0.5954594 ,\n",
       "          0.60072026, 0.60213714, 0.60072026, 0.54454885, 0.54370968,\n",
       "          0.53822898, 0.59113507, 0.54370968, 0.59113507, 0.53822898,\n",
       "          0.5954594 , 0.5954594 , 0.5954594 , 0.5647359 , 0.5647359 ]),\n",
       "   'std_test_F1': array([0.0059415 , 0.00125058, 0.00316577, 0.00258983, 0.00258983,\n",
       "          0.00125058, 0.00113047, 0.0040694 , 0.00311054, 0.00113047,\n",
       "          0.0059415 , 0.00311054, 0.00125058, 0.00325033, 0.00190499,\n",
       "          0.00306873, 0.00578175, 0.00306873, 0.00325033, 0.00316577,\n",
       "          0.00290107, 0.00311054, 0.00316577, 0.00311054, 0.00290107,\n",
       "          0.00190499, 0.00190499, 0.00190499, 0.0040694 , 0.0040694 ]),\n",
       "   'rank_test_F1': array([12, 19, 26, 22, 22, 19, 14, 16,  8, 14, 12,  8, 19, 24,  4,  2,  1,\n",
       "           2, 24, 26, 29,  8, 26,  8, 29,  4,  4,  4, 16, 16]),\n",
       "   'split0_train_F1': array([1.        , 0.73031837, 0.68715206, 0.7102959 , 0.7102959 ,\n",
       "          0.73031837, 1.        , 0.77061194, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73031837, 0.67054974, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67054974, 0.68715206,\n",
       "          0.65744589, 1.        , 0.68715206, 1.        , 0.65744589,\n",
       "          1.        , 1.        , 1.        , 0.77061194, 0.77061194]),\n",
       "   'split1_train_F1': array([1.        , 0.73489938, 0.68447653, 0.70672315, 0.70672315,\n",
       "          0.73489938, 1.        , 0.76547268, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73489938, 0.66953314, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.66953314, 0.68447653,\n",
       "          0.65910983, 1.        , 0.68447653, 1.        , 0.65910983,\n",
       "          1.        , 1.        , 1.        , 0.76547268, 0.76547268]),\n",
       "   'split2_train_F1': array([1.        , 0.73541281, 0.68293945, 0.70331635, 0.70331635,\n",
       "          0.73541281, 1.        , 0.77331477, 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73541281, 0.67039193, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67039193, 0.68293945,\n",
       "          0.65723148, 1.        , 0.68293945, 1.        , 0.65723148,\n",
       "          1.        , 1.        , 1.        , 0.77331477, 0.77331477]),\n",
       "   'mean_train_F1': array([1.        , 0.73354352, 0.68485602, 0.70677847, 0.70677847,\n",
       "          0.73354352, 1.        , 0.7697998 , 1.        , 1.        ,\n",
       "          1.        , 1.        , 0.73354352, 0.67015827, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.67015827, 0.68485602,\n",
       "          0.65792907, 1.        , 0.68485602, 1.        , 0.65792907,\n",
       "          1.        , 1.        , 1.        , 0.7697998 , 0.7697998 ]),\n",
       "   'std_train_F1': array([0.        , 0.00229014, 0.0017406 , 0.00284966, 0.00284966,\n",
       "          0.00229014, 0.        , 0.00325262, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.00229014, 0.00044671, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00044671, 0.0017406 ,\n",
       "          0.0008395 , 0.        , 0.0017406 , 0.        , 0.0008395 ,\n",
       "          0.        , 0.        , 0.        , 0.00325262, 0.00325262]),\n",
       "   'split0_test_Log_Loss': array([-5.57320181, -7.52757671, -6.16222797, -6.73774895, -6.73774895,\n",
       "          -7.52757671, -4.95622676, -8.72154324, -6.09360324, -4.95622676,\n",
       "          -5.57320181, -6.09360324, -7.52757671, -5.6482033 , -6.67793974,\n",
       "          -7.47728361, -8.68196531, -7.47728361, -5.6482033 , -6.16222797,\n",
       "          -5.03739997, -6.09360324, -6.16222797, -6.09360324, -5.03739997,\n",
       "          -6.67793974, -6.67793974, -6.67793974, -8.72154324, -8.72154324]),\n",
       "   'split1_test_Log_Loss': array([-5.65936898, -7.85971937, -6.30608089, -7.0167888 , -7.0167888 ,\n",
       "          -7.85971937, -5.25181389, -8.87652974, -6.24004349, -5.25181389,\n",
       "          -5.65936898, -6.24004349, -7.85971937, -5.73251157, -6.95975706,\n",
       "          -7.81288078, -8.84418666, -7.81288078, -5.73251157, -6.30608089,\n",
       "          -5.33044233, -6.24004349, -6.30608089, -6.24004349, -5.33044233,\n",
       "          -6.95975706, -6.95975706, -6.95975706, -8.87652974, -8.87652974]),\n",
       "   'split2_test_Log_Loss': array([-5.58825722, -7.56137605, -6.07081468, -6.72392635, -6.72392635,\n",
       "          -7.56137605, -5.16095586, -8.76423406, -6.00634439, -5.16095586,\n",
       "          -5.58825722, -6.00634439, -7.56137605, -5.65932832, -6.6683625 ,\n",
       "          -7.51506005, -8.72896097, -7.51506005, -5.65932832, -6.07081468,\n",
       "          -5.23948938, -6.00634439, -6.07081468, -6.00634439, -5.23948938,\n",
       "          -6.6683625 , -6.6683625 , -6.6683625 , -8.76423406, -8.76423406]),\n",
       "   'mean_test_Log_Loss': array([-5.60689845, -7.64942476, -6.17981607, -6.82610923, -6.82610923,\n",
       "          -7.64942476, -5.12260799, -8.78733174, -6.11343149, -5.12260799,\n",
       "          -5.60689845, -6.11343149, -7.64942476, -5.67997676, -6.76863366,\n",
       "          -7.60160182, -8.75159191, -7.60160182, -5.67997676, -6.17981607,\n",
       "          -5.20205778, -6.11343149, -6.17981607, -6.11343149, -5.20205778,\n",
       "          -6.76863366, -6.76863366, -6.76863366, -8.78733174, -8.78733174]),\n",
       "   'std_test_Log_Loss': array([0.0375883 , 0.14925974, 0.09672632, 0.13487605, 0.13487605,\n",
       "          0.14925974, 0.12379849, 0.06540408, 0.0963124 , 0.12379849,\n",
       "          0.0375883 , 0.0963124 , 0.14925974, 0.03740449, 0.13512817,\n",
       "          0.15011061, 0.06819444, 0.15011061, 0.03740449, 0.09672632,\n",
       "          0.12264321, 0.0963124 , 0.09672632, 0.0963124 , 0.12264321,\n",
       "          0.13512817, 0.13512817, 0.13512817, 0.06540408, 0.06540408]),\n",
       "   'rank_test_Log_Loss': array([ 5, 24, 13, 20, 20, 24,  1, 28,  9,  1,  5,  9, 24,  7, 16, 22, 27,\n",
       "          22,  7, 13,  3,  9, 13,  9,  3, 16, 16, 16, 28, 28]),\n",
       "   'split0_train_Log_Loss': array([-3.77251697e-14, -5.67770894e-01, -7.39059362e-01, -6.62497751e-01,\n",
       "          -6.62497751e-01, -5.67770894e-01, -3.77251697e-14, -4.45003036e-01,\n",
       "          -3.77251697e-14, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -5.67770894e-01, -8.04653483e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -3.77251697e-14, -3.77251697e-14, -8.04653483e-01, -7.39059362e-01,\n",
       "          -8.60405483e-01, -3.77251697e-14, -7.39059362e-01, -3.77251697e-14,\n",
       "          -8.60405483e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -4.45003036e-01, -4.45003036e-01]),\n",
       "   'split1_train_Log_Loss': array([-3.77252183e-14, -5.66498288e-01, -7.35916891e-01, -6.59614587e-01,\n",
       "          -6.59614587e-01, -5.66498288e-01, -3.77252183e-14, -4.40371190e-01,\n",
       "          -3.77252183e-14, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -5.66498288e-01, -8.00137158e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -3.77252183e-14, -3.77252183e-14, -8.00137158e-01, -7.35916891e-01,\n",
       "          -8.53639276e-01, -3.77252183e-14, -7.35916891e-01, -3.77252183e-14,\n",
       "          -8.53639276e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -4.40371190e-01, -4.40371190e-01]),\n",
       "   'split2_train_Log_Loss': array([-3.77251228e-14, -5.58652174e-01, -7.32717726e-01, -6.55610821e-01,\n",
       "          -6.55610821e-01, -5.58652174e-01, -3.77251228e-14, -4.40060165e-01,\n",
       "          -3.77251228e-14, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -5.58652174e-01, -7.97746330e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -3.77251228e-14, -3.77251228e-14, -7.97746330e-01, -7.32717726e-01,\n",
       "          -8.51150169e-01, -3.77251228e-14, -7.32717726e-01, -3.77251228e-14,\n",
       "          -8.51150169e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -4.40060165e-01, -4.40060165e-01]),\n",
       "   'mean_train_Log_Loss': array([-3.77251703e-14, -5.64307118e-01, -7.35897993e-01, -6.59241053e-01,\n",
       "          -6.59241053e-01, -5.64307118e-01, -3.77251703e-14, -4.41811464e-01,\n",
       "          -3.77251703e-14, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -5.64307118e-01, -8.00845657e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -3.77251703e-14, -3.77251703e-14, -8.00845657e-01, -7.35897993e-01,\n",
       "          -8.55064976e-01, -3.77251703e-14, -7.35897993e-01, -3.77251703e-14,\n",
       "          -8.55064976e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -4.41811464e-01, -4.41811464e-01]),\n",
       "   'std_train_Log_Loss': array([3.89952081e-20, 4.03226005e-03, 2.58899638e-03, 2.82395693e-03,\n",
       "          2.82395693e-03, 4.03226005e-03, 3.89952081e-20, 2.26035195e-03,\n",
       "          3.89952081e-20, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          4.03226005e-03, 2.86399130e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          3.89952081e-20, 3.89952081e-20, 2.86399130e-03, 2.58899638e-03,\n",
       "          3.91064155e-03, 3.89952081e-20, 2.58899638e-03, 3.89952081e-20,\n",
       "          3.91064155e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          2.26035195e-03, 2.26035195e-03])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "  6,\n",
       "  -5.122607987709848),\n",
       " 'MLPClassifier_V001_PCA_5components': ({'mean_fit_time': array([23.94333474,  1.9551065 , 13.80509973, 17.85062011,  6.71737758,\n",
       "          19.84828107, 18.5999496 , 11.98762496,  9.02055581,  2.64592703,\n",
       "           4.75495712, 21.55405466,  5.93779484, 13.21933206, 14.03880827,\n",
       "           1.08410255, 21.52546477, 20.64016493, 12.33469693, 21.47792363,\n",
       "          10.73031815,  5.09704192,  3.03189468,  9.3679595 , 16.02150925,\n",
       "          11.19208423, 10.49395045, 15.21766114, 12.49294003,  1.52159977]),\n",
       "   'std_fit_time': array([0.30005967, 0.02047669, 2.06604893, 1.92211153, 0.32754906,\n",
       "          0.69239306, 3.13450619, 0.55249137, 0.30111055, 0.21912487,\n",
       "          0.27512888, 2.04123333, 0.06331018, 0.07646055, 0.31609976,\n",
       "          0.12151913, 0.15595615, 2.11062826, 0.49231954, 1.32518923,\n",
       "          7.35201996, 0.38240149, 0.43074284, 0.7181038 , 0.20097169,\n",
       "          1.0131483 , 7.09314704, 1.59399062, 0.69343621, 0.29971664]),\n",
       "   'mean_score_time': array([0.10039878, 0.0458777 , 0.06815068, 0.05850967, 0.04421568,\n",
       "          0.0701464 , 0.05585146, 0.05618286, 0.0382309 , 0.0482053 ,\n",
       "          0.05418857, 0.06050595, 0.03922915, 0.04687484, 0.05152853,\n",
       "          0.07380231, 0.06715329, 0.06449326, 0.05684837, 0.06449413,\n",
       "          0.07114355, 0.07280652, 0.05053234, 0.05152917, 0.05784456,\n",
       "          0.05585114, 0.07081191, 0.05551505, 0.04255215, 0.05086398]),\n",
       "   'std_score_time': array([0.0255224 , 0.00215417, 0.00339062, 0.00047042, 0.00235045,\n",
       "          0.00554216, 0.00354961, 0.00124445, 0.0026163 , 0.00477094,\n",
       "          0.0018807 , 0.00188149, 0.00046985, 0.00215384, 0.00124365,\n",
       "          0.0016282 , 0.00261732, 0.0023509 , 0.00081498, 0.00248667,\n",
       "          0.00339048, 0.00373155, 0.0033905 , 0.00124375, 0.00373217,\n",
       "          0.00646442, 0.00373332, 0.00124312, 0.00308321, 0.005085  ]),\n",
       "   'param_solver': masked_array(data=['lbfgs', 'lbfgs', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                      'sgd', 'lbfgs', 'sgd', 'lbfgs', 'lbfgs', 'adam',\n",
       "                      'lbfgs', 'sgd', 'sgd', 'adam', 'sgd', 'adam', 'lbfgs',\n",
       "                      'sgd', 'lbfgs', 'lbfgs', 'lbfgs', 'sgd', 'sgd', 'sgd',\n",
       "                      'lbfgs', 'adam', 'adam', 'adam'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50, 50, 50), (100,), (100, 100), (100, 100, 50),\n",
       "                      (100,), (200, 50, 50), (100, 100), (100, 100), (100,),\n",
       "                      (100, 100), (200, 50, 50), (200, 50, 50, 50), (100,),\n",
       "                      (100, 100), (100, 100), (200, 50, 50, 50),\n",
       "                      (200, 50, 50, 50), (100, 100, 50), (100, 100, 50),\n",
       "                      (200, 50, 50), (200, 50, 50), (200, 50, 50),\n",
       "                      (100, 100), (200, 50, 50), (200, 50, 50),\n",
       "                      (100, 100, 50), (200, 50, 50), (200, 50), (100, 100),\n",
       "                      (200, 50, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0279, 0.037700000000000004, 0.0144, 0.0187,\n",
       "                      0.005900000000000001, 0.0131, 0.0202, 0.0476, 0.0207,\n",
       "                      0.04920000000000001, 0.04360000000000001,\n",
       "                      0.0068000000000000005, 0.0055000000000000005,\n",
       "                      0.004900000000000001, 0.048100000000000004, 0.0316,\n",
       "                      0.0045000000000000005, 0.0454, 0.0262, 0.0427,\n",
       "                      0.045700000000000005, 0.043800000000000006,\n",
       "                      0.0009000000000000001, 0.031900000000000005, 0.0476,\n",
       "                      0.0152, 0.0449, 0.0251, 0.035800000000000005, 0.0345],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['tanh', 'identity', 'logistic', 'relu', 'logistic',\n",
       "                      'logistic', 'relu', 'logistic', 'identity', 'identity',\n",
       "                      'identity', 'tanh', 'relu', 'tanh', 'relu', 'logistic',\n",
       "                      'relu', 'logistic', 'relu', 'tanh', 'logistic',\n",
       "                      'identity', 'identity', 'identity', 'tanh', 'identity',\n",
       "                      'logistic', 'relu', 'tanh', 'identity'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0279,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.037700000000000004,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0144,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0187,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.005900000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0131,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0202,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0476,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0207,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.04920000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.04360000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0068000000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0055000000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.004900000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.048100000000000004,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0316,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0045000000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0454,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0262,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0427,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.045700000000000005,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.043800000000000006,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0009000000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.031900000000000005,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0476,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0152,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0449,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0251,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.035800000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0345,\n",
       "     'activation': 'identity'}],\n",
       "   'split0_test_Accuracy': array([0.56185013, 0.29221943, 0.57439943, 0.54643241, 0.54571531,\n",
       "          0.41054141, 0.34026533, 0.58085335, 0.28791682, 0.29257798,\n",
       "          0.29221943, 0.56937971, 0.5442811 , 0.32664037, 0.34026533,\n",
       "          0.05593403, 0.35640014, 0.37504482, 0.54607386, 0.33273575,\n",
       "          0.05593403, 0.29150233, 0.29186088, 0.28612406, 0.31803514,\n",
       "          0.28970957, 0.05593403, 0.51595554, 0.57404087, 0.28074579]),\n",
       "   'split1_test_Accuracy': array([0.5501443 , 0.28535354, 0.56890332, 0.51479076, 0.54220779,\n",
       "          0.40548341, 0.34199134, 0.56421356, 0.27633478, 0.28391053,\n",
       "          0.28427128, 0.56060606, 0.5458153 , 0.31962482, 0.33297258,\n",
       "          0.05591631, 0.3488456 , 0.39393939, 0.53860029, 0.32828283,\n",
       "          0.52994228, 0.28463203, 0.28499278, 0.28535354, 0.33477633,\n",
       "          0.28246753, 0.53823954, 0.51623377, 0.54906205, 0.27128427]),\n",
       "   'split2_test_Accuracy': array([0.54110829, 0.28286853, 0.56066643, 0.51358204, 0.54183267,\n",
       "          0.39840637, 0.34407823, 0.56754799, 0.28178196, 0.28250634,\n",
       "          0.28178196, 0.5700833 , 0.53748642, 0.31691416, 0.32777979,\n",
       "          0.05613908, 0.34951105, 0.3625498 , 0.53712423, 0.31836291,\n",
       "          0.53132923, 0.28323071, 0.28250634, 0.28214415, 0.32053604,\n",
       "          0.28141978, 0.55414705, 0.5175661 , 0.55885549, 0.27453821]),\n",
       "   'mean_test_Accuracy': array([0.55106945, 0.28683009, 0.5680125 , 0.52499399, 0.54325883,\n",
       "          0.40483057, 0.34210526, 0.57089642, 0.28202355, 0.28634944,\n",
       "          0.28610911, 0.5666907 , 0.54253785, 0.32107666, 0.33369382,\n",
       "          0.05599615, 0.35159817, 0.37719298, 0.54061524, 0.32648402,\n",
       "          0.3715453 , 0.2864696 , 0.2864696 , 0.28454698, 0.32444124,\n",
       "          0.28454698, 0.38187936, 0.51658255, 0.56068253, 0.27553473]),\n",
       "   'std_test_Accuracy': array([8.49443605e-03, 3.95816304e-03, 5.64264450e-03, 1.52287488e-02,\n",
       "          1.75073420e-03, 4.97637234e-03, 1.55895280e-03, 7.19871272e-03,\n",
       "          4.73692198e-03, 4.45902602e-03, 4.45531752e-03, 4.30974916e-03,\n",
       "          3.61416926e-03, 4.10178016e-03, 5.12347159e-03, 1.00968534e-04,\n",
       "          3.42006293e-03, 1.28879474e-02, 3.92193860e-03, 6.00477964e-03,\n",
       "          2.24077275e-01, 3.61850671e-03, 3.95964369e-03, 1.72213247e-03,\n",
       "          7.37510132e-03, 3.69012427e-03, 2.31504356e-01, 7.02297643e-04,\n",
       "          1.02903022e-02, 3.93038264e-03]),\n",
       "   'rank_test_Accuracy': array([ 5, 21,  2,  9,  6, 11, 16,  1, 28, 24, 25,  3,  7, 20, 17, 30, 15,\n",
       "          13,  8, 18, 14, 22, 22, 26, 19, 26, 12, 10,  4, 29]),\n",
       "   'split0_train_Accuracy': array([0.86806434, 0.29549973, 0.75673233, 0.6206398 , 0.65949756,\n",
       "          0.43791795, 0.35550334, 0.74950298, 0.29568046, 0.29568046,\n",
       "          0.29513826, 0.68624616, 0.64829207, 0.33417676, 0.35188867,\n",
       "          0.05602747, 0.37520333, 0.39869872, 0.63112236, 0.34122538,\n",
       "          0.05602747, 0.295319  , 0.29513826, 0.29513826, 0.33146575,\n",
       "          0.295319  , 0.05602747, 0.58123983, 0.67269113, 0.29007772]),\n",
       "   'split1_train_Accuracy': array([0.86126126, 0.29693694, 0.73459459, 0.60612613, 0.67603604,\n",
       "          0.43027027, 0.35567568, 0.72936937, 0.28774775, 0.29747748,\n",
       "          0.2972973 , 0.74108108, 0.65009009, 0.33243243, 0.35585586,\n",
       "          0.05603604, 0.36468468, 0.40162162, 0.64648649, 0.33783784,\n",
       "          0.67297297, 0.2972973 , 0.29747748, 0.29099099, 0.33675676,\n",
       "          0.29243243, 0.67567568, 0.58756757, 0.67891892, 0.28864865]),\n",
       "   'split2_train_Accuracy': array([0.86854882, 0.29868729, 0.7322424 , 0.60169034, 0.68962417,\n",
       "          0.44056824, 0.35641072, 0.76047473, 0.29293293, 0.29886711,\n",
       "          0.29850746, 0.74770725, 0.65617695, 0.33159504, 0.34777918,\n",
       "          0.05592519, 0.37115627, 0.388779  , 0.66319007, 0.33375292,\n",
       "          0.65168135, 0.29868729, 0.29868729, 0.29419169, 0.33627045,\n",
       "          0.29311275, 0.70239166, 0.6043877 , 0.6853084 , 0.29131451]),\n",
       "   'mean_train_Accuracy': array([0.86595814, 0.29704132, 0.74118978, 0.60948542, 0.67505259,\n",
       "          0.43625215, 0.35586325, 0.74644903, 0.29212038, 0.29734168,\n",
       "          0.29698101, 0.7250115 , 0.6515197 , 0.33273474, 0.35184123,\n",
       "          0.05599623, 0.37034809, 0.39636644, 0.64693297, 0.33760538,\n",
       "          0.46022727, 0.29710119, 0.29710101, 0.29344031, 0.33483099,\n",
       "          0.29362139, 0.4780316 , 0.59106503, 0.67897281, 0.29001363]),\n",
       "   'std_train_Accuracy': array([3.32708018e-03, 1.30340637e-03, 1.10321197e-02, 8.09255239e-03,\n",
       "          1.23187799e-02, 4.36602123e-03, 3.93462163e-04, 1.28810174e-02,\n",
       "          3.28908964e-03, 1.30448219e-03, 1.39353484e-03, 2.75443884e-02,\n",
       "          3.37398641e-03, 1.07544223e-03, 3.29746117e-03, 5.03546264e-05,\n",
       "          4.33207500e-03, 5.49623345e-03, 1.30953969e-02, 3.05504131e-03,\n",
       "          2.85944562e-01, 1.38207316e-03, 1.47313533e-03, 1.77452130e-03,\n",
       "          2.38784916e-03, 1.23209826e-03, 2.98601239e-01, 9.76832061e-03,\n",
       "          5.15112062e-03, 1.08927720e-03]),\n",
       "   'split0_test_F1': array([0.55883813, 0.25845514, 0.57148036, 0.54038108, 0.54091683,\n",
       "          0.39824263, 0.30921123, 0.57662376, 0.25667255, 0.25896908,\n",
       "          0.25876078, 0.56363096, 0.54135956, 0.29836082, 0.30931748,\n",
       "          0.00592578, 0.33285304, 0.35694072, 0.5434004 , 0.29974116,\n",
       "          0.00592578, 0.25800517, 0.25847818, 0.25299094, 0.28335445,\n",
       "          0.25734581, 0.00592578, 0.5102656 , 0.56867745, 0.24114458]),\n",
       "   'split1_test_F1': array([0.5461275 , 0.25337999, 0.56549692, 0.51131472, 0.5388686 ,\n",
       "          0.38669283, 0.3102865 , 0.55897061, 0.24599272, 0.25216664,\n",
       "          0.25249157, 0.55573791, 0.53981261, 0.28422698, 0.29831162,\n",
       "          0.00592212, 0.32389522, 0.37033818, 0.53286222, 0.289485  ,\n",
       "          0.52499583, 0.25293083, 0.25330338, 0.25480682, 0.2990816 ,\n",
       "          0.25186784, 0.53378909, 0.51009181, 0.54541814, 0.23113284]),\n",
       "   'split2_test_F1': array([0.53785336, 0.25383559, 0.55939092, 0.50707157, 0.53941788,\n",
       "          0.38036858, 0.31305346, 0.56733552, 0.25058143, 0.2531973 ,\n",
       "          0.2527984 , 0.56655611, 0.53356984, 0.2821339 , 0.29520857,\n",
       "          0.00596815, 0.32041584, 0.33956739, 0.53207138, 0.28177513,\n",
       "          0.52407966, 0.25414327, 0.25348274, 0.25405503, 0.2872668 ,\n",
       "          0.25238538, 0.54921052, 0.5111166 , 0.55397077, 0.23453597]),\n",
       "   'mean_test_F1': array([0.54764217, 0.25523201, 0.56547639, 0.51964815, 0.53973727,\n",
       "          0.38846538, 0.31084414, 0.56766205, 0.25109431, 0.25478833,\n",
       "          0.2546944 , 0.56197232, 0.53825988, 0.28826931, 0.30097058,\n",
       "          0.00593862, 0.32574295, 0.35563935, 0.53613156, 0.29036429,\n",
       "          0.35073292, 0.25503367, 0.25509714, 0.25394883, 0.28989106,\n",
       "          0.25387541, 0.36199959, 0.51049005, 0.55605068, 0.23561719]),\n",
       "   'std_test_F1': array([8.63503971e-03, 2.29587403e-03, 4.93634120e-03, 1.48212004e-02,\n",
       "          8.66882385e-04, 7.40499966e-03, 1.61758724e-03, 7.21893857e-03,\n",
       "          4.38004362e-03, 2.99783014e-03, 2.88973624e-03, 4.56503109e-03,\n",
       "          3.36464923e-03, 7.21536842e-03, 6.05963806e-03, 2.08604460e-05,\n",
       "          5.24352077e-03, 1.25790819e-02, 5.17076426e-03, 7.36209970e-03,\n",
       "          2.44805226e-01, 2.16682436e-03, 2.40156908e-03, 7.45956549e-04,\n",
       "          6.68874383e-03, 2.47292278e-03, 2.52882179e-01, 4.47158767e-04,\n",
       "          9.61894848e-03, 4.16235675e-03]),\n",
       "   'rank_test_F1': array([ 5, 21,  2,  9,  6, 11, 16,  1, 28, 24, 25,  3,  7, 20, 17, 30, 15,\n",
       "          13,  8, 18, 14, 23, 22, 26, 19, 27, 12, 10,  4, 29]),\n",
       "   'split0_train_F1': array([0.86763364, 0.26467657, 0.75605828, 0.61512052, 0.6565037 ,\n",
       "          0.42464129, 0.32407366, 0.74778514, 0.26232425, 0.26491917,\n",
       "          0.26437589, 0.68346171, 0.64596998, 0.30596428, 0.32096509,\n",
       "          0.00594507, 0.34973495, 0.37896442, 0.62771023, 0.30772939,\n",
       "          0.00594507, 0.26454601, 0.26437939, 0.26477771, 0.29521492,\n",
       "          0.26491587, 0.00594507, 0.57512899, 0.66866023, 0.25110635]),\n",
       "   'split1_train_F1': array([0.86076535, 0.26495738, 0.73313569, 0.60081254, 0.67457535,\n",
       "          0.4177858 , 0.32356063, 0.72760431, 0.2565556 , 0.26539893,\n",
       "          0.26504342, 0.73854454, 0.64745055, 0.29936554, 0.32249039,\n",
       "          0.00594684, 0.33840842, 0.38169151, 0.64325769, 0.30299804,\n",
       "          0.66997981, 0.26517962, 0.26556054, 0.26069486, 0.30282375,\n",
       "          0.26128102, 0.67336127, 0.58306928, 0.67734543, 0.25190561]),\n",
       "   'split2_train_F1': array([0.86772916, 0.27059086, 0.73161027, 0.59560331, 0.68836837,\n",
       "          0.42164139, 0.32472254, 0.75956569, 0.26069251, 0.27057295,\n",
       "          0.27026781, 0.74620138, 0.6548187 , 0.29648276, 0.31532348,\n",
       "          0.00592396, 0.33999934, 0.36278946, 0.66028304, 0.29760503,\n",
       "          0.64864523, 0.27054981, 0.27043039, 0.26698826, 0.30263416,\n",
       "          0.2634076 , 0.70056753, 0.59812593, 0.68218301, 0.24975295]),\n",
       "   'mean_train_F1': array([0.86537605, 0.2667416 , 0.74026808, 0.60384546, 0.67314914,\n",
       "          0.42135616, 0.32411894, 0.74498505, 0.25985746, 0.26696368,\n",
       "          0.26656238, 0.72273588, 0.64941307, 0.30060419, 0.31959299,\n",
       "          0.00593862, 0.34271424, 0.3744818 , 0.64375032, 0.30277749,\n",
       "          0.44152337, 0.26675848, 0.2667901 , 0.26415361, 0.30022428,\n",
       "          0.2632015 , 0.45995796, 0.5854414 , 0.67606289, 0.25092164]),\n",
       "   'std_train_F1': array([3.26049069e-03, 2.72424903e-03, 1.11827099e-02, 8.25143602e-03,\n",
       "          1.30477298e-02, 2.80599902e-03, 4.75427902e-04, 1.31975479e-02,\n",
       "          2.42793767e-03, 2.55963931e-03, 2.63427355e-03, 2.79464027e-02,\n",
       "          3.86984751e-03, 3.96866972e-03, 3.08255090e-03, 1.03944448e-05,\n",
       "          5.00670065e-03, 8.34235399e-03, 1.33023551e-02, 4.13619017e-03,\n",
       "          3.08123497e-01, 2.69332867e-03, 2.61884589e-03, 2.60689275e-03,\n",
       "          3.54299514e-03, 1.49106096e-03, 3.21227669e-01, 9.53712284e-03,\n",
       "          5.59464472e-03, 8.88471700e-04]),\n",
       "   'split0_test_Log_Loss': array([-2.16264873, -2.38846782, -1.65518174, -1.48124269, -1.61742429,\n",
       "          -1.86546317, -2.14454894, -1.54643457, -2.42111947, -2.38851125,\n",
       "          -2.38851314, -1.45263545, -1.58726651, -2.24685443, -2.13644062,\n",
       "          -3.61220009, -2.03421041, -1.96225869, -1.57527883, -2.21586293,\n",
       "          -3.61179283, -2.38853326, -2.38842974, -2.3974221 , -2.22716534,\n",
       "          -2.39662921, -3.61191211, -1.52568557, -1.39695077, -2.40672721]),\n",
       "   'split1_test_Log_Loss': array([-2.08609459, -2.42396484, -1.60742679, -1.54857769, -1.6479049 ,\n",
       "          -1.87756031, -2.18899243, -1.55194226, -2.449419  , -2.42399879,\n",
       "          -2.42394867, -1.4784656 , -1.56933564, -2.28232915, -2.17044993,\n",
       "          -3.61239949, -2.11207362, -1.96813147, -1.58666983, -2.23741068,\n",
       "          -1.67687736, -2.42394875, -2.42412323, -2.43027758, -2.22886343,\n",
       "          -2.43198673, -1.65110454, -1.57578877, -1.44386128, -2.43757497]),\n",
       "   'split2_test_Log_Loss': array([-2.08108214, -2.39383164, -1.70052254, -1.56371449, -1.64495771,\n",
       "          -1.83040695, -2.13291964, -1.59838291, -2.42382849, -2.393774  ,\n",
       "          -2.39370209, -1.44567782, -1.63385649, -2.23544813, -2.16067889,\n",
       "          -3.6118419 , -2.0558487 , -1.96883212, -1.64202141, -2.20307655,\n",
       "          -1.61470789, -2.39370628, -2.39376909, -2.39888321, -2.23805668,\n",
       "          -2.39569413, -1.62398259, -1.55521245, -1.44326734, -2.40793869]),\n",
       "   'mean_test_Log_Loss': array([-2.11008763, -2.40207119, -1.65431767, -1.53103327, -1.63671196,\n",
       "          -1.857862  , -2.15549449, -1.56550411, -2.43144462, -2.40207793,\n",
       "          -2.40203801, -1.45893095, -1.59675108, -2.25488653, -2.15581044,\n",
       "          -3.61214767, -2.06732506, -1.96639575, -1.60121636, -2.21879818,\n",
       "          -2.30471073, -2.40204617, -2.40209043, -2.40885078, -2.2313444 ,\n",
       "          -2.40809632, -2.29924304, -1.55217076, -1.42794284, -2.41740432]),\n",
       "   'std_test_Log_Loss': array([3.73730498e-02, 1.56270133e-02, 3.79596512e-02, 3.58847609e-02,\n",
       "          1.37464105e-02, 1.99673161e-02, 2.41453324e-02, 2.32762711e-02,\n",
       "          1.27510008e-02, 1.56403298e-02, 1.56290767e-02, 1.40948845e-02,\n",
       "          2.71530695e-02, 1.99457499e-02, 1.43174667e-02, 2.30350282e-04,\n",
       "          3.28358998e-02, 2.95107176e-03, 2.91266828e-02, 1.41521388e-02,\n",
       "          9.28343534e-01, 1.56225371e-02, 1.57229992e-02, 1.51545865e-02,\n",
       "          4.78028058e-03, 1.68882550e-02, 9.32029673e-01, 2.05902512e-02,\n",
       "          2.20049665e-02, 1.42636749e-02]),\n",
       "   'rank_test_Log_Loss': array([13, 23,  9,  3,  8, 10, 14,  5, 29, 24, 21,  2,  6, 18, 15, 30, 12,\n",
       "          11,  7, 16, 20, 22, 25, 27, 17, 26, 19,  4,  1, 28]),\n",
       "   'split0_train_Log_Loss': array([-0.43976665, -2.37539008, -0.72199114, -1.15460204, -1.01374179,\n",
       "          -1.77365767, -2.10744422, -0.74946779, -2.41015995, -2.37537896,\n",
       "          -2.37537905, -0.98613462, -1.05783756, -2.21615793, -2.10708999,\n",
       "          -3.61206553, -1.97400033, -1.87926812, -1.07947156, -2.17651749,\n",
       "          -3.61162191, -2.3753786 , -2.37538418, -2.38250974, -2.20654881,\n",
       "          -2.3822173 , -3.61176075, -1.26894964, -1.05772142, -2.39238634]),\n",
       "   'split1_train_Log_Loss': array([-0.45008746, -2.35767654, -0.79775674, -1.20136001, -0.98514624,\n",
       "          -1.75360468, -2.09828915, -0.82680313, -2.39001562, -2.35766306,\n",
       "          -2.3576599 , -0.81711813, -1.07395529, -2.20981745, -2.08696677,\n",
       "          -3.61224787, -2.01159353, -1.8693896 , -1.07145554, -2.17645571,\n",
       "          -0.9857717 , -2.35766442, -2.35767633, -2.36546058, -2.16720954,\n",
       "          -2.3656833 , -0.97597167, -1.28540545, -1.03957239, -2.36958793]),\n",
       "   'split2_train_Log_Loss': array([-0.44228114, -2.37347571, -0.81697938, -1.19677201, -0.9585366 ,\n",
       "          -1.72936513, -2.10174838, -0.7274089 , -2.40959666, -2.37346849,\n",
       "          -2.3734668 , -0.79561706, -1.05379833, -2.22571299, -2.13044335,\n",
       "          -3.61213901, -2.00982756, -1.90524813, -1.00035083, -2.17702643,\n",
       "          -1.06702309, -2.37346436, -2.37346637, -2.37997295, -2.21362903,\n",
       "          -2.37818593, -0.913048  , -1.21737091, -1.02375168, -2.39054738]),\n",
       "   'mean_train_Log_Loss': array([-0.44404508, -2.36884744, -0.77890908, -1.18424468, -0.98580821,\n",
       "          -1.75220916, -2.10249391, -0.76789327, -2.40325741, -2.36883684,\n",
       "          -2.36883525, -0.86628993, -1.06186373, -2.21722946, -2.1081667 ,\n",
       "          -3.6121508 , -1.99847381, -1.88463528, -1.05042598, -2.17666654,\n",
       "          -1.8881389 , -2.36883579, -2.36884229, -2.37598109, -2.1957958 ,\n",
       "          -2.37536218, -1.83359347, -1.257242  , -1.0403485 , -2.38417388]),\n",
       "   'std_train_Log_Loss': array([4.39419060e-03, 7.93759331e-03, 4.10050133e-02, 2.10440392e-02,\n",
       "          2.25422846e-02, 1.81092616e-02, 3.77453849e-03, 4.26178930e-02,\n",
       "          9.36618055e-03, 7.93945722e-03, 7.94063604e-03, 8.51963811e-02,\n",
       "          8.70759139e-03, 6.53340800e-03, 1.77655572e-02, 7.49029482e-05,\n",
       "          1.73203738e-02, 1.51231249e-02, 3.55593832e-02, 2.55722794e-04,\n",
       "          1.21913787e+00, 7.93791431e-03, 7.93424980e-03, 7.51086788e-03,\n",
       "          2.04191529e-02, 7.03910564e-03, 1.25761653e+00, 2.89824811e-02,\n",
       "          1.38789440e-02, 1.03411148e-02])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (100, 100),\n",
       "   'alpha': 0.035800000000000005,\n",
       "   'activation': 'tanh'},\n",
       "  28,\n",
       "  -1.4279428375120533),\n",
       " 'LogisticRegression_V01_PCA_85': ({'mean_fit_time': array([ 2.69444712,  0.80917009,  1.28756007,  3.41254544,  7.35666839,\n",
       "           4.90389013,  2.03921549,  0.67153883,  0.70943753,  1.7912128 ,\n",
       "          22.39314485,  0.96807877,  3.44412772,  3.71141299,  5.47436817,\n",
       "           1.70577304,  1.82545336,  1.23636333,  3.34472537,  3.57411226,\n",
       "           0.68982267,  0.76628582,  0.87632537,  5.0644633 ,  7.00494274,\n",
       "           1.09341137,  8.03485672,  1.01262569,  5.41751854,  1.05218697]),\n",
       "   'std_fit_time': array([0.04043737, 0.02224635, 0.02077712, 0.30893752, 0.16227305,\n",
       "          0.15477801, 0.16998892, 0.01857737, 0.03897347, 0.02297403,\n",
       "          0.31270221, 0.02523528, 0.10859018, 0.56567664, 0.09691588,\n",
       "          0.16245861, 0.09446273, 0.09098783, 0.08338739, 0.22841739,\n",
       "          0.00943724, 0.01528609, 0.02893176, 0.15236849, 0.16827512,\n",
       "          0.02491868, 0.32532871, 0.00756552, 0.32168582, 0.07123781]),\n",
       "   'mean_score_time': array([0.07114347, 0.03756658, 0.06715433, 0.07180818, 0.03324509,\n",
       "          0.03391027, 0.03224707, 0.03191384, 0.05684837, 0.03390916,\n",
       "          0.03390908, 0.03956095, 0.0365688 , 0.03224754, 0.03291233,\n",
       "          0.03291273, 0.03922804, 0.03756658, 0.03424207, 0.03125008,\n",
       "          0.03091685, 0.03357625, 0.06981341, 0.03390876, 0.03523922,\n",
       "          0.03357601, 0.03590457, 0.04155437, 0.03457435, 0.03390908]),\n",
       "   'std_score_time': array([0.00477167, 0.00542135, 0.01716527, 0.04592695, 0.00169586,\n",
       "          0.00162888, 0.00094038, 0.00162772, 0.02961923, 0.00215428,\n",
       "          0.0008143 , 0.00600267, 0.00611212, 0.00046985, 0.00244211,\n",
       "          0.00081323, 0.00908005, 0.00204992, 0.00169526, 0.00188054,\n",
       "          0.00081449, 0.00463111, 0.02853634, 0.00354921, 0.0033898 ,\n",
       "          0.00046935, 0.00215417, 0.00571954, 0.00339053, 0.00373196]),\n",
       "   'param_C': masked_array(data=[0.2583674585760966, 0.13917972165797346,\n",
       "                      0.27011892202994375, 0.07742905258762606,\n",
       "                      0.8502638041848745, 0.03885164408761619,\n",
       "                      0.02637524530098539, 0.3126851228139758,\n",
       "                      0.1535788979070797, 0.01994656166478999,\n",
       "                      0.126264566351758, 0.03707391731766571,\n",
       "                      0.193695177721251, 0.3073820975603754,\n",
       "                      0.022228189303620027, 0.023796935953800773,\n",
       "                      0.059823782291347286, 0.02189009871403966,\n",
       "                      0.2898867883733087, 0.12855960184618595,\n",
       "                      0.3643494807861255, 0.16025163048330693,\n",
       "                      0.019905353307057453, 0.17648771587956766,\n",
       "                      0.18528246248783187, 0.3134796724477032,\n",
       "                      0.7309066607697216, 0.0655984158569253,\n",
       "                      0.2748666547805558, 0.06209880125622297],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', None, 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', 'balanced', None, 'balanced',\n",
       "                      'balanced', None, None, None, None, 'balanced',\n",
       "                      'balanced', 'balanced', None, 'balanced', None, None,\n",
       "                      None, 'balanced', 'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['saga', 'saga', 'saga', 'liblinear', 'liblinear',\n",
       "                      'newton-cg', 'liblinear', 'saga', 'saga', 'liblinear',\n",
       "                      'saga', 'saga', 'liblinear', 'liblinear', 'newton-cg',\n",
       "                      'liblinear', 'saga', 'saga', 'liblinear', 'newton-cg',\n",
       "                      'saga', 'saga', 'saga', 'liblinear', 'newton-cg',\n",
       "                      'saga', 'liblinear', 'saga', 'liblinear', 'saga'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.0733999887039742, 0.35999533070633927,\n",
       "                      0.10171966734294646, 0.10181684451999956,\n",
       "                      0.09338623269939977, 0.7818466228323337,\n",
       "                      0.08090612691802286, 0.5179295693153411,\n",
       "                      0.4767785180994089, 0.2396386907398169,\n",
       "                      0.004149213850464501, 0.1590483143099929,\n",
       "                      0.04860457533955899, 0.11604807193962352,\n",
       "                      0.07636334804673651, 0.35792762417987717,\n",
       "                      0.10234726953969485, 0.16938919329943602,\n",
       "                      0.39093901967317835, 0.5370994493911051,\n",
       "                      0.6347342860257525, 0.23939424018872138,\n",
       "                      0.20772047868509136, 0.030539242186987198,\n",
       "                      0.13001336731170318, 0.1948721070384608,\n",
       "                      0.03768105472203877, 0.29767017868245,\n",
       "                      0.09446779036835606, 0.16181397354144844],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.2583674585760966,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0733999887039742},\n",
       "    {'C': 0.13917972165797346,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.35999533070633927},\n",
       "    {'C': 0.27011892202994375,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.10171966734294646},\n",
       "    {'C': 0.07742905258762606,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.10181684451999956},\n",
       "    {'C': 0.8502638041848745,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.09338623269939977},\n",
       "    {'C': 0.03885164408761619,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.7818466228323337},\n",
       "    {'C': 0.02637524530098539,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.08090612691802286},\n",
       "    {'C': 0.3126851228139758,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.5179295693153411},\n",
       "    {'C': 0.1535788979070797,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.4767785180994089},\n",
       "    {'C': 0.01994656166478999,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.2396386907398169},\n",
       "    {'C': 0.126264566351758,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.004149213850464501},\n",
       "    {'C': 0.03707391731766571,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.1590483143099929},\n",
       "    {'C': 0.193695177721251,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.04860457533955899},\n",
       "    {'C': 0.3073820975603754,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.11604807193962352},\n",
       "    {'C': 0.022228189303620027,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.07636334804673651},\n",
       "    {'C': 0.023796935953800773,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.35792762417987717},\n",
       "    {'C': 0.059823782291347286,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.10234726953969485},\n",
       "    {'C': 0.02189009871403966,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.16938919329943602},\n",
       "    {'C': 0.2898867883733087,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.39093901967317835},\n",
       "    {'C': 0.12855960184618595,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.5370994493911051},\n",
       "    {'C': 0.3643494807861255,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.6347342860257525},\n",
       "    {'C': 0.16025163048330693,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.23939424018872138},\n",
       "    {'C': 0.019905353307057453,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.20772047868509136},\n",
       "    {'C': 0.17648771587956766,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.030539242186987198},\n",
       "    {'C': 0.18528246248783187,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.13001336731170318},\n",
       "    {'C': 0.3134796724477032,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.1948721070384608},\n",
       "    {'C': 0.7309066607697216,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.03768105472203877},\n",
       "    {'C': 0.0655984158569253,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.29767017868245},\n",
       "    {'C': 0.2748666547805558,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.09446779036835606},\n",
       "    {'C': 0.06209880125622297,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.16181397354144844}],\n",
       "   'split0_test_Accuracy': array([0.49874507, 0.47221226, 0.543564  , 0.58443887, 0.64037289,\n",
       "          0.59985658, 0.56220868, 0.4689853 , 0.5302976 , 0.55503765,\n",
       "          0.58694873, 0.54320545, 0.61204733, 0.62782359, 0.5937612 ,\n",
       "          0.55754751, 0.48440301, 0.47579778, 0.61240588, 0.63320186,\n",
       "          0.53388311, 0.53567587, 0.54320545, 0.61384009, 0.6167085 ,\n",
       "          0.46217282, 0.64969523, 0.46038006, 0.62208677, 0.53316601]),\n",
       "   'split1_test_Accuracy': array([0.5007215 , 0.46536797, 0.54076479, 0.5981241 , 0.64646465,\n",
       "          0.60209235, 0.56529582, 0.46103896, 0.53427128, 0.55663781,\n",
       "          0.58874459, 0.53896104, 0.62121212, 0.63203463, 0.59632035,\n",
       "          0.55988456, 0.48124098, 0.47871573, 0.61868687, 0.62950938,\n",
       "          0.52886003, 0.54076479, 0.53102453, 0.62157287, 0.62085137,\n",
       "          0.47438672, 0.6468254 , 0.46572872, 0.62626263, 0.54437229]),\n",
       "   'split2_test_Accuracy': array([0.48641796, 0.44766389, 0.53132923, 0.5878305 , 0.64288301,\n",
       "          0.59579862, 0.56030424, 0.44512858, 0.51647954, 0.54871423,\n",
       "          0.58457081, 0.5175661 , 0.61897863, 0.62948207, 0.5878305 ,\n",
       "          0.55523361, 0.47482796, 0.4708439 , 0.61897863, 0.63020645,\n",
       "          0.51321985, 0.51213329, 0.52191235, 0.62006519, 0.61608113,\n",
       "          0.46396233, 0.64578051, 0.43027888, 0.62549801, 0.52806954]),\n",
       "   'mean_test_Accuracy': array([0.49531363, 0.46178803, 0.53857246, 0.59012257, 0.6432348 ,\n",
       "          0.59925499, 0.56260514, 0.45842346, 0.52703677, 0.55347272,\n",
       "          0.58675799, 0.53328527, 0.61739966, 0.6297765 , 0.592646  ,\n",
       "          0.55755828, 0.48017304, 0.47512617, 0.61667868, 0.63097813,\n",
       "          0.52535448, 0.5295602 , 0.53208363, 0.61848113, 0.61788032,\n",
       "          0.4668349 , 0.64744052, 0.45217496, 0.62460947, 0.53520788]),\n",
       "   'std_test_Accuracy': array([0.00631993, 0.01033788, 0.00523041, 0.00582198, 0.00250216,\n",
       "          0.00260123, 0.00205442, 0.00991492, 0.00761411, 0.00341613,\n",
       "          0.00170701, 0.01121112, 0.00390761, 0.00173361, 0.00355068,\n",
       "          0.00189619, 0.00398184, 0.00324454, 0.00303592, 0.00160417,\n",
       "          0.00879337, 0.01245432, 0.00872649, 0.00335188, 0.00211528,\n",
       "          0.00538685, 0.0016565 , 0.01558259, 0.00181798, 0.00680281]),\n",
       "   'rank_test_Accuracy': array([24, 28, 17, 12,  2, 10, 14, 29, 22, 16, 13, 19,  8,  4, 11, 15, 25,\n",
       "          26,  9,  3, 23, 21, 20,  6,  7, 27,  1, 30,  5, 18]),\n",
       "   'split0_train_Accuracy': array([0.52792337, 0.5002711 , 0.59895174, 0.67088379, 0.72564612,\n",
       "          0.66853425, 0.6217242 , 0.49828303, 0.57184168, 0.6088921 ,\n",
       "          0.65407555, 0.5938912 , 0.70106633, 0.71010302, 0.65985903,\n",
       "          0.61485632, 0.51003072, 0.49376468, 0.69853606, 0.71715164,\n",
       "          0.57816736, 0.5805169 , 0.58557744, 0.7008856 , 0.68678836,\n",
       "          0.49268028, 0.72962227, 0.48436653, 0.70666908, 0.58322791]),\n",
       "   'split1_train_Accuracy': array([0.54036036, 0.48810811, 0.59009009, 0.66144144, 0.73027027,\n",
       "          0.67243243, 0.62      , 0.49297297, 0.57081081, 0.60828829,\n",
       "          0.65333333, 0.57513514, 0.69657658, 0.70990991, 0.65927928,\n",
       "          0.61423423, 0.5181982 , 0.51081081, 0.69693694, 0.71693694,\n",
       "          0.57567568, 0.58036036, 0.58036036, 0.6972973 , 0.69513514,\n",
       "          0.51297297, 0.73351351, 0.49171171, 0.70432432, 0.58684685]),\n",
       "   'split2_train_Accuracy': array([0.53317749, 0.48354612, 0.5975544 , 0.67344003, 0.73727747,\n",
       "          0.66984355, 0.62524726, 0.49253731, 0.58478691, 0.61391836,\n",
       "          0.65779536, 0.58838338, 0.70508901, 0.71443985, 0.66103219,\n",
       "          0.61967272, 0.5241863 , 0.51016004, 0.70005395, 0.7185758 ,\n",
       "          0.57579572, 0.57903255, 0.58334832, 0.69861536, 0.68782593,\n",
       "          0.49829167, 0.73745729, 0.46322604, 0.71156267, 0.5900018 ]),\n",
       "   'mean_train_Accuracy': array([0.53382041, 0.49064178, 0.59553208, 0.66858842, 0.73106462,\n",
       "          0.67027008, 0.62232382, 0.49459777, 0.57581313, 0.61036625,\n",
       "          0.65506808, 0.58580324, 0.70091064, 0.71148426, 0.66005683,\n",
       "          0.61625442, 0.51747174, 0.50491185, 0.69850898, 0.71755479,\n",
       "          0.57654625, 0.57996994, 0.58309537, 0.69893275, 0.68991648,\n",
       "          0.50131498, 0.73353102, 0.47976809, 0.70751869, 0.58669218]),\n",
       "   'std_train_Accuracy': array([0.00509769, 0.00705908, 0.00389012, 0.0051603 , 0.00478158,\n",
       "          0.00161975, 0.00218374, 0.00261193, 0.00635936, 0.00252379,\n",
       "          0.00195214, 0.00787148, 0.00347693, 0.0020914 , 0.00072916,\n",
       "          0.00243041, 0.00580177, 0.00788671, 0.00127266, 0.00072726,\n",
       "          0.00114734, 0.00066591, 0.00213736, 0.00148201, 0.00371438,\n",
       "          0.00855584, 0.00319866, 0.01207525, 0.00301549, 0.00276759]),\n",
       "   'split0_test_F1': array([0.457315  , 0.43769682, 0.54006748, 0.57239814, 0.6347628 ,\n",
       "          0.60127718, 0.54554065, 0.42795225, 0.52555195, 0.53732288,\n",
       "          0.58669582, 0.53643869, 0.60395111, 0.6180674 , 0.59386304,\n",
       "          0.54038042, 0.44246597, 0.42970588, 0.60072326, 0.62442347,\n",
       "          0.5281711 , 0.52804064, 0.53735135, 0.60234218, 0.61880446,\n",
       "          0.41456918, 0.6414325 , 0.42680984, 0.614717  , 0.52469521]),\n",
       "   'split1_test_F1': array([0.45747616, 0.42089367, 0.53595062, 0.58636618, 0.64085357,\n",
       "          0.60440221, 0.54790585, 0.41175053, 0.52458282, 0.5374423 ,\n",
       "          0.58930155, 0.53142235, 0.6131929 , 0.61884486, 0.59849779,\n",
       "          0.54138835, 0.43927874, 0.43453336, 0.6045301 , 0.61882209,\n",
       "          0.51921352, 0.53212713, 0.52158809, 0.60705796, 0.62474539,\n",
       "          0.42333462, 0.6358128 , 0.41791506, 0.61854768, 0.53766774]),\n",
       "   'split2_test_F1': array([0.44534605, 0.40396826, 0.52710499, 0.57763971, 0.63691042,\n",
       "          0.59848624, 0.54452126, 0.39993067, 0.50941116, 0.53060627,\n",
       "          0.58576563, 0.51091163, 0.61082465, 0.61900634, 0.59047039,\n",
       "          0.53864526, 0.43206613, 0.43551971, 0.60786509, 0.62257155,\n",
       "          0.50336404, 0.50359529, 0.51646508, 0.60855145, 0.61848962,\n",
       "          0.41589053, 0.6370959 , 0.38926222, 0.61830658, 0.52236552]),\n",
       "   'mean_test_F1': array([0.45339773, 0.42090964, 0.5343956 , 0.5787898 , 0.63750411,\n",
       "          0.60139215, 0.54599028, 0.41325882, 0.51987409, 0.53513428,\n",
       "          0.58725516, 0.52629864, 0.60930993, 0.61863788, 0.59428126,\n",
       "          0.54014048, 0.43795396, 0.43324274, 0.60436074, 0.62194328,\n",
       "          0.51695712, 0.52129156, 0.52517126, 0.60597303, 0.62067889,\n",
       "          0.41792727, 0.63812186, 0.41138983, 0.61718389, 0.52824334]),\n",
       "   'std_test_F1': array([0.00567378, 0.01377194, 0.00540569, 0.00576631, 0.00252435,\n",
       "          0.00241329, 0.00141633, 0.01149123, 0.00738305, 0.00319091,\n",
       "          0.00149528, 0.0110342 , 0.00392524, 0.00041034, 0.00328617,\n",
       "          0.00113124, 0.00434842, 0.00254308, 0.00291858, 0.00233183,\n",
       "          0.01025389, 0.01258056, 0.00889624, 0.00264875, 0.00287677,\n",
       "          0.0038594 , 0.00240799, 0.01600986, 0.00175419, 0.00672804]),\n",
       "   'rank_test_F1': array([24, 27, 17, 13,  2, 10, 14, 29, 22, 16, 12, 19,  7,  5, 11, 15, 25,\n",
       "          26,  9,  3, 23, 21, 20,  8,  4, 28,  1, 30,  6, 18]),\n",
       "   'split0_train_F1': array([0.49215085, 0.46752263, 0.59423589, 0.66272527, 0.72102102,\n",
       "          0.66920804, 0.60945569, 0.45848348, 0.56634559, 0.59539538,\n",
       "          0.65420261, 0.58832976, 0.69523577, 0.70199542, 0.66063514,\n",
       "          0.6017898 , 0.47213543, 0.44853893, 0.6892044 , 0.71057829,\n",
       "          0.57102708, 0.57317321, 0.58002367, 0.6925506 , 0.68821926,\n",
       "          0.44811843, 0.7230109 , 0.45210224, 0.7009363 , 0.57760702]),\n",
       "   'split1_train_F1': array([0.50273611, 0.45361032, 0.58436341, 0.6515983 , 0.72567587,\n",
       "          0.6734697 , 0.60584513, 0.4523003 , 0.56245419, 0.59287344,\n",
       "          0.65348894, 0.56727356, 0.68974569, 0.70073025, 0.6605525 ,\n",
       "          0.59930072, 0.48124031, 0.47361895, 0.68689724, 0.70903311,\n",
       "          0.56633359, 0.57389435, 0.57318788, 0.68751321, 0.69694966,\n",
       "          0.47505566, 0.72595305, 0.45192406, 0.69806997, 0.58063552]),\n",
       "   'split2_train_F1': array([0.49716166, 0.44121402, 0.59366355, 0.6677381 , 0.73429289,\n",
       "          0.67083129, 0.6150581 , 0.45045584, 0.57891273, 0.60237861,\n",
       "          0.6577575 , 0.58409108, 0.70123205, 0.70774614, 0.66186129,\n",
       "          0.60883877, 0.48436911, 0.4783661 , 0.69282843, 0.71316809,\n",
       "          0.56858877, 0.57210565, 0.57905058, 0.69065544, 0.6892561 ,\n",
       "          0.45209312, 0.731792  , 0.42067369, 0.70774261, 0.58579479]),\n",
       "   'mean_train_F1': array([0.49734954, 0.45411565, 0.59075428, 0.66068722, 0.72699659,\n",
       "          0.67116968, 0.61011964, 0.45374654, 0.5692375 , 0.59688248,\n",
       "          0.65514968, 0.57989814, 0.6954045 , 0.7034906 , 0.66101631,\n",
       "          0.60330976, 0.47924829, 0.46684133, 0.68964336, 0.7109265 ,\n",
       "          0.56864982, 0.57305774, 0.57742071, 0.69023975, 0.69147501,\n",
       "          0.4584224 , 0.72691865, 0.44156666, 0.70224963, 0.58134578]),\n",
       "   'std_train_F1': array([0.00432345, 0.01074639, 0.00452507, 0.0067448 , 0.00549811,\n",
       "          0.00175619, 0.00379037, 0.00343312, 0.00702345, 0.00402042,\n",
       "          0.00186688, 0.0090931 , 0.0046908 , 0.00305313, 0.00059844,\n",
       "          0.0040395 , 0.00518921, 0.01308605, 0.00244121, 0.00170596,\n",
       "          0.0019166 , 0.00073478, 0.00301931, 0.00207741, 0.00389424,\n",
       "          0.01187289, 0.00364931, 0.01477374, 0.00405657, 0.00338016]),\n",
       "   'split0_test_Log_Loss': array([-2.77166829, -3.22405652, -2.79648549, -1.76751886, -1.35041065,\n",
       "          -1.81596813, -2.13882464, -3.2685129 , -2.95178823, -2.25096342,\n",
       "          -1.9577643 , -2.86621144, -1.54121612, -1.45573626, -1.89941741,\n",
       "          -2.1839399 , -2.9205705 , -3.1062513 , -1.53319252, -1.36504512,\n",
       "          -2.95011551, -2.93110936, -2.91047309, -1.54440507, -1.65794458,\n",
       "          -3.11825314, -1.33896006, -3.19096424, -1.48231206, -2.87154927]),\n",
       "   'split1_test_Log_Loss': array([-2.75739355, -3.22142718, -2.78636572, -1.79198938, -1.38561671,\n",
       "          -1.84534754, -2.15524468, -3.24962035, -2.94212378, -2.26369334,\n",
       "          -1.98251581, -2.8673273 , -1.57499889, -1.49732085, -1.92730052,\n",
       "          -2.19736181, -2.9177285 , -3.08435734, -1.57016833, -1.4068535 ,\n",
       "          -2.94338141, -2.90646066, -2.90518681, -1.58596279, -1.68338628,\n",
       "          -3.10498486, -1.37886635, -3.1731702 , -1.51903799, -2.85865794]),\n",
       "   'split2_test_Log_Loss': array([-2.79208789, -3.23418045, -2.80330825, -1.78251226, -1.36363843,\n",
       "          -1.82870175, -2.14853422, -3.27120291, -2.95076365, -2.25914791,\n",
       "          -1.97219778, -2.87352196, -1.55705659, -1.46919631, -1.91127063,\n",
       "          -2.19259028, -2.94233793, -3.10148565, -1.54404861, -1.37591389,\n",
       "          -2.95729167, -2.92471719, -2.90705098, -1.55877664, -1.6666737 ,\n",
       "          -3.12156277, -1.35185347, -3.19709846, -1.49835405, -2.86330327]),\n",
       "   'mean_test_Log_Loss': array([-2.77368811, -3.22653953, -2.79537826, -1.7806442 , -1.36652614,\n",
       "          -1.82997885, -2.1475154 , -3.26311239, -2.94822914, -2.25791904,\n",
       "          -1.97079747, -2.86900855, -1.55772433, -1.47405345, -1.91263764,\n",
       "          -2.19128059, -2.92684566, -3.09737747, -1.54911064, -1.38257714,\n",
       "          -2.95025327, -2.92077831, -2.90757691, -1.56301573, -1.6693151 ,\n",
       "          -3.11493161, -1.35653023, -3.18707232, -1.49986748, -2.86451947]),\n",
       "   'std_test_Log_Loss': array([0.01421722, 0.00549017, 0.00695198, 0.01008794, 0.01453272,\n",
       "          0.01204175, 0.00674956, 0.00959821, 0.00433504, 0.00527459,\n",
       "          0.01016455, 0.00321279, 0.01381586, 0.01733779, 0.01143714,\n",
       "          0.00556294, 0.01097784, 0.00940514, 0.01552812, 0.01772138,\n",
       "          0.00567199, 0.01044984, 0.00219218, 0.01724629, 0.01056389,\n",
       "          0.00715833, 0.01664024, 0.01013921, 0.01504862, 0.00533824]),\n",
       "   'rank_test_Log_Loss': array([17, 29, 18, 10,  2, 11, 14, 30, 24, 16, 13, 20,  7,  4, 12, 15, 23,\n",
       "          26,  6,  3, 25, 22, 21,  8,  9, 27,  1, 28,  5, 19]),\n",
       "   'split0_train_Log_Loss': array([-2.71749395, -3.20209661, -2.75332557, -1.61105281, -1.08690112,\n",
       "          -1.68927059, -2.03054519, -3.24672673, -2.91687945, -2.15575842,\n",
       "          -1.8498677 , -2.82635003, -1.34041257, -1.24064342, -1.78923307,\n",
       "          -2.08190344, -2.87771509, -3.07685157, -1.33555237, -1.12376767,\n",
       "          -2.91539831, -2.89327513, -2.87474375, -1.34914562, -1.469787  ,\n",
       "          -3.0880895 , -1.07895944, -3.16582293, -1.26672777, -2.83575324]),\n",
       "   'split1_train_Log_Loss': array([-2.68750061, -3.19038697, -2.72532423, -1.60400593, -1.07247175,\n",
       "          -1.66374172, -2.02458657, -3.22039396, -2.89664898, -2.14719075,\n",
       "          -1.82438601, -2.81180076, -1.32934391, -1.22688706, -1.76663656,\n",
       "          -2.07334987, -2.86309926, -3.04132824, -1.32004914, -1.11244822,\n",
       "          -2.89707996, -2.85700943, -2.85434526, -1.33839523, -1.4358466 ,\n",
       "          -3.06182504, -1.06382042, -3.14036292, -1.25651073, -2.80495349]),\n",
       "   'split2_train_Log_Loss': array([-2.72249315, -3.20190448, -2.74880694, -1.59847769, -1.06728543,\n",
       "          -1.66804113, -2.01792416, -3.23901918, -2.90758542, -2.14197183,\n",
       "          -1.82900082, -2.82571891, -1.32464438, -1.22170595, -1.77028106,\n",
       "          -2.06781835, -2.88254794, -3.05630832, -1.31661396, -1.10977829,\n",
       "          -2.91293268, -2.88245791, -2.86082587, -1.33515521, -1.44437814,\n",
       "          -3.07764991, -1.06351391, -3.15749301, -1.24982929, -2.81437367]),\n",
       "   'mean_train_Log_Loss': array([-2.70916257, -3.19812935, -2.74248558, -1.60451214, -1.07555277,\n",
       "          -1.67368448, -2.02435197, -3.23537996, -2.90703795, -2.148307  ,\n",
       "          -1.83441818, -2.8212899 , -1.33146695, -1.22974547, -1.77538356,\n",
       "          -2.07435722, -2.8744541 , -3.05816271, -1.32407182, -1.11533139,\n",
       "          -2.90847031, -2.87758082, -2.86330496, -1.34089869, -1.45000391,\n",
       "          -3.07585481, -1.06876459, -3.15455962, -1.25768926, -2.81836014]),\n",
       "   'std_train_Log_Loss': array([0.01545269, 0.00547525, 0.01227432, 0.00514623, 0.00829913,\n",
       "          0.01115994, 0.00515518, 0.01105401, 0.00826813, 0.00568343,\n",
       "          0.01108572, 0.00671478, 0.00661006, 0.00799103, 0.00990546,\n",
       "          0.00579416, 0.00826794, 0.0145615 , 0.00823822, 0.00606411,\n",
       "          0.00811685, 0.01520174, 0.00851015, 0.00597959, 0.01441584,\n",
       "          0.01079729, 0.00720993, 0.01059895, 0.00694893, 0.01288604])},\n",
       "  {'C': 0.7309066607697216,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'liblinear',\n",
       "   'tol': 0.03768105472203877},\n",
       "  26,\n",
       "  -1.3565302286242427),\n",
       " 'RandomForestClassifier_V01_PCA_85': ({'mean_fit_time': array([ 8.47534235,  2.00996097,  4.31546458, 12.093009  ,  7.92947189,\n",
       "           5.69843491,  6.07177099,  1.95410983,  3.31314405,  5.00030136,\n",
       "           6.41385579,  1.65790208,  3.4298323 ,  4.5212485 ,  3.30948687,\n",
       "           1.99566611,  2.51693821,  2.31581004,  3.00430234,  5.90721035,\n",
       "           8.5933636 ,  7.62694669,  3.42019129,  2.73269542,  5.00262888,\n",
       "           2.12133018,  2.78422403,  3.41287764,  7.10467601,  3.5305624 ]),\n",
       "   'std_fit_time': array([0.09521171, 0.0237327 , 0.01572701, 0.12018155, 0.04780518,\n",
       "          0.04602352, 0.06372035, 0.01528507, 0.05707223, 0.0359071 ,\n",
       "          0.05915435, 0.00470201, 0.06559715, 0.03590713, 0.0162931 ,\n",
       "          0.01761594, 0.02158163, 0.02321912, 0.01689238, 0.05369571,\n",
       "          0.37159162, 0.12497091, 0.11660861, 0.03217386, 0.03107186,\n",
       "          0.08960394, 0.01404037, 0.03198657, 0.0554827 , 0.09565117]),\n",
       "   'mean_score_time': array([0.65824095, 0.23204652, 0.46575562, 0.5585076 , 0.66987618,\n",
       "          0.51861358, 0.46409249, 0.25963942, 0.19514545, 0.36302988,\n",
       "          0.61402583, 0.23969332, 0.2716078 , 0.4148914 , 0.20777806,\n",
       "          0.18350927, 0.35970521, 0.2140948 , 0.21775174, 0.52193872,\n",
       "          0.54454422, 0.53324159, 0.39062381, 0.40791035, 0.38862904,\n",
       "          0.23171369, 0.42320244, 0.2652909 , 0.4082431 , 0.33377504]),\n",
       "   'std_score_time': array([0.03945121, 0.05580481, 0.02309005, 0.03104093, 0.03145786,\n",
       "          0.05474156, 0.02649111, 0.01885893, 0.01062774, 0.02973105,\n",
       "          0.03005659, 0.02646675, 0.003848  , 0.02365789, 0.0084757 ,\n",
       "          0.01585246, 0.01288403, 0.00847495, 0.04479777, 0.07397457,\n",
       "          0.05631768, 0.01875239, 0.02119188, 0.04474354, 0.03652953,\n",
       "          0.02363379, 0.05033212, 0.00215443, 0.0452618 , 0.05054301]),\n",
       "   'param_n_estimators': masked_array(data=[250, 100, 250, 250, 350, 250, 250, 150, 100, 150, 350,\n",
       "                      100, 150, 250, 100, 100, 200, 100, 100, 250, 250, 250,\n",
       "                      200, 200, 150, 100, 200, 150, 200, 150],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[10, 200, 125, 10, 50, 50, 125, 250, 50, 10, 250, 150,\n",
       "                      150, 250, 50, 200, 250, 150, 75, 75, 50, 75, 150, 200,\n",
       "                      10, 200, 250, 150, 50, 50],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                      'log2', 'sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
       "                      'sqrt', 'log2', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                      'sqrt', 'log2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[65, 40, 50, 20, 80, 45, 20, 40, 35, 35, 75, 80, 100,\n",
       "                      60, 15, 25, 30, 45, 80, 15, 65, 20, 30, 5, 25, 55, 100,\n",
       "                      5, 85, 90],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 60},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90}],\n",
       "   'split0_test_Accuracy': array([0.67264252, 0.40086052, 0.45356759, 0.6780208 , 0.54248835,\n",
       "          0.5428469 , 0.46181427, 0.36859089, 0.543564  , 0.66116888,\n",
       "          0.38042309, 0.4313374 , 0.43169595, 0.38436716, 0.54535676,\n",
       "          0.40444604, 0.36357117, 0.43814987, 0.49157404, 0.51416278,\n",
       "          0.543564  , 0.50484044, 0.44137684, 0.38400861, 0.6654715 ,\n",
       "          0.39906777, 0.36787379, 0.40588024, 0.53926138, 0.54069559]),\n",
       "   'split1_test_Accuracy': array([0.64466089, 0.3953824 , 0.4455267 , 0.6518759 , 0.51551227,\n",
       "          0.51262626, 0.44047619, 0.37301587, 0.504329  , 0.63997114,\n",
       "          0.37121212, 0.41053391, 0.42893218, 0.36580087, 0.51406926,\n",
       "          0.38492063, 0.36075036, 0.41594517, 0.47691198, 0.48448773,\n",
       "          0.51587302, 0.48088023, 0.43001443, 0.37770563, 0.63888889,\n",
       "          0.3968254 , 0.36075036, 0.39718615, 0.51515152, 0.50937951]),\n",
       "   'split2_test_Accuracy': array([0.65266208, 0.40130388, 0.44005795, 0.66099239, 0.51539297,\n",
       "          0.52227454, 0.44042014, 0.35711699, 0.50633828, 0.64795364,\n",
       "          0.37558855, 0.41615357, 0.41905107, 0.37703731, 0.50307859,\n",
       "          0.38645418, 0.35566824, 0.42520826, 0.46685983, 0.47555234,\n",
       "          0.51430641, 0.48424484, 0.41289388, 0.37595074, 0.64976458,\n",
       "          0.39152481, 0.36291199, 0.39550887, 0.50778703, 0.51213329]),\n",
       "   'mean_test_Accuracy': array([0.6566931 , 0.39918289, 0.44640711, 0.66366258, 0.52451334,\n",
       "          0.5259553 , 0.44760875, 0.36625811, 0.51814468, 0.64972362,\n",
       "          0.37575102, 0.41937034, 0.42658015, 0.37575102, 0.52090844,\n",
       "          0.39197308, 0.36000961, 0.42645999, 0.47849075, 0.4914684 ,\n",
       "          0.5246335 , 0.49002644, 0.42814227, 0.37923576, 0.65140591,\n",
       "          0.39581831, 0.36385484, 0.39954338, 0.52078827, 0.52078827]),\n",
       "   'std_test_Accuracy': array([0.0117842 , 0.002692  , 0.00555119, 0.01085043, 0.01276193,\n",
       "          0.01262126, 0.01008561, 0.00669015, 0.0180657 , 0.00875334,\n",
       "          0.00376649, 0.00879981, 0.00542409, 0.00764243, 0.01792676,\n",
       "          0.00887755, 0.00326909, 0.00911836, 0.01015272, 0.01651917,\n",
       "          0.01345538, 0.01060667, 0.01170509, 0.00346331, 0.01092634,\n",
       "          0.00316108, 0.00298635, 0.0045507 , 0.01345476, 0.01417825]),\n",
       "   'rank_test_Accuracy': array([ 2, 22, 16,  1,  7,  5, 15, 28, 11,  4, 26, 20, 18, 26,  8, 24, 30,\n",
       "          19, 14, 12,  6, 13, 17, 25,  3, 23, 29, 21,  9,  9]),\n",
       "   'split0_train_Accuracy': array([0.93511657, 0.42617025, 0.49159588, 0.92770649, 0.63907464,\n",
       "          0.64015905, 0.49394542, 0.39183083, 0.62027833, 0.93855052,\n",
       "          0.4044822 , 0.46593168, 0.46340141, 0.40430146, 0.62190493,\n",
       "          0.42255558, 0.39454184, 0.46647388, 0.55738297, 0.568227  ,\n",
       "          0.62804988, 0.55756371, 0.47930598, 0.41478402, 0.93276703,\n",
       "          0.42110971, 0.39508404, 0.43448401, 0.62389301, 0.63889391]),\n",
       "   'split1_train_Accuracy': array([0.93513514, 0.43657658, 0.50990991, 0.92198198, 0.63513514,\n",
       "          0.63297297, 0.4954955 , 0.40990991, 0.61171171, 0.92666667,\n",
       "          0.41081081, 0.47117117, 0.47567568, 0.40864865, 0.60864865,\n",
       "          0.4354955 , 0.41225225, 0.47243243, 0.54900901, 0.57207207,\n",
       "          0.62252252, 0.55045045, 0.48648649, 0.43117117, 0.92810811,\n",
       "          0.44468468, 0.41153153, 0.45171171, 0.62576577, 0.62738739]),\n",
       "   'split2_train_Accuracy': array([0.93202661, 0.44128754, 0.50062938, 0.92429419, 0.62075166,\n",
       "          0.62111131, 0.49595397, 0.39543248, 0.60187017, 0.93130732,\n",
       "          0.41233591, 0.46358569, 0.46358569, 0.41233591, 0.61014206,\n",
       "          0.4319367 , 0.39345441, 0.47131811, 0.54360726, 0.55925193,\n",
       "          0.61212012, 0.56105017, 0.46808128, 0.42024816, 0.93274591,\n",
       "          0.43877001, 0.40963855, 0.43966912, 0.60888329, 0.61769466]),\n",
       "   'mean_train_Accuracy': array([0.93409277, 0.43467812, 0.50071172, 0.92466089, 0.63165381,\n",
       "          0.63141444, 0.49513163, 0.39905774, 0.61128674, 0.93217483,\n",
       "          0.40920964, 0.46689618, 0.46755426, 0.40842867, 0.61356521,\n",
       "          0.42999592, 0.40008284, 0.47007481, 0.54999975, 0.566517  ,\n",
       "          0.62089751, 0.55635478, 0.47795792, 0.42206778, 0.93120702,\n",
       "          0.4348548 , 0.40541804, 0.44195495, 0.61951402, 0.62799199]),\n",
       "   'std_train_Accuracy': array([0.00146102, 0.00631592, 0.0074769 , 0.00235136, 0.00787496,\n",
       "          0.00785391, 0.00085941, 0.00781324, 0.00752111, 0.00489019,\n",
       "          0.0034003 , 0.00317097, 0.0057432 , 0.00328374, 0.00592851,\n",
       "          0.00545804, 0.00861652, 0.00258656, 0.00566738, 0.00537166,\n",
       "          0.00660403, 0.00441095, 0.00757412, 0.00681263, 0.00219128,\n",
       "          0.01001471, 0.00734799, 0.00721652, 0.00755584, 0.00866511]),\n",
       "   'split0_test_F1': array([0.65998019, 0.34955271, 0.41381973, 0.66778891, 0.51046519,\n",
       "          0.51194454, 0.41855075, 0.32718219, 0.51348716, 0.65048045,\n",
       "          0.33065819, 0.38131417, 0.38224898, 0.33801104, 0.5101598 ,\n",
       "          0.35281302, 0.32833923, 0.3915269 , 0.45169616, 0.47593411,\n",
       "          0.51212116, 0.4630534 , 0.40196342, 0.34682018, 0.65340825,\n",
       "          0.34269035, 0.32815837, 0.35801934, 0.50535623, 0.51009469]),\n",
       "   'split1_test_F1': array([0.63163344, 0.34698894, 0.40281976, 0.64130159, 0.47896508,\n",
       "          0.47397658, 0.39605517, 0.3261965 , 0.46769978, 0.62666755,\n",
       "          0.31932787, 0.3693198 , 0.38831729, 0.3096224 , 0.4755077 ,\n",
       "          0.33636783, 0.31595741, 0.36912448, 0.43499859, 0.44681707,\n",
       "          0.48107654, 0.44012359, 0.3883412 , 0.33902619, 0.6265097 ,\n",
       "          0.35056304, 0.32142605, 0.34927265, 0.48052288, 0.47309553]),\n",
       "   'split2_test_F1': array([0.64349889, 0.3632831 , 0.4052926 , 0.65480865, 0.48754521,\n",
       "          0.49318066, 0.39950975, 0.31622666, 0.47596137, 0.63785227,\n",
       "          0.33090804, 0.37934777, 0.37791059, 0.33448639, 0.4717491 ,\n",
       "          0.34369061, 0.31467386, 0.38377007, 0.43088996, 0.44167701,\n",
       "          0.48504539, 0.4495732 , 0.37438916, 0.3372588 , 0.64112111,\n",
       "          0.34644267, 0.32419752, 0.34968135, 0.478594  , 0.48598549]),\n",
       "   'mean_test_F1': array([0.64507006, 0.35325409, 0.40732666, 0.65465969, 0.49236854,\n",
       "          0.49307236, 0.40474037, 0.32321913, 0.48578573, 0.63835887,\n",
       "          0.32696704, 0.37666653, 0.38283094, 0.3273856 , 0.48587386,\n",
       "          0.34430869, 0.31968116, 0.38149132, 0.43923142, 0.4548699 ,\n",
       "          0.49279745, 0.45094329, 0.38827761, 0.34105186, 0.64037201,\n",
       "          0.3465576 , 0.32460178, 0.35233957, 0.48820548, 0.48977179]),\n",
       "   'std_test_F1': array([0.01163878, 0.00714394, 0.00471888, 0.01082652, 0.01331588,\n",
       "          0.01551862, 0.00990568, 0.0049435 , 0.0199537 , 0.00973946,\n",
       "          0.00539975, 0.00525383, 0.00426283, 0.01263591, 0.0173104 ,\n",
       "          0.00673565, 0.00616926, 0.00929613, 0.00900681, 0.01510119,\n",
       "          0.01381446, 0.00942156, 0.01125912, 0.00415827, 0.01100676,\n",
       "          0.00321878, 0.00276637, 0.00403594, 0.012202  , 0.01535599]),\n",
       "   'rank_test_F1': array([ 2, 21, 15,  1,  7,  5, 16, 29, 11,  4, 27, 20, 18, 26, 10, 24, 30,\n",
       "          19, 14, 12,  6, 13, 17, 25,  3, 23, 28, 22,  9,  8]),\n",
       "   'split0_train_F1': array([0.93467344, 0.37659243, 0.45746699, 0.92693814, 0.62068639,\n",
       "          0.62302985, 0.45154027, 0.35152955, 0.60043534, 0.93792326,\n",
       "          0.3555913 , 0.42101712, 0.41832214, 0.35935566, 0.60040213,\n",
       "          0.37244062, 0.36217756, 0.41954033, 0.52876012, 0.53917435,\n",
       "          0.60877346, 0.52420462, 0.44038487, 0.37908525, 0.93249962,\n",
       "          0.37011254, 0.35860486, 0.38864853, 0.60459371, 0.62102003]),\n",
       "   'split1_train_F1': array([0.93450744, 0.3889428 , 0.47423124, 0.92101326, 0.61387903,\n",
       "          0.61228311, 0.45596128, 0.36901739, 0.58897825, 0.92608276,\n",
       "          0.36136996, 0.43565664, 0.43616173, 0.35737257, 0.58248931,\n",
       "          0.38881599, 0.37091565, 0.42856405, 0.51137225, 0.54105661,\n",
       "          0.60071547, 0.51419393, 0.44945213, 0.39944302, 0.92745773,\n",
       "          0.40108184, 0.37616314, 0.40729941, 0.60349789, 0.60860143]),\n",
       "   'split2_train_F1': array([0.93161898, 0.39813582, 0.46432406, 0.92383704, 0.59626466,\n",
       "          0.59663763, 0.45080684, 0.35318079, 0.5729909 , 0.93087705,\n",
       "          0.36594978, 0.42541506, 0.41971183, 0.36609224, 0.58426797,\n",
       "          0.39012292, 0.35505172, 0.42503775, 0.50669842, 0.52598524,\n",
       "          0.58482076, 0.52478746, 0.430328  , 0.38166956, 0.93246616,\n",
       "          0.38815335, 0.37058414, 0.39174811, 0.58097363, 0.59552073]),\n",
       "   'mean_train_F1': array([0.93359995, 0.38789035, 0.46534076, 0.92392948, 0.6102767 ,\n",
       "          0.6106502 , 0.45276947, 0.35790925, 0.58746816, 0.93162769,\n",
       "          0.36097035, 0.42736294, 0.4247319 , 0.36094016, 0.58905313,\n",
       "          0.38379318, 0.36271498, 0.42438071, 0.51561026, 0.5354054 ,\n",
       "          0.59810323, 0.521062  , 0.440055  , 0.38673261, 0.93080784,\n",
       "          0.38644925, 0.36845071, 0.39589868, 0.59635508, 0.60838073]),\n",
       "   'std_train_F1': array([0.0014024 , 0.00882648, 0.00688163, 0.00241971, 0.01029038,\n",
       "          0.01083627, 0.00227673, 0.00788352, 0.01125491, 0.00486292,\n",
       "          0.00423826, 0.00613322, 0.008102  , 0.00373195, 0.00805774,\n",
       "          0.00804518, 0.00648756, 0.0037131 , 0.00949211, 0.00670524,\n",
       "          0.00995158, 0.00486229, 0.00781088, 0.00904933, 0.00236892,\n",
       "          0.01270045, 0.00732516, 0.00816024, 0.01088552, 0.01041122]),\n",
       "   'split0_test_Log_Loss': array([-1.85488974, -2.80690877, -2.73980393, -1.73860851, -2.40225682,\n",
       "          -2.40477903, -2.63164743, -2.96377125, -2.29558408, -1.8768853 ,\n",
       "          -2.89203144, -2.78545779, -2.71243198, -2.8837922 , -2.28098211,\n",
       "          -2.80496939, -2.97936749, -2.72105372, -2.45600839, -2.54767782,\n",
       "          -2.2928088 , -2.43652194, -2.8016005 , -2.92969843, -1.86468684,\n",
       "          -2.80075125, -2.96466295, -2.78389038, -2.28952016, -2.41604438]),\n",
       "   'split1_test_Log_Loss': array([-1.87562017, -2.81092003, -2.73708056, -1.75386608, -2.40796981,\n",
       "          -2.40226168, -2.63376929, -2.95485664, -2.30159883, -1.89177372,\n",
       "          -2.89751603, -2.81189698, -2.71131962, -2.89089399, -2.29860524,\n",
       "          -2.80570142, -2.97146658, -2.71922771, -2.45365689, -2.56024757,\n",
       "          -2.30275957, -2.44267045, -2.80433819, -2.94163319, -1.88831104,\n",
       "          -2.82473566, -2.97349199, -2.79138854, -2.30145176, -2.40759564]),\n",
       "   'split2_test_Log_Loss': array([-1.85464336, -2.82366052, -2.73462689, -1.74020827, -2.39600082,\n",
       "          -2.40349598, -2.63223798, -2.97701335, -2.30476912, -1.86353525,\n",
       "          -2.89736728, -2.79979746, -2.69970325, -2.88514839, -2.29523678,\n",
       "          -2.81862292, -2.97938688, -2.71440478, -2.43688563, -2.549041  ,\n",
       "          -2.28887914, -2.44485534, -2.79889729, -2.92705667, -1.86433334,\n",
       "          -2.82417845, -2.97054601, -2.77794953, -2.29242183, -2.40425691]),\n",
       "   'mean_test_Log_Loss': array([-1.86171316, -2.81380264, -2.73717921, -1.74422146, -2.40208422,\n",
       "          -2.40351484, -2.63255014, -2.9651952 , -2.30063488, -1.87741537,\n",
       "          -2.8956286 , -2.79902199, -2.70783844, -2.8866077 , -2.29158154,\n",
       "          -2.80974307, -2.97674219, -2.71823956, -2.44888074, -2.55231698,\n",
       "          -2.29481958, -2.44133475, -2.80161556, -2.93279736, -1.87243861,\n",
       "          -2.81651276, -2.96955567, -2.78441696, -2.29445718, -2.40931942]),\n",
       "   'std_test_Log_Loss': array([0.00982894, 0.00713695, 0.00211502, 0.00684732, 0.00488124,\n",
       "          0.00102899, 0.00089471, 0.00908958, 0.00381177, 0.01151884,\n",
       "          0.00255462, 0.01082015, 0.00575024, 0.00307942, 0.00764963,\n",
       "          0.00626409, 0.00372841, 0.00280325, 0.0085065 , 0.00563231,\n",
       "          0.00583628, 0.00353118, 0.00221825, 0.00633698, 0.01121836,\n",
       "          0.01119261, 0.0036755 , 0.00549176, 0.00508324, 0.0049648 ]),\n",
       "   'rank_test_Log_Loss': array([ 2, 23, 18,  1,  9, 10, 15, 28,  8,  4, 26, 20, 16, 25,  5, 22, 30,\n",
       "          17, 13, 14,  7, 12, 21, 27,  3, 24, 29, 19,  6, 11]),\n",
       "   'split0_train_Log_Loss': array([-1.35418251, -2.75275382, -2.65494497, -1.25924259, -2.22757559,\n",
       "          -2.23221866, -2.55285647, -2.91886956, -2.13109728, -1.36304388,\n",
       "          -2.84880491, -2.71307284, -2.64434527, -2.84012801, -2.11821749,\n",
       "          -2.75546997, -2.93305209, -2.65090789, -2.33385535, -2.41932912,\n",
       "          -2.12536229, -2.31385307, -2.72906589, -2.88027274, -1.35898695,\n",
       "          -2.75115977, -2.91920391, -2.72897534, -2.12411246, -2.23511199]),\n",
       "   'split1_train_Log_Loss': array([-1.34620293, -2.74952264, -2.63745559, -1.24859367, -2.21601008,\n",
       "          -2.21313254, -2.54329649, -2.90221698, -2.11791181, -1.3547036 ,\n",
       "          -2.84477808, -2.72854699, -2.63309424, -2.83987165, -2.11273289,\n",
       "          -2.74249226, -2.91504762, -2.63965149, -2.31578596, -2.41575127,\n",
       "          -2.12142547, -2.30814341, -2.72090442, -2.87937132, -1.35326101,\n",
       "          -2.75809917, -2.91898228, -2.72238554, -2.11968154, -2.21663872]),\n",
       "   'split2_train_Log_Loss': array([-1.34933998, -2.763915  , -2.64354647, -1.25470508, -2.21769926,\n",
       "          -2.22613445, -2.54957707, -2.92412062, -2.13113589, -1.35231014,\n",
       "          -2.85002131, -2.72324486, -2.6279175 , -2.83741019, -2.11927085,\n",
       "          -2.75975299, -2.92753959, -2.64442856, -2.31040505, -2.41472409,\n",
       "          -2.11946531, -2.3192671 , -2.71975551, -2.87179517, -1.35332553,\n",
       "          -2.76303245, -2.9186724 , -2.71701544, -2.12104378, -2.22177669]),\n",
       "   'mean_train_Log_Loss': array([-1.34990847, -2.75539715, -2.64531568, -1.25418044, -2.22042831,\n",
       "          -2.22382855, -2.54857668, -2.91506905, -2.12671499, -1.35668587,\n",
       "          -2.8478681 , -2.72162156, -2.635119  , -2.83913661, -2.11674041,\n",
       "          -2.75257174, -2.9252131 , -2.64499598, -2.32001545, -2.41660149,\n",
       "          -2.12208436, -2.31375452, -2.72324194, -2.87714641, -1.35519116,\n",
       "          -2.75743046, -2.91895286, -2.72279211, -2.12161259, -2.22450913]),\n",
       "   'std_train_Log_Loss': array([0.00328236, 0.00616579, 0.00724878, 0.0043632 , 0.00510072,\n",
       "          0.00796065, 0.00396644, 0.00933721, 0.00622481, 0.00460075,\n",
       "          0.0022407 , 0.00642073, 0.00685773, 0.00122525, 0.00286619,\n",
       "          0.00733862, 0.00753214, 0.00461289, 0.01002981, 0.00197379,\n",
       "          0.0024521 , 0.00454176, 0.00414478, 0.00380175, 0.00268415,\n",
       "          0.00487001, 0.00021798, 0.00489107, 0.00185309, 0.00778525])},\n",
       "  {'n_estimators': 250,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 20},\n",
       "  3,\n",
       "  -1.744221455979702),\n",
       " 'DecisionTreeClassifier_V01_PCA_85': ({'mean_fit_time': array([0.03656848, 0.06050396, 0.04521195, 0.08078392, 0.0375665 ,\n",
       "          0.0664885 , 0.09009218, 0.80218959, 0.09175428, 0.06815084,\n",
       "          0.82745401, 0.04321766, 0.07579764, 0.06416178, 0.12765789,\n",
       "          0.07779153, 1.35138663, 0.6791842 , 0.1306506 , 1.59573412,\n",
       "          0.19447939, 0.05285923, 0.13630279, 0.0525256 , 0.05485272,\n",
       "          0.04355033, 0.27792327, 0.04155509, 0.37699175, 0.06283196]),\n",
       "   'std_fit_time': array([0.0026178 , 0.01099532, 0.00523532, 0.02540142, 0.00943823,\n",
       "          0.00285906, 0.00329116, 0.01099629, 0.00325757, 0.00248752,\n",
       "          0.06042592, 0.00448489, 0.00646331, 0.00523582, 0.00293612,\n",
       "          0.00709865, 0.03737951, 0.03541051, 0.02203137, 0.04855955,\n",
       "          0.02410156, 0.00453363, 0.00893346, 0.00367171, 0.00533996,\n",
       "          0.00124358, 0.01233155, 0.00477122, 0.00646361, 0.00732915]),\n",
       "   'mean_score_time': array([0.05119665, 0.03390988, 0.03025333, 0.02692787, 0.03490663,\n",
       "          0.02925491, 0.03324517, 0.05452069, 0.04089101, 0.03091749,\n",
       "          0.04488039, 0.0325799 , 0.041888  , 0.03224723, 0.04122361,\n",
       "          0.02892288, 0.03257998, 0.02958806, 0.04554526, 0.03457435,\n",
       "          0.03257982, 0.03623645, 0.02958703, 0.03191511, 0.03224762,\n",
       "          0.03989347, 0.03291194, 0.03690171, 0.02992042, 0.03224802]),\n",
       "   'std_score_time': array([0.0081564 , 0.00846253, 0.00329124, 0.00162859, 0.00880847,\n",
       "          0.00188093, 0.00248803, 0.0286792 , 0.00709907, 0.00141051,\n",
       "          0.01232324, 0.00658216, 0.01974614, 0.00047075, 0.00971553,\n",
       "          0.00081381, 0.00047008, 0.00124371, 0.02211232, 0.00663212,\n",
       "          0.00589095, 0.01037559, 0.00047036, 0.00354934, 0.0032912 ,\n",
       "          0.00814316, 0.00453428, 0.00695715, 0.00141063, 0.00477116]),\n",
       "   'param_min_samples_split': masked_array(data=[0.71, 0.15, 0.65, 0.58, 0.67, 0.68, 0.86, 0.31, 0.01,\n",
       "                      0.14, 0.26, 0.47000000000000003, 0.06, 0.07, 0.4, 0.87,\n",
       "                      0.08, 0.43, 0.6, 0.04, 0.3, 0.17, 0.49, 0.3, 0.25,\n",
       "                      0.44, 0.1, 0.48, 0.03, 0.23],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                      0.5, 'sqrt', 'sqrt', 0.5, 'log2', 'sqrt', 'log2', 0.5,\n",
       "                      0.5, 0.5, 0.5, 0.5, 0.5, 'sqrt', 'log2', 0.5, 'log2',\n",
       "                      'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[None, 20, None, 20, 20, 20, None, None, None, 20, None,\n",
       "                      None, None, None, None, None, 20, 20, None, 20, 20, 20,\n",
       "                      20, None, None, None, 20, 20, None, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'entropy', 'gini', 'entropy',\n",
       "                      'entropy', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                      'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                      'entropy', 'gini', 'entropy', 'entropy', 'gini',\n",
       "                      'gini', 'gini', 'gini', 'gini', 'entropy', 'gini',\n",
       "                      'entropy', 'gini'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=['balanced', None, 'balanced', None, None, None, None,\n",
       "                      'balanced', None, None, None, 'balanced', None,\n",
       "                      'balanced', None, 'balanced', None, None, None,\n",
       "                      'balanced', None, 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', None, None, 'balanced', 'balanced',\n",
       "                      'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'min_samples_split': 0.71,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.15,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.65,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.58,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.67,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.68,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.86,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.31,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.01,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.14,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.26,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.47000000000000003,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.06,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.07,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.4,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.87,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.08,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.43,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.6,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.04,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.3,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.17,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.49,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.3,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.25,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.44,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.1,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.48,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.03,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.23,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'}],\n",
       "   'split0_test_Accuracy': array([0.04051631, 0.13553245, 0.06561492, 0.06525636, 0.06704912,\n",
       "          0.06489781, 0.06489781, 0.09429903, 0.27285766, 0.16385801,\n",
       "          0.09752599, 0.07135174, 0.18429545, 0.17461456, 0.10218716,\n",
       "          0.04804589, 0.20186447, 0.08067408, 0.10254572, 0.27393331,\n",
       "          0.08927931, 0.14019362, 0.08139118, 0.11581212, 0.10182861,\n",
       "          0.09107207, 0.14449624, 0.07995697, 0.19433489, 0.14198638]),\n",
       "   'split1_test_Accuracy': array([0.06349206, 0.13816739, 0.04834055, 0.05591631, 0.06349206,\n",
       "          0.05735931, 0.06746032, 0.08766234, 0.34992785, 0.1525974 ,\n",
       "          0.11616162, 0.07683983, 0.21031746, 0.15945166, 0.09704185,\n",
       "          0.04437229, 0.20923521, 0.08766234, 0.08946609, 0.26803752,\n",
       "          0.08982684, 0.13095238, 0.08513709, 0.08874459, 0.08658009,\n",
       "          0.06962482, 0.16594517, 0.05880231, 0.20165945, 0.10281385]),\n",
       "   'split2_test_Accuracy': array([0.04454908, 0.1140891 , 0.05469033, 0.0702644 , 0.08004346,\n",
       "          0.06845346, 0.06265846, 0.10068816, 0.3158276 , 0.13980442,\n",
       "          0.12241941, 0.08873597, 0.22709163, 0.17566099, 0.08801159,\n",
       "          0.04853314, 0.21187975, 0.09018472, 0.09380659, 0.27960884,\n",
       "          0.09308222, 0.10394784, 0.09090909, 0.10286128, 0.11590004,\n",
       "          0.08076784, 0.14233973, 0.05179283, 0.20644694, 0.12169504]),\n",
       "   'mean_test_Accuracy': array([0.04950733, 0.12929584, 0.05623648, 0.06380678, 0.07017544,\n",
       "          0.06356645, 0.06500841, 0.09420812, 0.31278539, 0.15212689,\n",
       "          0.11199231, 0.07894737, 0.20716174, 0.16991108, 0.09577025,\n",
       "          0.0469839 , 0.20764239, 0.08615717, 0.09528959, 0.27385244,\n",
       "          0.09072338, 0.12509012, 0.08579668, 0.1024994 , 0.10141793,\n",
       "          0.08050949, 0.15092526, 0.06356645, 0.20079308, 0.1222062 ]),\n",
       "   'std_test_Accuracy': array([0.01001959, 0.01076901, 0.00714401, 0.00593949, 0.0071036 ,\n",
       "          0.00462075, 0.00195927, 0.00531096, 0.03157332, 0.00982711,\n",
       "          0.01058287, 0.00725285, 0.01761614, 0.00740427, 0.00585747,\n",
       "          0.00185638, 0.00424151, 0.00402641, 0.00544713, 0.00471792,\n",
       "          0.00167709, 0.01536871, 0.00391418, 0.0110661 , 0.01195716,\n",
       "          0.0087679 , 0.01065139, 0.01198264, 0.00498331, 0.01601482]),\n",
       "   'rank_test_Accuracy': array([29,  9, 28, 25, 23, 26, 24, 17,  1,  7, 12, 22,  4,  6, 15, 30,  3,\n",
       "          19, 16,  2, 18, 10, 20, 13, 14, 21,  8, 26,  5, 11]),\n",
       "   'split0_train_Accuracy': array([0.04409904, 0.13970721, 0.0679559 , 0.06614856, 0.0679559 ,\n",
       "          0.06397976, 0.0684981 , 0.0947045 , 0.41369962, 0.1776613 ,\n",
       "          0.09777697, 0.07211278, 0.21886861, 0.19446955, 0.10048798,\n",
       "          0.04807519, 0.21850714, 0.08747515, 0.10446412, 0.29604193,\n",
       "          0.08982469, 0.14729803, 0.08114947, 0.12560998, 0.10374119,\n",
       "          0.08837882, 0.15633472, 0.08693295, 0.23278511, 0.14404482]),\n",
       "   'split1_train_Accuracy': array([0.0627027 , 0.15153153, 0.04864865, 0.05603604, 0.06504505,\n",
       "          0.06      , 0.07045045, 0.08792793, 0.4563964 , 0.17351351,\n",
       "          0.12342342, 0.07621622, 0.24198198, 0.18666667, 0.10108108,\n",
       "          0.04396396, 0.2218018 , 0.09171171, 0.08864865, 0.29171171,\n",
       "          0.09621622, 0.13675676, 0.08990991, 0.09513514, 0.09873874,\n",
       "          0.06864865, 0.17477477, 0.05945946, 0.22810811, 0.11117117]),\n",
       "   'split2_train_Accuracy': array([0.04495594, 0.12641611, 0.05790325, 0.07210933, 0.08038123,\n",
       "          0.06941198, 0.05934184, 0.10178026, 0.42995864, 0.14529761,\n",
       "          0.12228017, 0.09117065, 0.25121381, 0.20787628, 0.09009171,\n",
       "          0.04873224, 0.22244201, 0.09296889, 0.09656537, 0.30659953,\n",
       "          0.0983636 , 0.10483726, 0.09081101, 0.10807409, 0.12138105,\n",
       "          0.08146017, 0.14385902, 0.05502607, 0.24617874, 0.12875382]),\n",
       "   'mean_train_Accuracy': array([0.0505859 , 0.13921829, 0.05816927, 0.06476464, 0.07112739,\n",
       "          0.06446391, 0.0660968 , 0.09480423, 0.43335155, 0.16549081,\n",
       "          0.11449352, 0.07983322, 0.2373548 , 0.1963375 , 0.09722026,\n",
       "          0.0469238 , 0.22091698, 0.09071858, 0.09655938, 0.29811772,\n",
       "          0.0948015 , 0.12963068, 0.08729013, 0.1096064 , 0.10795366,\n",
       "          0.07949588, 0.15832284, 0.06713949, 0.23569065, 0.12798994]),\n",
       "   'std_train_Accuracy': array([0.00857502, 0.01025915, 0.0078844 , 0.00663446, 0.00665048,\n",
       "          0.00385764, 0.00484252, 0.00565563, 0.01759522, 0.01437881,\n",
       "          0.01182959, 0.00818994, 0.01360419, 0.00875895, 0.00504646,\n",
       "          0.00211004, 0.00172394, 0.00235018, 0.00645664, 0.00625265,\n",
       "          0.00362669, 0.01805205, 0.00435766, 0.01248839, 0.00971175,\n",
       "          0.00817369, 0.01269936, 0.01411263, 0.00765805, 0.01343148]),\n",
       "   'split0_test_F1': array([0.00892622, 0.07080433, 0.01245755, 0.01240011, 0.02428351,\n",
       "          0.01005802, 0.00996706, 0.02165495, 0.27112569, 0.09451491,\n",
       "          0.02244937, 0.01256614, 0.14007311, 0.13237536, 0.02450736,\n",
       "          0.00788123, 0.12825371, 0.02055756, 0.02739671, 0.22889692,\n",
       "          0.0270905 , 0.06920647, 0.02145866, 0.05120054, 0.02835949,\n",
       "          0.02166512, 0.07254235, 0.02202189, 0.14915918, 0.07550686]),\n",
       "   'split1_test_F1': array([0.01455035, 0.0853106 , 0.00465808, 0.00592212, 0.0143151 ,\n",
       "          0.01099942, 0.01029896, 0.01995298, 0.34379007, 0.09535728,\n",
       "          0.03657475, 0.02157497, 0.17367982, 0.11045194, 0.02353867,\n",
       "          0.00472789, 0.14257486, 0.01914535, 0.0212438 , 0.21305779,\n",
       "          0.02344053, 0.06246446, 0.0195491 , 0.02722703, 0.03958446,\n",
       "          0.01774723, 0.09576562, 0.00858954, 0.16486736, 0.04197544]),\n",
       "   'split2_test_F1': array([0.00458513, 0.05280176, 0.01641149, 0.01649384, 0.01468438,\n",
       "          0.01058194, 0.01257039, 0.02588121, 0.30511591, 0.08545748,\n",
       "          0.03346044, 0.03534747, 0.16928487, 0.12477507, 0.02161208,\n",
       "          0.00467315, 0.1435607 , 0.01909475, 0.0276115 , 0.23104674,\n",
       "          0.02582742, 0.04617621, 0.02268406, 0.03360065, 0.04884841,\n",
       "          0.01595135, 0.07921884, 0.01082406, 0.17058723, 0.0600582 ]),\n",
       "   'mean_test_F1': array([0.00935933, 0.06966353, 0.0111714 , 0.01160052, 0.01777839,\n",
       "          0.01054542, 0.01094132, 0.02249019, 0.30660666, 0.09179051,\n",
       "          0.03080759, 0.02312511, 0.16095889, 0.12255127, 0.02322412,\n",
       "          0.00576653, 0.1381024 , 0.01960184, 0.02541848, 0.22433426,\n",
       "          0.02545567, 0.05931998, 0.02122915, 0.03737599, 0.03889608,\n",
       "          0.01846444, 0.08249293, 0.01383255, 0.16150068, 0.05921236]),\n",
       "   'std_test_F1': array([0.00407439, 0.01327842, 0.00487804, 0.00434726, 0.00462094,\n",
       "          0.00038563, 0.00115586, 0.00248859, 0.02971827, 0.00447566,\n",
       "          0.00606846, 0.00936628, 0.01493628, 0.00909661, 0.00120291,\n",
       "          0.00150155, 0.00700388, 0.00067885, 0.00295165, 0.00801756,\n",
       "          0.00151466, 0.00966266, 0.00128845, 0.01015324, 0.0083801 ,\n",
       "          0.00238745, 0.00976825, 0.00588518, 0.00906718, 0.01371806]),\n",
       "   'rank_test_F1': array([29,  9, 26, 25, 23, 28, 27, 19,  1,  7, 14, 18,  4,  6, 17, 30,  5,\n",
       "          21, 16,  2, 15, 10, 20, 13, 12, 22,  8, 24,  3, 11]),\n",
       "   'split0_train_F1': array([0.0095786 , 0.07281944, 0.0133622 , 0.01255075, 0.0244012 ,\n",
       "          0.00973412, 0.01054108, 0.02212098, 0.40861925, 0.10282463,\n",
       "          0.02238632, 0.01242464, 0.16877788, 0.14826583, 0.02442428,\n",
       "          0.00757493, 0.13873009, 0.02239355, 0.0280248 , 0.25006745,\n",
       "          0.02695253, 0.0774684 , 0.02339794, 0.0579935 , 0.02918277,\n",
       "          0.02058293, 0.08041003, 0.02437659, 0.1794184 , 0.07300201]),\n",
       "   'split1_train_F1': array([0.01425024, 0.09367454, 0.0046673 , 0.00594684, 0.01473275,\n",
       "          0.01145501, 0.01078342, 0.01991628, 0.44981473, 0.10809562,\n",
       "          0.03922466, 0.02034167, 0.201352  , 0.12974989, 0.02485257,\n",
       "          0.0046694 , 0.15229066, 0.01975458, 0.02143272, 0.23283576,\n",
       "          0.02522153, 0.06749009, 0.02087229, 0.03068211, 0.04376852,\n",
       "          0.01724463, 0.10185744, 0.00844934, 0.1895634 , 0.0440044 ]),\n",
       "   'split2_train_F1': array([0.00458901, 0.06073178, 0.01846282, 0.01676276, 0.01483682,\n",
       "          0.01071032, 0.01194292, 0.02575988, 0.42008377, 0.09121929,\n",
       "          0.03325299, 0.03837518, 0.19578748, 0.15244067, 0.02232097,\n",
       "          0.00465811, 0.15030815, 0.01965176, 0.0277411 , 0.25889486,\n",
       "          0.02760102, 0.04704903, 0.02236929, 0.03492617, 0.05082614,\n",
       "          0.01593428, 0.07718267, 0.01088423, 0.21202233, 0.06486485]),\n",
       "   'mean_train_F1': array([0.00947262, 0.07574192, 0.01216411, 0.01175345, 0.01799026,\n",
       "          0.01063315, 0.01108914, 0.02259905, 0.42617258, 0.10071318,\n",
       "          0.03162132, 0.02371383, 0.18863912, 0.14348546, 0.02386594,\n",
       "          0.00563415, 0.14710964, 0.02059996, 0.02573287, 0.24726602,\n",
       "          0.02659169, 0.06400251, 0.02221318, 0.04120059, 0.04125914,\n",
       "          0.01792061, 0.08648338, 0.01457005, 0.19366804, 0.06062375]),\n",
       "   'std_train_F1': array([0.00394489, 0.01360667, 0.00569536, 0.00445143, 0.00453342,\n",
       "          0.00070466, 0.00061176, 0.00240947, 0.01736034, 0.00704965,\n",
       "          0.00697037, 0.01085929, 0.01422656, 0.00986092, 0.00110636,\n",
       "          0.00137235, 0.00598026, 0.00126895, 0.00304287, 0.01082143,\n",
       "          0.00100437, 0.01266115, 0.00103699, 0.01200012, 0.00901227,\n",
       "          0.00195707, 0.01095065, 0.00700516, 0.01362327, 0.01221217]),\n",
       "   'split0_test_Log_Loss': array([-3.66753118, -3.55663624, -3.4350557 , -3.48658108, -3.48350511,\n",
       "          -3.52927619, -3.49772923, -3.20204653, -8.80220132, -3.54366687,\n",
       "          -3.18931214, -3.404522  , -3.95233729, -3.67673849, -3.18239847,\n",
       "          -3.48031825, -3.18223064, -3.19937562, -3.2755733 , -3.36128297,\n",
       "          -3.3693405 , -3.33029822, -3.32304369, -3.29701699, -3.29688876,\n",
       "          -3.33935583, -3.33164371, -3.39938485, -4.67015489, -3.34388838]),\n",
       "   'split1_test_Log_Loss': array([-3.37960778, -3.31992795, -3.53127309, -3.52347202, -3.52745971,\n",
       "          -3.5554589 , -3.49024843, -3.29480218, -6.98047455, -3.26501473,\n",
       "          -3.04669448, -3.39699095, -3.55286841, -3.82169195, -3.15546398,\n",
       "          -3.45744478, -3.13898285, -3.19009777, -3.294601  , -3.67075577,\n",
       "          -3.2999338 , -3.27649523, -3.23235246, -3.41534925, -3.48498857,\n",
       "          -3.48497426, -3.33812857, -3.50219801, -4.77427457, -3.37607093]),\n",
       "   'split2_test_Log_Loss': array([-3.55534369, -3.41883432, -3.56881571, -3.44963007, -3.42575463,\n",
       "          -3.40947839, -3.51959104, -3.11618623, -7.96922361, -3.44860767,\n",
       "          -3.14922538, -3.45099224, -3.74403847, -3.7613075 , -3.27877435,\n",
       "          -3.52682746, -3.1135257 , -3.18841136, -3.29920082, -3.30096336,\n",
       "          -3.33581624, -3.53987126, -3.31300858, -3.36247019, -3.42186052,\n",
       "          -3.36895658, -3.33315182, -3.54361578, -4.74487795, -3.29278307]),\n",
       "   'mean_test_Log_Loss': array([-3.53440533, -3.43207165, -3.51148276, -3.48660992, -3.47898613,\n",
       "          -3.498252  , -3.50249055, -3.20445682, -7.91903885, -3.41931189,\n",
       "          -3.12850756, -3.41743095, -3.75016945, -3.75307904, -3.20540152,\n",
       "          -3.48812967, -3.14503078, -3.19264761, -3.28975022, -3.44435388,\n",
       "          -3.33509923, -3.38190712, -3.28950572, -3.35814813, -3.40100553,\n",
       "          -3.39768099, -3.33430412, -3.48148287, -4.72962739, -3.33765289]),\n",
       "   'std_test_Log_Loss': array([0.11860254, 0.09719703, 0.05637883, 0.03010502, 0.04158862,\n",
       "          0.06346074, 0.01243129, 0.07284097, 0.74542339, 0.1157475 ,\n",
       "          0.06009148, 0.02384755, 0.16332982, 0.05952904, 0.05285926,\n",
       "          0.02882553, 0.02837712, 0.00482596, 0.01023849, 0.16188827,\n",
       "          0.02837271, 0.1134567 , 0.04059891, 0.04846107, 0.07827276,\n",
       "          0.06286511, 0.00277209, 0.06068428, 0.04389202, 0.03424344]),\n",
       "   'rank_test_Log_Loss': array([26, 17, 25, 21, 19, 23, 24,  4, 30, 16,  1, 15, 27, 28,  5, 22,  2,\n",
       "           3,  7, 18,  9, 12,  6, 11, 14, 13,  8, 20, 29, 10]),\n",
       "   'split0_train_Log_Loss': array([-3.56987258, -2.99921722, -3.39069957, -3.48254874, -3.44831726,\n",
       "          -3.5303482 , -3.48309445, -3.10627159, -1.80694712, -2.89551391,\n",
       "          -3.11721112, -3.39363529, -2.7290675 , -2.79349336, -3.11407323,\n",
       "          -3.47698384, -2.52597541, -3.14342577, -3.24097067, -2.20413486,\n",
       "          -3.3387763 , -3.03575429, -3.28562509, -3.13003953, -3.17704663,\n",
       "          -3.26752302, -2.91016333, -3.33639528, -2.45036299, -3.07174338]),\n",
       "   'split1_train_Log_Loss': array([-3.35500954, -2.97460632, -3.51157563, -3.51252969, -3.4933868 ,\n",
       "          -3.54237472, -3.48006318, -3.15463441, -1.64272673, -2.92869072,\n",
       "          -2.93498479, -3.3083197 , -2.61080032, -2.83674348, -3.11609163,\n",
       "          -3.44293075, -2.55168293, -3.08408542, -3.29357143, -2.21050239,\n",
       "          -3.22377033, -3.02982538, -3.14549414, -3.24314297, -3.27425108,\n",
       "          -3.42391832, -2.73917864, -3.47017576, -2.45707749, -3.25342591]),\n",
       "   'split2_train_Log_Loss': array([-3.53773337, -3.08983581, -3.49915013, -3.42558808, -3.40731437,\n",
       "          -3.39872128, -3.5181506 , -3.07353707, -1.76559021, -3.120204  ,\n",
       "          -3.0219777 , -3.34389409, -2.55190769, -2.79058897, -3.25291289,\n",
       "          -3.50384978, -2.48310325, -3.14016   , -3.2062681 , -2.19462719,\n",
       "          -3.28546309, -3.21028158, -3.16045156, -3.19112542, -3.12392753,\n",
       "          -3.34388847, -2.95471547, -3.50328402, -2.49880537, -3.06904725]),\n",
       "   'mean_train_Log_Loss': array([-3.4875385 , -3.02121978, -3.46714178, -3.4735555 , -3.44967281,\n",
       "          -3.4904814 , -3.49376941, -3.11148103, -1.73842136, -2.98146954,\n",
       "          -3.02472454, -3.34861636, -2.63059184, -2.80694194, -3.16102592,\n",
       "          -3.47458813, -2.52025386, -3.12255706, -3.24693673, -2.20308815,\n",
       "          -3.28266991, -3.09195375, -3.19719026, -3.18810264, -3.19174175,\n",
       "          -3.34510994, -2.86801915, -3.43661836, -2.46874861, -3.13140551]),\n",
       "   'std_train_Log_Loss': array([0.0946262 , 0.04954825, 0.05429031, 0.03605893, 0.03515199,\n",
       "          0.0650697 , 0.01728446, 0.03331215, 0.06974092, 0.09903067,\n",
       "          0.07441894, 0.03498964, 0.07366672, 0.02110621, 0.06497913,\n",
       "          0.02492772, 0.02828834, 0.02723621, 0.03589024, 0.00652315,\n",
       "          0.04699252, 0.08370542, 0.0628303 , 0.04622373, 0.06224282,\n",
       "          0.06385395, 0.09290185, 0.07214586, 0.02142938, 0.08628847])},\n",
       "  {'min_samples_split': 0.26,\n",
       "   'max_features': 0.5,\n",
       "   'max_depth': None,\n",
       "   'criterion': 'entropy',\n",
       "   'class_weight': None},\n",
       "  10,\n",
       "  -3.128507563951377),\n",
       " 'KNeighborsClassifier_V01_PCA_85': ({'mean_fit_time': array([0.04355049, 0.0472068 , 0.04787111, 0.05019959, 0.02360439,\n",
       "          0.02327116, 0.04853646, 0.04421536, 0.02260717, 0.05452148,\n",
       "          0.04654209, 0.04621029, 0.02493413, 0.05086414, 0.04920157,\n",
       "          0.04488023, 0.02393619, 0.05917517, 0.04953448, 0.04720743,\n",
       "          0.057513  , 0.02659575, 0.0511965 , 0.04321766, 0.0458773 ,\n",
       "          0.05618374, 0.04521298, 0.04986668, 0.05053155, 0.04886961]),\n",
       "   'std_fit_time': array([0.00204959, 0.00169466, 0.00141023, 0.00169477, 0.00124515,\n",
       "          0.00286032, 0.00517181, 0.00124403, 0.00094083, 0.00417879,\n",
       "          0.00094044, 0.0012442 , 0.00081459, 0.00354968, 0.00248752,\n",
       "          0.0008142 , 0.00141046, 0.00815709, 0.00124424, 0.00477156,\n",
       "          0.01506678, 0.00463088, 0.00235039, 0.00124362, 0.00293626,\n",
       "          0.00831675, 0.0018811 , 0.00081439, 0.0038483 , 0.00141057]),\n",
       "   'mean_score_time': array([12.03283795, 12.05311608, 11.91216032, 11.94440699,  1.15890249,\n",
       "           1.49300901, 12.3699371 , 10.02753027,  1.3726627 , 12.54746175,\n",
       "          12.11328864, 12.27419217,  1.37332877, 12.14487147, 12.18775702,\n",
       "          10.05412602,  1.2981964 , 12.53150439, 12.23429902,  9.92646774,\n",
       "          12.42013526,  1.08975418, 12.20171913, 10.08637341, 10.31642516,\n",
       "          12.60397768, 10.0913593 , 12.29846072, 12.27452501, 11.95870185]),\n",
       "   'std_score_time': array([0.08351774, 0.12713862, 0.08679657, 0.06230657, 0.05109387,\n",
       "          0.01440638, 0.12280026, 0.04567667, 0.0862722 , 0.29146209,\n",
       "          0.10147809, 0.11529746, 0.02249317, 0.0823803 , 0.02588438,\n",
       "          0.1731808 , 0.04336856, 0.13330983, 0.04948623, 0.07024429,\n",
       "          0.01816004, 0.02339439, 0.10831496, 0.18420442, 0.06188884,\n",
       "          0.16943791, 0.1864247 , 0.26480339, 0.15215935, 0.00752203]),\n",
       "   'param_weights': masked_array(data=['uniform', 'distance', 'distance', 'distance',\n",
       "                      'distance', 'uniform', 'distance', 'distance',\n",
       "                      'distance', 'uniform', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'distance',\n",
       "                      'distance', 'distance', 'uniform', 'distance',\n",
       "                      'distance'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[8, 6, 4, 5, 3, 4, 5, 7, 5, 4, 4, 8, 5, 6, 5, 6, 6, 3,\n",
       "                      8, 4, 7, 3, 3, 8, 5, 7, 8, 4, 6, 3],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['kd_tree', 'kd_tree', 'kd_tree', 'auto', 'brute',\n",
       "                      'brute', 'kd_tree', 'ball_tree', 'brute', 'auto',\n",
       "                      'auto', 'auto', 'brute', 'auto', 'kd_tree',\n",
       "                      'ball_tree', 'brute', 'kd_tree', 'kd_tree',\n",
       "                      'ball_tree', 'auto', 'brute', 'auto', 'ball_tree',\n",
       "                      'ball_tree', 'auto', 'ball_tree', 'kd_tree', 'auto',\n",
       "                      'auto'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'auto'}],\n",
       "   'split0_test_Accuracy': array([0.61491574, 0.66332019, 0.6787379 , 0.66798136, 0.68411617,\n",
       "          0.64109   , 0.66798136, 0.66152743, 0.66798136, 0.64109   ,\n",
       "          0.6787379 , 0.61491574, 0.63607028, 0.62889925, 0.63607028,\n",
       "          0.66332019, 0.62889925, 0.68411617, 0.65328075, 0.6787379 ,\n",
       "          0.63105056, 0.64826103, 0.64826103, 0.61491574, 0.66798136,\n",
       "          0.66152743, 0.65328075, 0.64109   , 0.66332019, 0.68411617]),\n",
       "   'split1_test_Accuracy': array([0.60533911, 0.6547619 , 0.67316017, 0.66269841, 0.67063492,\n",
       "          0.63347763, 0.66269841, 0.64862915, 0.66269841, 0.63347763,\n",
       "          0.67316017, 0.60533911, 0.62373737, 0.61544012, 0.62373737,\n",
       "          0.6547619 , 0.61544012, 0.67063492, 0.64718615, 0.67316017,\n",
       "          0.61544012, 0.62987013, 0.62987013, 0.60533911, 0.66269841,\n",
       "          0.64862915, 0.64718615, 0.63347763, 0.6547619 , 0.67063492]),\n",
       "   'split2_test_Accuracy': array([0.61137269, 0.65374864, 0.66461427, 0.66244114, 0.66714958,\n",
       "          0.63274176, 0.66244114, 0.64831583, 0.66244114, 0.63274176,\n",
       "          0.66461427, 0.61137269, 0.62513582, 0.61535675, 0.62513582,\n",
       "          0.65374864, 0.61535675, 0.66714958, 0.64505614, 0.66461427,\n",
       "          0.61354582, 0.63237957, 0.63237957, 0.61137269, 0.66244114,\n",
       "          0.64831583, 0.64505614, 0.63274176, 0.65374864, 0.66714958]),\n",
       "   'mean_test_Accuracy': array([0.61055035, 0.65729392, 0.67219418, 0.66438356, 0.67399664,\n",
       "          0.63578467, 0.66438356, 0.65284787, 0.66438356, 0.63578467,\n",
       "          0.67219418, 0.61055035, 0.62833453, 0.6199231 , 0.62833453,\n",
       "          0.65729392, 0.6199231 , 0.67399664, 0.64852199, 0.67219418,\n",
       "          0.62004326, 0.63686614, 0.63686614, 0.61055035, 0.66438356,\n",
       "          0.65284787, 0.64852199, 0.63578467, 0.65729392, 0.67399664]),\n",
       "   'std_test_Accuracy': array([0.00395686, 0.0042984 , 0.00580718, 0.0025565 , 0.0073238 ,\n",
       "          0.00377859, 0.0025565 , 0.0061636 , 0.0025565 , 0.00377859,\n",
       "          0.00580718, 0.00395686, 0.00552171, 0.00637295, 0.00552171,\n",
       "          0.0042984 , 0.00637295, 0.0073238 , 0.00348842, 0.00580718,\n",
       "          0.00785299, 0.00815454, 0.00815454, 0.00395686, 0.0025565 ,\n",
       "          0.0061636 , 0.00348842, 0.00377859, 0.0042984 , 0.0073238 ]),\n",
       "   'rank_test_Accuracy': array([28, 11,  4,  7,  1, 20,  7, 14,  7, 20,  4, 28, 23, 26, 23, 11, 26,\n",
       "           1, 16,  4, 25, 18, 18, 28,  7, 14, 16, 20, 11,  1]),\n",
       "   'split0_train_Accuracy': array([0.73359841, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79486716, 1.        , 1.        , 1.        , 0.79486716,\n",
       "          1.        , 0.73359841, 0.77498644, 0.75474426, 0.77498644,\n",
       "          1.        , 0.75474426, 1.        , 1.        , 1.        ,\n",
       "          0.73865896, 0.82016989, 0.82016989, 0.73359841, 1.        ,\n",
       "          1.        , 1.        , 0.79486716, 1.        , 1.        ]),\n",
       "   'split1_train_Accuracy': array([0.73009009, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79801802, 1.        , 1.        , 1.        , 0.79801802,\n",
       "          1.        , 0.73009009, 0.77801802, 0.75711712, 0.77801802,\n",
       "          1.        , 0.75711712, 1.        , 1.        , 1.        ,\n",
       "          0.74072072, 0.82702703, 0.82702703, 0.73009009, 1.        ,\n",
       "          1.        , 1.        , 0.79801802, 1.        , 1.        ]),\n",
       "   'split2_train_Accuracy': array([0.73440029, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.80147455, 1.        , 1.        , 1.        , 0.80147455,\n",
       "          1.        , 0.73440029, 0.78115447, 0.75975544, 0.78115447,\n",
       "          1.        , 0.75975544, 1.        , 1.        , 1.        ,\n",
       "          0.74518971, 0.83006653, 0.83006653, 0.73440029, 1.        ,\n",
       "          1.        , 1.        , 0.80147455, 1.        , 1.        ]),\n",
       "   'mean_train_Accuracy': array([0.73269626, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79811991, 1.        , 1.        , 1.        , 0.79811991,\n",
       "          1.        , 0.73269626, 0.77805298, 0.75720561, 0.77805298,\n",
       "          1.        , 0.75720561, 1.        , 1.        , 1.        ,\n",
       "          0.74152313, 0.82575448, 0.82575448, 0.73269626, 1.        ,\n",
       "          1.        , 1.        , 0.79811991, 1.        , 1.        ]),\n",
       "   'std_train_Accuracy': array([0.00187169, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00269842, 0.        , 0.        , 0.        , 0.00269842,\n",
       "          0.        , 0.00187169, 0.00251821, 0.00204676, 0.00251821,\n",
       "          0.        , 0.00204676, 0.        , 0.        , 0.        ,\n",
       "          0.00272588, 0.00413928, 0.00413928, 0.00187169, 0.        ,\n",
       "          0.        , 0.        , 0.00269842, 0.        , 0.        ]),\n",
       "   'split0_test_F1': array([0.61412104, 0.66263098, 0.67878424, 0.66715822, 0.68531246,\n",
       "          0.64092895, 0.66715822, 0.66062268, 0.66715822, 0.64092895,\n",
       "          0.67878424, 0.61412104, 0.6361381 , 0.62795057, 0.6361381 ,\n",
       "          0.66263098, 0.62795057, 0.68531246, 0.65126769, 0.67878424,\n",
       "          0.63024168, 0.64954609, 0.64954609, 0.61412104, 0.66715822,\n",
       "          0.66062268, 0.65126769, 0.64092895, 0.66263098, 0.68531246]),\n",
       "   'split1_test_F1': array([0.60087427, 0.65150984, 0.67096128, 0.65995412, 0.66885203,\n",
       "          0.6314855 , 0.65995412, 0.64477306, 0.65995412, 0.6314855 ,\n",
       "          0.67096128, 0.60087427, 0.6213133 , 0.61139045, 0.6213133 ,\n",
       "          0.65150984, 0.61139045, 0.66885203, 0.64341266, 0.67096128,\n",
       "          0.61132605, 0.62937539, 0.62937539, 0.60087427, 0.65995412,\n",
       "          0.64477306, 0.64341266, 0.6314855 , 0.65150984, 0.66885203]),\n",
       "   'split2_test_F1': array([0.60837043, 0.65347507, 0.66412119, 0.66221401, 0.66689961,\n",
       "          0.63205278, 0.66221401, 0.64758666, 0.66221401, 0.63205278,\n",
       "          0.66412119, 0.60837043, 0.62501425, 0.61387338, 0.62501425,\n",
       "          0.65347507, 0.61387338, 0.66689961, 0.64352225, 0.66412119,\n",
       "          0.61131936, 0.63344174, 0.63344174, 0.60837043, 0.66221401,\n",
       "          0.64758666, 0.64352225, 0.63205278, 0.65347507, 0.66689961]),\n",
       "   'mean_test_F1': array([0.60780075, 0.65588894, 0.67131369, 0.66311824, 0.67372075,\n",
       "          0.63483854, 0.66311824, 0.65101831, 0.66311824, 0.63483854,\n",
       "          0.67131369, 0.60780075, 0.62750949, 0.6177641 , 0.62750949,\n",
       "          0.65588894, 0.6177641 , 0.67372075, 0.64608152, 0.67131369,\n",
       "          0.61766314, 0.63748442, 0.63748442, 0.60780075, 0.66311824,\n",
       "          0.65101831, 0.64608152, 0.63483854, 0.65588894, 0.67372075]),\n",
       "   'std_test_F1': array([0.00542914, 0.00485328, 0.00599234, 0.00301264, 0.00826824,\n",
       "          0.00433022, 0.00301264, 0.00691469, 0.00301264, 0.00433022,\n",
       "          0.00599234, 0.00542914, 0.00630919, 0.00730265, 0.00630919,\n",
       "          0.00485328, 0.00730265, 0.00826824, 0.00368233, 0.00599234,\n",
       "          0.00893047, 0.0087225 , 0.0087225 , 0.00542914, 0.00301264,\n",
       "          0.00691469, 0.00368233, 0.00433022, 0.00485328, 0.00826824]),\n",
       "   'rank_test_F1': array([28, 11,  4,  7,  1, 20,  7, 14,  7, 20,  4, 28, 23, 25, 23, 11, 25,\n",
       "           1, 16,  4, 27, 18, 18, 28,  7, 14, 16, 20, 11,  1]),\n",
       "   'split0_train_F1': array([0.73191199, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79542844, 1.        , 1.        , 1.        , 0.79542844,\n",
       "          1.        , 0.73191199, 0.77430005, 0.75402211, 0.77430005,\n",
       "          1.        , 0.75402211, 1.        , 1.        , 1.        ,\n",
       "          0.73697363, 0.82079192, 0.82079192, 0.73191199, 1.        ,\n",
       "          1.        , 1.        , 0.79542844, 1.        , 1.        ]),\n",
       "   'split1_train_F1': array([0.72880411, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79810743, 1.        , 1.        , 1.        , 0.79810743,\n",
       "          1.        , 0.72880411, 0.77793992, 0.75625211, 0.77793992,\n",
       "          1.        , 0.75625211, 1.        , 1.        , 1.        ,\n",
       "          0.73962793, 0.82764674, 0.82764674, 0.72880411, 1.        ,\n",
       "          1.        , 1.        , 0.79810743, 1.        , 1.        ]),\n",
       "   'split2_train_F1': array([0.73298751, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.80173174, 1.        , 1.        , 1.        , 0.80173174,\n",
       "          1.        , 0.73298751, 0.78141817, 0.75917036, 0.78141817,\n",
       "          1.        , 0.75917036, 1.        , 1.        , 1.        ,\n",
       "          0.74416032, 0.83016917, 0.83016917, 0.73298751, 1.        ,\n",
       "          1.        , 1.        , 0.80173174, 1.        , 1.        ]),\n",
       "   'mean_train_F1': array([0.73123454, 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.79842254, 1.        , 1.        , 1.        , 0.79842254,\n",
       "          1.        , 0.73123454, 0.77788605, 0.75648153, 0.77788605,\n",
       "          1.        , 0.75648153, 1.        , 1.        , 1.        ,\n",
       "          0.74025396, 0.82620261, 0.82620261, 0.73123454, 1.        ,\n",
       "          1.        , 1.        , 0.79842254, 1.        , 1.        ]),\n",
       "   'std_train_F1': array([0.00177377, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00258294, 0.        , 0.        , 0.        , 0.00258294,\n",
       "          0.        , 0.00177377, 0.00290621, 0.00210802, 0.00290621,\n",
       "          0.        , 0.00210802, 0.        , 0.        , 0.        ,\n",
       "          0.00296716, 0.0039621 , 0.0039621 , 0.00177377, 0.        ,\n",
       "          0.        , 0.        , 0.00258294, 0.        , 0.        ]),\n",
       "   'split0_test_Log_Loss': array([-4.09332426, -4.64714388, -5.53893269, -5.00818584, -6.48016043,\n",
       "          -5.56045015, -5.00818584, -4.37807917, -5.00818584, -5.56045015,\n",
       "          -5.53893269, -4.09332426, -5.0339109 , -4.67626938, -5.0339109 ,\n",
       "          -4.64714388, -4.67626938, -6.48016043, -4.0585732 , -5.53893269,\n",
       "          -4.41054068, -6.49760785, -6.49760785, -4.09332426, -5.00818584,\n",
       "          -4.37807917, -4.0585732 , -5.56045015, -4.64714388, -6.48016043]),\n",
       "   'split1_test_Log_Loss': array([-4.46539618, -4.99803964, -6.18516563, -5.63430197, -7.05234078,\n",
       "          -6.20629245, -5.63430197, -4.73420003, -5.63430197, -6.20629245,\n",
       "          -6.18516563, -4.46539618, -5.65913017, -5.02584073, -5.65913017,\n",
       "          -4.99803964, -5.02584073, -7.05234078, -4.43265296, -6.18516563,\n",
       "          -4.76458795, -7.06953637, -7.06953637, -4.46539618, -5.63430197,\n",
       "          -4.73420003, -4.43265296, -6.20629245, -4.99803964, -7.05234078]),\n",
       "   'split2_test_Log_Loss': array([-4.56627886, -5.20268062, -6.02489175, -5.64150678, -6.72301751,\n",
       "          -6.04684799, -5.64150678, -4.86851982, -5.64150678, -6.04684799,\n",
       "          -6.02489175, -4.56627886, -5.66786447, -5.23232351, -5.66786447,\n",
       "          -5.20268062, -5.23232351, -6.72301751, -4.5317079 , -6.02489175,\n",
       "          -4.90060593, -6.73944966, -6.73944966, -4.56627886, -5.64150678,\n",
       "          -4.86851982, -4.5317079 , -6.04684799, -5.20268062, -6.72301751]),\n",
       "   'mean_test_Log_Loss': array([-4.37417153, -4.9483359 , -5.91541559, -5.4268584 , -6.75132269,\n",
       "          -5.9369485 , -5.4268584 , -4.65941462, -5.4268584 , -5.9369485 ,\n",
       "          -5.91541559, -4.37417153, -5.45249461, -4.9771919 , -5.45249461,\n",
       "          -4.9483359 , -4.9771919 , -6.75132269, -4.34014902, -5.91541559,\n",
       "          -4.69106089, -6.76834939, -6.76834939, -4.37417153, -5.4268584 ,\n",
       "          -4.65941462, -4.34014902, -5.9369485 , -4.9483359 , -6.75132269]),\n",
       "   'std_test_Log_Loss': array([0.20359265, 0.22953861, 0.27516498, 0.29726216, 0.23471299,\n",
       "          0.27509553, 0.29726216, 0.20711231, 0.29726216, 0.27509553,\n",
       "          0.27516498, 0.20359265, 0.29720589, 0.22963458, 0.29720589,\n",
       "          0.22953861, 0.22963458, 0.23471299, 0.20395041, 0.27516498,\n",
       "          0.20673879, 0.23464642, 0.23464642, 0.20359265, 0.29726216,\n",
       "          0.20711231, 0.20395041, 0.27509553, 0.22953861, 0.23471299]),\n",
       "   'rank_test_Log_Loss': array([ 3,  9, 20, 14, 26, 23, 14,  6, 14, 23, 20,  3, 18, 12, 18,  9, 12,\n",
       "          26,  1, 20,  8, 29, 29,  3, 14,  6,  1, 23,  9, 26]),\n",
       "   'split0_train_Log_Loss': array([-7.78087296e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -8.39988830e-09, -4.88328014e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -1.94072378e-08, -4.88328014e-01, -3.77251697e-14, -7.78087296e-01,\n",
       "          -5.78338796e-01, -6.56188543e-01, -5.78338796e-01, -3.77251697e-14,\n",
       "          -6.56188543e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -7.21728018e-01, -3.78263989e-01, -3.78263989e-01, -7.78087296e-01,\n",
       "          -3.77251697e-14, -3.77251697e-14, -3.77251697e-14, -4.88328014e-01,\n",
       "          -3.77251697e-14, -3.77251697e-14]),\n",
       "   'split1_train_Log_Loss': array([-7.64536985e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -8.58431797e-09, -4.74206373e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -1.95183177e-08, -4.74206373e-01, -3.77252183e-14, -7.64536985e-01,\n",
       "          -5.65740474e-01, -6.42217835e-01, -5.65740474e-01, -3.77252183e-14,\n",
       "          -6.42217835e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -7.06669659e-01, -3.64007710e-01, -3.64007710e-01, -7.64536985e-01,\n",
       "          -3.77252183e-14, -3.77252183e-14, -3.77252183e-14, -4.74206373e-01,\n",
       "          -3.77252183e-14, -3.77252183e-14]),\n",
       "   'split2_train_Log_Loss': array([-7.69872149e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -8.44320037e-09, -4.77856587e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -1.91210954e-08, -4.77856587e-01, -3.77251228e-14, -7.69872149e-01,\n",
       "          -5.65015103e-01, -6.41181140e-01, -5.65015103e-01, -3.77251228e-14,\n",
       "          -6.41181140e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -7.09858130e-01, -3.67043692e-01, -3.67043692e-01, -7.69872149e-01,\n",
       "          -3.77251228e-14, -3.77251228e-14, -3.77251228e-14, -4.77856587e-01,\n",
       "          -3.77251228e-14, -3.77251228e-14]),\n",
       "   'mean_train_Log_Loss': array([-7.70832143e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -8.47580221e-09, -4.80130325e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -1.93488837e-08, -4.80130325e-01, -3.77251703e-14, -7.70832143e-01,\n",
       "          -5.69698124e-01, -6.46529173e-01, -5.69698124e-01, -3.77251703e-14,\n",
       "          -6.46529173e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -7.12751936e-01, -3.69771797e-01, -3.69771797e-01, -7.70832143e-01,\n",
       "          -3.77251703e-14, -3.77251703e-14, -3.77251703e-14, -4.80130325e-01,\n",
       "          -3.77251703e-14, -3.77251703e-14]),\n",
       "   'std_train_Log_Loss': array([5.57338453e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          7.87431955e-11, 5.98512596e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          1.67332581e-10, 5.98512596e-03, 3.89952081e-20, 5.57338453e-03,\n",
       "          6.11704979e-03, 6.84330641e-03, 6.11704979e-03, 3.89952081e-20,\n",
       "          6.84330641e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          6.47915266e-03, 6.13146471e-03, 6.13146471e-03, 5.57338453e-03,\n",
       "          3.89952081e-20, 3.89952081e-20, 3.89952081e-20, 5.98512596e-03,\n",
       "          3.89952081e-20, 3.89952081e-20])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "  18,\n",
       "  -4.340149023442153),\n",
       " 'MLPClassifier_V01_PCA_85': ({'mean_fit_time': array([15.24491835, 22.86155891,  9.25492883,  7.07741626,  5.46140218,\n",
       "          14.94438775, 13.60663072,  4.60668667, 18.95267439, 19.95865202,\n",
       "           4.84272321, 26.34957012,  2.25264533, 10.30877797, 16.39484501,\n",
       "          24.21128488,  9.12993002, 13.19007723,  3.99266076, 22.68367092,\n",
       "           3.63561575, 15.50522208, 21.79540881,  2.76992997, 15.0740424 ,\n",
       "           3.29685473,  3.49233301, 14.28249145, 27.04138716,  8.29083904]),\n",
       "   'std_fit_time': array([0.25380918, 4.32931434, 0.12776312, 0.14161088, 0.11865612,\n",
       "          1.47161839, 1.31695392, 0.33656914, 0.29141575, 1.30483209,\n",
       "          0.62999552, 0.16370212, 0.21594096, 0.14295996, 0.08630796,\n",
       "          2.14247938, 0.41473907, 0.08888566, 0.14343754, 0.31256425,\n",
       "          0.06360261, 0.26668118, 3.76617939, 0.17597702, 0.38257997,\n",
       "          0.20159411, 0.27407718, 0.39442879, 0.24944025, 0.27857057]),\n",
       "   'mean_score_time': array([0.05086406, 0.05651593, 0.04754019, 0.07313704, 0.06981365,\n",
       "          0.06183457, 0.04355049, 0.05518619, 0.0561835 , 0.06515892,\n",
       "          0.0585103 , 0.07114259, 0.05851078, 0.04055913, 0.05319103,\n",
       "          0.06183545, 0.05019967, 0.07180866, 0.06848327, 0.0598402 ,\n",
       "          0.08311192, 0.05917517, 0.05718056, 0.06249897, 0.06216709,\n",
       "          0.07147598, 0.0704778 , 0.05119562, 0.06682102, 0.04787151]),\n",
       "   'std_score_time': array([1.41034595e-03, 5.42257155e-03, 1.24432506e-03, 5.23442411e-03,\n",
       "          6.66553838e-03, 3.25718423e-03, 4.70021816e-04, 1.24415524e-03,\n",
       "          2.61843333e-03, 1.24424023e-03, 1.24349689e-03, 1.69493664e-03,\n",
       "          4.70358829e-04, 1.24402774e-03, 4.69292815e-04, 5.70039222e-03,\n",
       "          2.04940865e-03, 5.94720425e-07, 2.86026810e-03, 8.13713168e-04,\n",
       "          1.24447456e-03, 1.24415524e-03, 2.04952471e-03, 4.90869881e-03,\n",
       "          4.77120105e-03, 2.34993970e-03, 1.69503008e-03, 1.88109815e-03,\n",
       "          6.36080267e-03, 5.33905807e-03]),\n",
       "   'param_solver': masked_array(data=['sgd', 'adam', 'lbfgs', 'lbfgs', 'lbfgs', 'adam',\n",
       "                      'adam', 'lbfgs', 'sgd', 'adam', 'adam', 'sgd', 'sgd',\n",
       "                      'sgd', 'sgd', 'sgd', 'lbfgs', 'adam', 'lbfgs', 'sgd',\n",
       "                      'sgd', 'adam', 'sgd', 'lbfgs', 'lbfgs', 'sgd', 'sgd',\n",
       "                      'adam', 'sgd', 'lbfgs'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(100, 100, 50), (100, 100), (100, 100), (200, 50, 50),\n",
       "                      (200, 50, 50, 50), (100, 100, 50), (100,), (100, 100),\n",
       "                      (200, 50), (200, 50, 50, 50), (200, 50, 50, 50),\n",
       "                      (200, 50, 50, 50), (100, 100), (100,), (100, 100),\n",
       "                      (200, 50, 50, 50), (100, 100), (200, 50, 50, 50),\n",
       "                      (200, 50, 50, 50), (200, 50, 50), (200, 50, 50, 50),\n",
       "                      (200, 50, 50), (100, 100), (100, 100, 50),\n",
       "                      (200, 50, 50, 50), (100, 100, 50), (200, 50, 50),\n",
       "                      (100, 100), (200, 50, 50, 50), (100, 100)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0239, 0.0456, 0.03320000000000001,\n",
       "                      0.0013000000000000002, 0.03200000000000001, 0.0268,\n",
       "                      0.0437, 0.0374, 0.037700000000000004,\n",
       "                      0.036500000000000005, 0.0017000000000000001, 0.0257,\n",
       "                      0.0033, 0.041800000000000004, 0.007300000000000001,\n",
       "                      0.0258, 0.0152, 0.0051, 0.040600000000000004, 0.0189,\n",
       "                      0.024300000000000002, 0.0071, 0.047400000000000005,\n",
       "                      0.026600000000000002, 0.033400000000000006,\n",
       "                      0.027800000000000002, 0.036000000000000004, 0.0183,\n",
       "                      0.0058000000000000005, 0.042300000000000004],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['identity', 'tanh', 'identity', 'relu', 'tanh', 'relu',\n",
       "                      'relu', 'relu', 'tanh', 'tanh', 'identity', 'relu',\n",
       "                      'logistic', 'tanh', 'relu', 'identity', 'identity',\n",
       "                      'relu', 'tanh', 'tanh', 'logistic', 'tanh', 'relu',\n",
       "                      'tanh', 'identity', 'logistic', 'logistic', 'tanh',\n",
       "                      'relu', 'identity'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0239,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0456,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.03320000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0013000000000000002,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.03200000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0268,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0437,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0374,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.037700000000000004,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.036500000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0017000000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0257,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0033,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.041800000000000004,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.007300000000000001,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0258,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0152,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0051,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.040600000000000004,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0189,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.024300000000000002,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0071,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.047400000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.026600000000000002,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.033400000000000006,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.027800000000000002,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.036000000000000004,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0183,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0058000000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.042300000000000004,\n",
       "     'activation': 'identity'}],\n",
       "   'split0_test_Accuracy': array([0.64503406, 0.72929365, 0.65184654, 0.69415561, 0.62495518,\n",
       "          0.69738257, 0.71136608, 0.70742202, 0.63607028, 0.70993188,\n",
       "          0.65830047, 0.64073144, 0.05593403, 0.61563284, 0.64539261,\n",
       "          0.65399785, 0.65865902, 0.68770169, 0.63965579, 0.64216565,\n",
       "          0.05593403, 0.72068842, 0.63320186, 0.64933668, 0.65220509,\n",
       "          0.05593403, 0.05593403, 0.72104697, 0.63033345, 0.65650771]),\n",
       "   'split1_test_Accuracy': array([0.65367965, 0.73629149, 0.65800866, 0.69588745, 0.64574315,\n",
       "          0.70995671, 0.73845599, 0.6998557 , 0.62878788, 0.6533189 ,\n",
       "          0.64862915, 0.62373737, 0.05591631, 0.62193362, 0.63311688,\n",
       "          0.64718615, 0.65692641, 0.69516595, 0.63383838, 0.61399711,\n",
       "          0.05591631, 0.72546898, 0.65151515, 0.6518759 , 0.65800866,\n",
       "          0.05591631, 0.05591631, 0.73881674, 0.63636364, 0.65836941]),\n",
       "   'split2_test_Accuracy': array([0.65555958, 0.7457443 , 0.66244114, 0.68525896, 0.62441145,\n",
       "          0.68562115, 0.7250996 , 0.70047084, 0.62260051, 0.67040927,\n",
       "          0.6548352 , 0.65266208, 0.05613908, 0.61209707, 0.64433176,\n",
       "          0.64831583, 0.66244114, 0.68960522, 0.62694676, 0.62948207,\n",
       "          0.05613908, 0.71459616, 0.63817457, 0.64940239, 0.66642521,\n",
       "          0.05613908, 0.05613908, 0.73668961, 0.64433176, 0.66352771]),\n",
       "   'mean_test_Accuracy': array([0.65140591, 0.73708243, 0.65741408, 0.69178082, 0.63169911,\n",
       "          0.69766883, 0.72494593, 0.70259553, 0.62917568, 0.67796203,\n",
       "          0.65392934, 0.63902908, 0.05599615, 0.61655852, 0.64095169,\n",
       "          0.64984379, 0.6593367 , 0.69081951, 0.63350156, 0.62857486,\n",
       "          0.05599615, 0.72025955, 0.64095169, 0.65020428, 0.65885604,\n",
       "          0.05599615, 0.05599615, 0.73215573, 0.6369863 , 0.65945686]),\n",
       "   'std_test_Accuracy': array([0.00458833, 0.00674029, 0.00434631, 0.00464965, 0.00992775,\n",
       "          0.00992357, 0.01107284, 0.00343586, 0.00550676, 0.02374321,\n",
       "          0.00400411, 0.01185424, 0.00010097, 0.00406381, 0.00555397,\n",
       "          0.00298503, 0.00229924, 0.00316854, 0.00519477, 0.0115309 ,\n",
       "          0.00010097, 0.00444324, 0.00773665, 0.00118168, 0.00583711,\n",
       "          0.00010097, 0.00010097, 0.00793449, 0.00573266, 0.00296762]),\n",
       "   'rank_test_Accuracy': array([15,  1, 13,  7, 23,  6,  3,  5, 24,  9, 14, 20, 27, 26, 18, 17, 11,\n",
       "           8, 22, 25, 27,  4, 18, 16, 12, 27, 27,  2, 21, 10]),\n",
       "   'split0_train_Accuracy': array([0.75944334, 1.        , 0.8512561 , 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.73576721, 0.99078258,\n",
       "          0.78058919, 0.87764323, 0.05602747, 0.70395807, 0.78474607,\n",
       "          0.76721489, 0.85089463, 1.        , 1.        , 0.729803  ,\n",
       "          0.05602747, 1.        , 0.77625158, 1.        , 0.838424  ,\n",
       "          0.05602747, 0.05602747, 1.        , 0.88324598, 0.8523405 ]),\n",
       "   'split1_train_Accuracy': array([0.75531532, 1.        , 0.85567568, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.7363964 , 0.91189189,\n",
       "          0.76324324, 0.88666667, 0.05603604, 0.70648649, 0.77837838,\n",
       "          0.75855856, 0.85297297, 1.        , 1.        , 0.73153153,\n",
       "          0.05603604, 1.        , 0.78882883, 1.        , 0.83351351,\n",
       "          0.05603604, 0.05603604, 1.        , 0.88594595, 0.85369369]),\n",
       "   'split2_train_Accuracy': array([0.75831685, 1.        , 0.85146556, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.72954505, 0.92807049,\n",
       "          0.77162381, 0.88401367, 0.05592519, 0.70904514, 0.7798957 ,\n",
       "          0.76784751, 0.85272433, 1.        , 1.        , 0.72954505,\n",
       "          0.05592519, 1.        , 0.7874483 , 1.        , 0.83636037,\n",
       "          0.05592519, 0.05592519, 1.        , 0.87394354, 0.85254451]),\n",
       "   'mean_train_Accuracy': array([0.75769183, 1.        , 0.85279911, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.73390289, 0.94358165,\n",
       "          0.77181875, 0.88277452, 0.05599623, 0.70649656, 0.78100672,\n",
       "          0.76454032, 0.85219731, 1.        , 1.        , 0.73029319,\n",
       "          0.05599623, 1.        , 0.78417624, 1.        , 0.83609929,\n",
       "          0.05599623, 0.05599623, 1.        , 0.88104515, 0.85285957]),\n",
       "   'std_train_Accuracy': array([1.74224554e-03, 0.00000000e+00, 2.03583368e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.09214527e-03, 3.40233467e-02, 7.08279543e-03, 3.78657327e-03,\n",
       "          5.03546264e-05, 2.07679822e-03, 2.71571178e-03, 4.23762157e-03,\n",
       "          9.26709722e-04, 0.00000000e+00, 0.00000000e+00, 8.81947744e-04,\n",
       "          5.03546264e-05, 0.00000000e+00, 5.63184923e-03, 0.00000000e+00,\n",
       "          2.01318028e-03, 5.03546264e-05, 5.03546264e-05, 0.00000000e+00,\n",
       "          5.14115352e-03, 5.95667287e-04]),\n",
       "   'split0_test_F1': array([0.64190246, 0.72699607, 0.6490722 , 0.69499956, 0.62518265,\n",
       "          0.69757795, 0.71168528, 0.70802367, 0.62670375, 0.70864666,\n",
       "          0.65544133, 0.6375787 , 0.00592578, 0.60656982, 0.63991772,\n",
       "          0.65137903, 0.65665801, 0.68678403, 0.64044811, 0.63067958,\n",
       "          0.00592578, 0.71894014, 0.62875356, 0.64830861, 0.65067397,\n",
       "          0.00592578, 0.00592578, 0.71840167, 0.62885673, 0.65388357]),\n",
       "   'split1_test_F1': array([0.65025431, 0.73570355, 0.65595213, 0.69625929, 0.64566396,\n",
       "          0.7098237 , 0.73742887, 0.6998136 , 0.61728424, 0.64949228,\n",
       "          0.64461562, 0.62200219, 0.00592212, 0.61156952, 0.62722082,\n",
       "          0.64528978, 0.65523574, 0.69517816, 0.63345926, 0.60133044,\n",
       "          0.00592212, 0.72556538, 0.64660406, 0.65059473, 0.65593326,\n",
       "          0.00592212, 0.00592212, 0.73891508, 0.63427529, 0.65702801]),\n",
       "   'split2_test_F1': array([0.65179938, 0.74474425, 0.66105049, 0.68508695, 0.62645568,\n",
       "          0.68511301, 0.72469835, 0.70119964, 0.61130543, 0.66895244,\n",
       "          0.65204219, 0.64939238, 0.00596815, 0.60270148, 0.63901763,\n",
       "          0.64531631, 0.66109444, 0.68909149, 0.62708938, 0.61735589,\n",
       "          0.00596815, 0.71311308, 0.63394639, 0.64935505, 0.66479587,\n",
       "          0.00596815, 0.00596815, 0.73764691, 0.64244898, 0.66223352]),\n",
       "   'mean_test_F1': array([0.64796792, 0.7357848 , 0.65533791, 0.69213045, 0.63242718,\n",
       "          0.69752141, 0.72457765, 0.70302494, 0.61845746, 0.67577335,\n",
       "          0.65070763, 0.63630971, 0.00593862, 0.60695178, 0.63538985,\n",
       "          0.64733931, 0.65765614, 0.6903456 , 0.63368813, 0.61648317,\n",
       "          0.00593862, 0.71921371, 0.63642227, 0.64941728, 0.65711104,\n",
       "          0.00593862, 0.00593862, 0.73161956, 0.63517114, 0.65770123]),\n",
       "   'std_test_F1': array([4.35215730e-03, 7.24710484e-03, 4.91016322e-03, 4.98964792e-03,\n",
       "          9.36917970e-03, 1.00745095e-02, 1.05223803e-02, 3.59368796e-03,\n",
       "          6.34182539e-03, 2.46509087e-02, 4.52355401e-03, 1.12031378e-02,\n",
       "          2.08604460e-05, 3.62561410e-03, 5.78493999e-03, 2.86813019e-03,\n",
       "          2.49147028e-03, 3.54285924e-03, 5.45698914e-03, 1.20114583e-02,\n",
       "          2.08604460e-05, 5.08045884e-03, 7.50161004e-03, 9.35423573e-04,\n",
       "          5.82597488e-03, 2.08604460e-05, 2.08604460e-05, 9.39862478e-03,\n",
       "          5.58593636e-03, 3.44246528e-03]),\n",
       "   'rank_test_F1': array([16,  1, 13,  7, 23,  6,  3,  5, 24,  9, 14, 19, 27, 26, 20, 17, 11,\n",
       "           8, 22, 25, 27,  4, 18, 15, 12, 27, 27,  2, 21, 10]),\n",
       "   'split0_train_F1': array([0.75622241, 1.        , 0.85055814, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.72805552, 0.99077969,\n",
       "          0.77917998, 0.87588936, 0.00594507, 0.69687633, 0.78165744,\n",
       "          0.76456647, 0.85031112, 1.        , 1.        , 0.72016211,\n",
       "          0.00594507, 1.        , 0.77322801, 1.        , 0.83710914,\n",
       "          0.00594507, 0.00594507, 1.        , 0.88154535, 0.85139313]),\n",
       "   'split1_train_F1': array([0.75137329, 1.        , 0.85481812, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.72883035, 0.91174589,\n",
       "          0.75816026, 0.8853976 , 0.00594684, 0.69945849, 0.77491761,\n",
       "          0.75516328, 0.85207193, 1.        , 1.        , 0.72232826,\n",
       "          0.00594684, 1.        , 0.78517399, 1.        , 0.8325379 ,\n",
       "          0.00594684, 0.00594684, 1.        , 0.88461867, 0.85309573]),\n",
       "   'split2_train_F1': array([0.75518494, 1.        , 0.85069976, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.72187783, 0.92807356,\n",
       "          0.76935656, 0.88256328, 0.00592396, 0.70310546, 0.77659776,\n",
       "          0.76519466, 0.85205132, 1.        , 1.        , 0.72092622,\n",
       "          0.00592396, 1.        , 0.78445609, 1.        , 0.83535395,\n",
       "          0.00592396, 0.00592396, 1.        , 0.87318412, 0.85184777]),\n",
       "   'mean_train_F1': array([0.75426021, 1.        , 0.85202534, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.72625457, 0.94353305,\n",
       "          0.76889893, 0.88128341, 0.00593862, 0.69981343, 0.77772427,\n",
       "          0.76164147, 0.85147812, 1.        , 1.        , 0.72113886,\n",
       "          0.00593862, 1.        , 0.7809527 , 1.        , 0.83500033,\n",
       "          0.00593862, 0.00593862, 1.        , 0.87978271, 0.85211221]),\n",
       "   'std_train_F1': array([2.08483907e-03, 0.00000000e+00, 1.97563707e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.11094611e-03, 3.40669137e-02, 8.58736279e-03, 3.98582528e-03,\n",
       "          1.03944448e-05, 2.55538512e-03, 2.86450708e-03, 4.58794389e-03,\n",
       "          8.25239820e-04, 0.00000000e+00, 0.00000000e+00, 8.97020902e-04,\n",
       "          1.03944448e-05, 0.00000000e+00, 5.47003423e-03, 0.00000000e+00,\n",
       "          1.88287966e-03, 1.03944448e-05, 1.03944448e-05, 0.00000000e+00,\n",
       "          4.83165697e-03, 7.19794681e-04]),\n",
       "   'split0_test_Log_Loss': array([-1.30530613, -1.09944715, -2.11735707, -3.9791792 , -2.77207198,\n",
       "          -2.05322163, -1.32926339, -3.08966192, -1.29604344, -1.26074366,\n",
       "          -1.31488191, -1.41100717, -3.60890088, -1.35187807, -1.22312502,\n",
       "          -1.30171738, -2.10635249, -2.3007836 , -2.62261613, -1.31537311,\n",
       "          -3.61210459, -1.18553435, -1.28361098, -2.30429745, -1.86717687,\n",
       "          -3.61207435, -3.61202684, -1.20716377, -1.42738481, -2.10258052]),\n",
       "   'split1_test_Log_Loss': array([-1.29987468, -1.0539649 , -2.15224557, -4.1417447 , -2.64174374,\n",
       "          -1.90791671, -1.24803256, -3.04781581, -1.31026741, -1.53431184,\n",
       "          -1.32726846, -1.45122437, -3.60925906, -1.36132024, -1.29733453,\n",
       "          -1.32047442, -2.13412072, -2.13733988, -2.61953723, -1.36378629,\n",
       "          -3.61198197, -1.26156251, -1.24330287, -2.19317568, -1.91697173,\n",
       "          -3.61205262, -3.6119437 , -1.17230369, -1.45138886, -2.16155488]),\n",
       "   'split2_test_Log_Loss': array([-1.25160371, -1.04542425, -1.92111115, -4.29572179, -2.73202446,\n",
       "          -1.99113906, -1.26599218, -3.17508004, -1.32720005, -1.48476212,\n",
       "          -1.28670862, -1.32387364, -3.61113693, -1.36742944, -1.24429923,\n",
       "          -1.2809788 , -1.8771528 , -2.08453081, -2.65130659, -1.32116656,\n",
       "          -3.61169775, -1.19400561, -1.21131738, -2.2853017 , -1.77837613,\n",
       "          -3.61179565, -3.61170536, -1.16907622, -1.36547627, -1.88362043]),\n",
       "   'mean_test_Log_Loss': array([-1.28568004, -1.06637409, -2.06386944, -4.13834835, -2.71537394,\n",
       "          -1.98422437, -1.2812144 , -3.10406254, -1.31111821, -1.42619018,\n",
       "          -1.30966069, -1.39549484, -3.60976204, -1.36018269, -1.25486868,\n",
       "          -1.30108475, -2.03956003, -2.17459519, -2.63110924, -1.3334213 ,\n",
       "          -3.61192877, -1.21366932, -1.2461997 , -2.26098132, -1.85430166,\n",
       "          -3.61197465, -3.61189249, -1.18291577, -1.41484092, -2.04957981]),\n",
       "   'std_test_Log_Loss': array([2.41133677e-02, 2.37378592e-02, 1.01596467e-01, 1.29271904e-01,\n",
       "          5.45450539e-02, 5.95891874e-02, 3.48905921e-02, 5.28827727e-02,\n",
       "          1.27359627e-02, 1.19187561e-01, 1.69464595e-02, 5.30755201e-02,\n",
       "          9.79775231e-04, 6.40057214e-03, 3.12321768e-02, 1.61084402e-02,\n",
       "          1.14997296e-01, 9.21414759e-02, 1.42870456e-02, 2.15896700e-02,\n",
       "          1.70324018e-04, 3.40235729e-02, 2.95895900e-02, 4.85435638e-02,\n",
       "          5.72393906e-02, 1.26439806e-04, 1.36164735e-04, 1.72657214e-02,\n",
       "          3.61406422e-02, 1.19397210e-01]),\n",
       "   'rank_test_Log_Loss': array([ 7,  1, 20, 30, 24, 17,  6, 25, 10, 15,  9, 13, 26, 12,  5,  8, 18,\n",
       "          21, 23, 11, 28,  3,  4, 22, 16, 29, 27,  2, 14, 19]),\n",
       "   'split0_train_Log_Loss': array([-8.09924683e-01, -1.99634904e-02, -4.86876501e-01, -1.29961087e-04,\n",
       "          -1.70004970e-03, -4.77073359e-03, -3.44205059e-02, -3.27966704e-04,\n",
       "          -1.03910453e+00, -5.93917365e-02, -7.22896744e-01, -5.01432999e-01,\n",
       "          -3.60790657e+00, -1.11550403e+00, -7.79430103e-01, -7.80392359e-01,\n",
       "          -4.87115629e-01, -2.18359313e-03, -2.16340519e-03, -1.03739745e+00,\n",
       "          -3.61191912e+00, -5.54662494e-03, -8.05671891e-01, -2.40504461e-03,\n",
       "          -5.37023923e-01, -3.61189318e+00, -3.61182195e+00, -1.09215253e-02,\n",
       "          -4.50839502e-01, -4.86849205e-01]),\n",
       "   'split1_train_Log_Loss': array([-8.03170989e-01, -1.99758988e-02, -4.73092695e-01, -9.50903437e-05,\n",
       "          -1.63755528e-03, -4.27012476e-03, -3.31455205e-02, -3.34571991e-04,\n",
       "          -1.02611249e+00, -2.84673194e-01, -7.72874430e-01, -4.58148895e-01,\n",
       "          -3.60908819e+00, -1.10317671e+00, -7.97154922e-01, -7.87371229e-01,\n",
       "          -4.72162659e-01, -2.30757540e-03, -2.24977403e-03, -1.05342867e+00,\n",
       "          -3.61184587e+00, -5.63951544e-03, -7.69700442e-01, -2.14450897e-03,\n",
       "          -5.20448914e-01, -3.61190884e+00, -3.61176213e+00, -1.09565614e-02,\n",
       "          -4.24023693e-01, -4.71755659e-01]),\n",
       "   'split2_train_Log_Loss': array([-8.05675177e-01, -2.00061030e-02, -4.83415814e-01, -7.19838545e-05,\n",
       "          -2.81505237e-03, -5.25263244e-03, -3.37762009e-02, -3.84311792e-04,\n",
       "          -1.04913211e+00, -2.35974058e-01, -7.43202127e-01, -4.41533531e-01,\n",
       "          -3.61169694e+00, -1.10084672e+00, -8.11268435e-01, -7.83360755e-01,\n",
       "          -4.87213370e-01, -2.36463109e-03, -1.94694487e-03, -1.03915199e+00,\n",
       "          -3.61199743e+00, -5.52902737e-03, -7.77388499e-01, -2.19888634e-03,\n",
       "          -5.28933748e-01, -3.61210794e+00, -3.61199793e+00, -1.05696706e-02,\n",
       "          -4.71143348e-01, -4.83854632e-01]),\n",
       "   'mean_train_Log_Loss': array([-8.06256950e-01, -1.99818307e-02, -4.81128337e-01, -9.90117617e-05,\n",
       "          -2.05088578e-03, -4.76449693e-03, -3.37807424e-02, -3.48950162e-04,\n",
       "          -1.03811638e+00, -1.93346330e-01, -7.46324433e-01, -4.67038475e-01,\n",
       "          -3.60956390e+00, -1.10650915e+00, -7.95951154e-01, -7.83708114e-01,\n",
       "          -4.82163886e-01, -2.28526654e-03, -2.12004136e-03, -1.04332604e+00,\n",
       "          -3.61192081e+00, -5.57172258e-03, -7.84253611e-01, -2.24947997e-03,\n",
       "          -5.28802195e-01, -3.61196999e+00, -3.61186067e+00, -1.08159191e-02,\n",
       "          -4.48668847e-01, -4.80819832e-01]),\n",
       "   'std_train_Log_Loss': array([2.78770430e-03, 1.78950528e-05, 5.85506860e-03, 2.38309744e-05,\n",
       "          5.40949358e-04, 4.01131326e-04, 5.20520503e-04, 2.51494349e-05,\n",
       "          9.42366366e-03, 9.67842145e-02, 2.05224083e-02, 2.52488292e-02,\n",
       "          1.58354827e-03, 6.43107162e-03, 1.30257856e-02, 2.85967930e-03,\n",
       "          7.07204791e-03, 7.55731422e-05, 1.27375275e-04, 7.17946194e-03,\n",
       "          6.18865058e-05, 4.84721389e-05, 1.54668159e-02, 1.12218509e-04,\n",
       "          6.76735863e-03, 9.77554469e-05, 1.00086051e-04, 1.74710455e-04,\n",
       "          1.92976556e-02, 6.52489044e-03])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (100, 100),\n",
       "   'alpha': 0.0456,\n",
       "   'activation': 'tanh'},\n",
       "  1,\n",
       "  -1.0663740914150075),\n",
       " 'LogisticRegression_V01_PCA_80': ({'mean_fit_time': array([ 1.89260761,  4.31812525,  2.2599597 ,  1.32811522,  4.94777441,\n",
       "           3.54585656,  0.81415812,  2.3706634 ,  4.13228718,  3.36567156,\n",
       "           2.3623515 ,  3.82776745,  2.19280624,  3.42318408,  3.61300866,\n",
       "           3.8344171 ,  6.36133011,  0.83044624,  3.46739864, 20.06902401,\n",
       "           0.92053978,  3.11700169,  2.55384096,  1.94879174,  1.76228905,\n",
       "           2.12033224,  2.09938828,  0.99400846,  7.59570614,  0.73071337]),\n",
       "   'std_fit_time': array([0.18698095, 0.27744546, 0.04739878, 0.01937914, 0.16472786,\n",
       "          0.08098536, 0.00658188, 0.05719332, 0.06793733, 0.18286281,\n",
       "          0.02552281, 0.10084733, 0.11192848, 0.19134927, 0.18031247,\n",
       "          0.15375419, 0.21829563, 0.01219698, 0.05776737, 0.09859912,\n",
       "          0.02699596, 0.07336273, 0.16034044, 0.069326  , 0.01131293,\n",
       "          0.10097467, 0.19340365, 0.05059542, 0.16145511, 0.01951554]),\n",
       "   'mean_score_time': array([0.0528578 , 0.03723383, 0.0339094 , 0.06183545, 0.03124968,\n",
       "          0.0339094 , 0.03158228, 0.03224675, 0.03091733, 0.03390837,\n",
       "          0.03091788, 0.03091701, 0.03324453, 0.03324533, 0.03257998,\n",
       "          0.03124913, 0.03025238, 0.03091764, 0.03058505, 0.03191463,\n",
       "          0.06050444, 0.02958783, 0.03457395, 0.04055882, 0.03523938,\n",
       "          0.03324382, 0.03224651, 0.04089053, 0.03157298, 0.03690171]),\n",
       "   'std_score_time': array([1.49263145e-02, 3.08293512e-03, 4.22997011e-03, 3.73976975e-02,\n",
       "          4.70752291e-04, 2.15438821e-03, 4.70302644e-04, 1.24434638e-03,\n",
       "          9.60274217e-07, 2.44288819e-03, 5.15042996e-07, 1.62839746e-03,\n",
       "          2.48780057e-03, 1.88143541e-03, 1.69535738e-03, 4.70808436e-04,\n",
       "          4.70246438e-04, 8.14588074e-04, 4.70864602e-04, 1.41028976e-03,\n",
       "          4.25661263e-02, 4.70077860e-04, 5.23485811e-03, 1.01163634e-02,\n",
       "          5.54352317e-03, 1.24396409e-03, 1.24415513e-03, 9.90729915e-03,\n",
       "          4.02971215e-03, 1.05863504e-02]),\n",
       "   'param_C': masked_array(data=[0.02773301840709759, 0.23988730168521666,\n",
       "                      0.10543319547912483, 0.041057839360592756,\n",
       "                      0.2413568323580492, 0.022289061297866723,\n",
       "                      0.5103071158436588, 0.05620086547990849,\n",
       "                      0.033109190868620984, 0.041877169799207366,\n",
       "                      0.17463911679757688, 0.5081305158193191,\n",
       "                      0.3921855141848242, 0.16263473837240625,\n",
       "                      0.048427946069332185, 0.10179954414805288,\n",
       "                      0.7176642896809294, 0.29822890040675465,\n",
       "                      0.16170876473883292, 0.30541810217560156,\n",
       "                      0.02151582160909052, 0.026584569539231037,\n",
       "                      0.06957535560579538, 0.1559574878992777,\n",
       "                      0.1946856161671629, 0.0005290715921905286,\n",
       "                      0.22312607416026742, 0.04483187841155994,\n",
       "                      0.07440258013339622, 0.2553914043225095],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, None, None, 'balanced', 'balanced', None,\n",
       "                      'balanced', 'balanced', None, 'balanced', None,\n",
       "                      'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', None, 'balanced', None,\n",
       "                      'balanced', 'balanced', 'balanced', 'balanced', None,\n",
       "                      None, 'balanced', None, 'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['liblinear', 'newton-cg', 'liblinear', 'liblinear',\n",
       "                      'newton-cg', 'newton-cg', 'saga', 'liblinear',\n",
       "                      'newton-cg', 'newton-cg', 'liblinear', 'newton-cg',\n",
       "                      'saga', 'liblinear', 'newton-cg', 'newton-cg',\n",
       "                      'newton-cg', 'saga', 'newton-cg', 'saga', 'liblinear',\n",
       "                      'newton-cg', 'saga', 'liblinear', 'liblinear',\n",
       "                      'newton-cg', 'liblinear', 'saga', 'saga', 'saga'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.007868759181831749, 0.058992254959588264,\n",
       "                      0.27661118684357894, 0.7744477399980741,\n",
       "                      0.36726571512809536, 0.14978425441874416,\n",
       "                      0.2159531804866097, 0.055724878918423676,\n",
       "                      0.0492478305641371, 0.06637787430705898,\n",
       "                      0.34822302196315397, 0.2444512599516575,\n",
       "                      0.03978749434786101, 0.031208958108304426,\n",
       "                      0.4337439444431354, 0.7206994607164303,\n",
       "                      0.11747109237986163, 0.1419092079651808,\n",
       "                      0.09467979024854994, 0.0028133289536883496,\n",
       "                      0.07626579004432117, 0.09280263882499151,\n",
       "                      0.0317778016822212, 0.4027506014105046,\n",
       "                      0.7415441510459443, 0.284877017696408,\n",
       "                      0.37487124262147264, 0.11941212146325,\n",
       "                      0.013890499188730462, 0.19981217725308753],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.02773301840709759,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.007868759181831749},\n",
       "    {'C': 0.23988730168521666,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.058992254959588264},\n",
       "    {'C': 0.10543319547912483,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.27661118684357894},\n",
       "    {'C': 0.041057839360592756,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.7744477399980741},\n",
       "    {'C': 0.2413568323580492,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.36726571512809536},\n",
       "    {'C': 0.022289061297866723,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.14978425441874416},\n",
       "    {'C': 0.5103071158436588,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.2159531804866097},\n",
       "    {'C': 0.05620086547990849,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.055724878918423676},\n",
       "    {'C': 0.033109190868620984,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.0492478305641371},\n",
       "    {'C': 0.041877169799207366,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.06637787430705898},\n",
       "    {'C': 0.17463911679757688,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.34822302196315397},\n",
       "    {'C': 0.5081305158193191,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.2444512599516575},\n",
       "    {'C': 0.3921855141848242,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.03978749434786101},\n",
       "    {'C': 0.16263473837240625,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.031208958108304426},\n",
       "    {'C': 0.048427946069332185,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.4337439444431354},\n",
       "    {'C': 0.10179954414805288,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.7206994607164303},\n",
       "    {'C': 0.7176642896809294,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.11747109237986163},\n",
       "    {'C': 0.29822890040675465,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.1419092079651808},\n",
       "    {'C': 0.16170876473883292,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.09467979024854994},\n",
       "    {'C': 0.30541810217560156,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0028133289536883496},\n",
       "    {'C': 0.02151582160909052,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.07626579004432117},\n",
       "    {'C': 0.026584569539231037,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.09280263882499151},\n",
       "    {'C': 0.06957535560579538,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0317778016822212},\n",
       "    {'C': 0.1559574878992777,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.4027506014105046},\n",
       "    {'C': 0.1946856161671629,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.7415441510459443},\n",
       "    {'C': 0.0005290715921905286,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.284877017696408},\n",
       "    {'C': 0.22312607416026742,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.37487124262147264},\n",
       "    {'C': 0.04483187841155994,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.11941212146325},\n",
       "    {'C': 0.07440258013339622,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.013890499188730462},\n",
       "    {'C': 0.2553914043225095,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.19981217725308753}],\n",
       "   'split0_test_Accuracy': array([0.54177124, 0.62029401, 0.57404087, 0.54033704, 0.60702761,\n",
       "          0.5790606 , 0.44352815, 0.55647185, 0.58013625, 0.58300466,\n",
       "          0.57834349, 0.63427752, 0.54571531, 0.58694873, 0.58981714,\n",
       "          0.59949803, 0.61384009, 0.52348512, 0.61348153, 0.57726784,\n",
       "          0.53675152, 0.5804948 , 0.54822517, 0.57332377, 0.55969882,\n",
       "          0.2104697 , 0.58730728, 0.52205091, 0.53065615, 0.51523844]),\n",
       "   'split1_test_Accuracy': array([0.53896104, 0.62121212, 0.57683983, 0.53715729, 0.61219336,\n",
       "          0.58189033, 0.44408369, 0.56962482, 0.59018759, 0.58152958,\n",
       "          0.59307359, 0.62842713, 0.54256854, 0.59848485, 0.59704185,\n",
       "          0.60425685, 0.61580087, 0.52200577, 0.61435786, 0.57828283,\n",
       "          0.52669553, 0.58658009, 0.54329004, 0.58513709, 0.57503608,\n",
       "          0.21248196, 0.59126984, 0.52272727, 0.52922078, 0.50865801]),\n",
       "   'split2_test_Accuracy': array([0.53350235, 0.61499457, 0.56791018, 0.5320536 , 0.59760956,\n",
       "          0.55921767, 0.41977544, 0.54835205, 0.56573705, 0.56827237,\n",
       "          0.57044549, 0.62404926, 0.51358204, 0.57660268, 0.57225643,\n",
       "          0.58638175, 0.60630206, 0.50199203, 0.59978269, 0.55994205,\n",
       "          0.52589641, 0.5613908 , 0.51575516, 0.56609924, 0.55632017,\n",
       "          0.2075335 , 0.58167331, 0.50162984, 0.51937704, 0.50488953]),\n",
       "   'mean_test_Accuracy': array([0.5380918 , 0.61884162, 0.5729392 , 0.53652968, 0.60562365,\n",
       "          0.57341985, 0.43583273, 0.5581591 , 0.57870704, 0.57762557,\n",
       "          0.58062966, 0.62893535, 0.53400625, 0.58735881, 0.5863975 ,\n",
       "          0.59673155, 0.61199231, 0.51586157, 0.60922855, 0.57185773,\n",
       "          0.52980053, 0.57618361, 0.5358087 , 0.57486181, 0.56368661,\n",
       "          0.21016583, 0.58675799, 0.51550108, 0.52643595, 0.50961307]),\n",
       "   'std_test_Accuracy': array([0.00343176, 0.00273658, 0.00372365, 0.00341122, 0.00602872,\n",
       "          0.01007379, 0.01131661, 0.00875515, 0.01001988, 0.006618  ,\n",
       "          0.00936707, 0.00419179, 0.01444873, 0.00892601, 0.01039247,\n",
       "          0.00754764, 0.00408879, 0.00979148, 0.0066654 , 0.0084063 ,\n",
       "          0.00494578, 0.01071599, 0.01427343, 0.00783808, 0.00813872,\n",
       "          0.00202897, 0.00393185, 0.0097779 , 0.00500835, 0.0042792 ]),\n",
       "   'rank_test_Accuracy': array([20,  2, 16, 21,  5, 15, 29, 19, 11, 12, 10,  1, 23,  7,  9,  6,  3,\n",
       "          26,  4, 17, 24, 13, 22, 14, 18, 30,  8, 27, 25, 28]),\n",
       "   'split0_train_Accuracy': array([0.57961323, 0.68986083, 0.63021869, 0.57708296, 0.65262968,\n",
       "          0.62353154, 0.46159407, 0.61431412, 0.62931502, 0.63907464,\n",
       "          0.64576179, 0.70431954, 0.57491415, 0.65407555, 0.63491777,\n",
       "          0.64377372, 0.66365444, 0.54997289, 0.68082415, 0.62371227,\n",
       "          0.56858847, 0.62606181, 0.5794325 , 0.63527923, 0.6217242 ,\n",
       "          0.22067594, 0.64973794, 0.55611784, 0.5676848 , 0.54816555]),\n",
       "   'split1_train_Accuracy': array([0.58864865, 0.69261261, 0.63657658, 0.58504505, 0.65711712,\n",
       "          0.62288288, 0.47675676, 0.61675676, 0.62918919, 0.6436036 ,\n",
       "          0.6436036 , 0.70738739, 0.57315315, 0.65603604, 0.63513514,\n",
       "          0.64648649, 0.67009009, 0.55423423, 0.68486486, 0.62108108,\n",
       "          0.5781982 , 0.62558559, 0.57531532, 0.63675676, 0.62720721,\n",
       "          0.21747748, 0.65297297, 0.5563964 , 0.5818018 , 0.54900901]),\n",
       "   'split2_train_Accuracy': array([0.58155008, 0.68476893, 0.62794461, 0.58280885, 0.652041  ,\n",
       "          0.62111131, 0.45171732, 0.60726488, 0.62866391, 0.63711563,\n",
       "          0.63945334, 0.69699694, 0.57795361, 0.6452077 , 0.63262003,\n",
       "          0.64340946, 0.66211113, 0.56033088, 0.67505844, 0.62614638,\n",
       "          0.56824312, 0.62416832, 0.58190973, 0.63136127, 0.62003237,\n",
       "          0.21956483, 0.64484805, 0.56176947, 0.567344  , 0.55223881]),\n",
       "   'mean_train_Accuracy': array([0.58327065, 0.68908079, 0.63157996, 0.58164562, 0.65392926,\n",
       "          0.62250858, 0.46335605, 0.61277858, 0.62905604, 0.63993129,\n",
       "          0.64293958, 0.70290129, 0.5753403 , 0.65177309, 0.63422431,\n",
       "          0.64455656, 0.66528522, 0.554846  , 0.68024915, 0.62364658,\n",
       "          0.5716766 , 0.6252719 , 0.57888585, 0.63446575, 0.62298793,\n",
       "          0.21923942, 0.64918632, 0.55809457, 0.57227687, 0.54980446]),\n",
       "   'std_train_Accuracy': array([0.00388415, 0.00324933, 0.00365308, 0.00335296, 0.00226693,\n",
       "          0.00102289, 0.01029795, 0.00402429, 0.000282  , 0.00271709,\n",
       "          0.00261787, 0.00435882, 0.00198281, 0.00471092, 0.00113786,\n",
       "          0.00137275, 0.00345548, 0.0042507 , 0.00402405, 0.00206842,\n",
       "          0.00461362, 0.00080421, 0.00271977, 0.00227657, 0.00306239,\n",
       "          0.00132589, 0.00333984, 0.00260103, 0.00673658, 0.00175545]),\n",
       "   'split0_test_F1': array([0.51546404, 0.61010169, 0.55458906, 0.51163414, 0.60671087,\n",
       "          0.58119784, 0.38536012, 0.54186899, 0.58201482, 0.56980059,\n",
       "          0.56623303, 0.62478943, 0.54347849, 0.57588753, 0.59077963,\n",
       "          0.59993399, 0.61335489, 0.51650583, 0.6033515 , 0.57790104,\n",
       "          0.50841329, 0.58270405, 0.54660755, 0.56052444, 0.54617104,\n",
       "          0.19353664, 0.57126789, 0.5169768 , 0.50364912, 0.50663339]),\n",
       "   'split1_test_F1': array([0.51107646, 0.60904408, 0.5561193 , 0.50676766, 0.61298941,\n",
       "          0.58325528, 0.38882535, 0.55367014, 0.59215153, 0.56538746,\n",
       "          0.57869248, 0.61803575, 0.53889826, 0.58571935, 0.59877885,\n",
       "          0.60596882, 0.61737038, 0.51383352, 0.60073213, 0.57856758,\n",
       "          0.49680058, 0.58826039, 0.53978154, 0.57026685, 0.56008855,\n",
       "          0.19554212, 0.57224456, 0.51608333, 0.50147938, 0.49845955]),\n",
       "   'split2_test_F1': array([0.50713776, 0.60444225, 0.548773  , 0.50558436, 0.59992421,\n",
       "          0.56064983, 0.36942596, 0.53230947, 0.56694346, 0.55444338,\n",
       "          0.55755248, 0.61504057, 0.51155071, 0.56414342, 0.57322825,\n",
       "          0.58820009, 0.6081352 , 0.49399405, 0.58891676, 0.56109165,\n",
       "          0.49796701, 0.56255861, 0.51404654, 0.55309826, 0.54091192,\n",
       "          0.18732841, 0.56434805, 0.49471016, 0.4931543 , 0.4972219 ]),\n",
       "   'mean_test_F1': array([0.51124015, 0.60787177, 0.55316917, 0.50800601, 0.60655059,\n",
       "          0.57506592, 0.38122787, 0.5426283 , 0.58039104, 0.56323553,\n",
       "          0.56750323, 0.61930543, 0.53136013, 0.57526608, 0.58762107,\n",
       "          0.59805118, 0.61296068, 0.50814694, 0.59768998, 0.57254619,\n",
       "          0.5010794 , 0.57787115, 0.53353105, 0.56130578, 0.54906204,\n",
       "          0.19214494, 0.56929741, 0.50929176, 0.49944452, 0.50078828]),\n",
       "   'std_test_F1': array([0.00340173, 0.00245488, 0.00316016, 0.00262068, 0.00532784,\n",
       "          0.01019266, 0.00843564, 0.00872531, 0.01034167, 0.00645239,\n",
       "          0.00866573, 0.0040805 , 0.01408315, 0.00880746, 0.0106555 ,\n",
       "          0.00736653, 0.00377553, 0.01003209, 0.00627383, 0.00807573,\n",
       "          0.00522856, 0.01102598, 0.01400984, 0.0070215 , 0.00808316,\n",
       "          0.00349142, 0.0035102 , 0.01028102, 0.00452008, 0.00418045]),\n",
       "   'rank_test_F1': array([22,  3, 17, 25,  4, 11, 29, 19,  8, 15, 14,  1, 21, 10,  7,  5,  2,\n",
       "          24,  6, 12, 26,  9, 20, 16, 18, 30, 13, 23, 28, 27]),\n",
       "   'split0_train_F1': array([0.55780926, 0.68099437, 0.61492956, 0.55391182, 0.65224955,\n",
       "          0.62407248, 0.40919606, 0.6011629 , 0.62920841, 0.62734369,\n",
       "          0.63538584, 0.695797  , 0.57342086, 0.64440161, 0.63465091,\n",
       "          0.6432768 , 0.66276594, 0.54343658, 0.67182033, 0.62321646,\n",
       "          0.54424502, 0.62625887, 0.57854282, 0.62498986, 0.61005539,\n",
       "          0.20631791, 0.63649326, 0.55090106, 0.54524338, 0.54160331]),\n",
       "   'split1_train_F1': array([0.56508818, 0.6844101 , 0.62173832, 0.56026047, 0.65747128,\n",
       "          0.62357071, 0.43062717, 0.6038555 , 0.62930458, 0.63299251,\n",
       "          0.63340874, 0.69924522, 0.5698464 , 0.64739338, 0.63533419,\n",
       "          0.64648924, 0.67015415, 0.54708779, 0.67647827, 0.62065628,\n",
       "          0.55277618, 0.62597146, 0.57256716, 0.62684939, 0.61636148,\n",
       "          0.20309096, 0.63951452, 0.55075794, 0.55953662, 0.54072621]),\n",
       "   'split2_train_F1': array([0.55992673, 0.67695478, 0.6134699 , 0.5591359 , 0.65288187,\n",
       "          0.62239297, 0.40199765, 0.59635457, 0.62972573, 0.62700229,\n",
       "          0.63124263, 0.69014577, 0.57582316, 0.63750958, 0.63307656,\n",
       "          0.64417637, 0.66316459, 0.55422668, 0.66638113, 0.62624947,\n",
       "          0.54336708, 0.62519503, 0.58021387, 0.62269805, 0.61139308,\n",
       "          0.20165407, 0.63197472, 0.55736134, 0.54519496, 0.54702898]),\n",
       "   'mean_train_F1': array([0.56094139, 0.68078642, 0.6167126 , 0.5577694 , 0.6542009 ,\n",
       "          0.62334539, 0.41394029, 0.60045766, 0.6294129 , 0.62911283,\n",
       "          0.63334574, 0.69506266, 0.57303014, 0.64310152, 0.63435388,\n",
       "          0.64464747, 0.66536156, 0.54825035, 0.67155991, 0.62337407,\n",
       "          0.54679609, 0.62580845, 0.57710795, 0.62484577, 0.61260332,\n",
       "          0.20368765, 0.63599417, 0.55300678, 0.54999166, 0.5431195 ]),\n",
       "   'std_train_F1': array([0.00305699, 0.00304717, 0.00360334, 0.00276609, 0.00232687,\n",
       "          0.00070392, 0.01215986, 0.00310258, 0.00022466, 0.00274689,\n",
       "          0.00169204, 0.00375095, 0.0024556 , 0.00413844, 0.0009453 ,\n",
       "          0.00135312, 0.00339278, 0.00448109, 0.00412625, 0.00228613,\n",
       "          0.00424372, 0.00044935, 0.0032825 , 0.00169784, 0.00271296,\n",
       "          0.00195019, 0.00309827, 0.00307969, 0.00674934, 0.00278752]),\n",
       "   'split0_test_Log_Loss': array([-2.18013895, -1.37683484, -1.7803644 , -2.13081805, -1.72686304,\n",
       "          -1.98520561, -3.14761106, -1.9454988 , -1.92608867, -1.59736248,\n",
       "          -1.69437173, -1.32648509, -2.56396931, -1.65509357, -1.87662453,\n",
       "          -1.79693469, -1.66623187, -2.85185094, -1.41289075, -1.96732605,\n",
       "          -2.28470328, -1.95797321, -2.50393188, -1.75486431, -1.79770419,\n",
       "          -3.19811063, -1.65083674, -2.8353621 , -2.12483927, -2.8875694 ]),\n",
       "   'split1_test_Log_Loss': array([-2.20740617, -1.4318702 , -1.82111186, -2.15699779, -1.7650493 ,\n",
       "          -2.01874639, -3.12756488, -1.97442619, -1.96254646, -1.63904437,\n",
       "          -1.7277333 , -1.38574986, -2.56642002, -1.69562716, -1.91405091,\n",
       "          -1.83392855, -1.70726855, -2.8475688 , -1.46656287, -1.9978708 ,\n",
       "          -2.30800622, -1.99277164, -2.51476138, -1.78713049, -1.82666187,\n",
       "          -3.2028127 , -1.68838516, -2.8285761 , -2.13074469, -2.88032147]),\n",
       "   'split2_test_Log_Loss': array([-2.19418107, -1.40795537, -1.79899966, -2.14065503, -1.7546488 ,\n",
       "          -2.0047222 , -3.15353328, -1.9639258 , -1.94761116, -1.62123228,\n",
       "          -1.71999246, -1.35946706, -2.5742478 , -1.67985955, -1.8997857 ,\n",
       "          -1.82236886, -1.69580639, -2.85528928, -1.44272794, -1.99114218,\n",
       "          -2.29777985, -1.97841026, -2.51347838, -1.77626123, -1.82057946,\n",
       "          -3.20294016, -1.66858768, -2.83238453, -2.14002677, -2.88030504]),\n",
       "   'mean_test_Log_Loss': array([-2.19388024, -1.40549163, -1.80011973, -2.14280197, -1.74880113,\n",
       "          -2.00285285, -3.14289864, -1.96124786, -1.94537305, -1.61916574,\n",
       "          -1.71398446, -1.35716824, -2.56819573, -1.67681166, -1.89677521,\n",
       "          -1.81769541, -1.68971288, -2.85156533, -1.44066768, -1.9854018 ,\n",
       "          -2.29680376, -1.97634475, -2.51070636, -1.77271083, -1.81493915,\n",
       "          -3.20127916, -1.66923311, -2.83211386, -2.1318451 , -2.88274506]),\n",
       "   'std_test_Log_Loss': array([0.01114679, 0.02256118, 0.01667317, 0.01080671, 0.01614238,\n",
       "          0.01377207, 0.01110326, 0.01197296, 0.01498441, 0.01709852,\n",
       "          0.01427773, 0.02427706, 0.00438048, 0.01670569, 0.01544345,\n",
       "          0.01547473, 0.01731354, 0.00315413, 0.02198509, 0.01312327,\n",
       "          0.00954928, 0.01429724, 0.00483808, 0.01342316, 0.01248516,\n",
       "          0.00225018, 0.01535369, 0.00278016, 0.00624988, 0.00342517]),\n",
       "   'rank_test_Log_Loss': array([22,  2, 11, 21,  9, 19, 29, 16, 15,  4,  8,  1, 25,  6, 14, 13,  7,\n",
       "          27,  3, 18, 23, 17, 24, 10, 12, 30,  5, 26, 20, 28]),\n",
       "   'split0_train_Log_Loss': array([-2.10478395, -1.19801195, -1.66797374, -2.05332261, -1.61468843,\n",
       "          -1.91874027, -3.12982374, -1.84773659, -1.85320393, -1.46289031,\n",
       "          -1.57016567, -1.12922467, -2.52444193, -1.52254181, -1.7970658 ,\n",
       "          -1.70268716, -1.53338398, -2.81907562, -1.24381434, -1.89525277,\n",
       "          -2.2175971 , -1.8887069 , -2.46250688, -1.63651857, -1.6867676 ,\n",
       "          -3.1834979 , -1.52184019, -2.80686241, -2.0433246 , -2.86124897]),\n",
       "   'split1_train_Log_Loss': array([-2.08955184, -1.17838597, -1.65513807, -2.0396268 , -1.56712536,\n",
       "          -1.88916199, -3.09216612, -1.83222124, -1.82039474, -1.44794038,\n",
       "          -1.55641786, -1.10778958, -2.49506269, -1.50513455, -1.76108396,\n",
       "          -1.66112596, -1.47939703, -2.80036131, -1.22532605, -1.85226065,\n",
       "          -2.20271548, -1.85772897, -2.43893207, -1.62387003, -1.66890887,\n",
       "          -3.1751437 , -1.5010282 , -2.78069803, -2.00692845, -2.83170882]),\n",
       "   'split2_train_Log_Loss': array([-2.09018756, -1.18297043, -1.65071299, -2.03599037, -1.58362396,\n",
       "          -1.896012  , -3.12189308, -1.83145483, -1.8286126 , -1.44880199,\n",
       "          -1.55656145, -1.11432264, -2.5156758 , -1.50550688, -1.77077246,\n",
       "          -1.67378882, -1.5004306 , -2.81619228, -1.22887071, -1.86836946,\n",
       "          -2.2036846 , -1.86515508, -2.45144034, -1.61988146, -1.6686753 ,\n",
       "          -3.17263301, -1.5015744 , -2.79278979, -2.02828942, -2.84249846]),\n",
       "   'mean_train_Log_Loss': array([-2.09484111, -1.18645612, -1.6579416 , -2.04297993, -1.58847925,\n",
       "          -1.90130475, -3.11462764, -1.83713755, -1.83407042, -1.45321089,\n",
       "          -1.56104833, -1.1171123 , -2.5117268 , -1.51106108, -1.77630741,\n",
       "          -1.67920064, -1.50440387, -2.81187641, -1.23267037, -1.87196096,\n",
       "          -2.20799906, -1.87053032, -2.45095977, -1.62675669, -1.67478392,\n",
       "          -3.17709154, -1.5081476 , -2.79345008, -2.02618082, -2.84515208]),\n",
       "   'std_train_Log_Loss': array([0.00703544, 0.00838281, 0.00732021, 0.00746254, 0.01971872,\n",
       "          0.01264196, 0.01620934, 0.00750118, 0.01393919, 0.00685341,\n",
       "          0.0064472 , 0.00897041, 0.01231479, 0.00811952, 0.01520197,\n",
       "          0.01739347, 0.02221843, 0.00822705, 0.00801175, 0.01773424,\n",
       "          0.00679836, 0.0132055 , 0.00963037, 0.00709215, 0.00847427,\n",
       "          0.0046445 , 0.00968469, 0.01069176, 0.01493329, 0.01220482])},\n",
       "  {'C': 0.5081305158193191,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.2444512599516575},\n",
       "  11,\n",
       "  -1.3571682407111565),\n",
       " 'RandomForestClassifier_V01_PCA_80': ({'mean_fit_time': array([ 5.02722065,  6.57043751,  4.50429344,  3.36533769,  8.75991996,\n",
       "           3.01858179,  2.93714952, 12.90517267, 10.76921487,  3.46207937,\n",
       "           3.01693606,  5.59803605,  5.87429746,  2.46740484,  7.80746468,\n",
       "           6.46904182,  4.92383885,  4.89491622,  8.53252649,  4.92882601,\n",
       "           3.04752008,  4.44944032,  6.98133866,  4.89990298, 10.34102567,\n",
       "           5.61166676,  6.08307441,  4.05682286, 10.00824904,  5.43480627]),\n",
       "   'std_fit_time': array([0.0388733 , 0.04878512, 0.02145765, 0.02656687, 0.05933061,\n",
       "          0.01322267, 0.02679871, 0.08228023, 0.03895887, 0.04168449,\n",
       "          0.02945139, 0.03868655, 0.05635286, 0.03576516, 0.06501449,\n",
       "          0.07385394, 0.05020419, 0.06620105, 0.03862112, 0.04052086,\n",
       "          0.00799363, 0.04349116, 0.06067081, 0.03461554, 0.08012792,\n",
       "          0.17054275, 0.02157992, 0.02230597, 0.12250917, 0.11654016]),\n",
       "   'mean_score_time': array([0.40458528, 0.47971813, 0.3939472 , 0.39494507, 0.59075379,\n",
       "          0.3105038 , 0.21043793, 0.74933076, 0.59075522, 0.29155413,\n",
       "          0.2699453 , 0.41056991, 0.62433139, 0.26861564, 0.59840083,\n",
       "          0.49068888, 0.34806999, 0.51030302, 0.43982426, 0.37599516,\n",
       "          0.29820283, 0.61568848, 0.66023548, 0.47971813, 0.73403827,\n",
       "          0.61901291, 0.5801158 , 0.37865464, 0.73702995, 0.42951902]),\n",
       "   'std_score_time': array([0.02872506, 0.01626583, 0.02419797, 0.02055341, 0.05454176,\n",
       "          0.02363428, 0.01360247, 0.0747289 , 0.02502287, 0.01558589,\n",
       "          0.00367148, 0.01617055, 0.03341659, 0.010996  , 0.03032722,\n",
       "          0.02786506, 0.02135916, 0.02101986, 0.00709891, 0.01039573,\n",
       "          0.02932701, 0.0179389 , 0.05008589, 0.00495331, 0.04049574,\n",
       "          0.0207026 , 0.02139645, 0.02185569, 0.02710598, 0.02757052]),\n",
       "   'param_n_estimators': masked_array(data=[150, 200, 200, 200, 300, 150, 100, 300, 250, 150, 150,\n",
       "                      250, 350, 150, 300, 250, 150, 300, 200, 150, 150, 350,\n",
       "                      350, 300, 350, 350, 300, 200, 300, 250],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[10, 10, 50, 125, 50, 150, 50, 10, 10, 50, 75, 50, 125,\n",
       "                      250, 75, 75, 10, 250, 10, 10, 150, 250, 75, 250, 50,\n",
       "                      150, 75, 75, 10, 125],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'log2', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
       "                      'log2', 'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
       "                      'log2', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[40, 90, 95, 55, 90, 70, 55, 65, 40, 50, 20, 5, 35, 25,\n",
       "                      30, 95, 70, 50, 55, 35, 35, 100, 40, 10, 65, 75, 55,\n",
       "                      70, 70, 65],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65}],\n",
       "   'split0_test_Accuracy': array([0.67049122, 0.67300108, 0.5317318 , 0.46539978, 0.53997849,\n",
       "          0.43062029, 0.53424166, 0.67551094, 0.6801721 , 0.54248835,\n",
       "          0.49766942, 0.45858731, 0.46002151, 0.37647902, 0.50017928,\n",
       "          0.50376479, 0.67300108, 0.38365005, 0.67586949, 0.67049122,\n",
       "          0.42811043, 0.38436716, 0.51416278, 0.37934744, 0.54463966,\n",
       "          0.43994263, 0.51021872, 0.50770886, 0.67371818, 0.45285048]),\n",
       "   'split1_test_Accuracy': array([0.64502165, 0.6511544 , 0.52092352, 0.4476912 , 0.51370851,\n",
       "          0.40909091, 0.51262626, 0.65692641, 0.65873016, 0.51298701,\n",
       "          0.48520924, 0.43867244, 0.44444444, 0.35858586, 0.47907648,\n",
       "          0.48304473, 0.6461039 , 0.36507937, 0.65873016, 0.6511544 ,\n",
       "          0.42676768, 0.36399711, 0.47619048, 0.37121212, 0.51767677,\n",
       "          0.43001443, 0.48737374, 0.48665224, 0.64862915, 0.43867244]),\n",
       "   'split2_test_Accuracy': array([0.65990583, 0.66171677, 0.51611735, 0.43317639, 0.51394422,\n",
       "          0.41144513, 0.51032235, 0.66207896, 0.67077146, 0.51611735,\n",
       "          0.48352046, 0.43752264, 0.43788482, 0.37305324, 0.47700109,\n",
       "          0.47265484, 0.65519739, 0.36870699, 0.66461427, 0.65700833,\n",
       "          0.40492575, 0.37269105, 0.47156827, 0.36725824, 0.50996016,\n",
       "          0.42375951, 0.48062296, 0.48352046, 0.66823615, 0.42955451]),\n",
       "   'mean_test_Accuracy': array([0.65849555, 0.66198029, 0.52295121, 0.44881038, 0.52259072,\n",
       "          0.41708724, 0.51910598, 0.66486422, 0.66991108, 0.52391252,\n",
       "          0.4888248 , 0.44496515, 0.44748858, 0.36938236, 0.48546023,\n",
       "          0.4865417 , 0.65813506, 0.37250661, 0.66642634, 0.65957702,\n",
       "          0.41997116, 0.37370824, 0.48738284, 0.37262677, 0.52415285,\n",
       "          0.43126652, 0.49279019, 0.49267003, 0.66354242, 0.44039894]),\n",
       "   'std_test_Accuracy': array([0.01045736, 0.0089312 , 0.0065347 , 0.0131811 , 0.01234528,\n",
       "          0.00965597, 0.01078695, 0.00784539, 0.00878479, 0.01325   ,\n",
       "          0.0063171 , 0.00968276, 0.00929128, 0.00775731, 0.01048438,\n",
       "          0.01294089, 0.01118671, 0.00804863, 0.00712067, 0.00810803,\n",
       "          0.01061554, 0.00835653, 0.01910629, 0.00503645, 0.01488149,\n",
       "          0.00666683, 0.01267623, 0.01075328, 0.01077465, 0.00959007]),\n",
       "   'rank_test_Accuracy': array([ 7,  5, 11, 20, 12, 26, 13,  3,  1, 10, 16, 22, 21, 30, 19, 18,  8,\n",
       "          29,  2,  6, 25, 27, 17, 28,  9, 24, 14, 15,  4, 23]),\n",
       "   'split0_train_Accuracy': array([0.91830833, 0.92174227, 0.62208567, 0.49213808, 0.61702512,\n",
       "          0.4579794 , 0.60907284, 0.91957347, 0.91342852, 0.62407374,\n",
       "          0.55358757, 0.48671607, 0.49611422, 0.39761431, 0.54943069,\n",
       "          0.55250316, 0.91794686, 0.39851798, 0.91794686, 0.9197542 ,\n",
       "          0.45725646, 0.40918128, 0.56786553, 0.39436111, 0.62262787,\n",
       "          0.47008856, 0.5660582 , 0.56208205, 0.92535695, 0.48454726]),\n",
       "   'split1_train_Accuracy': array([0.90882883, 0.91351351, 0.61981982, 0.50468468, 0.61495495,\n",
       "          0.46144144, 0.60378378, 0.91225225, 0.90774775, 0.61873874,\n",
       "          0.55963964, 0.49855856, 0.49675676, 0.3981982 , 0.54648649,\n",
       "          0.54972973, 0.90882883, 0.39603604, 0.90756757, 0.91387387,\n",
       "          0.46432432, 0.40882883, 0.55513514, 0.40864865, 0.6163964 ,\n",
       "          0.47927928, 0.5572973 , 0.55621622, 0.91585586, 0.48828829]),\n",
       "   'split2_train_Accuracy': array([0.91278547, 0.91692142, 0.605107  , 0.49307678, 0.60996224,\n",
       "          0.45819097, 0.60384823, 0.91368459, 0.91476353, 0.60978241,\n",
       "          0.55403704, 0.49451537, 0.49685308, 0.40748067, 0.54666427,\n",
       "          0.5454055 , 0.91584247, 0.40784032, 0.91350477, 0.91206618,\n",
       "          0.45423485, 0.41251573, 0.55349757, 0.40909908, 0.59827369,\n",
       "          0.47419529, 0.55763352, 0.56033088, 0.91961877, 0.48228736]),\n",
       "   'mean_train_Accuracy': array([0.91330754, 0.9173924 , 0.61567083, 0.49663318, 0.61398077,\n",
       "          0.45920394, 0.60556828, 0.9151701 , 0.91197993, 0.61753163,\n",
       "          0.55575475, 0.49326333, 0.49657469, 0.40109773, 0.54752715,\n",
       "          0.5492128 , 0.91420606, 0.40079811, 0.9130064 , 0.91523142,\n",
       "          0.45860521, 0.41017528, 0.55883275, 0.40403628, 0.61243265,\n",
       "          0.47452104, 0.56032967, 0.55954305, 0.92027719, 0.48504097]),\n",
       "   'std_train_Accuracy': array([0.00388756, 0.00337584, 0.00752682, 0.00570615, 0.00296455,\n",
       "          0.00158451, 0.00247823, 0.00316808, 0.00304183, 0.00589651,\n",
       "          0.00275315, 0.00491507, 0.00032796, 0.00451971, 0.00134796,\n",
       "          0.00292057, 0.00389812, 0.00508163, 0.00425196, 0.00328214,\n",
       "          0.00422798, 0.00166119, 0.00642204, 0.00684385, 0.01033005,\n",
       "          0.00375916, 0.004053  , 0.00245866, 0.00390665, 0.00247462]),\n",
       "   'split0_test_F1': array([0.66229838, 0.66240192, 0.49739616, 0.42325088, 0.50721724,\n",
       "          0.3799124 , 0.49974587, 0.6637076 , 0.66958403, 0.50874777,\n",
       "          0.4578733 , 0.41919666, 0.41721473, 0.32655585, 0.46068973,\n",
       "          0.46481465, 0.66208676, 0.32649191, 0.66564026, 0.65946067,\n",
       "          0.37822416, 0.34129037, 0.47457003, 0.32351341, 0.51326216,\n",
       "          0.39612366, 0.4735606 , 0.47153869, 0.66375204, 0.4048421 ]),\n",
       "   'split1_test_F1': array([0.63437165, 0.640775  , 0.4857161 , 0.40193482, 0.47721543,\n",
       "          0.36017022, 0.47374532, 0.64696724, 0.64827262, 0.4753914 ,\n",
       "          0.44427885, 0.39556285, 0.39915029, 0.30370057, 0.43517868,\n",
       "          0.44401945, 0.63501494, 0.30579917, 0.64738265, 0.63903226,\n",
       "          0.37800446, 0.31338206, 0.43546318, 0.31264519, 0.48147252,\n",
       "          0.38405529, 0.44627603, 0.44364727, 0.6348357 , 0.39106832]),\n",
       "   'split2_test_F1': array([0.65032245, 0.65306751, 0.4854972 , 0.39672333, 0.48512322,\n",
       "          0.36141302, 0.4833065 , 0.6550881 , 0.66450909, 0.48783057,\n",
       "          0.45214311, 0.40437185, 0.40109007, 0.322652  , 0.44380826,\n",
       "          0.43565622, 0.64716693, 0.3189293 , 0.65738743, 0.64862048,\n",
       "          0.36290743, 0.32952413, 0.4362027 , 0.31573036, 0.48022531,\n",
       "          0.38584938, 0.44548359, 0.45130825, 0.65946832, 0.38791583]),\n",
       "   'mean_test_F1': array([0.64902291, 0.65210126, 0.48955788, 0.40734957, 0.48989369,\n",
       "          0.36719885, 0.48563116, 0.6552718 , 0.66080163, 0.49069727,\n",
       "          0.45144397, 0.40640596, 0.40584789, 0.31764773, 0.44659139,\n",
       "          0.44821399, 0.64811936, 0.31709025, 0.65682072, 0.64905965,\n",
       "          0.37306933, 0.32809061, 0.44881464, 0.31731109, 0.49171258,\n",
       "          0.38869506, 0.45515716, 0.45553637, 0.65269899, 0.3946385 ]),\n",
       "   'std_test_F1': array([0.01145101, 0.00886563, 0.00556571, 0.01148775, 0.01271484,\n",
       "          0.00904053, 0.01075256, 0.00684342, 0.0090938 , 0.01378238,\n",
       "          0.00557818, 0.00976547, 0.00810884, 0.00998486, 0.0106098 ,\n",
       "          0.01226937, 0.01108525, 0.00855632, 0.007473  , 0.00835532,\n",
       "          0.00716087, 0.01145144, 0.01828821, 0.00457962, 0.01530814,\n",
       "          0.00532461, 0.01307   , 0.01178277, 0.01274502, 0.00735744]),\n",
       "   'rank_test_F1': array([ 7,  5, 12, 20, 11, 26, 13,  3,  1, 10, 16, 21, 22, 28, 19, 18,  8,\n",
       "          30,  2,  6, 25, 27, 17, 29,  9, 24, 15, 14,  4, 23]),\n",
       "   'split0_train_F1': array([0.91759528, 0.92078079, 0.60164158, 0.44973692, 0.59754664,\n",
       "          0.41094647, 0.58702053, 0.91877832, 0.9124071 , 0.60275936,\n",
       "          0.52107458, 0.44828383, 0.45582762, 0.3449558 , 0.51858144,\n",
       "          0.52268707, 0.9170634 , 0.3427484 , 0.91700679, 0.91866204,\n",
       "          0.40805463, 0.36842773, 0.53861239, 0.34127205, 0.60194302,\n",
       "          0.42710843, 0.53660211, 0.53059893, 0.92457408, 0.44039731]),\n",
       "   'split1_train_F1': array([0.90792316, 0.91269163, 0.59833695, 0.46568364, 0.5917214 ,\n",
       "          0.41662835, 0.58022547, 0.91134134, 0.90665403, 0.59664763,\n",
       "          0.52440203, 0.46407692, 0.45871866, 0.34167575, 0.50844685,\n",
       "          0.51524286, 0.90795461, 0.33901809, 0.90643376, 0.91282842,\n",
       "          0.42011208, 0.36126375, 0.52341065, 0.35337418, 0.59304451,\n",
       "          0.43924819, 0.52225687, 0.52225886, 0.9150021 , 0.4424216 ]),\n",
       "   'split2_train_F1': array([0.91217637, 0.91637543, 0.5768044 , 0.4521454 , 0.58419053,\n",
       "          0.40543024, 0.57703143, 0.91309717, 0.91421646, 0.5837158 ,\n",
       "          0.51867725, 0.45874187, 0.45458008, 0.35220403, 0.5075121 ,\n",
       "          0.50594039, 0.91521759, 0.35399061, 0.91286758, 0.91147959,\n",
       "          0.40806546, 0.3686847 , 0.51402205, 0.35466638, 0.56863792,\n",
       "          0.42942347, 0.51765771, 0.52343028, 0.91897691, 0.43398653]),\n",
       "   'mean_train_F1': array([0.91256494, 0.91661595, 0.59226097, 0.45585532, 0.59115286,\n",
       "          0.41100169, 0.58142581, 0.91440561, 0.91109253, 0.59437426,\n",
       "          0.52138462, 0.45703421, 0.45637545, 0.34627853, 0.51151346,\n",
       "          0.51462344, 0.91341187, 0.34525237, 0.91210271, 0.91432335,\n",
       "          0.41207739, 0.36612539, 0.52534836, 0.34977087, 0.58787515,\n",
       "          0.4319267 , 0.52550556, 0.52542936, 0.9195177 , 0.43893514]),\n",
       "   'std_train_F1': array([0.00395818, 0.00330676, 0.0110124 , 0.00701889, 0.00546741,\n",
       "          0.00457178, 0.00416542, 0.00317397, 0.00322425, 0.00793895,\n",
       "          0.00234739, 0.0065596 , 0.00173341, 0.00439874, 0.00501236,\n",
       "          0.00685082, 0.00393175, 0.00636378, 0.00435017, 0.00311695,\n",
       "          0.00568139, 0.0034393 , 0.01013203, 0.00603268, 0.01407952,\n",
       "          0.00526264, 0.00806796, 0.00368659, 0.00392641, 0.00359546]),\n",
       "   'split0_test_Log_Loss': array([-1.73930476, -1.74323851, -2.304478  , -2.6532549 , -2.23630303,\n",
       "          -2.6596304 , -2.24111124, -1.67915805, -1.66780638, -2.30320157,\n",
       "          -2.47683741, -2.61286985, -2.65505585, -2.85278671, -2.3932976 ,\n",
       "          -2.39821684, -1.74962687, -2.85419125, -1.67268251, -1.74438271,\n",
       "          -2.66405738, -2.91187492, -2.46050059, -2.85151768, -2.23001759,\n",
       "          -2.72576498, -2.46000012, -2.46209298, -1.7513901 , -2.58777707]),\n",
       "   'split1_test_Log_Loss': array([-1.76504004, -1.76480734, -2.31036631, -2.65764492, -2.23323791,\n",
       "          -2.66157901, -2.23567239, -1.6913399 , -1.69061221, -2.30870731,\n",
       "          -2.47749063, -2.6104986 , -2.65504865, -2.86704342, -2.39881272,\n",
       "          -2.39308335, -1.76046742, -2.86000691, -1.69988865, -1.76376356,\n",
       "          -2.66292795, -2.91925397, -2.46113937, -2.85575736, -2.24173539,\n",
       "          -2.73445892, -2.46481384, -2.46315291, -1.76449829, -2.59924355]),\n",
       "   'split2_test_Log_Loss': array([-1.7462593 , -1.74157917, -2.30200807, -2.65992294, -2.2344358 ,\n",
       "          -2.66854868, -2.23993407, -1.67260361, -1.67306583, -2.30606444,\n",
       "          -2.46889575, -2.61590718, -2.65275992, -2.85836563, -2.39304123,\n",
       "          -2.39348362, -1.74904822, -2.8555437 , -1.67358758, -1.75593419,\n",
       "          -2.66028334, -2.90236741, -2.45926564, -2.84916331, -2.23559108,\n",
       "          -2.72181797, -2.46395188, -2.45810774, -1.74645106, -2.59442047]),\n",
       "   'mean_test_Log_Loss': array([-1.75018432, -1.74987241, -2.3056199 , -2.65692945, -2.23466257,\n",
       "          -2.6632383 , -2.23890905, -1.68104117, -1.67714778, -2.30598531,\n",
       "          -2.47442018, -2.6130877 , -2.65429173, -2.85938645, -2.39504959,\n",
       "          -2.39493656, -1.7530458 , -2.85657711, -1.68204496, -1.75467078,\n",
       "          -2.66242905, -2.91117851, -2.46030364, -2.85214877, -2.23576983,\n",
       "          -2.72735137, -2.46291462, -2.46112385, -1.75411772, -2.59380057]),\n",
       "   'std_test_Log_Loss': array([0.01087615, 0.0105766 , 0.00350273, 0.00276923, 0.00126294,\n",
       "          0.00382564, 0.00233738, 0.00775482, 0.00975497, 0.00225102,\n",
       "          0.00390178, 0.00221047, 0.00107935, 0.00587129, 0.00266155,\n",
       "          0.00233463, 0.00525036, 0.00248603, 0.01261598, 0.00797129,\n",
       "          0.00158082, 0.0069023 , 0.0007766 , 0.00272544, 0.00479101,\n",
       "          0.00527529, 0.00209885, 0.00216893, 0.00760835, 0.00470694]),\n",
       "   'rank_test_Log_Loss': array([ 5,  4, 12, 23,  9, 25, 11,  2,  1, 13, 19, 21, 22, 29, 15, 14,  6,\n",
       "          28,  3,  8, 24, 30, 16, 27, 10, 26, 18, 17,  7, 20]),\n",
       "   'split0_train_Log_Loss': array([-1.27730224, -1.27778798, -2.13863581, -2.57297591, -2.07535422,\n",
       "          -2.59196573, -2.08370575, -1.22209043, -1.21540081, -2.13697458,\n",
       "          -2.35358948, -2.53595064, -2.57527121, -2.81041036, -2.27413524,\n",
       "          -2.28070725, -1.28163604, -2.8135982 , -1.21741541, -1.2805832 ,\n",
       "          -2.59589242, -2.86855325, -2.33834045, -2.80940593, -2.0689841 ,\n",
       "          -2.65649267, -2.33995121, -2.33997528, -1.28492433, -2.50998434]),\n",
       "   'split1_train_Log_Loss': array([-1.27196621, -1.27239171, -2.12791136, -2.56800763, -2.06056463,\n",
       "          -2.58639782, -2.05999307, -1.21133481, -1.21263551, -2.12598623,\n",
       "          -2.34043061, -2.52138238, -2.56542734, -2.81679262, -2.27013395,\n",
       "          -2.26134641, -1.27152593, -2.81050181, -1.21751645, -1.27236615,\n",
       "          -2.58616735, -2.86650145, -2.3262903 , -2.80684147, -2.06276859,\n",
       "          -2.65523024, -2.32934943, -2.33084655, -1.27430119, -2.51019626]),\n",
       "   'split2_train_Log_Loss': array([-1.27429378, -1.27225439, -2.13480087, -2.57522915, -2.07155341,\n",
       "          -2.59719946, -2.07264742, -1.21479289, -1.21097302, -2.13794108,\n",
       "          -2.34400049, -2.53007393, -2.56874577, -2.80870013, -2.27151825,\n",
       "          -2.27143907, -1.27742347, -2.80800905, -1.21334015, -1.28213457,\n",
       "          -2.5894684 , -2.85390837, -2.33162884, -2.80211151, -2.07012021,\n",
       "          -2.64791871, -2.33784677, -2.33094245, -1.27756431, -2.50995404]),\n",
       "   'mean_train_Log_Loss': array([-1.27452074, -1.2741447 , -2.13378268, -2.57207089, -2.06915742,\n",
       "          -2.59185433, -2.07211541, -1.21607271, -1.21300311, -2.13363396,\n",
       "          -2.34600686, -2.52913565, -2.56981478, -2.8119677 , -2.27192915,\n",
       "          -2.27116424, -1.27686182, -2.81070302, -1.21609067, -1.27836131,\n",
       "          -2.59050939, -2.86298769, -2.33208653, -2.80611964, -2.06729097,\n",
       "          -2.65321387, -2.3357158 , -2.33392142, -1.27892994, -2.51004488]),\n",
       "   'std_train_Log_Loss': array([0.00218433, 0.0025768 , 0.00443704, 0.00301683, 0.00627102,\n",
       "          0.00441045, 0.00968797, 0.00448325, 0.00182623, 0.00542214,\n",
       "          0.00555627, 0.00598436, 0.00408922, 0.00348244, 0.00165916,\n",
       "          0.00790642, 0.0041465 , 0.00228619, 0.00194535, 0.00428627,\n",
       "          0.00403791, 0.00647446, 0.00493009, 0.00302136, 0.00323126,\n",
       "          0.00377955, 0.00458295, 0.0042809 , 0.00444308, 0.00010775])},\n",
       "  {'n_estimators': 250,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40},\n",
       "  8,\n",
       "  -1.6771477773620214),\n",
       " 'KNeighborsClassifier_V01_PCA_80': ({'mean_fit_time': array([0.03424255, 0.03889592, 0.03723383, 0.03623645, 0.04288586,\n",
       "          0.03823137, 0.04953376, 0.04055794, 0.01762033, 0.04986707,\n",
       "          0.0332435 , 0.01828535, 0.039229  , 0.03989244, 0.01795181,\n",
       "          0.04122368, 0.03557118, 0.03789941, 0.03723407, 0.03690155,\n",
       "          0.01795228, 0.01762017, 0.03656872, 0.01994673, 0.02027909,\n",
       "          0.01795236, 0.04122345, 0.03623676, 0.03656888, 0.04355049]),\n",
       "   'std_fit_time': array([0.00047058, 0.00354995, 0.00169478, 0.00261786, 0.01199578,\n",
       "          0.00248776, 0.0150448 , 0.00384891, 0.00094038, 0.01835371,\n",
       "          0.00093943, 0.00124373, 0.00261814, 0.00495411, 0.0008143 ,\n",
       "          0.00756676, 0.00384773, 0.00423177, 0.00235011, 0.00081381,\n",
       "          0.00081459, 0.00046957, 0.00124288, 0.00215501, 0.00047008,\n",
       "          0.0008142 , 0.00964614, 0.00188009, 0.00046952, 0.01011603]),\n",
       "   'mean_score_time': array([ 9.19109941,  9.52155026, 10.17779557,  8.98132769,  8.16683706,\n",
       "           9.96270363, 10.05312904,  9.52254677,  1.36767753,  9.15120657,\n",
       "           7.25760142,  1.28223983,  9.41716123,  9.82839656,  1.33011158,\n",
       "           9.57540528,  7.58838375,  7.86265071,  8.09835354,  9.38325198,\n",
       "           1.28822319,  1.01794553,  9.28850468,  1.27858265,  1.26794489,\n",
       "           1.12465954,  8.18545469,  7.74263803,  9.63325206,  9.41417019]),\n",
       "   'std_score_time': array([0.05725964, 0.0789462 , 0.6276611 , 0.12747732, 0.05932956,\n",
       "          0.52458675, 0.5509642 , 0.15369561, 0.0736161 , 0.16752492,\n",
       "          0.22230984, 0.03874918, 0.14039011, 0.38935763, 0.04832258,\n",
       "          0.30458476, 0.22402838, 0.10580615, 0.06186651, 0.10850499,\n",
       "          0.0075659 , 0.02823548, 0.07536961, 0.02495333, 0.07317222,\n",
       "          0.05421403, 0.05948578, 0.41979029, 0.00850238, 0.17160653]),\n",
       "   'param_weights': masked_array(data=['uniform', 'distance', 'distance', 'distance',\n",
       "                      'uniform', 'distance', 'uniform', 'distance',\n",
       "                      'distance', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'distance', 'distance',\n",
       "                      'distance', 'uniform', 'uniform', 'distance',\n",
       "                      'distance', 'distance', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'distance', 'distance',\n",
       "                      'uniform'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[5, 3, 3, 8, 3, 6, 6, 7, 8, 4, 8, 7, 3, 7, 6, 7, 3, 5,\n",
       "                      7, 5, 7, 3, 8, 5, 8, 3, 6, 6, 5, 8],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['kd_tree', 'auto', 'kd_tree', 'ball_tree', 'ball_tree',\n",
       "                      'kd_tree', 'auto', 'auto', 'brute', 'kd_tree',\n",
       "                      'ball_tree', 'brute', 'kd_tree', 'kd_tree', 'brute',\n",
       "                      'kd_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                      'auto', 'brute', 'brute', 'kd_tree', 'brute', 'brute',\n",
       "                      'brute', 'ball_tree', 'ball_tree', 'auto', 'auto'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'auto'}],\n",
       "   'split0_test_Accuracy': array([0.63571172, 0.68949444, 0.68949444, 0.66260308, 0.64467551,\n",
       "          0.66798136, 0.63499462, 0.66439584, 0.66260308, 0.63750448,\n",
       "          0.62352098, 0.62961635, 0.64467551, 0.62961635, 0.66798136,\n",
       "          0.66439584, 0.68949444, 0.67049122, 0.62961635, 0.63571172,\n",
       "          0.66439584, 0.68949444, 0.66260308, 0.63571172, 0.62352098,\n",
       "          0.64467551, 0.63499462, 0.66798136, 0.67049122, 0.62352098]),\n",
       "   'split1_test_Accuracy': array([0.64105339, 0.67821068, 0.67821068, 0.64790765, 0.6468254 ,\n",
       "          0.66378066, 0.63167388, 0.65295815, 0.64790765, 0.64033189,\n",
       "          0.61652237, 0.62481962, 0.6468254 , 0.62481962, 0.66378066,\n",
       "          0.65295815, 0.67821068, 0.66955267, 0.62481962, 0.64105339,\n",
       "          0.65295815, 0.67821068, 0.64790765, 0.64105339, 0.61652237,\n",
       "          0.6468254 , 0.63167388, 0.66378066, 0.66955267, 0.61652237]),\n",
       "   'split2_test_Accuracy': array([0.63600145, 0.67765302, 0.67765302, 0.65809489, 0.64650489,\n",
       "          0.67077146, 0.6345527 , 0.66751177, 0.65809489, 0.64143426,\n",
       "          0.62477363, 0.63129301, 0.64650489, 0.63129301, 0.67077146,\n",
       "          0.66751177, 0.67765302, 0.67113365, 0.63129301, 0.63600145,\n",
       "          0.66751177, 0.67765302, 0.65809489, 0.63600145, 0.62477363,\n",
       "          0.64650489, 0.6345527 , 0.67077146, 0.67113365, 0.62477363]),\n",
       "   'mean_test_Accuracy': array([0.63758712, 0.68180726, 0.68180726, 0.65621245, 0.64599856,\n",
       "          0.66750781, 0.63374189, 0.6616198 , 0.65621245, 0.63975006,\n",
       "          0.62160538, 0.62857486, 0.64599856, 0.62857486, 0.66750781,\n",
       "          0.6616198 , 0.68180726, 0.67039173, 0.62857486, 0.63758712,\n",
       "          0.6616198 , 0.68180726, 0.65621245, 0.63758712, 0.62160538,\n",
       "          0.64599856, 0.63374189, 0.66750781, 0.67039173, 0.62160538]),\n",
       "   'std_test_Accuracy': array([0.00245255, 0.00546245, 0.00546245, 0.0061511 , 0.00094838,\n",
       "          0.00286988, 0.00147261, 0.00625222, 0.0061511 , 0.00165644,\n",
       "          0.00362852, 0.0027408 , 0.00094838, 0.0027408 , 0.00286988,\n",
       "          0.00625222, 0.00546245, 0.00064842, 0.0027408 , 0.00245255,\n",
       "          0.00625222, 0.00546245, 0.0061511 , 0.00245255, 0.00362852,\n",
       "          0.00094838, 0.00147261, 0.00286988, 0.00064842, 0.00362852]),\n",
       "   'rank_test_Accuracy': array([20,  1,  1, 13, 16,  7, 23, 10, 13, 19, 28, 25, 16, 25,  7, 10,  1,\n",
       "           5, 25, 20, 10,  1, 13, 20, 28, 16, 23,  7,  5, 28]),\n",
       "   'split0_train_Accuracy': array([0.78185433, 1.        , 1.        , 1.        , 0.8250497 ,\n",
       "          1.        , 0.76287728, 1.        , 1.        , 0.80191578,\n",
       "          0.73667088, 0.74914151, 0.8250497 , 0.74914151, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.74914151, 0.78185433,\n",
       "          1.        , 1.        , 1.        , 0.78185433, 0.73667088,\n",
       "          0.8250497 , 0.76287728, 1.        , 1.        , 0.73667088]),\n",
       "   'split1_train_Accuracy': array([0.78324324, 1.        , 1.        , 1.        , 0.82558559,\n",
       "          1.        , 0.76756757, 1.        , 1.        , 0.79927928,\n",
       "          0.74072072, 0.7572973 , 0.82558559, 0.7572973 , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.7572973 , 0.78324324,\n",
       "          1.        , 1.        , 1.        , 0.78324324, 0.74072072,\n",
       "          0.82558559, 0.76756757, 1.        , 1.        , 0.74072072]),\n",
       "   'split2_train_Accuracy': array([0.78421147, 1.        , 1.        , 1.        , 0.83420248,\n",
       "          1.        , 0.76676857, 1.        , 1.        , 0.80758856,\n",
       "          0.74087394, 0.75364143, 0.83420248, 0.75364143, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.75364143, 0.78421147,\n",
       "          1.        , 1.        , 1.        , 0.78421147, 0.74087394,\n",
       "          0.83420248, 0.76676857, 1.        , 1.        , 0.74087394]),\n",
       "   'mean_train_Accuracy': array([0.78310301, 1.        , 1.        , 1.        , 0.82827926,\n",
       "          1.        , 0.76573781, 1.        , 1.        , 0.80292787,\n",
       "          0.73942185, 0.75336008, 0.82827926, 0.75336008, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.75336008, 0.78310301,\n",
       "          1.        , 1.        , 1.        , 0.78310301, 0.73942185,\n",
       "          0.82827926, 0.76573781, 1.        , 1.        , 0.73942185]),\n",
       "   'std_train_Accuracy': array([0.0009674 , 0.        , 0.        , 0.        , 0.00419406,\n",
       "          0.        , 0.00204883, 0.        , 0.        , 0.00346692,\n",
       "          0.00194623, 0.00333552, 0.00419406, 0.00333552, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00333552, 0.0009674 ,\n",
       "          0.        , 0.        , 0.        , 0.0009674 , 0.00194623,\n",
       "          0.00419406, 0.00204883, 0.        , 0.        , 0.00194623]),\n",
       "   'split0_test_F1': array([0.63599737, 0.68956887, 0.68956887, 0.65987409, 0.64505679,\n",
       "          0.66657884, 0.63448907, 0.66215282, 0.65987409, 0.63795194,\n",
       "          0.62125747, 0.62751593, 0.64505679, 0.62751593, 0.66657884,\n",
       "          0.66215282, 0.68956887, 0.67001691, 0.62751593, 0.63599737,\n",
       "          0.66215282, 0.68956887, 0.65987409, 0.63599737, 0.62125747,\n",
       "          0.64505679, 0.63448907, 0.66657884, 0.67001691, 0.62125747]),\n",
       "   'split1_test_F1': array([0.63771791, 0.67702659, 0.67702659, 0.64362231, 0.64717646,\n",
       "          0.66115654, 0.62842835, 0.64930006, 0.64362231, 0.6388591 ,\n",
       "          0.61144939, 0.61992804, 0.64717646, 0.61992804, 0.66115654,\n",
       "          0.64930006, 0.67702659, 0.66720404, 0.61992804, 0.63771791,\n",
       "          0.64930006, 0.67702659, 0.64362231, 0.63771791, 0.61144939,\n",
       "          0.64717646, 0.62842835, 0.66115654, 0.66720404, 0.61144939]),\n",
       "   'split2_test_F1': array([0.63532652, 0.67695677, 0.67695677, 0.656376  , 0.64669667,\n",
       "          0.66895096, 0.63270586, 0.66569069, 0.656376  , 0.64002513,\n",
       "          0.62257978, 0.62897494, 0.64669667, 0.62897494, 0.66895096,\n",
       "          0.66569069, 0.67695677, 0.67029233, 0.62897494, 0.63532652,\n",
       "          0.66569069, 0.67695677, 0.656376  , 0.63532652, 0.62257978,\n",
       "          0.64669667, 0.63270586, 0.66895096, 0.67029233, 0.62257978]),\n",
       "   'mean_test_F1': array([0.6363479 , 0.68120679, 0.68120679, 0.65330017, 0.6463069 ,\n",
       "          0.66555971, 0.63187867, 0.65904542, 0.65330017, 0.63894194,\n",
       "          0.61842917, 0.62547251, 0.6463069 , 0.62547251, 0.66555971,\n",
       "          0.65904542, 0.68120679, 0.66917134, 0.62547251, 0.6363479 ,\n",
       "          0.65904542, 0.68120679, 0.65330017, 0.6363479 , 0.61842917,\n",
       "          0.6463069 , 0.63187867, 0.66555971, 0.66917134, 0.61842917]),\n",
       "   'std_test_F1': array([0.00100622, 0.00593695, 0.00593695, 0.00698713, 0.00090885,\n",
       "          0.00325908, 0.00254481, 0.00703715, 0.00698713, 0.00084854,\n",
       "          0.00496224, 0.00396344, 0.00090885, 0.00396344, 0.00325908,\n",
       "          0.00703715, 0.00593695, 0.00139488, 0.00396344, 0.00100622,\n",
       "          0.00703715, 0.00593695, 0.00698713, 0.00100622, 0.00496224,\n",
       "          0.00090885, 0.00254481, 0.00325908, 0.00139488, 0.00496224]),\n",
       "   'rank_test_F1': array([20,  1,  1, 13, 16,  7, 23, 10, 13, 19, 28, 25, 16, 25,  7, 10,  1,\n",
       "           5, 25, 20, 10,  1, 13, 20, 28, 16, 23,  7,  5, 28]),\n",
       "   'split0_train_F1': array([0.78152488, 1.        , 1.        , 1.        , 0.82556651,\n",
       "          1.        , 0.76238113, 1.        , 1.        , 0.8017024 ,\n",
       "          0.7353548 , 0.74813942, 0.82556651, 0.74813942, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.74813942, 0.78152488,\n",
       "          1.        , 1.        , 1.        , 0.78152488, 0.7353548 ,\n",
       "          0.82556651, 0.76238113, 1.        , 1.        , 0.7353548 ]),\n",
       "   'split1_train_F1': array([0.78321435, 1.        , 1.        , 1.        , 0.82599695,\n",
       "          1.        , 0.76674947, 1.        , 1.        , 0.79925569,\n",
       "          0.73913884, 0.75617171, 0.82599695, 0.75617171, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.75617171, 0.78321435,\n",
       "          1.        , 1.        , 1.        , 0.78321435, 0.73913884,\n",
       "          0.82599695, 0.76674947, 1.        , 1.        , 0.73913884]),\n",
       "   'split2_train_F1': array([0.78422254, 1.        , 1.        , 1.        , 0.83468167,\n",
       "          1.        , 0.76665423, 1.        , 1.        , 0.80783528,\n",
       "          0.73976521, 0.75291109, 0.83468167, 0.75291109, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.75291109, 0.78422254,\n",
       "          1.        , 1.        , 1.        , 0.78422254, 0.73976521,\n",
       "          0.83468167, 0.76665423, 1.        , 1.        , 0.73976521]),\n",
       "   'mean_train_F1': array([0.78298726, 1.        , 1.        , 1.        , 0.82874838,\n",
       "          1.        , 0.76526161, 1.        , 1.        , 0.80293112,\n",
       "          0.73808628, 0.75240741, 0.82874838, 0.75240741, 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.75240741, 0.78298726,\n",
       "          1.        , 1.        , 1.        , 0.78298726, 0.73808628,\n",
       "          0.82874838, 0.76526161, 1.        , 1.        , 0.73808628]),\n",
       "   'std_train_F1': array([0.00111296, 0.        , 0.        , 0.        , 0.00419915,\n",
       "          0.        , 0.00203718, 0.        , 0.        , 0.00360875,\n",
       "          0.0019483 , 0.00329845, 0.00419915, 0.00329845, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00329845, 0.00111296,\n",
       "          0.        , 0.        , 0.        , 0.00111296, 0.0019483 ,\n",
       "          0.00419915, 0.00203718, 0.        , 0.        , 0.0019483 ]),\n",
       "   'split0_test_Log_Loss': array([-4.93676528, -6.23929343, -6.23929343, -3.78070695, -6.25925537,\n",
       "          -4.43553148, -4.46930178, -4.11337899, -3.78070695, -5.47648647,\n",
       "          -3.82016488, -4.14977237, -6.25925537, -4.14977237, -4.43553148,\n",
       "          -4.11337899, -6.23929343, -4.90678316, -4.14977237, -4.93676528,\n",
       "          -4.11337899, -6.23929343, -3.78070695, -4.93676528, -3.82016488,\n",
       "          -6.25925537, -4.46930178, -4.43553148, -4.90678316, -3.82016488]),\n",
       "   'split1_test_Log_Loss': array([-5.15852633, -6.5954221 , -6.5954221 , -4.13006017, -6.61440838,\n",
       "          -4.80069558, -4.83346657, -4.43229122, -4.13006017, -5.77571158,\n",
       "          -4.16813326, -4.46774369, -6.61440838, -4.46774369, -4.80069558,\n",
       "          -4.43229122, -6.5954221 , -5.13006617, -4.46774369, -5.15852633,\n",
       "          -4.43229122, -6.5954221 , -4.13006017, -5.15852633, -4.16813326,\n",
       "          -6.61440838, -4.83346657, -4.80069558, -5.13006617, -4.16813326]),\n",
       "   'split2_test_Log_Loss': array([-5.2465367 , -6.6247789 , -6.6247789 , -4.1453833 , -6.64336028,\n",
       "          -4.71517859, -4.74844395, -4.36686829, -4.1453833 , -5.80676058,\n",
       "          -4.18541372, -4.40382476, -6.64336028, -4.40382476, -4.71517859,\n",
       "          -4.36686829, -6.6247789 , -5.21671712, -4.40382476, -5.2465367 ,\n",
       "          -4.36686829, -6.6247789 , -4.1453833 , -5.2465367 , -4.18541372,\n",
       "          -6.64336028, -4.74844395, -4.71517859, -5.21671712, -4.18541372]),\n",
       "   'mean_test_Log_Loss': array([-5.11340557, -6.48581038, -6.48581038, -4.01806318, -6.50498931,\n",
       "          -4.64994395, -4.68321386, -4.30370688, -4.01806318, -5.6857317 ,\n",
       "          -4.05724976, -4.33997366, -6.50498931, -4.33997366, -4.64994395,\n",
       "          -4.30370688, -6.48581038, -5.08398433, -4.33997366, -5.11340557,\n",
       "          -4.30370688, -6.48581038, -4.01806318, -5.11340557, -4.05724976,\n",
       "          -6.50498931, -4.68321386, -4.64994395, -5.08398433, -4.05724976]),\n",
       "   'std_test_Log_Loss': array([0.13044253, 0.17542997, 0.17542997, 0.16863308, 0.17486413,\n",
       "          0.15616933, 0.15577808, 0.13773557, 0.16863308, 0.14909751,\n",
       "          0.16847205, 0.1375299 , 0.17486413, 0.1375299 , 0.15616933,\n",
       "          0.13773557, 0.17542997, 0.13067451, 0.1375299 , 0.13044253,\n",
       "          0.13773557, 0.17542997, 0.16863308, 0.13044253, 0.16847205,\n",
       "          0.17486413, 0.15577808, 0.15616933, 0.13067451, 0.16847205]),\n",
       "   'rank_test_Log_Loss': array([20, 24, 24,  1, 28, 13, 16,  7,  1, 23,  4, 10, 28, 10, 13,  7, 24,\n",
       "          18, 10, 20,  7, 24,  1, 20,  4, 28, 16, 13, 18,  4]),\n",
       "   'split0_train_Log_Loss': array([-5.62038591e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -3.64657792e-01, -3.77251697e-14, -6.34303227e-01, -3.77251697e-14,\n",
       "          -3.77688966e-08, -4.74779464e-01, -7.48754853e-01, -6.97859548e-01,\n",
       "          -3.64657792e-01, -6.97859548e-01, -2.56690613e-08, -3.77251697e-14,\n",
       "          -3.77251697e-14, -3.77251697e-14, -6.97859548e-01, -5.62038591e-01,\n",
       "          -3.17798009e-08, -8.75357104e-09, -3.77251697e-14, -5.62038591e-01,\n",
       "          -7.48754853e-01, -3.64657792e-01, -6.34303227e-01, -3.77251697e-14,\n",
       "          -3.77251697e-14, -7.48754853e-01]),\n",
       "   'split1_train_Log_Loss': array([-5.53192028e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -3.59805912e-01, -3.77252183e-14, -6.23208766e-01, -3.77252183e-14,\n",
       "          -3.71854818e-08, -4.67010000e-01, -7.38123701e-01, -6.83953852e-01,\n",
       "          -3.59805912e-01, -6.83953852e-01, -2.52189573e-08, -3.77252183e-14,\n",
       "          -3.77252183e-14, -3.77252183e-14, -6.83953852e-01, -5.53192028e-01,\n",
       "          -3.11323306e-08, -8.75938308e-09, -3.77252183e-14, -5.53192028e-01,\n",
       "          -7.38123701e-01, -3.59805912e-01, -6.23208766e-01, -3.77252183e-14,\n",
       "          -3.77252183e-14, -7.38123701e-01]),\n",
       "   'split2_train_Log_Loss': array([-5.54394622e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -3.58139400e-01, -3.77251228e-14, -6.24625035e-01, -3.77251228e-14,\n",
       "          -3.71831781e-08, -4.68155509e-01, -7.41265134e-01, -6.86656921e-01,\n",
       "          -3.58139400e-01, -6.86656921e-01, -2.49748880e-08, -3.77251228e-14,\n",
       "          -3.77251228e-14, -3.77251228e-14, -6.86656921e-01, -5.54394622e-01,\n",
       "          -3.09884847e-08, -8.59798149e-09, -3.77251228e-14, -5.54394622e-01,\n",
       "          -7.41265134e-01, -3.58139400e-01, -6.24625035e-01, -3.77251228e-14,\n",
       "          -3.77251228e-14, -7.41265134e-01]),\n",
       "   'mean_train_Log_Loss': array([-5.56541747e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -3.60867701e-01, -3.77251703e-14, -6.27379009e-01, -3.77251703e-14,\n",
       "          -3.73791855e-08, -4.69981657e-01, -7.42714563e-01, -6.89490107e-01,\n",
       "          -3.60867701e-01, -6.89490107e-01, -2.52876355e-08, -3.77251703e-14,\n",
       "          -3.77251703e-14, -3.77251703e-14, -6.89490107e-01, -5.56541747e-01,\n",
       "          -3.13002054e-08, -8.70364520e-09, -3.77251703e-14, -5.56541747e-01,\n",
       "          -7.42714563e-01, -3.60867701e-01, -6.27379009e-01, -3.77251703e-14,\n",
       "          -3.77251703e-14, -7.42714563e-01]),\n",
       "   'std_train_Log_Loss': array([3.91773991e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          2.76500819e-03, 3.89952081e-20, 4.93018220e-03, 3.89952081e-20,\n",
       "          2.75568998e-10, 3.42464176e-03, 4.45952029e-03, 6.02009412e-03,\n",
       "          2.76500819e-03, 6.02009412e-03, 2.87525866e-10, 3.89952081e-20,\n",
       "          3.89952081e-20, 3.89952081e-20, 6.02009412e-03, 3.91773991e-03,\n",
       "          3.44172223e-10, 7.47531950e-11, 3.89952081e-20, 3.91773991e-03,\n",
       "          4.45952029e-03, 2.76500819e-03, 4.93018220e-03, 3.89952081e-20,\n",
       "          3.89952081e-20, 4.45952029e-03])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "  3,\n",
       "  -4.018063181069744),\n",
       " 'MLPClassifier_V01_PCA_80': ({'mean_fit_time': array([25.3216509 , 14.14851578, 18.41178672,  5.5421857 , 16.22363631,\n",
       "           4.45509235, 16.40515041, 13.56208229,  3.84339341,  6.8756214 ,\n",
       "          12.26488527,  7.90520342, 20.52979199, 20.03843904, 20.67872723,\n",
       "          17.29743195, 11.4593699 , 22.2747945 , 10.5228734 , 20.25884994,\n",
       "           0.61269625,  3.53222664, 17.35793686, 21.47692736,  4.03853917,\n",
       "          18.61856755, 19.97228161, 19.63485082, 16.54145201,  5.62895354]),\n",
       "   'std_fit_time': array([0.25587561, 0.43179662, 0.53256594, 0.6125177 , 1.40564918,\n",
       "          0.54600375, 0.16158178, 3.05997473, 0.44867239, 0.27488929,\n",
       "          0.24887371, 0.78657836, 1.06272524, 0.81376136, 0.15800239,\n",
       "          0.4796257 , 0.17702206, 2.0889812 , 0.33702548, 0.08923784,\n",
       "          0.02451563, 0.02303711, 0.0590724 , 0.74994871, 0.12533503,\n",
       "          0.29160115, 0.10760885, 0.02258653, 0.68982153, 0.37163005]),\n",
       "   'mean_score_time': array([0.07347051, 0.05319095, 0.07280501, 0.05651546, 0.05784527,\n",
       "          0.04986644, 0.06449469, 0.04355065, 0.06981325, 0.04022574,\n",
       "          0.05352203, 0.0698127 , 0.05917645, 0.05651609, 0.05884218,\n",
       "          0.06083759, 0.05219388, 0.06582451, 0.04188824, 0.0521938 ,\n",
       "          0.08111652, 0.06648954, 0.05418865, 0.06648898, 0.04421504,\n",
       "          0.05784607, 0.06482673, 0.05684876, 0.04853694, 0.06017296]),\n",
       "   'std_score_time': array([0.00329079, 0.00094004, 0.01095596, 0.00529833, 0.00140978,\n",
       "          0.00162898, 0.01081348, 0.00448545, 0.00776847, 0.00169604,\n",
       "          0.00248848, 0.00453377, 0.00094004, 0.00124309, 0.00215387,\n",
       "          0.01017085, 0.00261812, 0.00162879, 0.00141006, 0.00093999,\n",
       "          0.00417934, 0.00204848, 0.00124358, 0.00286031, 0.00188087,\n",
       "          0.00850166, 0.00141007, 0.00162801, 0.00204884, 0.00093999]),\n",
       "   'param_solver': masked_array(data=['sgd', 'adam', 'sgd', 'lbfgs', 'adam', 'adam', 'adam',\n",
       "                      'adam', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'sgd',\n",
       "                      'sgd', 'sgd', 'adam', 'lbfgs', 'adam', 'adam', 'adam',\n",
       "                      'lbfgs', 'sgd', 'sgd', 'adam', 'lbfgs', 'adam', 'adam',\n",
       "                      'sgd', 'sgd', 'lbfgs'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50, 50, 50), (100, 100), (100, 100), (100, 100),\n",
       "                      (100, 100, 50), (100, 100, 50), (100, 100), (100,),\n",
       "                      (200, 50, 50), (100,), (100, 100), (200, 50),\n",
       "                      (100, 100, 50), (200, 50, 50), (200, 50, 50),\n",
       "                      (100, 100), (200, 50), (100, 100, 50), (100,),\n",
       "                      (200, 50), (200, 50, 50, 50), (200, 50), (200, 50, 50),\n",
       "                      (200, 50), (100,), (200, 50), (200, 50),\n",
       "                      (200, 50, 50, 50), (100, 100), (200, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0205, 0.0228, 0.049, 0.004600000000000001,\n",
       "                      0.049100000000000005, 0.0282, 0.0198, 0.0147, 0.0299,\n",
       "                      0.04410000000000001, 0.0024, 0.0208,\n",
       "                      0.0045000000000000005, 0.032600000000000004, 0.0275,\n",
       "                      0.0396, 0.033, 0.0035, 0.0058000000000000005, 0.0308,\n",
       "                      0.0437, 0.037700000000000004, 0.0197, 0.0284, 0.0299,\n",
       "                      0.013, 0.043500000000000004, 0.0241, 0.0107,\n",
       "                      0.04850000000000001],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['relu', 'relu', 'relu', 'logistic', 'relu', 'identity',\n",
       "                      'logistic', 'tanh', 'tanh', 'identity', 'identity',\n",
       "                      'logistic', 'relu', 'tanh', 'tanh', 'tanh', 'identity',\n",
       "                      'logistic', 'relu', 'tanh', 'logistic', 'logistic',\n",
       "                      'identity', 'logistic', 'logistic', 'tanh', 'logistic',\n",
       "                      'identity', 'relu', 'relu'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0205,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0228,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.049,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.004600000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.049100000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0282,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0198,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0147,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0299,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.04410000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0024,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0208,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0045000000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.032600000000000004,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0275,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0396,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.033,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0035,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0058000000000000005,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0308,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0437,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.037700000000000004,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0197,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0284,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0299,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.013,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.043500000000000004,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0241,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0107,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.04850000000000001,\n",
       "     'activation': 'relu'}],\n",
       "   'split0_test_Accuracy': array([0.65328075, 0.72140552, 0.630692  , 0.66869846, 0.71315884,\n",
       "          0.66188598, 0.73503048, 0.72319828, 0.66941556, 0.6536393 ,\n",
       "          0.65399785, 0.6654715 , 0.64037289, 0.62603084, 0.61276443,\n",
       "          0.75008964, 0.65005378, 0.70025099, 0.72678379, 0.75475081,\n",
       "          0.05593403, 0.05593403, 0.64288275, 0.74291861, 0.69236285,\n",
       "          0.75797777, 0.73933309, 0.64610972, 0.64575117, 0.73861599]),\n",
       "   'split1_test_Accuracy': array([0.6453824 , 0.73629149, 0.63203463, 0.68795094, 0.71789322,\n",
       "          0.6497114 , 0.73665224, 0.72402597, 0.6461039 , 0.66486291,\n",
       "          0.66414141, 0.67099567, 0.63131313, 0.61075036, 0.62518038,\n",
       "          0.7463925 , 0.66414141, 0.68686869, 0.72041847, 0.76226551,\n",
       "          0.05591631, 0.05591631, 0.63455988, 0.7463925 , 0.68578644,\n",
       "          0.74819625, 0.74819625, 0.63600289, 0.63672439, 0.73268398]),\n",
       "   'split2_test_Accuracy': array([0.65411083, 0.73306773, 0.63600145, 0.68779428, 0.71387179,\n",
       "          0.65990583, 0.74900398, 0.72835929, 0.67077146, 0.66497646,\n",
       "          0.65555958, 0.66823615, 0.6403477 , 0.60123144, 0.61861644,\n",
       "          0.75842086, 0.65773271, 0.68199928, 0.73668961, 0.73922492,\n",
       "          0.05613908, 0.05613908, 0.63708801, 0.75660992, 0.67656646,\n",
       "          0.7515393 , 0.74429555, 0.63600145, 0.64795364, 0.74284679]),\n",
       "   'mean_test_Accuracy': array([0.65092526, 0.73023312, 0.63290075, 0.68144677, 0.71497236,\n",
       "          0.65717376, 0.74020668, 0.72518625, 0.66210046, 0.66113915,\n",
       "          0.65789474, 0.66822879, 0.63734679, 0.61271329, 0.61884162,\n",
       "          0.75162221, 0.65729392, 0.68973804, 0.72795001, 0.75210286,\n",
       "          0.05599615, 0.05599615, 0.63818794, 0.74861812, 0.68493151,\n",
       "          0.75258351, 0.74393175, 0.63938957, 0.64347513, 0.73804374]),\n",
       "   'std_test_Accuracy': array([0.00393191, 0.00640371, 0.00225269, 0.00905122, 0.00208467,\n",
       "          0.00533545, 0.00623412, 0.00226124, 0.01131871, 0.00532492,\n",
       "          0.0044605 , 0.00225787, 0.00426415, 0.01022059, 0.00507718,\n",
       "          0.00502317, 0.00576625, 0.00772344, 0.00668514, 0.00957982,\n",
       "          0.00010097, 0.00010097, 0.00348893, 0.00580745, 0.00647817,\n",
       "          0.00406509, 0.00363165, 0.00477115, 0.00485493, 0.0041632 ]),\n",
       "   'rank_test_Accuracy': array([21,  8, 26, 14, 11, 20,  6, 10, 16, 17, 18, 15, 25, 28, 27,  3, 19,\n",
       "          12,  9,  2, 29, 29, 24,  4, 13,  1,  5, 23, 22,  7]),\n",
       "   'split0_train_Accuracy': array([0.83426712, 1.        , 0.73974336, 1.        , 1.        ,\n",
       "          0.74968372, 0.94379179, 0.99873486, 1.        , 0.79866257,\n",
       "          0.7955901 , 1.        , 0.76811856, 0.69275258, 0.70197   ,\n",
       "          1.        , 0.79540936, 0.93511657, 0.99981927, 1.        ,\n",
       "          0.05602747, 0.05602747, 0.7180553 , 0.95481656, 1.        ,\n",
       "          1.        , 0.92933309, 0.71877824, 0.74805711, 1.        ]),\n",
       "   'split1_train_Accuracy': array([0.83783784, 1.        , 0.74504505, 1.        , 1.        ,\n",
       "          0.73567568, 0.94108108, 0.99891892, 1.        , 0.79927928,\n",
       "          0.79477477, 1.        , 0.77981982, 0.6963964 , 0.70288288,\n",
       "          1.        , 0.7954955 , 0.94882883, 0.99981982, 1.        ,\n",
       "          0.05603604, 0.05603604, 0.71945946, 0.94900901, 1.        ,\n",
       "          1.        , 0.92882883, 0.71945946, 0.75243243, 1.        ]),\n",
       "   'split2_train_Accuracy': array([0.86333393, 1.        , 0.74698795, 1.        , 1.        ,\n",
       "          0.74465024, 0.94353534, 0.99856141, 1.        , 0.80057544,\n",
       "          0.80093508, 0.99982018, 0.77072469, 0.6853084 , 0.692861  ,\n",
       "          1.        , 0.79931667, 0.94749146, 0.99982018, 1.        ,\n",
       "          0.05592519, 0.05592519, 0.71875562, 0.95648265, 1.        ,\n",
       "          1.        , 0.92825031, 0.72109333, 0.74968531, 1.        ]),\n",
       "   'mean_train_Accuracy': array([0.8451463 , 1.        , 0.74392545, 1.        , 1.        ,\n",
       "          0.74333654, 0.94280274, 0.9987384 , 1.        , 0.79950576,\n",
       "          0.79709998, 0.99994006, 0.77288769, 0.69148579, 0.69923796,\n",
       "          1.        , 0.79674051, 0.94381229, 0.99981975, 1.        ,\n",
       "          0.05599623, 0.05599623, 0.71875679, 0.95343607, 1.        ,\n",
       "          1.        , 0.92880408, 0.71977701, 0.75005828, 1.        ]),\n",
       "   'std_train_Accuracy': array([1.29429526e-02, 0.00000000e+00, 3.06171540e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.79371208e-03, 1.22188851e-03, 1.45973869e-04,\n",
       "          0.00000000e+00, 7.97176211e-04, 2.73217553e-03, 8.47697394e-05,\n",
       "          5.01589413e-03, 4.61443299e-03, 4.52456858e-03, 0.00000000e+00,\n",
       "          1.82196000e-03, 6.17299038e-03, 3.74404687e-07, 0.00000000e+00,\n",
       "          5.03546264e-05, 5.03546264e-05, 5.73244449e-04, 3.20344814e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.42388439e-04, 9.71437945e-04,\n",
       "          1.80558222e-03, 0.00000000e+00]),\n",
       "   'split0_test_F1': array([0.64936688, 0.72125673, 0.62529543, 0.66649592, 0.71284663,\n",
       "          0.65496673, 0.73196869, 0.72147283, 0.66729236, 0.65014628,\n",
       "          0.65069073, 0.66575799, 0.6332174 , 0.61239441, 0.60036353,\n",
       "          0.74964379, 0.64728943, 0.69616819, 0.726432  , 0.75297717,\n",
       "          0.00592578, 0.00592578, 0.63751168, 0.73915589, 0.69087516,\n",
       "          0.75637944, 0.73710585, 0.64079075, 0.63873845, 0.73834122]),\n",
       "   'split1_test_F1': array([0.64406102, 0.73531859, 0.62562881, 0.68606867, 0.71730737,\n",
       "          0.64831276, 0.73520195, 0.72304578, 0.64733199, 0.66174444,\n",
       "          0.66111123, 0.67152662, 0.6256491 , 0.59434968, 0.61205206,\n",
       "          0.74495149, 0.66124379, 0.68466081, 0.7203418 , 0.7599334 ,\n",
       "          0.00592212, 0.00592212, 0.63057746, 0.7450119 , 0.68573877,\n",
       "          0.74741427, 0.74594962, 0.63261431, 0.62899721, 0.73220977]),\n",
       "   'split2_test_F1': array([0.65141539, 0.73386699, 0.63071863, 0.68785381, 0.7127128 ,\n",
       "          0.65503067, 0.74746242, 0.72747684, 0.67091181, 0.6626147 ,\n",
       "          0.65335241, 0.66773715, 0.63414122, 0.58743762, 0.60266539,\n",
       "          0.75769438, 0.65530828, 0.6779322 , 0.73726404, 0.73860507,\n",
       "          0.00596815, 0.00596815, 0.63373713, 0.75468271, 0.6779177 ,\n",
       "          0.75009432, 0.74220677, 0.63330145, 0.6417861 , 0.74305866]),\n",
       "   'mean_test_F1': array([0.64827917, 0.73012436, 0.62720574, 0.6801014 , 0.71428807,\n",
       "          0.65277155, 0.73818604, 0.72398873, 0.66184453, 0.65814621,\n",
       "          0.6550448 , 0.66833611, 0.63100295, 0.59810389, 0.60502059,\n",
       "          0.75075177, 0.65459795, 0.68628499, 0.72799716, 0.75052599,\n",
       "          0.00593862, 0.00593862, 0.63394965, 0.74625784, 0.68486535,\n",
       "          0.75130798, 0.74174399, 0.6355825 , 0.63650483, 0.73786399]),\n",
       "   'std_test_F1': array([3.09619244e-03, 6.32356149e-03, 2.47901292e-03, 9.68694944e-03,\n",
       "          2.13451383e-03, 3.15124509e-03, 6.66860276e-03, 2.54050003e-03,\n",
       "          1.03622974e-02, 5.69083340e-03, 4.42290126e-03, 2.39525182e-03,\n",
       "          3.80245486e-03, 1.05300088e-02, 5.05741708e-03, 5.25443156e-03,\n",
       "          5.72540431e-03, 7.53401007e-03, 6.98803474e-03, 8.86789586e-03,\n",
       "          2.08604460e-05, 2.08604460e-05, 2.83814031e-03, 6.40071560e-03,\n",
       "          5.32663504e-03, 3.76275258e-03, 3.62934320e-03, 3.70832900e-03,\n",
       "          5.44979702e-03, 4.43599919e-03]),\n",
       "   'rank_test_F1': array([21,  8, 26, 14, 11, 20,  6, 10, 16, 17, 18, 15, 25, 28, 27,  2, 19,\n",
       "          12,  9,  3, 29, 29, 24,  4, 13,  1,  5, 23, 22,  7]),\n",
       "   'split0_train_F1': array([0.83147785, 1.        , 0.73511509, 1.        , 1.        ,\n",
       "          0.74620746, 0.94302964, 0.99873388, 1.        , 0.79719338,\n",
       "          0.79408443, 1.        , 0.76328467, 0.68084392, 0.6906498 ,\n",
       "          1.        , 0.79419091, 0.9344096 , 0.99981928, 1.        ,\n",
       "          0.00594507, 0.00594507, 0.71430314, 0.9542685 , 1.        ,\n",
       "          1.        , 0.92890317, 0.71551968, 0.74272234, 1.        ]),\n",
       "   'split1_train_F1': array([0.83666721, 1.        , 0.74070082, 1.        , 1.        ,\n",
       "          0.73473285, 0.94076205, 0.99891877, 1.        , 0.79790132,\n",
       "          0.79356246, 1.        , 0.77595   , 0.68550111, 0.69356317,\n",
       "          1.        , 0.79398457, 0.94860205, 0.99981962, 1.        ,\n",
       "          0.00594684, 0.00594684, 0.7154439 , 0.9484088 , 1.        ,\n",
       "          1.        , 0.9281965 , 0.71489227, 0.74753751, 1.        ]),\n",
       "   'split2_train_F1': array([0.86159378, 1.        , 0.74432129, 1.        , 1.        ,\n",
       "          0.74226525, 0.94306752, 0.99856214, 1.        , 0.79941635,\n",
       "          0.79962104, 0.99982016, 0.76681986, 0.67669948, 0.68327925,\n",
       "          1.        , 0.79801553, 0.94718801, 0.99982017, 1.        ,\n",
       "          0.00592396, 0.00592497, 0.71498323, 0.95636874, 1.        ,\n",
       "          1.        , 0.92770704, 0.71769473, 0.74566053, 1.        ]),\n",
       "   'mean_train_F1': array([0.84324628, 1.        , 0.74004573, 1.        , 1.        ,\n",
       "          0.74106852, 0.9422864 , 0.99873827, 1.        , 0.79817035,\n",
       "          0.79575598, 0.99994005, 0.76868484, 0.68101484, 0.68916407,\n",
       "          1.        , 0.79539701, 0.94339989, 0.99981969, 1.        ,\n",
       "          0.00593862, 0.00593896, 0.71491009, 0.95301535, 1.        ,\n",
       "          1.        , 0.9282689 , 0.71603556, 0.74530679, 1.        ]),\n",
       "   'std_train_F1': array([1.31454807e-02, 0.00000000e+00, 3.78684992e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.76030849e-03, 1.07799276e-03, 1.45627778e-04,\n",
       "          0.00000000e+00, 9.27248489e-04, 2.74130462e-03, 8.47792607e-05,\n",
       "          5.33611979e-03, 3.59528256e-03, 4.32783735e-03, 0.00000000e+00,\n",
       "          1.85349425e-03, 6.38324811e-03, 3.64857164e-07, 0.00000000e+00,\n",
       "          1.03944448e-05, 9.91999337e-06, 4.68573799e-04, 3.36827903e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.90997096e-04, 1.20084569e-03,\n",
       "          1.98163402e-03, 0.00000000e+00]),\n",
       "   'split0_test_Log_Loss': array([-1.24849083, -1.62354466, -1.2657079 , -2.19621568, -1.73508026,\n",
       "          -1.26695354, -0.92413522, -1.07724268, -2.38446838, -1.65631511,\n",
       "          -1.66154739, -2.14183649, -1.23282729, -1.3291651 , -1.35586128,\n",
       "          -1.01463723, -1.67587544, -1.13465884, -1.37798025, -0.95300861,\n",
       "          -3.61185512, -3.60927197, -1.28703018, -0.86438676, -1.69012349,\n",
       "          -1.04484568, -0.89092842, -1.28019604, -1.23918002, -2.56017236]),\n",
       "   'split1_test_Log_Loss': array([-1.29282109, -1.55844566, -1.27998788, -1.98705131, -1.63875555,\n",
       "          -1.30294555, -0.90607974, -1.0961151 , -2.41003484, -1.50032965,\n",
       "          -1.49984661, -2.10232955, -1.31274045, -1.36551009, -1.35141488,\n",
       "          -1.01231004, -1.49599116, -1.21085456, -1.36256604, -0.93644847,\n",
       "          -3.61188762, -3.60928011, -1.30987328, -0.85356902, -1.89123887,\n",
       "          -1.04731004, -0.86511342, -1.31736909, -1.27735758, -2.57163405]),\n",
       "   'split2_test_Log_Loss': array([-1.2300971 , -1.51444909, -1.24218886, -2.17863895, -1.72887752,\n",
       "          -1.27098825, -0.88418385, -1.01761484, -2.2588704 , -1.52530883,\n",
       "          -1.55013356, -1.91972569, -1.22070172, -1.37382518, -1.3662096 ,\n",
       "          -1.00218011, -1.544844  , -1.22424618, -1.33728374, -1.00186169,\n",
       "          -3.61156163, -3.6087926 , -1.28808398, -0.8486811 , -1.92101894,\n",
       "          -1.00983551, -0.87908597, -1.31786891, -1.20968892, -2.64644046]),\n",
       "   'mean_test_Log_Loss': array([-1.25715442, -1.56566587, -1.26266152, -2.12071304, -1.70093728,\n",
       "          -1.28028083, -0.90486635, -1.06374615, -2.3513146 , -1.56089333,\n",
       "          -1.57072209, -2.05498703, -1.25542289, -1.35608829, -1.35781349,\n",
       "          -1.00972915, -1.57248478, -1.1897616 , -1.35934396, -0.96370059,\n",
       "          -3.61176857, -3.60911564, -1.29498868, -0.85557276, -1.83371808,\n",
       "          -1.03405117, -0.87840064, -1.3050769 , -1.2421124 , -2.59261144]),\n",
       "   'std_test_Log_Loss': array([0.02630162, 0.04483685, 0.01556152, 0.09473426, 0.04401827,\n",
       "          0.01610221, 0.01633534, 0.03340788, 0.06597115, 0.06850836,\n",
       "          0.0676645 , 0.09666644, 0.04080917, 0.01941311, 0.00618894,\n",
       "          0.0054036 , 0.07605901, 0.03950079, 0.01677236, 0.02772799,\n",
       "          0.00014642, 0.00022764, 0.01052811, 0.00656737, 0.10266918,\n",
       "          0.01709262, 0.01056227, 0.017666  , 0.02766663, 0.03821737]),\n",
       "   'rank_test_Log_Loss': array([11, 20, 12, 26, 23, 13,  3,  7, 27, 19, 21, 25, 10, 16, 17,  5, 22,\n",
       "           8, 18,  4, 30, 29, 14,  1, 24,  6,  2, 15,  9, 28]),\n",
       "   'split0_train_Log_Loss': array([-5.92363944e-01, -9.55218392e-03, -9.31630372e-01, -4.29838708e-03,\n",
       "          -8.91594579e-03, -8.32425233e-01, -2.95717323e-01, -8.53693582e-02,\n",
       "          -2.21557595e-03, -6.49545993e-01, -6.55646707e-01, -5.72514855e-03,\n",
       "          -7.94607515e-01, -1.13251009e+00, -1.13098973e+00, -2.27045738e-02,\n",
       "          -6.55247044e-01, -3.16066102e-01, -3.46657601e-02, -1.67098840e-02,\n",
       "          -3.61169919e+00, -3.60884470e+00, -9.45961344e-01, -2.96352153e-01,\n",
       "          -6.31645568e-03, -9.86741760e-03, -3.87739812e-01, -9.24027816e-01,\n",
       "          -8.91997451e-01, -4.00178958e-04]),\n",
       "   'split1_train_Log_Loss': array([-5.80493615e-01, -1.03481007e-02, -8.92351881e-01, -3.27483766e-03,\n",
       "          -1.00798192e-02, -8.61462956e-01, -2.98017354e-01, -8.25850705e-02,\n",
       "          -2.18968044e-03, -6.37403952e-01, -6.43519741e-01, -5.61321027e-03,\n",
       "          -7.71354709e-01, -1.14614523e+00, -1.11681758e+00, -2.28982702e-02,\n",
       "          -6.44990597e-01, -2.60528413e-01, -3.90839770e-02, -1.76467380e-02,\n",
       "          -3.61171987e+00, -3.60886764e+00, -9.28705441e-01, -3.04469081e-01,\n",
       "          -7.58902653e-03, -9.41746451e-03, -3.82658178e-01, -9.19980123e-01,\n",
       "          -8.70657487e-01, -3.21861102e-04]),\n",
       "   'split2_train_Log_Loss': array([-4.97937213e-01, -9.40820205e-03, -8.94363050e-01, -5.08941206e-03,\n",
       "          -9.68534787e-03, -8.30694476e-01, -2.92228082e-01, -8.55593254e-02,\n",
       "          -2.05246444e-03, -6.47433471e-01, -6.52445244e-01, -9.32219060e-03,\n",
       "          -7.91444332e-01, -1.15076065e+00, -1.14482748e+00, -2.28643194e-02,\n",
       "          -6.54215927e-01, -2.63762897e-01, -3.88300711e-02, -1.69070082e-02,\n",
       "          -3.61185407e+00, -3.60903747e+00, -9.33166954e-01, -2.86824347e-01,\n",
       "          -9.20228668e-03, -9.89479388e-03, -3.87731464e-01, -9.19461297e-01,\n",
       "          -8.77016323e-01, -3.78256144e-04]),\n",
       "   'mean_train_Log_Loss': array([-5.56931591e-01, -9.76949556e-03, -9.06115101e-01, -4.22087893e-03,\n",
       "          -9.56037094e-03, -8.41527555e-01, -2.95320920e-01, -8.45045847e-02,\n",
       "          -2.15257361e-03, -6.44794472e-01, -6.50537231e-01, -6.88684981e-03,\n",
       "          -7.85802186e-01, -1.14313866e+00, -1.13087826e+00, -2.28223878e-02,\n",
       "          -6.51484523e-01, -2.80119137e-01, -3.75266027e-02, -1.70878768e-02,\n",
       "          -3.61175771e+00, -3.60891661e+00, -9.35944580e-01, -2.95881860e-01,\n",
       "          -7.70258963e-03, -9.72655866e-03, -3.86043151e-01, -9.21156412e-01,\n",
       "          -8.79890420e-01, -3.66765401e-04]),\n",
       "   'std_train_Log_Loss': array([4.19958617e-02, 4.13336534e-04, 1.80606936e-02, 7.42821510e-04,\n",
       "          4.83297513e-04, 1.41141546e-02, 2.38002367e-03, 1.35951538e-03,\n",
       "          7.15729414e-05, 5.29657296e-03, 5.13135530e-03, 1.72265224e-03,\n",
       "          1.02972037e-02, 7.74813129e-03, 1.14352654e-02, 8.44522497e-05,\n",
       "          4.61115366e-03, 2.54526182e-02, 2.02557522e-03, 4.03285604e-04,\n",
       "          6.86599985e-05, 8.59744221e-05, 7.31336432e-03, 7.21110439e-03,\n",
       "          1.18086905e-03, 2.18848137e-04, 2.39353999e-03, 2.04140742e-03,\n",
       "          8.94590551e-03, 3.29893873e-05])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (200, 50),\n",
       "   'alpha': 0.0284,\n",
       "   'activation': 'logistic'},\n",
       "  23,\n",
       "  -0.8555727577123722),\n",
       " 'LogisticRegression_V01_PCA_5components': ({'mean_fit_time': array([0.52160573, 0.15059725, 0.30751077, 0.77725585, 0.09208608,\n",
       "          0.09108941, 0.92452828, 0.083776  , 0.09275119, 0.75531491,\n",
       "          0.45012895, 0.87998112, 0.34773596, 0.77293324, 0.29620632,\n",
       "          0.09208695, 0.73304001, 0.79853169, 0.96375624, 0.36103455,\n",
       "          0.72838569, 0.81315883, 0.08610288, 0.72938299, 0.65890463,\n",
       "          0.09507895, 0.08676712, 0.6984663 , 0.63530127, 0.75365233]),\n",
       "   'std_fit_time': array([0.00826407, 0.00373174, 0.01671519, 0.02649138, 0.00047019,\n",
       "          0.00169503, 0.06083454, 0.00162869, 0.01058708, 0.01852146,\n",
       "          0.01466612, 0.03171067, 0.01741426, 0.04746162, 0.01068009,\n",
       "          0.00188132, 0.00564099, 0.03621083, 0.04762429, 0.02055227,\n",
       "          0.02664052, 0.04259732, 0.00367261, 0.02242532, 0.0066332 ,\n",
       "          0.00773985, 0.00282103, 0.00523512, 0.06506442, 0.05829853]),\n",
       "   'mean_score_time': array([0.02759329, 0.03191471, 0.02859036, 0.02859004, 0.02792605,\n",
       "          0.02726022, 0.03058545, 0.0262634 , 0.03058521, 0.02825753,\n",
       "          0.0285906 , 0.02726094, 0.02892288, 0.0275929 , 0.03357704,\n",
       "          0.03690179, 0.02726054, 0.02659575, 0.02659535, 0.02825761,\n",
       "          0.02759298, 0.02792509, 0.02792565, 0.02825777, 0.04255311,\n",
       "          0.04720743, 0.02892335, 0.02726086, 0.02925531, 0.02825761]),\n",
       "   'std_score_time': array([0.0004698 , 0.00785345, 0.00169448, 0.00124377, 0.00215424,\n",
       "          0.00094032, 0.00329063, 0.00046991, 0.00329118, 0.00124396,\n",
       "          0.00308264, 0.00047025, 0.00215483, 0.00093987, 0.00803368,\n",
       "          0.00495279, 0.00047053, 0.00094027, 0.00046968, 0.00046952,\n",
       "          0.00046991, 0.00141035, 0.00081439, 0.00124377, 0.02070208,\n",
       "          0.02377453, 0.00162879, 0.00047064, 0.00261746, 0.00124394]),\n",
       "   'param_C': masked_array(data=[0.24807378130822674, 0.49113323220006644,\n",
       "                      0.14424971273703227, 0.578399543948392,\n",
       "                      0.18165568578410393, 0.06213004648192029,\n",
       "                      0.4433592455387964, 0.025837334305612095,\n",
       "                      0.06247978894826633, 0.03423378460058229,\n",
       "                      0.20144973677631534, 0.6060694339983912,\n",
       "                      0.1884699887113226, 0.2423605212504863,\n",
       "                      0.19512391140046784, 0.016387588058254233,\n",
       "                      0.014402687378415206, 0.11700359577495421,\n",
       "                      0.14553077150589652, 0.18285060358489055,\n",
       "                      0.06225956296943237, 0.14204537452979407,\n",
       "                      0.026454209110596462, 0.12656143102163211,\n",
       "                      0.18143923467004086, 0.042013781482899075,\n",
       "                      0.013126733044705364, 0.10917555170512067,\n",
       "                      0.0494624155026132, 0.07974513339856973],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, None, None, 'balanced', 'balanced', None,\n",
       "                      None, None, 'balanced', 'balanced', 'balanced', None,\n",
       "                      None, None, None, 'balanced', 'balanced', 'balanced',\n",
       "                      None, 'balanced', 'balanced', 'balanced', None,\n",
       "                      'balanced', 'balanced', 'balanced', None, 'balanced',\n",
       "                      'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['newton-cg', 'liblinear', 'saga', 'newton-cg',\n",
       "                      'liblinear', 'liblinear', 'newton-cg', 'liblinear',\n",
       "                      'liblinear', 'newton-cg', 'saga', 'newton-cg', 'saga',\n",
       "                      'newton-cg', 'saga', 'liblinear', 'newton-cg',\n",
       "                      'newton-cg', 'newton-cg', 'saga', 'newton-cg',\n",
       "                      'newton-cg', 'liblinear', 'newton-cg', 'saga',\n",
       "                      'liblinear', 'liblinear', 'newton-cg', 'saga',\n",
       "                      'newton-cg'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.16419947984379105, 0.04664729169982079,\n",
       "                      0.18956403072887776, 0.3152014417209951,\n",
       "                      0.24380508693569825, 0.252127085723101,\n",
       "                      0.015975111615315972, 0.1284755697831752,\n",
       "                      0.20109241139136047, 0.08764768181201878,\n",
       "                      0.03143301355445696, 0.054932832519371616,\n",
       "                      0.12251253768120157, 0.08760774406371008,\n",
       "                      0.18119938963493168, 0.03290469235490328,\n",
       "                      0.28979918999259463, 0.11360878448600364,\n",
       "                      0.004258564413709681, 0.11171461645118946,\n",
       "                      0.30874996400106514, 0.24043490030344772,\n",
       "                      0.2146802717915966, 0.14846354291269503,\n",
       "                      0.014831841312127695, 0.48057033620333756,\n",
       "                      0.021256594899740036, 0.46710590642696204,\n",
       "                      0.010648782615721936, 0.10528790417508929],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.24807378130822674,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.16419947984379105},\n",
       "    {'C': 0.49113323220006644,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.04664729169982079},\n",
       "    {'C': 0.14424971273703227,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.18956403072887776},\n",
       "    {'C': 0.578399543948392,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3152014417209951},\n",
       "    {'C': 0.18165568578410393,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.24380508693569825},\n",
       "    {'C': 0.06213004648192029,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.252127085723101},\n",
       "    {'C': 0.4433592455387964,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.015975111615315972},\n",
       "    {'C': 0.025837334305612095,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.1284755697831752},\n",
       "    {'C': 0.06247978894826633,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.20109241139136047},\n",
       "    {'C': 0.03423378460058229,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.08764768181201878},\n",
       "    {'C': 0.20144973677631534,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.03143301355445696},\n",
       "    {'C': 0.6060694339983912,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.054932832519371616},\n",
       "    {'C': 0.1884699887113226,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.12251253768120157},\n",
       "    {'C': 0.2423605212504863,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.08760774406371008},\n",
       "    {'C': 0.19512391140046784,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.18119938963493168},\n",
       "    {'C': 0.016387588058254233,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.03290469235490328},\n",
       "    {'C': 0.014402687378415206,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.28979918999259463},\n",
       "    {'C': 0.11700359577495421,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.11360878448600364},\n",
       "    {'C': 0.14553077150589652,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.004258564413709681},\n",
       "    {'C': 0.18285060358489055,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.11171461645118946},\n",
       "    {'C': 0.06225956296943237,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.30874996400106514},\n",
       "    {'C': 0.14204537452979407,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.24043490030344772},\n",
       "    {'C': 0.026454209110596462,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.2146802717915966},\n",
       "    {'C': 0.12656143102163211,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.14846354291269503},\n",
       "    {'C': 0.18143923467004086,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.014831841312127695},\n",
       "    {'C': 0.042013781482899075,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.48057033620333756},\n",
       "    {'C': 0.013126733044705364,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.021256594899740036},\n",
       "    {'C': 0.10917555170512067,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.46710590642696204},\n",
       "    {'C': 0.0494624155026132,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.010648782615721936},\n",
       "    {'C': 0.07974513339856973,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.10528790417508929}],\n",
       "   'split0_test_Accuracy': array([0.24058802, 0.23700251, 0.18967372, 0.23915382, 0.21728218,\n",
       "          0.20294012, 0.24022947, 0.1964862 , 0.21190391, 0.21082825,\n",
       "          0.21154536, 0.21943349, 0.19576909, 0.24058802, 0.18393689,\n",
       "          0.18967372, 0.20186447, 0.21441377, 0.21548942, 0.19756185,\n",
       "          0.21262101, 0.21548942, 0.18859806, 0.23879527, 0.20509143,\n",
       "          0.19290068, 0.17389745, 0.23807816, 0.20544998, 0.21369667]),\n",
       "   'split1_test_Accuracy': array([0.23556999, 0.23376623, 0.19949495, 0.23881674, 0.22330447,\n",
       "          0.20670996, 0.23737374, 0.2012987 , 0.21608947, 0.21861472,\n",
       "          0.21969697, 0.22619048, 0.20562771, 0.23593074, 0.21103896,\n",
       "          0.18939394, 0.21031746, 0.22474747, 0.22546898, 0.20923521,\n",
       "          0.22113997, 0.22510823, 0.19372294, 0.23448773, 0.21933622,\n",
       "          0.19660895, 0.17857143, 0.23412698, 0.21789322, 0.22294372]),\n",
       "   'split2_test_Accuracy': array([0.24483883, 0.24085476, 0.18833756, 0.24483883, 0.2339732 ,\n",
       "          0.21151757, 0.24520101, 0.1959435 , 0.21115538, 0.22636726,\n",
       "          0.22202101, 0.23216226, 0.19956537, 0.24447664, 0.19449475,\n",
       "          0.18616443, 0.22057226, 0.22781601, 0.22854038, 0.198841  ,\n",
       "          0.22890257, 0.2281782 , 0.19703006, 0.24339008, 0.22419413,\n",
       "          0.19811662, 0.18688881, 0.24194133, 0.22455632, 0.22854038]),\n",
       "   'mean_test_Accuracy': array([0.24032684, 0.2372026 , 0.1925018 , 0.24092766, 0.22482576,\n",
       "          0.20704158, 0.24092766, 0.19790916, 0.21304975, 0.21857727,\n",
       "          0.21773612, 0.22590723, 0.20031242, 0.24032684, 0.1964672 ,\n",
       "          0.18841625, 0.21088681, 0.22230233, 0.22314348, 0.20187455,\n",
       "          0.22086037, 0.22290315, 0.19310262, 0.23888488, 0.216174  ,\n",
       "          0.19586638, 0.17976448, 0.23804374, 0.21593367, 0.22170151]),\n",
       "   'std_test_Accuracy': array([0.00378341, 0.00289345, 0.00497225, 0.00275934, 0.0068995 ,\n",
       "          0.00351015, 0.00322941, 0.0024057 , 0.00216988, 0.00634489,\n",
       "          0.00449626, 0.00520122, 0.00406369, 0.00348905, 0.01116412,\n",
       "          0.00159079, 0.00764929, 0.00573871, 0.0055766 , 0.00522811,\n",
       "          0.00665097, 0.00541033, 0.00347072, 0.00363   , 0.00811379,\n",
       "          0.00219346, 0.00537118, 0.00318596, 0.0079234 , 0.00612419]),\n",
       "   'rank_test_Accuracy': array([ 3,  7, 28,  1,  9, 21,  1, 24, 19, 15, 16,  8, 23,  3, 25, 29, 20,\n",
       "          12, 10, 22, 14, 11, 27,  5, 17, 26, 30,  6, 18, 13]),\n",
       "   'split0_train_Accuracy': array([0.24019519, 0.23603832, 0.19193927, 0.24218326, 0.22447135,\n",
       "          0.21145852, 0.24164106, 0.19718055, 0.21326586, 0.21200072,\n",
       "          0.20874751, 0.21886861, 0.19880716, 0.24001446, 0.18452919,\n",
       "          0.18904753, 0.20477137, 0.21633833, 0.21742274, 0.19953009,\n",
       "          0.21398879, 0.21742274, 0.19374661, 0.23748419, 0.20910898,\n",
       "          0.19880716, 0.18199892, 0.23694198, 0.20856678, 0.21525393]),\n",
       "   'split1_train_Accuracy': array([0.24936937, 0.24612613, 0.20558559, 0.25207207, 0.23531532,\n",
       "          0.21153153, 0.25153153, 0.2018018 , 0.21621622, 0.22936937,\n",
       "          0.23009009, 0.24      , 0.21171171, 0.24954955, 0.21603604,\n",
       "          0.19027027, 0.22378378, 0.23585586, 0.23657658, 0.21099099,\n",
       "          0.23225225, 0.23657658, 0.19603604, 0.24738739, 0.23423423,\n",
       "          0.2       , 0.1818018 , 0.24666667, 0.22900901, 0.23261261]),\n",
       "   'split2_train_Accuracy': array([0.2375472 , 0.2375472 , 0.19205179, 0.23772703, 0.22280165,\n",
       "          0.21021399, 0.23880597, 0.19960439, 0.21596835, 0.21578853,\n",
       "          0.2118324 , 0.22262183, 0.19996404, 0.2375472 , 0.19780615,\n",
       "          0.19169214, 0.21291135, 0.22028412, 0.22064377, 0.19708685,\n",
       "          0.219385  , 0.22064377, 0.19726668, 0.23718756, 0.21686747,\n",
       "          0.2012228 , 0.18054307, 0.23628844, 0.21488941, 0.22046395]),\n",
       "   'mean_train_Accuracy': array([0.24237059, 0.23990388, 0.19652555, 0.24399412, 0.22752944,\n",
       "          0.21106801, 0.24399285, 0.19952891, 0.21515014, 0.21905287,\n",
       "          0.21689   , 0.22716348, 0.2034943 , 0.2423704 , 0.19945712,\n",
       "          0.19033665, 0.21382217, 0.22415944, 0.22488103, 0.20253598,\n",
       "          0.22187535, 0.22488103, 0.19568311, 0.24068638, 0.22007023,\n",
       "          0.20000999, 0.18144793, 0.2399657 , 0.2174884 , 0.22277683]),\n",
       "   'std_train_Accuracy': array([0.00506558, 0.0044427 , 0.00640658, 0.00599469, 0.00554748,\n",
       "          0.00060462, 0.00545486, 0.00188737, 0.00133623, 0.00745696,\n",
       "          0.00941845, 0.00920521, 0.00582975, 0.00517539, 0.01291549,\n",
       "          0.00108068, 0.00778846, 0.00842603, 0.00837389, 0.00606123,\n",
       "          0.00766115, 0.00837389, 0.00145857, 0.00473988, 0.01050437,\n",
       "          0.00098621, 0.00064487, 0.00474581, 0.00854546, 0.00727292]),\n",
       "   'split0_test_F1': array([0.19225523, 0.18546496, 0.12553917, 0.19129954, 0.16186846,\n",
       "          0.14373037, 0.19216593, 0.13370273, 0.14989958, 0.18670564,\n",
       "          0.18649803, 0.19378706, 0.13547168, 0.19229337, 0.12278357,\n",
       "          0.12817504, 0.17660498, 0.19019424, 0.19159671, 0.13653016,\n",
       "          0.18876238, 0.19173953, 0.12280911, 0.19003049, 0.18123978,\n",
       "          0.12927857, 0.10650183, 0.18933581, 0.18217227, 0.18987388]),\n",
       "   'split1_test_F1': array([0.19165628, 0.18626663, 0.14156171, 0.19518461, 0.17093012,\n",
       "          0.15070926, 0.19358813, 0.14114079, 0.15732242, 0.19100297,\n",
       "          0.19131388, 0.19643253, 0.1468789 , 0.19197206, 0.15606942,\n",
       "          0.1290926 , 0.182753  , 0.19685731, 0.19725334, 0.1532819 ,\n",
       "          0.19403018, 0.1969066 , 0.13592363, 0.18866911, 0.19126682,\n",
       "          0.13809072, 0.11705064, 0.18757285, 0.19042062, 0.19542646]),\n",
       "   'split2_test_F1': array([0.20116372, 0.19536314, 0.1312939 , 0.20314971, 0.18572449,\n",
       "          0.15991924, 0.20321504, 0.14064531, 0.15800831, 0.2016488 ,\n",
       "          0.1953938 , 0.20614187, 0.14493689, 0.20077185, 0.13871604,\n",
       "          0.12849068, 0.19613769, 0.20283925, 0.20349258, 0.14289076,\n",
       "          0.20411519, 0.20313322, 0.14075988, 0.20016001, 0.19965532,\n",
       "          0.14099153, 0.12889162, 0.19782163, 0.20064696, 0.2035075 ]),\n",
       "   'mean_test_F1': array([0.1950113 , 0.18901592, 0.13278542, 0.19652518, 0.17280158,\n",
       "          0.15142599, 0.19630544, 0.13848365, 0.15506232, 0.19309476,\n",
       "          0.19105352, 0.19876722, 0.14241163, 0.19499926, 0.13915679,\n",
       "          0.1285854 , 0.18513324, 0.19660891, 0.1974276 , 0.14422031,\n",
       "          0.19561067, 0.19724074, 0.13313301, 0.19293771, 0.19068946,\n",
       "          0.13609986, 0.11744385, 0.19156393, 0.19104911, 0.19624665]),\n",
       "   'std_test_F1': array([0.00434204, 0.00448438, 0.0066326 , 0.0049305 , 0.0098302 ,\n",
       "          0.00662956, 0.00490325, 0.00340034, 0.00367608, 0.00627807,\n",
       "          0.00363695, 0.00530765, 0.00499041, 0.00406962, 0.01360828,\n",
       "          0.00038092, 0.008151  , 0.00516615, 0.00485884, 0.00691064,\n",
       "          0.00636754, 0.00465822, 0.0075903 , 0.00511933, 0.00753044,\n",
       "          0.00498526, 0.00914635, 0.00446781, 0.00755659, 0.00559693]),\n",
       "   'rank_test_F1': array([ 9, 17, 28,  5, 19, 21,  6, 25, 20, 11, 14,  1, 23, 10, 24, 29, 18,\n",
       "           4,  2, 22,  8,  3, 27, 12, 16, 26, 30, 13, 15,  7]),\n",
       "   'split0_train_F1': array([0.19373623, 0.18614036, 0.13320548, 0.19684233, 0.17123192,\n",
       "          0.156678  , 0.19597278, 0.13918277, 0.1578815 , 0.1890552 ,\n",
       "          0.18441682, 0.19464598, 0.14023964, 0.19362369, 0.12537841,\n",
       "          0.13067931, 0.18126817, 0.1937797 , 0.1943384 , 0.14291979,\n",
       "          0.19100928, 0.19445839, 0.1340305 , 0.19051046, 0.18559974,\n",
       "          0.14075648, 0.11932734, 0.19029423, 0.18639091, 0.19282303]),\n",
       "   'split1_train_F1': array([0.202959  , 0.19668173, 0.14522794, 0.20612543, 0.18260228,\n",
       "          0.1557003 , 0.20567346, 0.13826959, 0.15608231, 0.20337283,\n",
       "          0.20294992, 0.21117563, 0.1506289 , 0.20334758, 0.1570966 ,\n",
       "          0.12496474, 0.19840701, 0.20858079, 0.20935386, 0.15547231,\n",
       "          0.20568487, 0.20937607, 0.13691518, 0.20071348, 0.20675266,\n",
       "          0.14010944, 0.11676213, 0.20010546, 0.20253631, 0.20584446]),\n",
       "   'split2_train_F1': array([0.19370633, 0.19064386, 0.13375975, 0.19433753, 0.17183487,\n",
       "          0.15574136, 0.19494013, 0.14146492, 0.16118241, 0.190433  ,\n",
       "          0.18600938, 0.19626931, 0.1433872 , 0.19359621, 0.13845815,\n",
       "          0.13185123, 0.18597086, 0.1951977 , 0.19542204, 0.13912899,\n",
       "          0.19477956, 0.19540389, 0.13930115, 0.1925573 , 0.19231951,\n",
       "          0.14270336, 0.11834902, 0.19167969, 0.19023555, 0.19600271]),\n",
       "   'mean_train_F1': array([0.19680052, 0.19115532, 0.13739772, 0.19910176, 0.17522302,\n",
       "          0.15603989, 0.19886212, 0.13963909, 0.15838207, 0.19428701,\n",
       "          0.19112537, 0.20069697, 0.14475191, 0.19685583, 0.14031105,\n",
       "          0.12916509, 0.18854868, 0.19918606, 0.19970476, 0.14584036,\n",
       "          0.1971579 , 0.19974612, 0.13674894, 0.19459375, 0.19489064,\n",
       "          0.14118976, 0.11814616, 0.19402646, 0.19305426, 0.1982234 ]),\n",
       "   'std_train_F1': array([0.00435472, 0.00431866, 0.00554142, 0.00507066, 0.00522372,\n",
       "          0.00045152, 0.00483476, 0.0013438 , 0.00211198, 0.00644922,\n",
       "          0.00838646, 0.00743911, 0.00434979, 0.00459038, 0.01301501,\n",
       "          0.00300838, 0.00723043, 0.00666825, 0.00683727, 0.00698443,\n",
       "          0.00622284, 0.00682033, 0.00215494, 0.00440725, 0.00882495,\n",
       "          0.00110239, 0.00105702, 0.00433555, 0.00688609, 0.00554304]),\n",
       "   'split0_test_Log_Loss': array([-2.70404014, -2.73151679, -3.0206786 , -2.68887212, -2.84523135,\n",
       "          -2.95939993, -2.69228731, -3.0735947 , -2.93647113, -2.89496981,\n",
       "          -2.89179127, -2.85597233, -2.97167063, -2.70457117, -3.01087707,\n",
       "          -3.15886194, -2.93375311, -2.86804608, -2.86535297, -2.96675845,\n",
       "          -2.87890594, -2.86568242, -3.08684899, -2.72619118, -2.88136576,\n",
       "          -3.02177665, -3.21541899, -2.7330867 , -2.89571661, -2.87397545]),\n",
       "   'split1_test_Log_Loss': array([-2.70489284, -2.73261413, -2.91868356, -2.68844885, -2.84266368,\n",
       "          -2.95662677, -2.69207448, -3.07111072, -2.93585297, -2.90559999,\n",
       "          -2.89040887, -2.86724684, -2.88821717, -2.70531961, -2.90732567,\n",
       "          -3.15587404, -2.94319216, -2.87933352, -2.87667195, -2.88321385,\n",
       "          -2.88995598, -2.87698712, -3.08268365, -2.72766152, -2.88414136,\n",
       "          -3.01704309, -3.21084471, -2.73499228, -2.90049801, -2.88515114]),\n",
       "   'split2_test_Log_Loss': array([-2.6974523 , -2.72505654, -3.0178607 , -2.68166403, -2.84007854,\n",
       "          -2.95106138, -2.68506068, -3.06663864, -2.92875902, -2.88979646,\n",
       "          -2.88519735, -2.84994925, -2.96749981, -2.69790684, -3.00550158,\n",
       "          -3.15237636, -2.92893452, -2.86248362, -2.85973837, -2.95695264,\n",
       "          -2.87352779, -2.86007264, -3.07886759, -2.71970852, -2.87664534,\n",
       "          -3.01258116, -3.20857372, -2.7266971 , -2.89052436, -2.8685314 ]),\n",
       "   'mean_test_Log_Loss': array([-2.70213851, -2.72973898, -2.98576987, -2.6863397 , -2.84266652,\n",
       "          -2.95570972, -2.68981883, -3.07045948, -2.93370657, -2.89679428,\n",
       "          -2.88914313, -2.85772951, -2.94248911, -2.70260944, -2.97460139,\n",
       "          -3.15571496, -2.93529852, -2.86996038, -2.86726048, -2.93567704,\n",
       "          -2.88080232, -2.86758677, -3.08281355, -2.72453018, -2.88072419,\n",
       "          -3.01714914, -3.21162427, -2.73160155, -2.89558662, -2.87589181]),\n",
       "   'std_test_Log_Loss': array([0.00332035, 0.0033297 , 0.04742549, 0.00329912, 0.00210398,\n",
       "          0.0034659 , 0.00335383, 0.00287732, 0.0034953 , 0.00657194,\n",
       "          0.00283712, 0.00716164, 0.0383931 , 0.00332765, 0.04759603,\n",
       "          0.00265056, 0.00591542, 0.00700278, 0.00703532, 0.03729258,\n",
       "          0.00683168, 0.00702724, 0.00326023, 0.00345019, 0.00308985,\n",
       "          0.00375542, 0.00284882, 0.00354247, 0.00406726, 0.00691104]),\n",
       "   'rank_test_Log_Loss': array([ 3,  6, 25,  1,  8, 23,  2, 27, 19, 18, 16,  9, 22,  4, 24, 29, 20,\n",
       "          12, 10, 21, 15, 11, 28,  5, 14, 26, 30,  7, 17, 13]),\n",
       "   'split0_train_Log_Loss': array([-2.69158822, -2.72053192, -3.01603716, -2.67450527, -2.83626773,\n",
       "          -2.95250971, -2.67843399, -3.06895805, -2.93070903, -2.88581992,\n",
       "          -2.8847708 , -2.8440698 , -2.96510179, -2.69218144, -3.00431142,\n",
       "          -3.1548749 , -2.9258433 , -2.85744667, -2.85453764, -2.96028687,\n",
       "          -2.86900463, -2.85489953, -3.08111575, -2.71545601, -2.87163745,\n",
       "          -3.01517713, -3.21083281, -2.72279675, -2.88647879, -2.86378426]),\n",
       "   'split1_train_Log_Loss': array([-2.66560607, -2.69574786, -2.89251955, -2.64814649, -2.81404062,\n",
       "          -2.93372177, -2.65195126, -3.0524744 , -2.91098945, -2.87602285,\n",
       "          -2.85874642, -2.83458703, -2.86043915, -2.66605735, -2.88107105,\n",
       "          -3.14064684, -2.91663558, -2.84755603, -2.84468687, -2.85557661,\n",
       "          -2.85906193, -2.84502296, -3.06538645, -2.6899592 , -2.85236134,\n",
       "          -2.9981252 , -3.19833034, -2.69781264, -2.87041461, -2.8538503 ]),\n",
       "   'split2_train_Log_Loss': array([-2.69844438, -2.72606071, -3.0199842 , -2.68296752, -2.84002841,\n",
       "          -2.95233333, -2.68627705, -3.06827703, -2.93040164, -2.88990956,\n",
       "          -2.88776237, -2.84935356, -2.96833914, -2.69888875, -3.00597408,\n",
       "          -3.15398338, -2.92965396, -2.86205052, -2.85925445, -2.95810969,\n",
       "          -2.87331885, -2.8595941 , -3.08045326, -2.72062903, -2.87657849,\n",
       "          -3.01394095, -3.210218  , -2.727629  , -2.89073931, -2.86821643]),\n",
       "   'mean_train_Log_Loss': array([-2.68521289, -2.7141135 , -2.9761803 , -2.66853976, -2.83011225,\n",
       "          -2.94618827, -2.67222076, -3.0632365 , -2.92403337, -2.88391744,\n",
       "          -2.87709319, -2.84267013, -2.93129336, -2.68570918, -2.96378552,\n",
       "          -3.14983504, -2.92404428, -2.85568441, -2.85282632, -2.92465772,\n",
       "          -2.86712847, -2.8531722 , -3.07565182, -2.70868141, -2.86685909,\n",
       "          -3.00908109, -3.20646039, -2.71607946, -2.88254424, -2.86195033]),\n",
       "   'std_train_Log_Loss': array([0.01414384, 0.01318116, 0.05917903, 0.01482827, 0.0114676 ,\n",
       "          0.00881544, 0.014686  , 0.00761503, 0.0092243 , 0.00582665,\n",
       "          0.01303049, 0.00610911, 0.05011892, 0.01416317, 0.0584919 ,\n",
       "          0.00650723, 0.00546485, 0.00604713, 0.00606905, 0.04885581,\n",
       "          0.00596964, 0.00607274, 0.00726375, 0.01340599, 0.01044803,\n",
       "          0.00776341, 0.00575429, 0.01306638, 0.00875153, 0.0060066 ])},\n",
       "  {'C': 0.578399543948392,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.3152014417209951},\n",
       "  3,\n",
       "  -2.6863396963991786),\n",
       " 'RandomForestClassifier_V01_PCA_5components': ({'mean_fit_time': array([0.76927765, 2.37066293, 2.02625044, 1.15624253, 2.00763273,\n",
       "          1.36202526, 1.52292879, 1.14992682, 2.14127596, 2.09972088,\n",
       "          1.03656189, 1.57445828, 2.33342934, 1.27758511, 1.9637506 ,\n",
       "          1.2353642 , 0.88097819, 3.11068527, 2.42950646, 2.07113012,\n",
       "          3.29685473, 0.76894228, 1.37332877, 0.68217595, 1.19613528,\n",
       "          2.75164398, 1.50397968, 1.17818348, 1.6186734 , 0.83011365]),\n",
       "   'std_fit_time': array([0.00774006, 0.02939526, 0.01316437, 0.02158052, 0.01389188,\n",
       "          0.03158449, 0.00587132, 0.0021545 , 0.00723815, 0.00572007,\n",
       "          0.01457528, 0.00738882, 0.01754742, 0.00990701, 0.09402843,\n",
       "          0.0282135 , 0.00477167, 0.02256655, 0.04849815, 0.09616553,\n",
       "          0.01673542, 0.01694447, 0.02898558, 0.02269809, 0.02523501,\n",
       "          0.06459407, 0.0085017 , 0.00985037, 0.02419744, 0.0114098 ]),\n",
       "   'mean_score_time': array([0.23636842, 0.62599421, 0.57911897, 0.33178059, 0.55983742,\n",
       "          0.34208608, 0.3736678 , 0.24966621, 0.48902639, 0.53024944,\n",
       "          0.25199358, 0.40225832, 0.57114021, 0.28723224, 0.60937246,\n",
       "          0.25265781, 0.19581016, 0.6489327 , 0.62599452, 0.56648644,\n",
       "          0.66887927, 0.21176759, 0.34507807, 0.21210035, 0.29886794,\n",
       "          0.65524864, 0.40325658, 0.25731277, 0.37699286, 0.2529908 ]),\n",
       "   'std_score_time': array([0.01485965, 0.04122036, 0.01338806, 0.03314136, 0.02203632,\n",
       "          0.03001968, 0.02576757, 0.01769809, 0.04326152, 0.0160054 ,\n",
       "          0.00448529, 0.00448533, 0.02310891, 0.00570011, 0.02540056,\n",
       "          0.00964646, 0.00124348, 0.01942972, 0.03986255, 0.05787982,\n",
       "          0.02860922, 0.00600238, 0.01752206, 0.01830535, 0.01169676,\n",
       "          0.04029826, 0.01024724, 0.01547259, 0.00924938, 0.02150399]),\n",
       "   'param_n_estimators': masked_array(data=[100, 350, 300, 200, 350, 200, 200, 100, 250, 300, 150,\n",
       "                      250, 350, 150, 350, 100, 100, 250, 300, 300, 250, 100,\n",
       "                      200, 100, 150, 350, 250, 100, 200, 150],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[75, 125, 125, 200, 200, 125, 75, 10, 50, 50, 125, 150,\n",
       "                      125, 50, 250, 10, 50, 10, 75, 150, 10, 75, 125, 125,\n",
       "                      75, 75, 200, 10, 75, 250],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt',\n",
       "                      'log2', 'log2', 'sqrt', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                      'log2', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'log2',\n",
       "                      'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                      'sqrt', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[20, 25, 85, 90, 70, 40, 70, 90, 75, 5, 70, 15, 80, 80,\n",
       "                      55, 25, 60, 65, 20, 100, 100, 50, 45, 90, 90, 85, 85,\n",
       "                      100, 15, 35],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 100,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 80},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 60},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35}],\n",
       "   'split0_test_Accuracy': array([0.37217641, 0.31588383, 0.31265687, 0.26425242, 0.26532807,\n",
       "          0.31409107, 0.36141986, 0.51416278, 0.40516314, 0.33130154,\n",
       "          0.31588383, 0.29652205, 0.31911079, 0.39691646, 0.25134457,\n",
       "          0.5191825 , 0.3951237 , 0.52886339, 0.36894944, 0.28863392,\n",
       "          0.52563643, 0.3700251 , 0.31480817, 0.31839369, 0.36428828,\n",
       "          0.36787379, 0.26640373, 0.52527788, 0.36608103, 0.2459663 ]),\n",
       "   'split1_test_Accuracy': array([0.35858586, 0.30844156, 0.31493506, 0.25036075, 0.251443  ,\n",
       "          0.31349206, 0.36471861, 0.51298701, 0.39285714, 0.32503608,\n",
       "          0.31890332, 0.28174603, 0.31385281, 0.39357864, 0.22330447,\n",
       "          0.51046176, 0.39141414, 0.51551227, 0.36760462, 0.28643579,\n",
       "          0.51370851, 0.35064935, 0.31277056, 0.31493506, 0.36183261,\n",
       "          0.36868687, 0.26118326, 0.50757576, 0.36616162, 0.23232323]),\n",
       "   'split2_test_Accuracy': array([0.35711699, 0.30641072, 0.30967041, 0.26946758, 0.26946758,\n",
       "          0.31075697, 0.35421949, 0.52299891, 0.39623325, 0.31727635,\n",
       "          0.31039478, 0.28975009, 0.30568635, 0.39152481, 0.24085476,\n",
       "          0.52010141, 0.3889895 , 0.5233611 , 0.35421949, 0.29373415,\n",
       "          0.52372329, 0.34770011, 0.31365447, 0.3100326 , 0.35530605,\n",
       "          0.3596523 , 0.2662079 , 0.51611735, 0.36363636, 0.24773633]),\n",
       "   'mean_test_Accuracy': array([0.36265321, 0.31026196, 0.3124249 , 0.26135544, 0.26207642,\n",
       "          0.31278539, 0.36012978, 0.51670272, 0.39810142, 0.3245614 ,\n",
       "          0.31506849, 0.28935352, 0.31290555, 0.39401586, 0.23852439,\n",
       "          0.51658255, 0.39185292, 0.52259072, 0.36361452, 0.28959385,\n",
       "          0.5210286 , 0.35616438, 0.3137467 , 0.31446768, 0.36049027,\n",
       "          0.36541697, 0.26459986, 0.51634223, 0.3652968 , 0.24200913]),\n",
       "   'std_test_Accuracy': array([0.00678772, 0.00407637, 0.00215268, 0.00805672, 0.00770264,\n",
       "          0.00145009, 0.00437734, 0.0044624 , 0.00519916, 0.00573654,\n",
       "          0.00351686, 0.00604578, 0.00552215, 0.00222308, 0.0115777 ,\n",
       "          0.00434196, 0.00252382, 0.00548386, 0.00664273, 0.00305256,\n",
       "          0.00523193, 0.00991397, 0.00083535, 0.00342992, 0.0037883 ,\n",
       "          0.00407549, 0.00241591, 0.00723702, 0.00117045, 0.00688331]),\n",
       "   'rank_test_Accuracy': array([12, 23, 22, 28, 27, 21, 14,  3,  6, 16, 17, 25, 20,  7, 30,  4,  8,\n",
       "           1, 11, 24,  2, 15, 19, 18, 13,  9, 26,  5, 10, 29]),\n",
       "   'split0_train_Accuracy': array([0.39743358, 0.33742997, 0.33309235, 0.28067956, 0.28537864,\n",
       "          0.3365263 , 0.39237303, 0.69528285, 0.43954455, 0.34917766,\n",
       "          0.33544189, 0.31393457, 0.3370685 , 0.43665281, 0.26694379,\n",
       "          0.69727092, 0.44044822, 0.70106633, 0.39797578, 0.31375384,\n",
       "          0.70016266, 0.39562624, 0.33435749, 0.32983915, 0.39761431,\n",
       "          0.39616844, 0.28628231, 0.70431954, 0.39508404, 0.25881077]),\n",
       "   'split1_train_Accuracy': array([0.40342342, 0.34594595, 0.34810811, 0.27387387, 0.2763964 ,\n",
       "          0.34702703, 0.41189189, 0.69981982, 0.45441441, 0.36630631,\n",
       "          0.35081081, 0.31279279, 0.34522523, 0.45153153, 0.24486486,\n",
       "          0.69441441, 0.45495495, 0.6963964 , 0.4163964 , 0.31027027,\n",
       "          0.69531532, 0.40378378, 0.3445045 , 0.3445045 , 0.40684685,\n",
       "          0.41531532, 0.28468468, 0.69603604, 0.41711712, 0.24666667]),\n",
       "   'split2_train_Accuracy': array([0.39417371, 0.3373494 , 0.34148534, 0.28951627, 0.28699874,\n",
       "          0.33914764, 0.39830966, 0.695918  , 0.44937961, 0.34723971,\n",
       "          0.34166517, 0.30965654, 0.33788887, 0.44362525, 0.25067434,\n",
       "          0.69627765, 0.43912965, 0.70095307, 0.39039741, 0.32080561,\n",
       "          0.69555835, 0.39165618, 0.34400288, 0.33501169, 0.39669124,\n",
       "          0.39795001, 0.28250315, 0.69358029, 0.39471318, 0.25157346]),\n",
       "   'mean_train_Accuracy': array([0.39834357, 0.34024177, 0.34089527, 0.28135657, 0.28292459,\n",
       "          0.34090032, 0.40085819, 0.69700689, 0.44777952, 0.35424122,\n",
       "          0.34263929, 0.31212797, 0.34006086, 0.44393653, 0.254161  ,\n",
       "          0.69598766, 0.44484428, 0.69947193, 0.40158986, 0.31494324,\n",
       "          0.69701211, 0.39702207, 0.34095496, 0.33645178, 0.40038413,\n",
       "          0.40314459, 0.28449005, 0.69797862, 0.40230478, 0.2523503 ]),\n",
       "   'std_train_Accuracy': array([0.00383061, 0.0040336 , 0.00614434, 0.0064039 , 0.00466327,\n",
       "          0.00446246, 0.00816977, 0.00200587, 0.00617513, 0.00856791,\n",
       "          0.00631203, 0.00180866, 0.00366708, 0.0060782 , 0.00934478,\n",
       "          0.00118405, 0.00716957, 0.00217522, 0.01091736, 0.00438249,\n",
       "          0.00222998, 0.0050485 , 0.00466961, 0.00607309, 0.00458534,\n",
       "          0.00863668, 0.00154896, 0.00459442, 0.010475  , 0.00498815]),\n",
       "   'split0_test_F1': array([0.33025044, 0.26047793, 0.2542986 , 0.1928124 , 0.19411776,\n",
       "          0.25493684, 0.31772483, 0.50295369, 0.37263216, 0.27878013,\n",
       "          0.25697245, 0.23468265, 0.26188555, 0.36397723, 0.18496155,\n",
       "          0.50885806, 0.3614129 , 0.51860371, 0.32708475, 0.223671  ,\n",
       "          0.51624716, 0.32835888, 0.25565767, 0.25972335, 0.32081062,\n",
       "          0.32522183, 0.19550271, 0.51550872, 0.32297833, 0.17883188]),\n",
       "   'split1_test_F1': array([0.31689316, 0.24761195, 0.25392507, 0.17715439, 0.17809513,\n",
       "          0.25464475, 0.31936318, 0.50030648, 0.35834819, 0.27582201,\n",
       "          0.26157633, 0.20896249, 0.25322892, 0.3599285 , 0.14761179,\n",
       "          0.49813295, 0.35814653, 0.50343612, 0.32578412, 0.21359963,\n",
       "          0.50051126, 0.30725789, 0.25263943, 0.25634313, 0.31898709,\n",
       "          0.32635406, 0.18925805, 0.49616118, 0.32394271, 0.15782651]),\n",
       "   'split2_test_F1': array([0.31294181, 0.23951622, 0.24598515, 0.19453561, 0.19162041,\n",
       "          0.24754379, 0.31000143, 0.51104304, 0.3616965 , 0.26648907,\n",
       "          0.24764276, 0.21662482, 0.241402  , 0.3559767 , 0.16032373,\n",
       "          0.50894235, 0.35563858, 0.51036808, 0.3109479 , 0.225915  ,\n",
       "          0.51119099, 0.30332864, 0.24892687, 0.24369753, 0.31121663,\n",
       "          0.31674588, 0.18967993, 0.50154503, 0.32097367, 0.17944602]),\n",
       "   'mean_test_F1': array([0.32005872, 0.24923787, 0.25141602, 0.18816854, 0.18795218,\n",
       "          0.25238675, 0.31570815, 0.50475574, 0.36424613, 0.27371698,\n",
       "          0.25541065, 0.22012437, 0.25220624, 0.35997428, 0.16434649,\n",
       "          0.50531357, 0.35840914, 0.51081915, 0.32129778, 0.22106079,\n",
       "          0.50932815, 0.31302597, 0.25241923, 0.25328052, 0.31702021,\n",
       "          0.32278689, 0.19149083, 0.50443144, 0.32263447, 0.17203889]),\n",
       "   'std_test_F1': array([0.00741304, 0.0086358 , 0.00382975, 0.0078157 , 0.00704046,\n",
       "          0.00341455, 0.00407646, 0.00456039, 0.00610837, 0.0052345 ,\n",
       "          0.00578786, 0.01079779, 0.00839495, 0.00326691, 0.01552668,\n",
       "          0.00507483, 0.00236504, 0.0062075 , 0.00731211, 0.005352  ,\n",
       "          0.00656422, 0.01100324, 0.0027527 , 0.00689228, 0.0041567 ,\n",
       "          0.00428172, 0.00285353, 0.00816517, 0.00123484, 0.01004737]),\n",
       "   'rank_test_F1': array([12, 23, 22, 27, 28, 20, 14,  4,  6, 16, 17, 25, 21,  7, 30,  3,  8,\n",
       "           1, 11, 24,  2, 15, 19, 18, 13,  9, 26,  5, 10, 29]),\n",
       "   'split0_train_F1': array([0.3521515 , 0.27478433, 0.26815943, 0.20556739, 0.20984833,\n",
       "          0.26953883, 0.34455181, 0.68911287, 0.40488204, 0.29218052,\n",
       "          0.26930718, 0.24686363, 0.27208634, 0.40035525, 0.19551867,\n",
       "          0.69144359, 0.40727027, 0.69567845, 0.35172205, 0.24414051,\n",
       "          0.69453999, 0.34982218, 0.26726718, 0.26607984, 0.35285765,\n",
       "          0.35091542, 0.21186934, 0.69863642, 0.34954416, 0.18682035]),\n",
       "   'split1_train_F1': array([0.36576088, 0.2858869 , 0.28910755, 0.20056528, 0.20322624,\n",
       "          0.28859399, 0.37196133, 0.69320035, 0.42718837, 0.31587613,\n",
       "          0.2923363 , 0.23990827, 0.28730594, 0.42401127, 0.16572291,\n",
       "          0.68700204, 0.42605875, 0.69002963, 0.37696206, 0.23906871,\n",
       "          0.68873959, 0.363664  , 0.28668778, 0.28729311, 0.36735211,\n",
       "          0.37744576, 0.21175955, 0.68922651, 0.37697708, 0.16750902]),\n",
       "   'split2_train_F1': array([0.35160557, 0.26869477, 0.2754362 , 0.21022352, 0.2080019 ,\n",
       "          0.27521648, 0.35306457, 0.68900244, 0.41570668, 0.29622964,\n",
       "          0.27726568, 0.23338623, 0.27186082, 0.40977354, 0.16793833,\n",
       "          0.68949084, 0.40502436, 0.69416776, 0.34685197, 0.25104748,\n",
       "          0.68861739, 0.34813832, 0.27877935, 0.26960786, 0.35130282,\n",
       "          0.35428489, 0.20242947, 0.68579514, 0.35111201, 0.17878725]),\n",
       "   'mean_train_F1': array([0.35650598, 0.27645533, 0.27756772, 0.20545206, 0.20702549,\n",
       "          0.2777831 , 0.3565259 , 0.69043855, 0.4159257 , 0.30142876,\n",
       "          0.27963639, 0.24005271, 0.27708437, 0.41138002, 0.1763933 ,\n",
       "          0.68931216, 0.41278446, 0.69329195, 0.35851202, 0.24475224,\n",
       "          0.69063233, 0.35387483, 0.2775781 , 0.27432694, 0.35717086,\n",
       "          0.36088202, 0.20868612, 0.69121936, 0.35921108, 0.17770554]),\n",
       "   'std_train_F1': array([0.006548  , 0.00711742, 0.00868383, 0.0039438 , 0.00279023,\n",
       "          0.00798814, 0.01145443, 0.00195341, 0.00910784, 0.01034871,\n",
       "          0.00954988, 0.00550307, 0.00722833, 0.00972411, 0.01355388,\n",
       "          0.00181765, 0.00943102, 0.00238783, 0.01319677, 0.0049094 ,\n",
       "          0.00276359, 0.00695604, 0.0079738 , 0.00928091, 0.00722716,\n",
       "          0.01179283, 0.00442435, 0.00542852, 0.01257876, 0.00792084]),\n",
       "   'split0_test_Log_Loss': array([-2.30658885, -2.48493576, -2.47960827, -2.6518918 , -2.64733975,\n",
       "          -2.48428162, -2.31024749, -1.72445749, -2.16943736, -2.50149126,\n",
       "          -2.48749541, -2.55005778, -2.4776922 , -2.17686714, -2.72388302,\n",
       "          -1.75029551, -2.1713134 , -1.72751882, -2.30766055, -2.54921532,\n",
       "          -1.71446373, -2.30994204, -2.47950571, -2.48233482, -2.31316235,\n",
       "          -2.31113677, -2.65069308, -1.73107459, -2.30992685, -2.72467116]),\n",
       "   'split1_test_Log_Loss': array([-2.3177105 , -2.48158858, -2.48240384, -2.64912188, -2.64876185,\n",
       "          -2.4838273 , -2.30797938, -1.75253013, -2.17234692, -2.5074284 ,\n",
       "          -2.48379428, -2.55230178, -2.48485204, -2.17323137, -2.73193495,\n",
       "          -1.76420536, -2.17174481, -1.71613836, -2.30801351, -2.55636548,\n",
       "          -1.73667918, -2.31240516, -2.4867688 , -2.48333795, -2.30629753,\n",
       "          -2.3080862 , -2.64645556, -1.71812685, -2.30913123, -2.72703074]),\n",
       "   'split2_test_Log_Loss': array([-2.30556841, -2.48423484, -2.48606853, -2.65273263, -2.65630739,\n",
       "          -2.48695918, -2.30615916, -1.70927746, -2.16495409, -2.51603101,\n",
       "          -2.48621216, -2.55678334, -2.48147601, -2.16348767, -2.7289634 ,\n",
       "          -1.72611137, -2.16611367, -1.72538647, -2.30139671, -2.55593655,\n",
       "          -1.70493862, -2.30154767, -2.48449669, -2.49161103, -2.30779982,\n",
       "          -2.30210852, -2.65459012, -1.72779741, -2.30151794, -2.73385232]),\n",
       "   'mean_test_Log_Loss': array([-2.30995484, -2.48358829, -2.48268278, -2.65124812, -2.65078865,\n",
       "          -2.48501863, -2.30813561, -1.72877199, -2.16891909, -2.50829275,\n",
       "          -2.48583684, -2.55303659, -2.48133245, -2.17121717, -2.72825059,\n",
       "          -1.74690518, -2.16973198, -1.72302061, -2.30569996, -2.5538269 ,\n",
       "          -1.71870338, -2.30797748, -2.48358086, -2.48574654, -2.30909659,\n",
       "          -2.30712533, -2.65057452, -1.72567452, -2.306872  , -2.72850317]),\n",
       "   'std_test_Log_Loss': array([0.00549693, 0.00144194, 0.00264519, 0.00154139, 0.00393183,\n",
       "          0.00137991, 0.00167298, 0.01789799, 0.0030364 , 0.00596817,\n",
       "          0.00153568, 0.00279483, 0.00292815, 0.00564547, 0.00332913,\n",
       "          0.01571616, 0.00255563, 0.00494117, 0.0030356 , 0.00327878,\n",
       "          0.01328594, 0.00464109, 0.00303793, 0.00415255, 0.00295085,\n",
       "          0.00374841, 0.00331749, 0.0054994 , 0.00378658, 0.00389056]),\n",
       "   'rank_test_Log_Loss': array([15, 19, 17, 28, 27, 20, 13,  4,  6, 23, 22, 24, 16,  8, 29,  5,  7,\n",
       "           2,  9, 25,  1, 12, 18, 21, 14, 11, 26,  3, 10, 30]),\n",
       "   'split0_train_Log_Loss': array([-2.19237987, -2.41133802, -2.40806315, -2.60378466, -2.59984701,\n",
       "          -2.40967981, -2.19545334, -1.27760665, -2.01757165, -2.43557517,\n",
       "          -2.41339815, -2.48757822, -2.40516782, -2.02272716, -2.68603174,\n",
       "          -1.28000403, -2.01838201, -1.27884605, -2.19503616, -2.48687643,\n",
       "          -1.27805888, -2.19781432, -2.40774189, -2.40772752, -2.19596858,\n",
       "          -2.19741194, -2.60375128, -1.28072128, -2.1958952 , -2.68723165]),\n",
       "   'split1_train_Log_Loss': array([-2.20034603, -2.40736169, -2.40624226, -2.59828761, -2.59739606,\n",
       "          -2.4076803 , -2.1940095 , -1.27518006, -2.01562004, -2.43128986,\n",
       "          -2.40630495, -2.48537061, -2.40968444, -2.01790802, -2.68978615,\n",
       "          -1.27723587, -2.01508632, -1.27296491, -2.19274879, -2.4922031 ,\n",
       "          -1.27263496, -2.19569083, -2.4100011 , -2.40737497, -2.19067131,\n",
       "          -2.19253663, -2.59429555, -1.27444071, -2.19150508, -2.6854046 ]),\n",
       "   'split2_train_Log_Loss': array([-2.20189002, -2.41194314, -2.41523674, -2.60212269, -2.60618953,\n",
       "          -2.41501202, -2.20408683, -1.28145768, -2.02849892, -2.44239793,\n",
       "          -2.41433677, -2.49356426, -2.41043296, -2.02689936, -2.68654188,\n",
       "          -1.28228156, -2.02798733, -1.28137889, -2.20156454, -2.49412228,\n",
       "          -1.28231932, -2.20019027, -2.4152096 , -2.42019747, -2.20346118,\n",
       "          -2.20037136, -2.60429075, -1.28397094, -2.19883047, -2.68926233]),\n",
       "   'mean_train_Log_Loss': array([-2.19820531, -2.41021428, -2.40984738, -2.60139832, -2.6011442 ,\n",
       "          -2.41079071, -2.19784989, -1.27808146, -2.02056353, -2.43642099,\n",
       "          -2.41134663, -2.4888377 , -2.40842841, -2.02251151, -2.68745325,\n",
       "          -1.27984049, -2.02048522, -1.27772995, -2.19644983, -2.49106727,\n",
       "          -1.27767105, -2.19789847, -2.4109842 , -2.41176666, -2.19670035,\n",
       "          -2.19677331, -2.60077919, -1.27971098, -2.19541025, -2.68729953]),\n",
       "   'std_train_Log_Loss': array([0.00416716, 0.00203216, 0.00388268, 0.00230187, 0.00370525,\n",
       "          0.00309452, 0.0044494 , 0.00258473, 0.00566745, 0.00457412,\n",
       "          0.00358553, 0.00346157, 0.00232575, 0.00367387, 0.0016627 ,\n",
       "          0.00206314, 0.00547276, 0.00352449, 0.00373526, 0.0030652 ,\n",
       "          0.00396312, 0.00183785, 0.00312693, 0.00596323, 0.00524702,\n",
       "          0.00323024, 0.00458991, 0.00395574, 0.00301018, 0.00157564])},\n",
       "  {'n_estimators': 250,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': 100},\n",
       "  20,\n",
       "  -1.718703380947592),\n",
       " 'DecisionTreeClassifier_V01_PCA_5components': ({'mean_fit_time': array([0.01761937, 0.01163499, 0.04089046, 0.02626284, 0.0149591 ,\n",
       "          0.02858973, 0.04155469, 0.01296449, 0.04487952, 0.00897527,\n",
       "          0.02626355, 0.02227362, 0.03889569, 0.02061184, 0.02393627,\n",
       "          0.015625  , 0.03158188, 0.01761842, 0.01695474, 0.00997329,\n",
       "          0.06316376, 0.05850943, 0.05684717, 0.01728694, 0.05817763,\n",
       "          0.05751236, 0.07712611, 0.02792581, 0.05585043, 0.02592985]),\n",
       "   'std_fit_time': array([4.70021695e-04, 9.40605267e-04, 4.95352157e-03, 9.41111075e-04,\n",
       "          1.62888412e-03, 1.24394287e-03, 4.70190252e-04, 5.15042996e-07,\n",
       "          8.14782726e-04, 2.82097288e-03, 1.24443141e-03, 4.70201482e-03,\n",
       "          7.85320058e-03, 1.24396397e-03, 2.44298550e-03, 2.48820406e-03,\n",
       "          4.70173383e-03, 1.24311440e-03, 2.44347218e-03, 1.41023355e-03,\n",
       "          4.77185996e-03, 1.24441003e-03, 3.25728158e-03, 1.24370912e-03,\n",
       "          4.77154990e-03, 1.24319934e-03, 1.24430384e-03, 2.15427775e-03,\n",
       "          8.14296434e-04, 8.14782726e-04]),\n",
       "   'mean_score_time': array([0.03756682, 0.03457499, 0.02958798, 0.02692827, 0.02426958,\n",
       "          0.0242691 , 0.02958751, 0.04089149, 0.03390988, 0.02726086,\n",
       "          0.03091757, 0.0272607 , 0.03124992, 0.0312496 , 0.03124913,\n",
       "          0.02726038, 0.02825753, 0.02925587, 0.02493318, 0.02493358,\n",
       "          0.02559868, 0.02825816, 0.02825809, 0.03357649, 0.03723407,\n",
       "          0.02759337, 0.0272607 , 0.03124889, 0.0322473 , 0.02526641]),\n",
       "   'std_score_time': array([0.00448451, 0.0150444 , 0.00188026, 0.00081381, 0.00047002,\n",
       "          0.00047002, 0.00169469, 0.01310576, 0.00430811, 0.00124373,\n",
       "          0.00709945, 0.00248748, 0.00401727, 0.00401649, 0.0049082 ,\n",
       "          0.00204915, 0.00261786, 0.0055431 , 0.00081469, 0.0008143 ,\n",
       "          0.00046963, 0.00047013, 0.00401672, 0.01152524, 0.00678081,\n",
       "          0.00204951, 0.00094049, 0.00738808, 0.00417878, 0.0012435 ]),\n",
       "   'param_min_samples_split': masked_array(data=[0.04, 0.48, 0.37, 0.02, 0.78, 0.5, 0.3, 0.24, 0.3,\n",
       "                      0.97, 0.71, 0.59, 0.01, 0.85, 0.78, 0.9400000000000001,\n",
       "                      0.58, 0.22, 0.64, 0.79, 0.07, 0.12, 0.19,\n",
       "                      0.5700000000000001, 0.15, 0.13, 0.04, 0.76, 0.11, 0.97],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=[0.5, 'log2', 'sqrt', 0.5, 'sqrt', 0.5, 0.5, 'sqrt',\n",
       "                      'sqrt', 'sqrt', 0.5, 0.5, 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'log2', 'log2', 0.5, 'log2', 'sqrt', 'sqrt',\n",
       "                      0.5, 'sqrt', 'log2', 'log2', 0.5, 'sqrt', 'sqrt',\n",
       "                      'log2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[None, 20, 20, 20, 20, None, None, None, None, None, 20,\n",
       "                      None, 20, 20, None, None, 20, None, None, 20, 20, 20,\n",
       "                      20, 20, None, 20, 20, None, 20, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_criterion': masked_array(data=['gini', 'gini', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                      'entropy', 'gini', 'entropy', 'gini', 'entropy',\n",
       "                      'entropy', 'gini', 'entropy', 'entropy', 'gini',\n",
       "                      'entropy', 'gini', 'gini', 'gini', 'entropy',\n",
       "                      'entropy', 'entropy', 'gini', 'entropy', 'entropy',\n",
       "                      'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, 'balanced', 'balanced', 'balanced', None,\n",
       "                      None, None, 'balanced', None, 'balanced', None,\n",
       "                      'balanced', None, None, 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', None, None, None, 'balanced',\n",
       "                      'balanced', None, 'balanced', 'balanced', 'balanced',\n",
       "                      None, 'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'min_samples_split': 0.04,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.48,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.37,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.02,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.78,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.5,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.3,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.24,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.3,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.97,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.71,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.59,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.01,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.85,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.78,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.9400000000000001,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.58,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.22,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.64,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.79,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.07,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.12,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.19,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.5700000000000001,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.15,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.13,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.04,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.76,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.11,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.97,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'}],\n",
       "   'split0_test_Accuracy': array([0.25421298, 0.10792399, 0.07242739, 0.28397275, 0.06884188,\n",
       "          0.08461814, 0.10182861, 0.12441735, 0.09931875, 0.06704912,\n",
       "          0.04732879, 0.06955898, 0.34743636, 0.06704912, 0.0620294 ,\n",
       "          0.04625314, 0.06095375, 0.12907852, 0.08246683, 0.09501613,\n",
       "          0.19290068, 0.13624955, 0.12190749, 0.06669057, 0.13302259,\n",
       "          0.15740409, 0.22373611, 0.04732879, 0.17067049, 0.04517748]),\n",
       "   'split1_test_Accuracy': array([0.24458874, 0.09704185, 0.08333333, 0.29076479, 0.04437229,\n",
       "          0.08116883, 0.11291486, 0.13528139, 0.09018759, 0.07467532,\n",
       "          0.04689755, 0.05880231, 0.3531746 , 0.05663781, 0.07034632,\n",
       "          0.04473304, 0.04689755, 0.10137085, 0.08513709, 0.10750361,\n",
       "          0.1969697 , 0.17135642, 0.12193362, 0.06818182, 0.1547619 ,\n",
       "          0.16233766, 0.23340548, 0.04689755, 0.16810967, 0.04689755]),\n",
       "   'split2_test_Accuracy': array([0.24085476, 0.09960159, 0.08982253, 0.29808041, 0.0467222 ,\n",
       "          0.07533502, 0.10322347, 0.12640348, 0.09308222, 0.07352409,\n",
       "          0.04744658, 0.05758783, 0.35277074, 0.0554147 , 0.0554147 ,\n",
       "          0.04599783, 0.07388627, 0.11590004, 0.06954002, 0.07243752,\n",
       "          0.21369069, 0.13473379, 0.13980442, 0.06954002, 0.13980442,\n",
       "          0.12966317, 0.20644694, 0.04599783, 0.15863817, 0.04744658]),\n",
       "   'mean_test_Accuracy': array([0.24657534, 0.10153809, 0.08183129, 0.29091565, 0.05335256,\n",
       "          0.08038933, 0.10598414, 0.12869503, 0.09420812, 0.07173756,\n",
       "          0.04722422, 0.06200433, 0.35111752, 0.05972122, 0.06260514,\n",
       "          0.0456621 , 0.06056236, 0.11547705, 0.07906753, 0.09168469,\n",
       "          0.20115357, 0.14744052, 0.12785388, 0.06813266, 0.14251382,\n",
       "          0.14984379, 0.22122086, 0.04674357, 0.16582552, 0.04650324]),\n",
       "   'std_test_Accuracy': array([0.00563218, 0.00465239, 0.00718161, 0.00576138, 0.0110387 ,\n",
       "          0.00383028, 0.00493111, 0.00472486, 0.00381552, 0.00336161,\n",
       "          0.00023583, 0.00538643, 0.00261872, 0.00522648, 0.00610126,\n",
       "          0.00066481, 0.01100668, 0.01132872, 0.00680144, 0.01449061,\n",
       "          0.00898913, 0.01691328, 0.00842063, 0.001164  , 0.00908817,\n",
       "          0.01436199, 0.011135  , 0.00055424, 0.0051714 , 0.00096751]),\n",
       "   'rank_test_Accuracy': array([ 3, 14, 17,  2, 26, 18, 13, 10, 15, 20, 27, 23,  1, 25, 22, 30, 24,\n",
       "          12, 19, 16,  5,  8, 11, 21,  9,  7,  4, 28,  6, 29]),\n",
       "   'split0_train_Accuracy': array([0.27453461, 0.11060907, 0.07283571, 0.34773179, 0.06885957,\n",
       "          0.0818724 , 0.10735586, 0.12850172, 0.10012651, 0.07030544,\n",
       "          0.04735225, 0.07428158, 0.43809868, 0.07030544, 0.05982288,\n",
       "          0.04699078, 0.06235315, 0.136454  , 0.08349901, 0.09380083,\n",
       "          0.20314477, 0.1503705 , 0.12886318, 0.0684981 , 0.14277969,\n",
       "          0.16681728, 0.23947226, 0.04735225, 0.17278149, 0.04644858]),\n",
       "   'split1_train_Accuracy': array([0.28234234, 0.10036036, 0.08648649, 0.35693694, 0.04396396,\n",
       "          0.07927928, 0.11279279, 0.14684685, 0.08774775, 0.07621622,\n",
       "          0.04774775, 0.06216216, 0.46756757, 0.05837838, 0.06558559,\n",
       "          0.04540541, 0.04774775, 0.11045045, 0.08990991, 0.11333333,\n",
       "          0.20864865, 0.17387387, 0.11477477, 0.06828829, 0.15747748,\n",
       "          0.16108108, 0.26234234, 0.04774775, 0.17207207, 0.04774775]),\n",
       "   'split2_train_Accuracy': array([0.27045495, 0.0983636 , 0.09548642, 0.34813882, 0.04513577,\n",
       "          0.0771444 , 0.1096925 , 0.13486783, 0.0945873 , 0.07462687,\n",
       "          0.0476533 , 0.05862255, 0.44128754, 0.05664449, 0.05664449,\n",
       "          0.04603489, 0.0733681 , 0.11598633, 0.06707427, 0.07480669,\n",
       "          0.22855602, 0.14044237, 0.13378889, 0.06707427, 0.14511778,\n",
       "          0.14835461, 0.23413055, 0.04621471, 0.15932386, 0.0476533 ]),\n",
       "   'mean_train_Accuracy': array([0.2757773 , 0.10311101, 0.08493621, 0.35093585, 0.0526531 ,\n",
       "          0.07943203, 0.10994705, 0.1367388 , 0.09415386, 0.07371617,\n",
       "          0.04758443, 0.0650221 , 0.4489846 , 0.0617761 , 0.06068432,\n",
       "          0.04614369, 0.06115633, 0.1209636 , 0.08016106, 0.09398028,\n",
       "          0.21344981, 0.15489558, 0.12580895, 0.06795355, 0.14845832,\n",
       "          0.15875099, 0.24531505, 0.0471049 , 0.16805914, 0.04728321]),\n",
       "   'std_train_Accuracy': array([0.00493192, 0.00536423, 0.00931186, 0.00424666, 0.01146969,\n",
       "          0.00193322, 0.0022269 , 0.00760532, 0.0050629 , 0.00249751,\n",
       "          0.00016864, 0.00670501, 0.01320448, 0.00607255, 0.00370066,\n",
       "          0.00065178, 0.01049365, 0.0111841 , 0.00961676, 0.01572895,\n",
       "          0.01091547, 0.01401841, 0.00805731, 0.00062762, 0.00644855,\n",
       "          0.00771533, 0.01223601, 0.00064984, 0.00618356, 0.00059143]),\n",
       "   'split0_test_F1': array([0.20862058, 0.03678405, 0.01263185, 0.25821546, 0.01493422,\n",
       "          0.01805705, 0.03197722, 0.03976627, 0.02218283, 0.01029199,\n",
       "          0.00431482, 0.01647022, 0.33844317, 0.01029199, 0.01054977,\n",
       "          0.01146447, 0.00811305, 0.05019296, 0.0216662 , 0.02336426,\n",
       "          0.12861079, 0.07144698, 0.0507374 , 0.00888731, 0.05665203,\n",
       "          0.07415284, 0.18920918, 0.00431482, 0.09618299, 0.00422588]),\n",
       "   'split1_test_F1': array([0.20370972, 0.02415957, 0.01609542, 0.26619726, 0.00472789,\n",
       "          0.01688997, 0.03567035, 0.05867456, 0.01947096, 0.01603782,\n",
       "          0.00430345, 0.0097795 , 0.34464277, 0.00942605, 0.01111162,\n",
       "          0.00771948, 0.00430345, 0.03514268, 0.0195491 , 0.02892441,\n",
       "          0.13158693, 0.08244909, 0.03935232, 0.01460549, 0.06766692,\n",
       "          0.08047227, 0.19089035, 0.00430345, 0.09121042, 0.00430345]),\n",
       "   'split2_test_F1': array([0.20688436, 0.02654645, 0.01976305, 0.27175751, 0.00463932,\n",
       "          0.0155619 , 0.03460174, 0.05100368, 0.02162766, 0.01247158,\n",
       "          0.00436449, 0.00967094, 0.3392387 , 0.00900391, 0.00900391,\n",
       "          0.00737467, 0.0119956 , 0.03537131, 0.00926026, 0.01063721,\n",
       "          0.14563032, 0.05788426, 0.05280055, 0.00926026, 0.05696301,\n",
       "          0.05827956, 0.15484498, 0.00433386, 0.07276464, 0.00436449]),\n",
       "   'mean_test_F1': array([0.20640878, 0.02918238, 0.01615147, 0.26536701, 0.00811901,\n",
       "          0.01684048, 0.03407812, 0.04979274, 0.02109534, 0.01292901,\n",
       "          0.00432751, 0.01198579, 0.34077215, 0.0095762 , 0.01022404,\n",
       "          0.00886016, 0.00813222, 0.04026242, 0.01684507, 0.02099384,\n",
       "          0.13524871, 0.07061199, 0.04762961, 0.01091573, 0.06042419,\n",
       "          0.0709915 , 0.17836811, 0.00431735, 0.08675713, 0.00429771]),\n",
       "   'std_test_F1': array([2.03496990e-03, 5.48403397e-03, 2.91205969e-03, 5.56049012e-03,\n",
       "          4.83876892e-03, 1.01941054e-03, 1.55390940e-03, 7.77524016e-03,\n",
       "          1.17015576e-03, 2.37047751e-03, 2.64673378e-05, 3.18415257e-03,\n",
       "          2.75468228e-03, 5.36544401e-04, 8.89877127e-04, 1.85433209e-03,\n",
       "          3.13608241e-03, 7.05106495e-03, 5.41402883e-03, 7.64318759e-03,\n",
       "          7.41556866e-03, 1.00324937e-02, 5.91010517e-03, 2.61208600e-03,\n",
       "          5.12019212e-03, 9.32209658e-03, 1.65891760e-02, 1.25258860e-05,\n",
       "          1.00667298e-02, 5.67418846e-05]),\n",
       "   'rank_test_F1': array([ 3, 14, 19,  2, 27, 18, 13, 10, 15, 20, 28, 21,  1, 24, 23, 25, 26,\n",
       "          12, 17, 16,  5,  8, 11, 22,  9,  7,  4, 29,  6, 30]),\n",
       "   'split0_train_F1': array([0.22446473, 0.03904574, 0.01275483, 0.31208885, 0.01569267,\n",
       "          0.01728036, 0.03452474, 0.04125682, 0.02241724, 0.01088529,\n",
       "          0.00431973, 0.01817269, 0.42889512, 0.01088529, 0.01005577,\n",
       "          0.0123188 , 0.0083468 , 0.05329867, 0.02373638, 0.02330092,\n",
       "          0.13748721, 0.07728124, 0.05401623, 0.0091126 , 0.06119834,\n",
       "          0.07984866, 0.20181559, 0.00431973, 0.100954  , 0.00433334]),\n",
       "   'split1_train_F1': array([0.24206893, 0.02529442, 0.01658169, 0.33477544, 0.0046694 ,\n",
       "          0.01652202, 0.0356709 , 0.06383874, 0.01851326, 0.01662411,\n",
       "          0.00436035, 0.01055988, 0.45798624, 0.00963371, 0.01027826,\n",
       "          0.00795184, 0.00436035, 0.03783044, 0.02087229, 0.03032895,\n",
       "          0.14152624, 0.08362889, 0.03644742, 0.01505085, 0.06931288,\n",
       "          0.07989621, 0.21650628, 0.00436035, 0.09297178, 0.00436035]),\n",
       "   'split2_train_F1': array([0.23092013, 0.02576789, 0.02106504, 0.32206793, 0.00442204,\n",
       "          0.01610182, 0.0368028 , 0.05413121, 0.02167951, 0.0128185 ,\n",
       "          0.00438305, 0.00973683, 0.42969654, 0.0093814 , 0.0093814 ,\n",
       "          0.00765265, 0.01170542, 0.03523659, 0.00892014, 0.0109517 ,\n",
       "          0.15857438, 0.06246373, 0.05037407, 0.00892014, 0.05865574,\n",
       "          0.06890258, 0.17627197, 0.0043709 , 0.07329679, 0.00438305]),\n",
       "   'mean_train_F1': array([0.23248459, 0.03003602, 0.01680052, 0.3229774 , 0.00826137,\n",
       "          0.01663474, 0.03566615, 0.05307559, 0.02087   , 0.01344263,\n",
       "          0.00435438, 0.01282314, 0.4388593 , 0.0099668 , 0.00990514,\n",
       "          0.00930776, 0.00813753, 0.0421219 , 0.01784294, 0.02152719,\n",
       "          0.14586261, 0.07445795, 0.04694591, 0.01102787, 0.06305566,\n",
       "          0.07621581, 0.19819795, 0.00435033, 0.08907419, 0.00435891]),\n",
       "   'std_train_F1': array([7.27152536e-03, 6.37377171e-03, 3.39615658e-03, 9.28406254e-03,\n",
       "          5.25569182e-03, 4.87696014e-04, 9.30018666e-04, 9.24920121e-03,\n",
       "          1.69346504e-03, 2.38406871e-03, 2.61906798e-05, 3.79760357e-03,\n",
       "          1.35287464e-02, 6.57586326e-04, 3.81318335e-04, 2.13262545e-03,\n",
       "          3.00226002e-03, 7.97379598e-03, 6.41679902e-03, 8.00953605e-03,\n",
       "          9.13857017e-03, 8.86826864e-03, 7.57099645e-03, 2.84576455e-03,\n",
       "          4.54465789e-03, 5.17127595e-03, 1.66235870e-02, 2.20603333e-05,\n",
       "          1.16224992e-02, 2.03195910e-05]),\n",
       "   'split0_test_Log_Loss': array([-3.20989481, -3.27201235, -3.24408975, -4.5396422 , -3.35321131,\n",
       "          -3.34173416, -3.14677398, -3.03191383, -3.08802798, -3.4136368 ,\n",
       "          -3.41688242, -3.35638561, -5.87951204, -3.4136368 , -3.45870709,\n",
       "          -3.54354273, -3.38435158, -3.1551263 , -3.25822656, -3.3557658 ,\n",
       "          -3.06673374, -3.32806133, -3.13995992, -3.2561095 , -3.10054943,\n",
       "          -3.07726024, -3.73996162, -3.41688242, -3.07036677, -3.43836606]),\n",
       "   'split1_test_Log_Loss': array([-3.66092298, -3.1944548 , -3.28302816, -4.40292236, -3.45744478,\n",
       "          -3.37573088, -3.18630812, -3.08927537, -3.25085113, -3.4933462 ,\n",
       "          -3.46753598, -3.44622732, -5.79669039, -3.44216611, -3.45016483,\n",
       "          -3.48200321, -3.46753598, -3.19636682, -3.23235246, -3.25012427,\n",
       "          -3.13464308, -3.08644291, -3.24391933, -3.3181352 , -2.96227929,\n",
       "          -3.23426367, -3.61261676, -3.46753598, -3.12257707, -3.46753598]),\n",
       "   'split2_test_Log_Loss': array([-3.42062235, -3.27540502, -3.19147762, -4.00359532, -3.44359334,\n",
       "          -3.28930298, -3.21527106, -3.24594235, -3.1388395 , -3.51974147,\n",
       "          -3.42867544, -3.45207812, -5.8536502 , -3.4033923 , -3.4033923 ,\n",
       "          -3.54593353, -3.35964859, -3.07339325, -3.24352617, -3.49990594,\n",
       "          -3.03613426, -3.18456006, -3.17116698, -3.24352617, -3.09386744,\n",
       "          -3.1383724 , -3.25306526, -3.43473919, -3.06606211, -3.42867544]),\n",
       "   'mean_test_Log_Loss': array([-3.43004247, -3.24730406, -3.23960467, -4.31625685, -3.41791691,\n",
       "          -3.33566307, -3.18266788, -3.12202906, -3.15912103, -3.47538992,\n",
       "          -3.43766735, -3.41805927, -5.84334451, -3.41974088, -3.43750987,\n",
       "          -3.52383754, -3.40386398, -3.14174656, -3.24473091, -3.36839889,\n",
       "          -3.07920184, -3.19997033, -3.18494168, -3.27259504, -3.05227572,\n",
       "          -3.14983224, -3.53600574, -3.43967913, -3.0863295 , -3.44486729]),\n",
       "   'std_test_Log_Loss': array([0.18446568, 0.03737555, 0.03746031, 0.22728502, 0.04628524,\n",
       "          0.03549889, 0.02808657, 0.09040509, 0.0680669 , 0.0451446 ,\n",
       "          0.02165115, 0.04385177, 0.03462133, 0.01639119, 0.02429224,\n",
       "          0.02958146, 0.04611519, 0.05102773, 0.01060939, 0.10222902,\n",
       "          0.04112555, 0.09935051, 0.0435852 , 0.03259189, 0.06366117,\n",
       "          0.06467718, 0.20604862, 0.02099391, 0.02567728, 0.01650193]),\n",
       "   'rank_test_Log_Loss': array([21, 13, 11, 29, 18, 15,  8,  4,  7, 26, 23, 19, 30, 20, 22, 27, 17,\n",
       "           5, 12, 16,  2, 10,  9, 14,  1,  6, 28, 24,  3, 25]),\n",
       "   'split0_train_Log_Loss': array([-2.29472181, -3.18813544, -3.21264907, -1.97085337, -3.33715182,\n",
       "          -3.31448946, -3.02896951, -2.96612891, -3.03694721, -3.3969163 ,\n",
       "          -3.41616225, -3.32223515, -1.65070875, -3.3969163 , -3.43321158,\n",
       "          -3.52575849, -3.357682  , -2.93513267, -3.2190251 , -3.33918746,\n",
       "          -2.5747146 , -2.87448016, -2.90584606, -3.23498544, -2.85429262,\n",
       "          -2.76612943, -2.372168  , -3.41616225, -2.64363266, -3.42211965]),\n",
       "   'split1_train_Log_Loss': array([-2.28422606, -3.14326553, -3.15090272, -1.97580089, -3.44293075,\n",
       "          -3.31768506, -3.02349068, -2.96877096, -3.13745286, -3.48945853,\n",
       "          -3.41062349, -3.43577809, -1.61110701, -3.38507407, -3.40162766,\n",
       "          -3.48553784, -3.41062349, -3.07909437, -3.14549414, -3.23629368,\n",
       "          -2.52675317, -2.71798261, -2.93545894, -3.31685969, -2.7336968 ,\n",
       "          -2.79472612, -2.2720303 , -3.41062349, -2.68812567, -3.41062349]),\n",
       "   'split2_train_Log_Loss': array([-2.35154686, -3.21059406, -3.08964277, -2.03697424, -3.43098731,\n",
       "          -3.22152467, -3.07201414, -2.9791555 , -3.11133619, -3.44669728,\n",
       "          -3.41474762, -3.43671656, -1.64554419, -3.38937315, -3.38937315,\n",
       "          -3.47232174, -3.33137102, -2.99168868, -3.240013  , -3.48128515,\n",
       "          -2.50002633, -2.81407977, -2.92843266, -3.240013  , -2.87087266,\n",
       "          -2.86220558, -2.34803294, -3.42385117, -2.73394676, -3.41474762]),\n",
       "   'mean_train_Log_Loss': array([-2.31016491, -3.18066501, -3.15106485, -1.99454283, -3.40368996,\n",
       "          -3.28456639, -3.04149144, -2.97135179, -3.09524542, -3.44435737,\n",
       "          -3.41384445, -3.39824327, -1.63578665, -3.39045451, -3.4080708 ,\n",
       "          -3.49453936, -3.36655884, -3.00197191, -3.20151075, -3.35225543,\n",
       "          -2.53383137, -2.80218085, -2.92324589, -3.26395271, -2.81962069,\n",
       "          -2.80768704, -2.33074375, -3.41687897, -2.68856837, -3.41583025]),\n",
       "   'std_train_Log_Loss': array([0.02957352, 0.02798974, 0.05021724, 0.03007145, 0.04730154,\n",
       "          0.04459632, 0.0216984 , 0.00562249, 0.04257958, 0.03781642,\n",
       "          0.00234965, 0.05374722, 0.01757805, 0.00489466, 0.01846777,\n",
       "          0.02272505, 0.03295792, 0.05922022, 0.04052586, 0.1004433 ,\n",
       "          0.03089941, 0.06444149, 0.01263349, 0.03746715, 0.06113325,\n",
       "          0.04027941, 0.04266987, 0.00542391, 0.03687191, 0.00475531])},\n",
       "  {'min_samples_split': 0.15,\n",
       "   'max_features': 'log2',\n",
       "   'max_depth': None,\n",
       "   'criterion': 'entropy',\n",
       "   'class_weight': None},\n",
       "  24,\n",
       "  -3.0522757198686974),\n",
       " 'KNeighborsClassifier_V01_PCA_5components': ({'mean_fit_time': array([0.00631698, 0.01030548, 0.00598375, 0.00565116, 0.00797717,\n",
       "          0.00897551, 0.00565084, 0.00897551, 0.00997289, 0.00964101,\n",
       "          0.00864355, 0.00930866, 0.00598359, 0.00897543, 0.0063169 ,\n",
       "          0.00864339, 0.00964093, 0.01196798, 0.01030525, 0.00997313,\n",
       "          0.00664862, 0.00565179, 0.00964022, 0.00531896, 0.00930794,\n",
       "          0.00731349, 0.00764577, 0.00930834, 0.00897582, 0.00631587]),\n",
       "   'std_fit_time': array([4.69965469e-04, 4.70303127e-04, 2.24783192e-07, 4.69796871e-04,\n",
       "          1.40978439e-03, 8.14101456e-04, 9.39987159e-04, 8.14685460e-04,\n",
       "          8.13225616e-04, 4.70077941e-04, 9.40605287e-04, 9.40942462e-04,\n",
       "          1.41023355e-03, 2.97360213e-07, 1.24432506e-03, 1.69487421e-03,\n",
       "          9.40380565e-04, 2.82125385e-03, 9.40773860e-04, 1.62849482e-03,\n",
       "          9.40324414e-04, 4.70246438e-04, 4.70021816e-04, 4.70639818e-04,\n",
       "          4.70134046e-04, 4.69010171e-04, 9.40436927e-04, 1.24438878e-03,\n",
       "          4.05233662e-07, 4.70078102e-04]),\n",
       "   'mean_score_time': array([1.23436705, 0.13364299, 1.34374054, 1.27259906, 0.31848168,\n",
       "          0.14128939, 1.25763837, 0.12832387, 0.12167422, 0.11003892,\n",
       "          0.1033903 , 0.14095712, 1.21508606, 0.11801847, 1.02027281,\n",
       "          0.33144728, 0.143284  , 0.11037175, 0.09474635, 0.12067755,\n",
       "          1.3843019 , 1.02924919, 0.09906872, 1.34507124, 0.09042501,\n",
       "          0.30053083, 0.30950642, 0.09341701, 0.13264545, 1.16422272]),\n",
       "   'std_score_time': array([0.07825261, 0.01360167, 0.04212695, 0.06109063, 0.01728087,\n",
       "          0.02523468, 0.04796206, 0.00682888, 0.02045359, 0.02098843,\n",
       "          0.0052359 , 0.01267577, 0.00554303, 0.00729787, 0.02204655,\n",
       "          0.01448295, 0.01397138, 0.01316484, 0.00850178, 0.00587146,\n",
       "          0.062065  , 0.11052272, 0.00169505, 0.13065778, 0.00261818,\n",
       "          0.0260627 , 0.03802425, 0.00448491, 0.00990645, 0.02808359]),\n",
       "   'param_weights': masked_array(data=['uniform', 'distance', 'distance', 'distance',\n",
       "                      'uniform', 'uniform', 'distance', 'distance',\n",
       "                      'uniform', 'uniform', 'distance', 'distance',\n",
       "                      'uniform', 'distance', 'distance', 'distance',\n",
       "                      'distance', 'distance', 'distance', 'distance',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'uniform', 'distance',\n",
       "                      'distance'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[5, 4, 4, 8, 6, 6, 5, 7, 6, 4, 5, 6, 8, 5, 3, 8, 8, 4,\n",
       "                      3, 6, 4, 3, 4, 7, 3, 5, 7, 3, 8, 7],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['brute', 'auto', 'brute', 'brute', 'ball_tree', 'auto',\n",
       "                      'brute', 'kd_tree', 'kd_tree', 'kd_tree', 'auto',\n",
       "                      'auto', 'brute', 'kd_tree', 'brute', 'ball_tree',\n",
       "                      'auto', 'kd_tree', 'kd_tree', 'kd_tree', 'brute',\n",
       "                      'brute', 'auto', 'brute', 'kd_tree', 'ball_tree',\n",
       "                      'ball_tree', 'auto', 'kd_tree', 'brute'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'}],\n",
       "   'split0_test_Accuracy': array([0.56937971, 0.61240588, 0.61240588, 0.60774471, 0.55862316,\n",
       "          0.55862316, 0.60846181, 0.60846181, 0.55862316, 0.57511653,\n",
       "          0.60846181, 0.60774471, 0.55181068, 0.60846181, 0.60917892,\n",
       "          0.60774471, 0.60774471, 0.61240588, 0.60917892, 0.60774471,\n",
       "          0.57511653, 0.57439943, 0.57511653, 0.55898171, 0.57439943,\n",
       "          0.56937971, 0.60846181, 0.57439943, 0.60774471, 0.60846181]),\n",
       "   'split1_test_Accuracy': array([0.55194805, 0.59559885, 0.59559885, 0.58766234, 0.55519481,\n",
       "          0.55519481, 0.5959596 , 0.58982684, 0.55519481, 0.55122655,\n",
       "          0.5959596 , 0.59487734, 0.52922078, 0.5959596 , 0.6024531 ,\n",
       "          0.58766234, 0.58766234, 0.59559885, 0.6024531 , 0.59487734,\n",
       "          0.55122655, 0.55735931, 0.55122655, 0.53860029, 0.55735931,\n",
       "          0.55194805, 0.58982684, 0.55735931, 0.58766234, 0.58982684]),\n",
       "   'split2_test_Accuracy': array([0.57370518, 0.61934082, 0.61934082, 0.60195581, 0.56356393,\n",
       "          0.56356393, 0.61427019, 0.60557769, 0.56356393, 0.57189424,\n",
       "          0.61427019, 0.61137269, 0.55161173, 0.61427019, 0.62404926,\n",
       "          0.60195581, 0.60195581, 0.61934082, 0.62404926, 0.61137269,\n",
       "          0.57189424, 0.58203549, 0.57189424, 0.55994205, 0.58203549,\n",
       "          0.57370518, 0.60557769, 0.58203549, 0.60195581, 0.60557769]),\n",
       "   'mean_test_Accuracy': array([0.56500841, 0.60910839, 0.60910839, 0.59913482, 0.5591204 ,\n",
       "          0.5591204 , 0.60622447, 0.60129776, 0.5591204 , 0.56608988,\n",
       "          0.60622447, 0.60466234, 0.54422014, 0.60622447, 0.61187215,\n",
       "          0.59913482, 0.59913482, 0.60910839, 0.61187215, 0.60466234,\n",
       "          0.56608988, 0.57125691, 0.56608988, 0.55251142, 0.57125691,\n",
       "          0.56500841, 0.60129776, 0.57125691, 0.59913482, 0.60129776]),\n",
       "   'std_test_Accuracy': array([0.00939753, 0.00995859, 0.00995859, 0.00844541, 0.00343027,\n",
       "          0.00343027, 0.00763227, 0.00819187, 0.00343027, 0.01058636,\n",
       "          0.00763227, 0.00707218, 0.01060073, 0.00763227, 0.00900989,\n",
       "          0.00844541, 0.00844541, 0.00995859, 0.00900989, 0.00707218,\n",
       "          0.01058636, 0.01030479, 0.01058636, 0.00983915, 0.01030479,\n",
       "          0.00939753, 0.00819187, 0.01030479, 0.00844541, 0.00819187]),\n",
       "   'rank_test_Accuracy': array([24,  3,  3, 14, 26, 26,  6, 11, 26, 21,  6,  9, 30,  6,  1, 14, 14,\n",
       "           3,  1,  9, 21, 18, 21, 29, 18, 24, 11, 18, 14, 11]),\n",
       "   'split0_train_Accuracy': array([0.7158865 , 1.        , 1.        , 1.        , 0.69492138,\n",
       "          0.69492138, 1.        , 1.        , 0.69492138, 0.74299657,\n",
       "          1.        , 1.        , 0.6607627 , 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74299657, 0.77082957, 0.74299657, 0.67359479, 0.77082957,\n",
       "          0.7158865 , 1.        , 0.77082957, 1.        , 1.        ]),\n",
       "   'split1_train_Accuracy': array([0.72198198, 1.        , 1.        , 1.        , 0.70288288,\n",
       "          0.70288288, 1.        , 1.        , 0.70288288, 0.74666667,\n",
       "          1.        , 1.        , 0.66522523, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74666667, 0.77243243, 0.74666667, 0.67657658, 0.77243243,\n",
       "          0.72198198, 1.        , 0.77243243, 1.        , 1.        ]),\n",
       "   'split2_train_Accuracy': array([0.71443985, 1.        , 1.        , 1.        , 0.69106276,\n",
       "          0.69106276, 1.        , 1.        , 0.69106276, 0.74141341,\n",
       "          1.        , 1.        , 0.65689624, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74141341, 0.76892645, 0.74141341, 0.67721633, 0.76892645,\n",
       "          0.71443985, 1.        , 0.76892645, 1.        , 1.        ]),\n",
       "   'mean_train_Accuracy': array([0.71743611, 1.        , 1.        , 1.        , 0.69628901,\n",
       "          0.69628901, 1.        , 1.        , 0.69628901, 0.74369222,\n",
       "          1.        , 1.        , 0.66096139, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74369222, 0.77072948, 0.74369222, 0.6757959 , 0.77072948,\n",
       "          0.71743611, 1.        , 0.77072948, 1.        , 1.        ]),\n",
       "   'std_train_Accuracy': array([0.00326822, 0.        , 0.        , 0.        , 0.00492149,\n",
       "          0.00492149, 0.        , 0.        , 0.00492149, 0.00220032,\n",
       "          0.        , 0.        , 0.00340319, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00220032, 0.00143306, 0.00220032, 0.00157818, 0.00143306,\n",
       "          0.00326822, 0.        , 0.00143306, 0.        , 0.        ]),\n",
       "   'split0_test_F1': array([0.56336644, 0.60707375, 0.60707375, 0.60099399, 0.55068434,\n",
       "          0.55068434, 0.60239573, 0.60177325, 0.55068434, 0.57023382,\n",
       "          0.60239573, 0.60069239, 0.54435514, 0.60239573, 0.60545195,\n",
       "          0.60099399, 0.60099399, 0.60707375, 0.60545195, 0.60069239,\n",
       "          0.57023382, 0.56700581, 0.57023382, 0.55166711, 0.56700581,\n",
       "          0.56336644, 0.60177325, 0.56700581, 0.60099399, 0.60177325]),\n",
       "   'split1_test_F1': array([0.5451344 , 0.59039038, 0.59039038, 0.58006789, 0.54818972,\n",
       "          0.54818972, 0.5905374 , 0.58321073, 0.54818972, 0.54537933,\n",
       "          0.5905374 , 0.58933338, 0.52092012, 0.5905374 , 0.59879075,\n",
       "          0.58006789, 0.58006789, 0.59039038, 0.59879075, 0.58933338,\n",
       "          0.54537933, 0.55167283, 0.54537933, 0.53044619, 0.55167283,\n",
       "          0.5451344 , 0.58321073, 0.55167283, 0.58006789, 0.58321073]),\n",
       "   'split2_test_F1': array([0.56709327, 0.61411837, 0.61411837, 0.59446414, 0.55542754,\n",
       "          0.55542754, 0.6084174 , 0.5986888 , 0.55542754, 0.56791939,\n",
       "          0.6084174 , 0.60483292, 0.54338353, 0.6084174 , 0.62040947,\n",
       "          0.59446414, 0.59446414, 0.61411837, 0.62040947, 0.60483292,\n",
       "          0.56791939, 0.57797406, 0.56791939, 0.55156789, 0.57797406,\n",
       "          0.56709327, 0.5986888 , 0.57797406, 0.59446414, 0.5986888 ]),\n",
       "   'mean_test_F1': array([0.55852993, 0.60385384, 0.60385384, 0.59185724, 0.55142706,\n",
       "          0.55142706, 0.60044362, 0.59456687, 0.55142706, 0.5611871 ,\n",
       "          0.60044362, 0.59828249, 0.53622675, 0.60044362, 0.60819563,\n",
       "          0.59185724, 0.59185724, 0.60385384, 0.60819563, 0.59828249,\n",
       "          0.5611871 , 0.56553745, 0.5611871 , 0.54456565, 0.56553745,\n",
       "          0.55852993, 0.59456687, 0.56553745, 0.59185724, 0.59456687]),\n",
       "   'std_test_F1': array([0.00958847, 0.00994023, 0.00994023, 0.00874803, 0.00299757,\n",
       "          0.00299757, 0.00742017, 0.00812388, 0.00299757, 0.01121163,\n",
       "          0.00742017, 0.00654663, 0.01082484, 0.00742017, 0.00902654,\n",
       "          0.00874803, 0.00874803, 0.00994023, 0.00902654, 0.00654663,\n",
       "          0.01121163, 0.01077344, 0.01121163, 0.00997865, 0.01077344,\n",
       "          0.00958847, 0.00812388, 0.01077344, 0.00874803, 0.00812388]),\n",
       "   'rank_test_F1': array([24,  3,  3, 14, 26, 26,  6, 11, 26, 21,  6,  9, 30,  6,  1, 14, 14,\n",
       "           3,  1,  9, 21, 18, 21, 29, 18, 24, 11, 18, 14, 11]),\n",
       "   'split0_train_F1': array([0.71198786, 1.        , 1.        , 1.        , 0.68949764,\n",
       "          0.68949764, 1.        , 1.        , 0.68949764, 0.73946619,\n",
       "          1.        , 1.        , 0.65548679, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.73946619, 0.76686812, 0.73946619, 0.66815213, 0.76686812,\n",
       "          0.71198786, 1.        , 0.76686812, 1.        , 1.        ]),\n",
       "   'split1_train_F1': array([0.71889471, 1.        , 1.        , 1.        , 0.69903146,\n",
       "          0.69903146, 1.        , 1.        , 0.69903146, 0.74422587,\n",
       "          1.        , 1.        , 0.6598798 , 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74422587, 0.76995029, 0.74422587, 0.67162509, 0.76995029,\n",
       "          0.71889471, 1.        , 0.76995029, 1.        , 1.        ]),\n",
       "   'split2_train_F1': array([0.71104852, 1.        , 1.        , 1.        , 0.68709703,\n",
       "          0.68709703, 1.        , 1.        , 0.68709703, 0.73923095,\n",
       "          1.        , 1.        , 0.65074595, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.73923095, 0.7661349 , 0.73923095, 0.67197089, 0.7661349 ,\n",
       "          0.71104852, 1.        , 0.7661349 , 1.        , 1.        ]),\n",
       "   'mean_train_F1': array([0.71397703, 1.        , 1.        , 1.        , 0.69187538,\n",
       "          0.69187538, 1.        , 1.        , 0.69187538, 0.74097434,\n",
       "          1.        , 1.        , 0.65537085, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "          0.74097434, 0.76765111, 0.74097434, 0.6705827 , 0.76765111,\n",
       "          0.71397703, 1.        , 0.76765111, 1.        , 1.        ]),\n",
       "   'std_train_F1': array([0.00349841, 0.        , 0.        , 0.        , 0.00515415,\n",
       "          0.00515415, 0.        , 0.        , 0.00515415, 0.00230118,\n",
       "          0.        , 0.        , 0.00372978, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.00230118, 0.0016531 , 0.00230118, 0.00172446, 0.0016531 ,\n",
       "          0.00349841, 0.        , 0.0016531 , 0.        , 0.        ]),\n",
       "   'split0_test_Log_Loss': array([-6.62037105, -7.37530297, -7.37530297, -5.18650796, -6.08202254,\n",
       "          -6.08202254, -6.56017901, -5.45973375, -6.08202254, -7.42330533,\n",
       "          -6.56017901, -6.01212882, -5.27406309, -6.56017901, -8.61661139,\n",
       "          -5.18650796, -5.18650796, -7.37530297, -8.61661139, -6.01212882,\n",
       "          -7.42330533, -8.65164534, -7.42330533, -5.53862382, -8.65164534,\n",
       "          -6.62037105, -5.45973375, -8.65164534, -5.18650796, -5.45973375]),\n",
       "   'split1_test_Log_Loss': array([-6.84433126, -7.49612482, -7.49612482, -5.48074136, -6.28733099,\n",
       "          -6.28733099, -6.78300572, -5.75643822, -6.28733099, -7.54567146,\n",
       "          -6.78300572, -6.21738774, -5.57001166, -6.78300572, -8.7755334 ,\n",
       "          -5.48074136, -5.48074136, -7.49612482, -8.7755334 , -6.21738774,\n",
       "          -7.54567146, -8.81196935, -7.54567146, -5.83562554, -8.81196935,\n",
       "          -6.84433126, -5.75643822, -8.81196935, -5.48074136, -5.75643822]),\n",
       "   'split2_test_Log_Loss': array([-6.82215606, -7.30990703, -7.30990703, -5.20581767, -6.18146839,\n",
       "          -6.18146839, -6.76129975, -5.5769204 , -6.18146839, -7.358676  ,\n",
       "          -6.76129975, -6.1104041 , -5.29313017, -6.76129975, -8.4051443 ,\n",
       "          -5.20581767, -5.20581767, -7.30990703, -8.4051443 , -6.1104041 ,\n",
       "          -7.358676  , -8.44117367, -7.358676  , -5.65577024, -8.44117367,\n",
       "          -6.82215606, -5.5769204 , -8.44117367, -5.20581767, -5.5769204 ]),\n",
       "   'mean_test_Log_Loss': array([-6.76191709, -7.39385139, -7.39385139, -5.29092146, -6.18340262,\n",
       "          -6.18340262, -6.7011271 , -5.59744309, -6.18340262, -7.44262248,\n",
       "          -6.7011271 , -6.11310404, -5.3789674 , -6.7011271 , -8.59938851,\n",
       "          -5.29092146, -5.29092146, -7.39385139, -8.59938851, -6.11310404,\n",
       "          -7.44262248, -8.63521971, -7.44262248, -5.67641882, -8.63521971,\n",
       "          -6.76191709, -5.59744309, -8.63521971, -5.29092146, -5.59744309]),\n",
       "   'std_test_Log_Loss': array([0.10090019, 0.07705377, 0.07705377, 0.13438187, 0.08392564,\n",
       "          0.08392564, 0.10046035, 0.1221295 , 0.08392564, 0.07746094,\n",
       "          0.10046035, 0.0839159 , 0.13523993, 0.10046035, 0.15150014,\n",
       "          0.13438187, 0.13438187, 0.07705377, 0.15150014, 0.0839159 ,\n",
       "          0.07746094, 0.15162078, 0.07746094, 0.12226066, 0.15162078,\n",
       "          0.10090019, 0.1221295 , 0.15162078, 0.13438187, 0.1221295 ]),\n",
       "   'rank_test_Log_Loss': array([18, 20, 20,  1, 12, 12, 15,  6, 12, 23, 16, 10,  5, 16, 26,  1,  1,\n",
       "          20, 26, 10, 23, 28, 23,  9, 28, 18,  6, 28,  1,  6]),\n",
       "   'split0_train_Log_Loss': array([-6.47308204e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -7.24485535e-01, -7.24485535e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -7.24485535e-01, -5.54500212e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -8.46368180e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -3.77251697e-14, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -5.54500212e-01, -4.32327831e-01, -5.54500212e-01, -7.88139174e-01,\n",
       "          -4.32327831e-01, -6.47308204e-01, -3.77251697e-14, -4.32327831e-01,\n",
       "          -3.77251697e-14, -3.77251697e-14]),\n",
       "   'split1_train_Log_Loss': array([-6.37617191e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -7.13947732e-01, -7.13947732e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -7.13947732e-01, -5.45117260e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -8.40734872e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -3.77252183e-14, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -5.45117260e-01, -4.27843361e-01, -5.45117260e-01, -7.81636355e-01,\n",
       "          -4.27843361e-01, -6.37617191e-01, -3.77252183e-14, -4.27843361e-01,\n",
       "          -3.77252183e-14, -3.77252183e-14]),\n",
       "   'split2_train_Log_Loss': array([-6.46395154e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -7.25114632e-01, -7.25114632e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -7.25114632e-01, -5.52359604e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -8.47452107e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -3.77251228e-14, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -5.52359604e-01, -4.33895236e-01, -5.52359604e-01, -7.88793325e-01,\n",
       "          -4.33895236e-01, -6.46395154e-01, -3.77251228e-14, -4.33895236e-01,\n",
       "          -3.77251228e-14, -3.77251228e-14]),\n",
       "   'mean_train_Log_Loss': array([-6.43773516e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -7.21182633e-01, -7.21182633e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -7.21182633e-01, -5.50659025e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -8.44851720e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -3.77251703e-14, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -5.50659025e-01, -4.31355476e-01, -5.50659025e-01, -7.86189618e-01,\n",
       "          -4.31355476e-01, -6.43773516e-01, -3.77251703e-14, -4.31355476e-01,\n",
       "          -3.77251703e-14, -3.77251703e-14]),\n",
       "   'std_train_Log_Loss': array([4.36910887e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          5.12229035e-03, 5.12229035e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          5.12229035e-03, 4.01488238e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          2.94449231e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          3.89952081e-20, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          4.01488238e-03, 2.56455332e-03, 4.01488238e-03, 3.23069995e-03,\n",
       "          2.56455332e-03, 4.36910887e-03, 3.89952081e-20, 2.56455332e-03,\n",
       "          3.89952081e-20, 3.89952081e-20])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "  3,\n",
       "  -5.290921455335419),\n",
       " 'MLPClassifier_V01_PCA_5components': ({'mean_fit_time': array([ 4.88560851, 14.3812271 , 13.69871815, 13.62424874, 19.53677948,\n",
       "           4.84538102,  7.71271761,  5.73899293, 21.87785673,  3.23934118,\n",
       "           4.15655716,  0.67386524, 18.14184252, 18.52780938, 13.73894437,\n",
       "          14.14585551,  2.33010642,  2.49599576,  7.18446191,  3.16853094,\n",
       "           7.20175004,  7.10334635, 15.81871716, 14.43707752, 23.479906  ,\n",
       "           1.17219941, 11.47532606,  8.59236797, 17.22196603,  3.97670333]),\n",
       "   'std_fit_time': array([6.11592173, 0.63319867, 1.99239485, 0.15534065, 0.68843036,\n",
       "          6.05503332, 0.81769212, 0.57523248, 0.10029542, 0.74343455,\n",
       "          1.51555469, 0.010996  , 0.0359073 , 0.18243702, 1.96943288,\n",
       "          0.22758832, 0.43491191, 0.53157888, 0.07094034, 1.09742755,\n",
       "          0.0639589 , 0.86422295, 3.13037225, 0.5147204 , 0.50849058,\n",
       "          0.11505363, 1.0740562 , 0.88517299, 0.65069077, 0.86923281]),\n",
       "   'mean_score_time': array([0.07912183, 0.05651506, 0.05551791, 0.04720767, 0.05618358,\n",
       "          0.06881674, 0.04055842, 0.03825625, 0.06947931, 0.04288546,\n",
       "          0.0485363 , 0.08111715, 0.06815076, 0.07047892, 0.06748597,\n",
       "          0.05817803, 0.05950665, 0.05285788, 0.03823153, 0.06216685,\n",
       "          0.03922908, 0.05452108, 0.05319134, 0.0634977 , 0.06249968,\n",
       "          0.04288578, 0.05086454, 0.03590496, 0.0551854 , 0.04953551]),\n",
       "   'std_score_time': array([0.01673466, 0.00448367, 0.00046952, 0.00047047, 0.00248795,\n",
       "          0.00162752, 0.00169536, 0.00331941, 0.00490911, 0.00215476,\n",
       "          0.00477236, 0.00285997, 0.00124375, 0.00261839, 0.00663304,\n",
       "          0.00308218, 0.00463055, 0.00495352, 0.00338983, 0.00285954,\n",
       "          0.00188048, 0.00093987, 0.00169405, 0.00248861, 0.00417923,\n",
       "          0.00081342, 0.00215431, 0.00081459, 0.00823826, 0.00188026]),\n",
       "   'param_solver': masked_array(data=['lbfgs', 'adam', 'adam', 'adam', 'adam', 'lbfgs',\n",
       "                      'sgd', 'sgd', 'lbfgs', 'lbfgs', 'adam', 'lbfgs',\n",
       "                      'adam', 'adam', 'adam', 'lbfgs', 'adam', 'adam',\n",
       "                      'lbfgs', 'sgd', 'sgd', 'sgd', 'sgd', 'lbfgs', 'adam',\n",
       "                      'adam', 'lbfgs', 'adam', 'sgd', 'lbfgs'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50, 50), (100, 100, 50), (100, 100, 50),\n",
       "                      (100, 100), (200, 50, 50), (200, 50, 50), (100,),\n",
       "                      (100,), (200, 50, 50, 50), (100,), (100, 100),\n",
       "                      (200, 50, 50, 50), (200, 50, 50), (200, 50, 50),\n",
       "                      (200, 50, 50), (100, 100, 50), (200, 50, 50),\n",
       "                      (100, 100, 50), (100,), (100, 100, 50), (100,),\n",
       "                      (200, 50, 50, 50), (100, 100), (100, 100, 50),\n",
       "                      (100, 100, 50), (100, 100), (200, 50), (100,),\n",
       "                      (200, 50, 50), (200, 50, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0352, 0.026000000000000002, 0.0111,\n",
       "                      0.038700000000000005, 0.0178, 0.0259, 0.008,\n",
       "                      0.04850000000000001, 0.0261, 0.0254,\n",
       "                      0.044700000000000004, 0.0471, 0.049300000000000004,\n",
       "                      0.032200000000000006, 0.04000000000000001,\n",
       "                      0.03780000000000001, 0.0012000000000000001,\n",
       "                      0.0078000000000000005, 0.001, 0.04220000000000001,\n",
       "                      0.0035, 0.0009000000000000001, 0.0224,\n",
       "                      0.048100000000000004, 0.0064, 0.0236, 0.017, 0.0391,\n",
       "                      0.034, 0.0047],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['logistic', 'relu', 'relu', 'tanh', 'tanh', 'logistic',\n",
       "                      'logistic', 'identity', 'tanh', 'identity', 'identity',\n",
       "                      'logistic', 'logistic', 'logistic', 'relu', 'relu',\n",
       "                      'identity', 'identity', 'tanh', 'logistic', 'relu',\n",
       "                      'identity', 'tanh', 'logistic', 'tanh', 'identity',\n",
       "                      'tanh', 'tanh', 'tanh', 'identity'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0352,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.026000000000000002,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0111,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.038700000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0178,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0259,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.008,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.04850000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0261,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0254,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.044700000000000004,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0471,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.049300000000000004,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.032200000000000006,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.04000000000000001,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.03780000000000001,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0012000000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0078000000000000005,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.04220000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0035,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0009000000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0224,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.048100000000000004,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0064,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0236,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.017,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0391,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.034,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0047,\n",
       "     'activation': 'identity'}],\n",
       "   'split0_test_Accuracy': array([0.53424166, 0.54141269, 0.54714952, 0.57547508, 0.55647185,\n",
       "          0.05593403, 0.1351739 , 0.25242022, 0.55934027, 0.26676228,\n",
       "          0.25457153, 0.05593403, 0.3323772 , 0.36357117, 0.53065615,\n",
       "          0.55503765, 0.23234134, 0.24094658, 0.55181068, 0.05593403,\n",
       "          0.27751882, 0.25743994, 0.29221943, 0.55216924, 0.59662962,\n",
       "          0.26855504, 0.57117246, 0.45858731, 0.30692004, 0.26855504]),\n",
       "   'split1_test_Accuracy': array([0.05591631, 0.52056277, 0.53282828, 0.5544733 , 0.54040404,\n",
       "          0.52561328, 0.13600289, 0.2507215 , 0.55050505, 0.26587302,\n",
       "          0.27092352, 0.05591631, 0.33116883, 0.34704185, 0.504329  ,\n",
       "          0.5472583 , 0.26190476, 0.25541126, 0.55808081, 0.05591631,\n",
       "          0.27561328, 0.252886  , 0.3015873 , 0.52849928, 0.57720058,\n",
       "          0.26479076, 0.5515873 , 0.4527417 , 0.31493506, 0.26587302]),\n",
       "   'split2_test_Accuracy': array([0.05613908, 0.54183267, 0.55306049, 0.57479174, 0.56465049,\n",
       "          0.05613908, 0.14125317, 0.25787758, 0.56573705, 0.26838102,\n",
       "          0.26331039, 0.05613908, 0.34625136, 0.37921043, 0.53277798,\n",
       "          0.56791018, 0.25063383, 0.26439696, 0.55450924, 0.05613908,\n",
       "          0.27960884, 0.26077508, 0.30315103, 0.56175299, 0.57841362,\n",
       "          0.26693227, 0.5613908 , 0.47337921, 0.31401666, 0.27091633]),\n",
       "   'mean_test_Accuracy': array([0.21629416, 0.53460707, 0.5443403 , 0.56825282, 0.55383321,\n",
       "          0.21244893, 0.13746696, 0.25366498, 0.55851959, 0.26700312,\n",
       "          0.26291757, 0.05599615, 0.33657775, 0.36325403, 0.52259072,\n",
       "          0.55671714, 0.24825763, 0.25354482, 0.55479452, 0.05599615,\n",
       "          0.27757751, 0.25702956, 0.29896659, 0.54746455, 0.5841144 ,\n",
       "          0.2667628 , 0.56140351, 0.4615477 , 0.31194424, 0.26844509]),\n",
       "   'std_test_Accuracy': array([2.25735247e-01, 9.92692807e-03, 8.48627579e-03, 9.74231970e-03,\n",
       "          1.00611102e-02, 2.21320918e-01, 2.68928332e-03, 3.04841286e-03,\n",
       "          6.23728883e-03, 1.03670094e-03, 6.68918655e-03, 1.00968534e-04,\n",
       "          6.83411843e-03, 1.31169109e-02, 1.29350508e-02, 8.50368756e-03,\n",
       "          1.21987415e-02, 9.66560983e-03, 2.57062406e-03, 1.00968534e-04,\n",
       "          1.62950415e-03, 3.22950966e-03, 4.83256191e-03, 1.39627917e-02,\n",
       "          8.89926383e-03, 1.54317742e-03, 8.00493849e-03, 8.67236247e-03,\n",
       "          3.58666209e-03, 2.05761834e-03]),\n",
       "   'rank_test_Accuracy': array([26, 10,  9,  2,  7, 27, 28, 23,  4, 19, 21, 29, 14, 13, 11,  5, 25,\n",
       "          24,  6, 29, 17, 22, 16,  8,  1, 20,  3, 12, 15, 18]),\n",
       "   'split0_train_Accuracy': array([0.66383517, 0.60961504, 0.61196458, 0.67305259, 0.69166817,\n",
       "          0.05602747, 0.13464667, 0.25248509, 0.84673776, 0.27561901,\n",
       "          0.26314838, 0.05602747, 0.34429785, 0.39020423, 0.59624074,\n",
       "          0.6618471 , 0.2412796 , 0.25881077, 0.7281764 , 0.05602747,\n",
       "          0.29134285, 0.26423279, 0.29712633, 0.66365444, 0.75112959,\n",
       "          0.2696548 , 0.80408458, 0.49900596, 0.31538044, 0.27778782]),\n",
       "   'split1_train_Accuracy': array([0.05603604, 0.62126126, 0.63531532, 0.66954955, 0.67747748,\n",
       "          0.65585586, 0.14      , 0.25531532, 0.85243243, 0.27765766,\n",
       "          0.28378378, 0.05603604, 0.35837838, 0.37747748, 0.61081081,\n",
       "          0.67297297, 0.27495495, 0.26612613, 0.74486486, 0.05603604,\n",
       "          0.29405405, 0.26846847, 0.31837838, 0.66702703, 0.74288288,\n",
       "          0.27657658, 0.80576577, 0.49963964, 0.33225225, 0.2763964 ]),\n",
       "   'split2_train_Accuracy': array([0.05592519, 0.62956303, 0.6513217 , 0.67272073, 0.68548822,\n",
       "          0.05592519, 0.13342924, 0.25373134, 0.86369358, 0.2594857 ,\n",
       "          0.25966553, 0.05592519, 0.34741953, 0.3805071 , 0.58226938,\n",
       "          0.66247078, 0.23898579, 0.25534976, 0.72684769, 0.05592519,\n",
       "          0.28178385, 0.25840676, 0.30012588, 0.68494875, 0.74087394,\n",
       "          0.26164359, 0.78511059, 0.4840856 , 0.32386261, 0.26038482]),\n",
       "   'mean_train_Accuracy': array([0.2585988 , 0.62014644, 0.6328672 , 0.67177429, 0.68487796,\n",
       "          0.25593617, 0.1360253 , 0.25384392, 0.85428792, 0.27092079,\n",
       "          0.2688659 , 0.05599623, 0.35003192, 0.3827296 , 0.59644031,\n",
       "          0.66576362, 0.25174011, 0.26009555, 0.73329632, 0.05599623,\n",
       "          0.28906025, 0.26370267, 0.3052102 , 0.67187674, 0.74496214,\n",
       "          0.26929165, 0.79832031, 0.49424373, 0.32383177, 0.27152301]),\n",
       "   'std_train_Accuracy': array([2.86545389e-01, 8.18179704e-03, 1.61604630e-02, 1.57895383e-03,\n",
       "          5.80937605e-03, 2.82785922e-01, 2.85414343e-03, 1.15817358e-03,\n",
       "          7.04543036e-03, 8.12854802e-03, 1.06439359e-02, 5.03546264e-05,\n",
       "          6.03786723e-03, 5.42814778e-03, 1.16528465e-02, 5.10413915e-03,\n",
       "          1.64420596e-02, 4.49225454e-03, 8.19816420e-03, 5.03546264e-05,\n",
       "          5.26289911e-03, 4.12474263e-03, 9.39148857e-03, 9.34529175e-03,\n",
       "          4.43749374e-03, 6.10177200e-03, 9.36586567e-03, 7.18754477e-03,\n",
       "          6.88792116e-03, 7.89634796e-03]),\n",
       "   'split0_test_F1': array([0.52782334, 0.53115163, 0.53738474, 0.56856584, 0.54773517,\n",
       "          0.00592578, 0.06580003, 0.21801976, 0.55578789, 0.23931756,\n",
       "          0.22112259, 0.00592578, 0.29279577, 0.32779735, 0.52103149,\n",
       "          0.54811534, 0.19859901, 0.19877217, 0.54655657, 0.00592578,\n",
       "          0.23709713, 0.2270583 , 0.2553014 , 0.54426698, 0.58831105,\n",
       "          0.23339001, 0.56647105, 0.44270265, 0.26520381, 0.24033512]),\n",
       "   'split1_test_F1': array([0.00592212, 0.51022647, 0.52202911, 0.54628106, 0.53375836,\n",
       "          0.51743729, 0.06510552, 0.214381  , 0.54699149, 0.23542021,\n",
       "          0.2363813 , 0.00592212, 0.29374427, 0.3142711 , 0.49420163,\n",
       "          0.53991211, 0.22960799, 0.22075761, 0.55560874, 0.00592212,\n",
       "          0.2367931 , 0.22062834, 0.26392937, 0.52038441, 0.57160869,\n",
       "          0.22300327, 0.54938351, 0.43473169, 0.27389102, 0.23531499]),\n",
       "   'split2_test_F1': array([0.00596815, 0.53472667, 0.54385633, 0.56688998, 0.55825523,\n",
       "          0.00596815, 0.07437922, 0.2297366 , 0.56131286, 0.24440148,\n",
       "          0.22952275, 0.00596815, 0.3074077 , 0.34341735, 0.51656551,\n",
       "          0.56136353, 0.22371354, 0.22811151, 0.54951071, 0.00596815,\n",
       "          0.24339399, 0.23645558, 0.26582582, 0.55164191, 0.57043585,\n",
       "          0.23466378, 0.55788634, 0.45338243, 0.27634184, 0.24638857]),\n",
       "   'mean_test_F1': array([0.18084517, 0.5253677 , 0.53441698, 0.56058693, 0.54656984,\n",
       "          0.17632074, 0.06841502, 0.22069502, 0.5546909 , 0.23970608,\n",
       "          0.22899209, 0.00593862, 0.29795953, 0.32847412, 0.51061297,\n",
       "          0.54977827, 0.21726016, 0.21582932, 0.55055188, 0.00593862,\n",
       "          0.23908498, 0.22803427, 0.26166702, 0.53875865, 0.57681713,\n",
       "          0.23035286, 0.55793115, 0.44359082, 0.27179274, 0.24067131]),\n",
       "   'std_test_F1': array([2.46346322e-01, 1.07997858e-02, 9.14490400e-03, 1.01334413e-02,\n",
       "          1.00214690e-02, 2.41075407e-01, 4.21208984e-03, 6.54219171e-03,\n",
       "          5.89047099e-03, 3.67199592e-03, 6.24780729e-03, 2.08604460e-05,\n",
       "          6.66867951e-03, 1.18924962e-02, 1.17407688e-02, 8.82497221e-03,\n",
       "          1.34651585e-02, 1.24757829e-02, 3.77187410e-03, 2.08604460e-05,\n",
       "          3.03877218e-03, 6.48978896e-03, 4.58509718e-03, 1.33301115e-02,\n",
       "          8.17440472e-03, 5.22010657e-03, 6.98416398e-03, 7.62992115e-03,\n",
       "          4.78350095e-03, 4.52095084e-03]),\n",
       "   'rank_test_F1': array([26, 10,  9,  2,  7, 27, 28, 23,  4, 18, 21, 29, 14, 13, 11,  6, 24,\n",
       "          25,  5, 29, 19, 22, 16,  8,  1, 20,  3, 12, 15, 17]),\n",
       "   'split0_train_F1': array([0.65936538, 0.60131842, 0.60310655, 0.6681872 , 0.68530158,\n",
       "          0.00594507, 0.06751128, 0.21943992, 0.84575144, 0.24910787,\n",
       "          0.23187398, 0.00594507, 0.30513987, 0.35387627, 0.5847451 ,\n",
       "          0.65507225, 0.20779324, 0.21683616, 0.72594121, 0.00594507,\n",
       "          0.25069221, 0.23318827, 0.26072373, 0.65892995, 0.74646215,\n",
       "          0.23670219, 0.80279286, 0.481348  , 0.27157693, 0.25081201]),\n",
       "   'split1_train_F1': array([0.00594684, 0.61337805, 0.6281433 , 0.66356621, 0.67227734,\n",
       "          0.64848913, 0.0685102 , 0.22214224, 0.85164822, 0.24747674,\n",
       "          0.24878909, 0.00594684, 0.32096832, 0.34104945, 0.60405737,\n",
       "          0.66651261, 0.24203846, 0.2300675 , 0.74322738, 0.00594684,\n",
       "          0.25516741, 0.23552948, 0.28214062, 0.66171692, 0.73817168,\n",
       "          0.23519049, 0.80449643, 0.48276423, 0.29174549, 0.2453416 ]),\n",
       "   'split2_train_F1': array([0.00592396, 0.62385745, 0.64122052, 0.66650392, 0.6788927 ,\n",
       "          0.00592396, 0.06858946, 0.22153238, 0.86259624, 0.23364134,\n",
       "          0.22752028, 0.00592396, 0.30618894, 0.34644362, 0.56841164,\n",
       "          0.65535248, 0.20930858, 0.22049893, 0.72497039, 0.00592396,\n",
       "          0.24726635, 0.22916748, 0.26364302, 0.68035933, 0.73739204,\n",
       "          0.22572912, 0.78307364, 0.46176975, 0.28641426, 0.23424059]),\n",
       "   'mean_train_F1': array([0.22374539, 0.61285131, 0.62415679, 0.66608578, 0.67882387,\n",
       "          0.22011938, 0.06820364, 0.22103818, 0.85333197, 0.24340865,\n",
       "          0.23606112, 0.00593862, 0.31076571, 0.34712311, 0.58573804,\n",
       "          0.65897911, 0.21971342, 0.22246753, 0.73137966, 0.00593862,\n",
       "          0.25104199, 0.23262841, 0.26883579, 0.66700206, 0.74067529,\n",
       "          0.2325406 , 0.79678764, 0.47529399, 0.28324556, 0.24346474]),\n",
       "   'std_train_F1': array([3.08029849e-01, 9.20905730e-03, 1.58132424e-02, 1.90954302e-03,\n",
       "          5.31734601e-03, 3.02903150e-01, 4.90645916e-04, 1.15724030e-03,\n",
       "          6.97916351e-03, 6.93856009e-03, 9.17386555e-03, 1.03944448e-05,\n",
       "          7.22703499e-03, 5.25852456e-03, 1.45692364e-02, 5.32821653e-03,\n",
       "          1.57982998e-02, 5.57814940e-03, 8.38697261e-03, 1.03944448e-05,\n",
       "          3.23506152e-03, 2.62727224e-03, 9.48312302e-03, 9.51329331e-03,\n",
       "          4.10428841e-03, 4.85582018e-03, 9.72217126e-03, 9.58054737e-03,\n",
       "          8.53319668e-03, 6.89419853e-03]),\n",
       "   'split0_test_Log_Loss': array([-1.743801  , -1.59588144, -1.58189851, -1.46461722, -1.52633918,\n",
       "          -3.61186179, -3.29025799, -2.59705597, -2.07215554, -2.55833487,\n",
       "          -2.57041765, -3.61186827, -2.20398021, -2.09138455, -1.61208385,\n",
       "          -1.63829985, -2.57709067, -2.58162823, -1.83349944, -3.61210187,\n",
       "          -2.50087088, -2.57602982, -2.41657537, -1.65374155, -1.43309172,\n",
       "          -2.56695895, -1.88962883, -1.82121239, -2.37798307, -2.55906974]),\n",
       "   'split1_test_Log_Loss': array([-3.61187955, -1.61255927, -1.58850657, -1.49585111, -1.57734854,\n",
       "          -1.71560837, -3.2914843 , -2.62409685, -2.11174454, -2.56368514,\n",
       "          -2.5740356 , -3.61186278, -2.19470698, -2.14838578, -1.67218531,\n",
       "          -1.70235916, -2.57628441, -2.59752082, -1.96534355, -3.61192776,\n",
       "          -2.52583647, -2.58140096, -2.43942117, -1.69950424, -1.49228909,\n",
       "          -2.57856867, -2.13193755, -1.82161087, -2.39336003, -2.56350284]),\n",
       "   'split2_test_Log_Loss': array([-3.61155335, -1.53542221, -1.53817974, -1.4467219 , -1.49439947,\n",
       "          -3.61159465, -3.28872506, -2.5781978 , -2.14331739, -2.52459486,\n",
       "          -2.53936246, -3.6115623 , -2.17785107, -2.05919681, -1.58676659,\n",
       "          -1.61682841, -2.54628252, -2.5448078 , -1.98305736, -3.61178791,\n",
       "          -2.4897173 , -2.54796936, -2.40821484, -1.57998919, -1.42805556,\n",
       "          -2.54208485, -1.94484382, -1.78481415, -2.33840354, -2.52224329]),\n",
       "   'mean_test_Log_Loss': array([-2.98571136, -1.58137808, -1.56959498, -1.46908386, -1.53273337,\n",
       "          -2.9801444 , -3.29015789, -2.5998065 , -2.10895181, -2.54892305,\n",
       "          -2.56131955, -3.61176493, -2.19222247, -2.09969229, -1.62370369,\n",
       "          -1.65251395, -2.56660086, -2.57470598, -1.9270348 , -3.61193971,\n",
       "          -2.50548631, -2.56850926, -2.42141136, -1.64451587, -1.4511391 ,\n",
       "          -2.56257355, -1.98865891, -1.80926924, -2.36997368, -2.54832842]),\n",
       "   'std_test_Log_Loss': array([8.81727074e-01, 3.30912653e-02, 2.23000586e-02, 2.02792323e-02,\n",
       "          3.41212836e-02, 8.93678552e-01, 1.12717021e-03, 1.88144419e-02,\n",
       "          2.91235237e-02, 1.72811140e-02, 1.55419730e-02, 1.42792620e-04,\n",
       "          1.08124854e-02, 3.68371969e-02, 3.57886322e-02, 3.63014051e-02,\n",
       "          1.43205580e-02, 2.20456371e-02, 6.67994308e-02, 1.28473769e-04,\n",
       "          1.50858032e-02, 1.46384311e-02, 1.31778196e-02, 4.91639929e-02,\n",
       "          2.91543163e-02, 1.51966520e-02, 1.03738004e-01, 1.72323819e-02,\n",
       "          2.31158483e-02, 1.84692698e-02]),\n",
       "   'rank_test_Log_Loss': array([27,  5,  4,  2,  3, 26, 28, 25, 13, 19, 20, 29, 14, 12,  6,  8, 22,\n",
       "          24, 10, 30, 17, 23, 16,  7,  1, 21, 11,  9, 15, 18]),\n",
       "   'split0_train_Log_Loss': array([-1.07312395, -1.2039849 , -1.21060003, -1.07509678, -1.00926345,\n",
       "          -3.6116998 , -3.28634907, -2.5823736 , -0.50771591, -2.521431  ,\n",
       "          -2.53699907, -3.61171294, -2.15644185, -2.0192728 , -1.27114567,\n",
       "          -1.04373107, -2.54497612, -2.55146552, -0.82284936, -3.61192454,\n",
       "          -2.47828722, -2.55055362, -2.3938627 , -1.05542326, -0.84269438,\n",
       "          -2.53730153, -0.6328257 , -1.68775909, -2.34686092, -2.52155427]),\n",
       "   'split1_train_Log_Loss': array([-3.61171579, -1.21770616, -1.13447232, -1.07664185, -1.06528135,\n",
       "          -1.09505553, -3.28444111, -2.56033288, -0.50091121, -2.50137346,\n",
       "          -2.51232813, -3.6116937 , -2.11259856, -2.05100353, -1.23545495,\n",
       "          -1.00435803, -2.51388838, -2.53042874, -0.77761191, -3.61175222,\n",
       "          -2.4498208 , -2.51968181, -2.37140849, -1.05447078, -0.85881053,\n",
       "          -2.51631521, -0.6221031 , -1.6682484 , -2.3207898 , -2.50131216]),\n",
       "   'split2_train_Log_Loss': array([-3.61184539, -1.17340455, -1.09097654, -1.09047663, -1.04376826,\n",
       "          -3.61188138, -3.29190794, -2.59146181, -0.46819985, -2.54401187,\n",
       "          -2.55595187, -3.61185368, -2.14317894, -2.00721962, -1.3020935 ,\n",
       "          -1.05712998, -2.56376127, -2.56576427, -0.83195925, -3.61203812,\n",
       "          -2.48223651, -2.56286228, -2.39397649, -1.00770704, -0.87198635,\n",
       "          -2.56082863, -0.69016933, -1.69158724, -2.31713013, -2.54305215]),\n",
       "   'mean_train_Log_Loss': array([-2.76556171, -1.1983652 , -1.14534963, -1.08073842, -1.03943769,\n",
       "          -2.77287891, -3.28756604, -2.5780561 , -0.49227566, -2.52227211,\n",
       "          -2.53509302, -3.61175344, -2.13740645, -2.02583198, -1.26956471,\n",
       "          -1.03507302, -2.54087526, -2.54921951, -0.81080684, -3.61190496,\n",
       "          -2.47011484, -2.5443659 , -2.38641589, -1.03920036, -0.85783042,\n",
       "          -2.53814846, -0.64836604, -1.68253158, -2.32826028, -2.52197286]),\n",
       "   'std_train_Log_Loss': array([1.19673422e+00, 1.85174498e-02, 4.94380520e-02, 6.91478449e-03,\n",
       "          2.30733145e-02, 1.18640029e+00, 3.16745217e-03, 1.30698963e-02,\n",
       "          1.72493333e-02, 1.74172163e-02, 1.78602453e-02, 7.13145653e-05,\n",
       "          1.83584652e-02, 1.84666337e-02, 2.72280333e-02, 2.23970404e-02,\n",
       "          2.05659744e-02, 1.45128284e-02, 2.37651721e-02, 1.17536793e-04,\n",
       "          1.44403467e-02, 1.81632251e-02, 1.06119415e-02, 2.22725356e-02,\n",
       "          1.19784641e-02, 1.81823925e-02, 2.98817649e-02, 1.02199301e-02,\n",
       "          1.32372200e-02, 1.70428482e-02])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'alpha': 0.0064,\n",
       "   'activation': 'tanh'},\n",
       "  24,\n",
       "  -1.4511390951677714),\n",
       " 'LogisticRegression_V09_PCA_90': ({'mean_fit_time': array([0.60737642, 1.14660311, 2.46773783, 5.3998998 , 1.95544044,\n",
       "          6.56079706, 4.20143636, 0.96907719, 4.53986478, 5.50096345,\n",
       "          2.23402961, 5.15555302, 4.36466678, 3.45642853, 5.947438  ,\n",
       "          2.67784214, 1.15524451, 4.37131532, 2.36667426, 0.9378264 ,\n",
       "          4.50628861, 4.34372298, 0.99534027, 1.82711728, 4.46140742,\n",
       "          1.24068411, 0.66455634, 5.71804921, 4.22736692, 2.27425392]),\n",
       "   'std_fit_time': array([0.02191054, 0.01081421, 0.25766052, 0.15967766, 0.1329747 ,\n",
       "          0.09487639, 0.5663995 , 0.02872464, 0.16791356, 0.18168176,\n",
       "          0.08236796, 0.02518189, 0.48041591, 0.71537264, 0.12520485,\n",
       "          0.24362957, 0.02718449, 0.04820375, 0.08958688, 0.01084437,\n",
       "          0.33403107, 0.13447913, 0.03467259, 0.04170471, 0.12210515,\n",
       "          0.07069228, 0.0150667 , 0.02890919, 0.14013041, 0.0719618 ]),\n",
       "   'mean_score_time': array([0.05319111, 0.04521251, 0.03324374, 0.0335776 , 0.0339098 ,\n",
       "          0.06216717, 0.03224738, 0.05485137, 0.03457395, 0.07280501,\n",
       "          0.03922804, 0.03257855, 0.03357689, 0.03590417, 0.04355033,\n",
       "          0.044547  , 0.03523962, 0.03224778, 0.03124944, 0.03590449,\n",
       "          0.03690195, 0.03390988, 0.06050483, 0.03690076, 0.0342416 ,\n",
       "          0.03357649, 0.03324453, 0.02992074, 0.02958751, 0.03058473]),\n",
       "   'std_score_time': array([1.95150855e-02, 2.02319668e-02, 9.39762376e-04, 4.70471583e-04,\n",
       "          2.15379952e-03, 3.50850292e-02, 9.40436927e-04, 3.03266588e-02,\n",
       "          1.24455881e-03, 4.53984202e-02, 3.84769811e-03, 1.24396488e-03,\n",
       "          4.68954187e-04, 6.36015462e-03, 1.08141508e-02, 1.58810819e-02,\n",
       "          2.48678109e-03, 4.70527668e-04, 4.70415116e-04, 2.93671506e-03,\n",
       "          7.10029759e-03, 8.14198955e-04, 3.26974391e-02, 2.15435131e-03,\n",
       "          1.24383653e-03, 1.24400712e-03, 1.69465601e-03, 1.12391596e-07,\n",
       "          9.40549197e-04, 2.04922815e-03]),\n",
       "   'param_C': masked_array(data=[0.04980533840563023, 0.11291613601522482,\n",
       "                      0.020770233945947143, 0.10178031805909911,\n",
       "                      0.08024794999814452, 0.14867286697175472,\n",
       "                      0.5319525377462326, 0.013052630830371992,\n",
       "                      0.23251788066116563, 0.5945256771943986,\n",
       "                      0.09440738204201521, 0.2511942372390798,\n",
       "                      0.13948036518503143, 0.015337332787671779,\n",
       "                      0.25028333860564544, 0.07187605575320831,\n",
       "                      0.03739238807128891, 0.0403714352446517,\n",
       "                      0.00286691688254547, 0.030153124832187562,\n",
       "                      0.15093629218939858, 0.10783574695699688,\n",
       "                      0.0664598331729593, 0.011927320008242195,\n",
       "                      0.1001019575954672, 0.07898882553026425,\n",
       "                      0.15003992940854463, 0.21846016063494328,\n",
       "                      0.12276446668532542, 0.15980855083546758],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, 'balanced', 'balanced', 'balanced',\n",
       "                      'balanced', None, 'balanced', None, 'balanced', None,\n",
       "                      None, None, None, None, 'balanced', 'balanced',\n",
       "                      'balanced', None, None, None, 'balanced', 'balanced',\n",
       "                      None, None, 'balanced', 'balanced', None, None, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['saga', 'saga', 'liblinear', 'newton-cg', 'liblinear',\n",
       "                      'saga', 'liblinear', 'saga', 'newton-cg', 'liblinear',\n",
       "                      'saga', 'liblinear', 'newton-cg', 'newton-cg',\n",
       "                      'liblinear', 'liblinear', 'saga', 'newton-cg',\n",
       "                      'newton-cg', 'saga', 'newton-cg', 'liblinear', 'saga',\n",
       "                      'liblinear', 'liblinear', 'saga', 'saga', 'saga',\n",
       "                      'newton-cg', 'saga'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.5953169049226101, 0.17371624217674456,\n",
       "                      0.009165483789684173, 0.3071045219301484,\n",
       "                      0.3568176976773543, 0.014086440588204924,\n",
       "                      0.12658887333777555, 0.15516913628677487,\n",
       "                      0.18191201859244835, 0.08346529718196362,\n",
       "                      0.08288395179353031, 0.0680723345992613,\n",
       "                      0.1705461442124004, 0.1764208665942954,\n",
       "                      0.021984637589615094, 0.19935368536963224,\n",
       "                      0.10939262567912995, 0.23659743905212496,\n",
       "                      0.2395488866817103, 0.20068300307471656,\n",
       "                      0.09151607293645396, 0.02770856623524448,\n",
       "                      0.1664397784455478, 0.12767908250640947,\n",
       "                      0.011868151174498846, 0.09796677853801622,\n",
       "                      0.3952250856379096, 0.023583396451433213,\n",
       "                      0.010539975842157797, 0.06739457938792703],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.04980533840563023,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.5953169049226101},\n",
       "    {'C': 0.11291613601522482,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.17371624217674456},\n",
       "    {'C': 0.020770233945947143,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.009165483789684173},\n",
       "    {'C': 0.10178031805909911,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3071045219301484},\n",
       "    {'C': 0.08024794999814452,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3568176976773543},\n",
       "    {'C': 0.14867286697175472,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.014086440588204924},\n",
       "    {'C': 0.5319525377462326,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.12658887333777555},\n",
       "    {'C': 0.013052630830371992,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.15516913628677487},\n",
       "    {'C': 0.23251788066116563,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.18191201859244835},\n",
       "    {'C': 0.5945256771943986,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.08346529718196362},\n",
       "    {'C': 0.09440738204201521,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.08288395179353031},\n",
       "    {'C': 0.2511942372390798,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.0680723345992613},\n",
       "    {'C': 0.13948036518503143,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.1705461442124004},\n",
       "    {'C': 0.015337332787671779,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.1764208665942954},\n",
       "    {'C': 0.25028333860564544,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.021984637589615094},\n",
       "    {'C': 0.07187605575320831,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.19935368536963224},\n",
       "    {'C': 0.03739238807128891,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.10939262567912995},\n",
       "    {'C': 0.0403714352446517,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.23659743905212496},\n",
       "    {'C': 0.00286691688254547,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.2395488866817103},\n",
       "    {'C': 0.030153124832187562,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.20068300307471656},\n",
       "    {'C': 0.15093629218939858,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.09151607293645396},\n",
       "    {'C': 0.10783574695699688,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.02770856623524448},\n",
       "    {'C': 0.0664598331729593,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.1664397784455478},\n",
       "    {'C': 0.011927320008242195,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.12767908250640947},\n",
       "    {'C': 0.1001019575954672,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.011868151174498846},\n",
       "    {'C': 0.07898882553026425,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.09796677853801622},\n",
       "    {'C': 0.15003992940854463,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.3952250856379096},\n",
       "    {'C': 0.21846016063494328,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.023583396451433213},\n",
       "    {'C': 0.12276446668532542,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.010539975842157797},\n",
       "    {'C': 0.15980855083546758,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.06739457938792703}],\n",
       "   'split0_test_Accuracy': array([0.47543923, 0.48655432, 0.56471854, 0.64037289, 0.5916099 ,\n",
       "          0.58228756, 0.66260308, 0.55432054, 0.66583005, 0.65794191,\n",
       "          0.49802797, 0.64682682, 0.65830047, 0.59340265, 0.64718537,\n",
       "          0.59770527, 0.55360344, 0.62387953, 0.53388311, 0.48619577,\n",
       "          0.65901757, 0.61204733, 0.54894227, 0.55503765, 0.62136967,\n",
       "          0.55862316, 0.53961994, 0.55324489, 0.6550735 , 0.50233058]),\n",
       "   'split1_test_Accuracy': array([0.47763348, 0.47222222, 0.56313131, 0.64357864, 0.58946609,\n",
       "          0.59487734, 0.65836941, 0.5494228 , 0.66305916, 0.65692641,\n",
       "          0.50324675, 0.64502165, 0.65151515, 0.58910534, 0.64574315,\n",
       "          0.59559885, 0.5537518 , 0.62987013, 0.52453102, 0.48160173,\n",
       "          0.6533189 , 0.61507937, 0.54365079, 0.55483405, 0.61940837,\n",
       "          0.54761905, 0.52958153, 0.5523088 , 0.64718615, 0.51190476]),\n",
       "   'split2_test_Accuracy': array([0.45780514, 0.46975733, 0.55632017, 0.63129301, 0.59543644,\n",
       "          0.58384643, 0.65157552, 0.53748642, 0.65845708, 0.65411083,\n",
       "          0.4882289 , 0.63962332, 0.64867802, 0.58891706, 0.63962332,\n",
       "          0.60195581, 0.54038392, 0.61245925, 0.51503079, 0.47193046,\n",
       "          0.65048895, 0.61644332, 0.53676204, 0.53929736, 0.62078957,\n",
       "          0.54762767, 0.53132923, 0.53422673, 0.64505614, 0.49474828]),\n",
       "   'mean_test_Accuracy': array([0.47031963, 0.47620764, 0.56140351, 0.63842826, 0.59216534,\n",
       "          0.58699832, 0.65753425, 0.54710406, 0.66246095, 0.65633261,\n",
       "          0.49651526, 0.64383562, 0.65284787, 0.59048306, 0.64419611,\n",
       "          0.59841384, 0.549267  , 0.62208604, 0.52451334, 0.47993271,\n",
       "          0.65428983, 0.61451574, 0.54313867, 0.54974766, 0.62052391,\n",
       "          0.55130978, 0.53352559, 0.54662341, 0.64912281, 0.50300409]),\n",
       "   'std_test_Accuracy': array([0.00886349, 0.00741432, 0.00364011, 0.00519559, 0.00246582,\n",
       "          0.00560456, 0.00454126, 0.00706629, 0.00304005, 0.00161961,\n",
       "          0.00621619, 0.00305841, 0.00404032, 0.00207427, 0.00327556,\n",
       "          0.00264008, 0.00625952, 0.00721164, 0.00769773, 0.00594299,\n",
       "          0.00354934, 0.00183862, 0.00498654, 0.00736399, 0.00082319,\n",
       "          0.00519233, 0.00438511, 0.00874336, 0.00431318, 0.00701094]),\n",
       "   'rank_test_Accuracy': array([30, 29, 17,  9, 14, 16,  2, 21,  1,  3, 27,  8,  5, 15,  7, 13, 20,\n",
       "          10, 25, 28,  4, 12, 23, 19, 11, 18, 24, 22,  6, 26]),\n",
       "   'split0_train_Accuracy': array([0.49466835, 0.5013555 , 0.59877101, 0.68335442, 0.63817097,\n",
       "          0.62136273, 0.71841677, 0.57455268, 0.72203145, 0.71389843,\n",
       "          0.515272  , 0.70269293, 0.71227182, 0.63076089, 0.70377734,\n",
       "          0.64648473, 0.58575818, 0.66455811, 0.54328574, 0.49936743,\n",
       "          0.71462136, 0.66582324, 0.57744442, 0.57636002, 0.67052232,\n",
       "          0.58575818, 0.56316646, 0.57455268, 0.71046449, 0.51924815]),\n",
       "   'split1_train_Accuracy': array([0.50162162, 0.50252252, 0.6045045 , 0.68432432, 0.64072072,\n",
       "          0.61765766, 0.71747748, 0.57333333, 0.72342342, 0.7172973 ,\n",
       "          0.52846847, 0.70252252, 0.71207207, 0.63567568, 0.70234234,\n",
       "          0.64774775, 0.57351351, 0.66666667, 0.55279279, 0.50144144,\n",
       "          0.71423423, 0.66666667, 0.57117117, 0.58846847, 0.67207207,\n",
       "          0.57927928, 0.56666667, 0.58666667, 0.70954955, 0.53477477]),\n",
       "   'split2_train_Accuracy': array([0.47563388, 0.49829167, 0.60007193, 0.68207157, 0.63819457,\n",
       "          0.62129113, 0.71821615, 0.57615537, 0.72217227, 0.71749685,\n",
       "          0.51753282, 0.70059342, 0.71048373, 0.62452796, 0.70149254,\n",
       "          0.64251034, 0.57687466, 0.66822514, 0.5491818 , 0.49289696,\n",
       "          0.71192232, 0.66570761, 0.57058083, 0.58352814, 0.66588743,\n",
       "          0.57633519, 0.56320806, 0.57597554, 0.7072469 , 0.52364683]),\n",
       "   'mean_train_Accuracy': array([0.49064128, 0.50072323, 0.60111581, 0.6832501 , 0.63902875,\n",
       "          0.62010384, 0.7180368 , 0.57468046, 0.72254238, 0.71623086,\n",
       "          0.52042443, 0.70193629, 0.71160921, 0.63032151, 0.70253741,\n",
       "          0.64558094, 0.57871545, 0.6664833 , 0.54842011, 0.49790194,\n",
       "          0.71359264, 0.66606584, 0.57306548, 0.58278554, 0.66949394,\n",
       "          0.58045755, 0.56434706, 0.57906496, 0.70908698, 0.52588992]),\n",
       "   'std_train_Accuracy': array([0.01098495, 0.00178416, 0.00245432, 0.00092264, 0.00119644,\n",
       "          0.00172996, 0.00040389, 0.00115563, 0.00062564, 0.00165129,\n",
       "          0.00576239, 0.0009521 , 0.0008    , 0.00456163, 0.00094291,\n",
       "          0.00223163, 0.00516555, 0.00150266, 0.00391843, 0.00363894,\n",
       "          0.00119162, 0.00042746, 0.00310575, 0.00497106, 0.0026275 ,\n",
       "          0.00393611, 0.0016403 , 0.00540651, 0.00135369, 0.00653415]),\n",
       "   'split0_test_F1': array([0.43098613, 0.43975401, 0.54300526, 0.63953652, 0.57436187,\n",
       "          0.57860494, 0.64792313, 0.54448318, 0.65327385, 0.6475854 ,\n",
       "          0.44886231, 0.62977763, 0.64425478, 0.56988015, 0.63011272,\n",
       "          0.58083527, 0.54284576, 0.62287774, 0.49980758, 0.43826409,\n",
       "          0.64496801, 0.59718985, 0.53922963, 0.52236653, 0.60046361,\n",
       "          0.54922087, 0.5279386 , 0.52160317, 0.64112572, 0.45617305]),\n",
       "   'split1_test_F1': array([0.43095002, 0.42100173, 0.54245699, 0.64325594, 0.57426183,\n",
       "          0.5929461 , 0.64527286, 0.54022488, 0.65153007, 0.65022282,\n",
       "          0.4567248 , 0.63058817, 0.63895751, 0.56815689, 0.63127289,\n",
       "          0.58074038, 0.54602926, 0.62996332, 0.49026726, 0.43129649,\n",
       "          0.64072801, 0.60345642, 0.53364678, 0.52175778, 0.59926656,\n",
       "          0.54021783, 0.52023661, 0.51969528, 0.63429651, 0.46714667]),\n",
       "   'split2_test_F1': array([0.40858482, 0.42218674, 0.53554486, 0.6308088 , 0.57940408,\n",
       "          0.58010772, 0.63695853, 0.52946521, 0.64655766, 0.64446521,\n",
       "          0.44361299, 0.62300528, 0.63547588, 0.56861126, 0.62333743,\n",
       "          0.58628243, 0.53350368, 0.61215872, 0.48680638, 0.42111452,\n",
       "          0.63750145, 0.60333263, 0.52852547, 0.50774389, 0.60136149,\n",
       "          0.54118828, 0.51964229, 0.50433657, 0.63166907, 0.45124566]),\n",
       "   'mean_test_F1': array([0.42354199, 0.42767944, 0.54034749, 0.63787983, 0.57600141,\n",
       "          0.58388046, 0.64340261, 0.53808224, 0.65046477, 0.64742872,\n",
       "          0.44973968, 0.62780075, 0.63957771, 0.56888516, 0.62825132,\n",
       "          0.58261087, 0.54080673, 0.62168163, 0.49231634, 0.4302535 ,\n",
       "          0.64107851, 0.6013152 , 0.53381869, 0.51731239, 0.60036278,\n",
       "          0.54355704, 0.52262064, 0.51523911, 0.63571351, 0.45819352]),\n",
       "   'std_test_F1': array([0.01053918, 0.00858626, 0.00339146, 0.00520917, 0.00239795,\n",
       "          0.00643623, 0.00466806, 0.00631628, 0.0028438 , 0.00234999,\n",
       "          0.0053818 , 0.00339519, 0.00361127, 0.0007303 , 0.00349476,\n",
       "          0.00258735, 0.00530785, 0.00730836, 0.00550258, 0.00704114,\n",
       "          0.00305876, 0.00292933, 0.00437238, 0.00674678, 0.00085709,\n",
       "          0.0040406 , 0.00378339, 0.00772165, 0.00398906, 0.00663958]),\n",
       "   'rank_test_F1': array([30, 29, 19,  6, 15, 13,  3, 20,  1,  2, 27,  9,  5, 16,  8, 14, 18,\n",
       "          10, 25, 28,  4, 11, 21, 23, 12, 17, 22, 24,  7, 26]),\n",
       "   'split0_train_F1': array([0.4502583 , 0.45776965, 0.57927521, 0.68287488, 0.62436203,\n",
       "          0.61910198, 0.70788428, 0.56614994, 0.71291636, 0.70698696,\n",
       "          0.46802815, 0.69081836, 0.70268303, 0.61350542, 0.69192022,\n",
       "          0.6328299 , 0.57783205, 0.66395321, 0.51215855, 0.4519499 ,\n",
       "          0.70531132, 0.65444013, 0.56998776, 0.54571686, 0.65537558,\n",
       "          0.57862382, 0.55123709, 0.5447052 , 0.70070947, 0.4750612 ]),\n",
       "   'split1_train_F1': array([0.45930382, 0.45736464, 0.5860635 , 0.68260506, 0.62694438,\n",
       "          0.61375654, 0.70554327, 0.56442041, 0.71300933, 0.70991088,\n",
       "          0.48544588, 0.68882658, 0.70092099, 0.6164226 , 0.68859475,\n",
       "          0.63470657, 0.56538008, 0.66482518, 0.52210205, 0.45389052,\n",
       "          0.70297525, 0.6551397 , 0.56092879, 0.55967609, 0.655886  ,\n",
       "          0.57276642, 0.55853071, 0.55990368, 0.6982969 , 0.4937819 ]),\n",
       "   'split2_train_F1': array([0.42396752, 0.45145261, 0.58270506, 0.68202793, 0.62633845,\n",
       "          0.61828377, 0.70739341, 0.56889992, 0.71271092, 0.71145176,\n",
       "          0.47304718, 0.68813046, 0.70060888, 0.6080294 , 0.68905971,\n",
       "          0.63057308, 0.5709913 , 0.66738423, 0.51872297, 0.44410487,\n",
       "          0.70218854, 0.65610375, 0.56275493, 0.55497074, 0.65025531,\n",
       "          0.5700562 , 0.55407028, 0.54757652, 0.69716684, 0.48230925]),\n",
       "   'mean_train_F1': array([0.44450988, 0.45552897, 0.58268125, 0.68250262, 0.62588162,\n",
       "          0.61704743, 0.70694032, 0.56649009, 0.71287887, 0.70944987,\n",
       "          0.47550707, 0.68925847, 0.7014043 , 0.61265247, 0.68985823,\n",
       "          0.63270318, 0.57140115, 0.66538754, 0.51766119, 0.44998176,\n",
       "          0.7034917 , 0.65522786, 0.56455716, 0.55345456, 0.65383897,\n",
       "          0.57381548, 0.55461269, 0.55072847, 0.69872441, 0.48371745]),\n",
       "   'std_train_F1': array([0.0149877 , 0.00288716, 0.00277136, 0.00035327, 0.00110262,\n",
       "          0.00235086, 0.00100799, 0.0018445 , 0.00012467, 0.00185167,\n",
       "          0.00732041, 0.00113904, 0.00091313, 0.00347918, 0.00147036,\n",
       "          0.00168987, 0.00509175, 0.00145606, 0.00412826, 0.00423044,\n",
       "          0.00132614, 0.00068203, 0.00391172, 0.0057988 , 0.00254258,\n",
       "          0.00357551, 0.00300221, 0.0065929 , 0.00147753, 0.00770729]),\n",
       "   'split0_test_Log_Loss': array([-3.26906937, -3.07494437, -2.21023278, -1.68578345, -1.80351164,\n",
       "          -2.23287554, -1.33902514, -2.87464051, -1.25505067, -1.3334661 ,\n",
       "          -2.83168447, -1.43903437, -1.30241678, -1.70073344, -1.43695089,\n",
       "          -1.77577345, -2.81507302, -1.79729386, -2.33447877, -3.12874266,\n",
       "          -1.29390254, -1.63894944, -2.86715899, -2.43071133, -1.64618147,\n",
       "          -2.79871722, -2.944932  , -2.25913608, -1.31574618, -2.74057791]),\n",
       "   'split1_test_Log_Loss': array([-3.25168031, -3.06535743, -2.22972808, -1.7069299 , -1.83428866,\n",
       "          -2.24273971, -1.37489552, -2.88343877, -1.29600818, -1.36896012,\n",
       "          -2.8172214 , -1.47845243, -1.34394677, -1.73014297, -1.4764892 ,\n",
       "          -1.80212377, -2.81296715, -1.82045301, -2.35005128, -3.12131199,\n",
       "          -1.3359079 , -1.67049008, -2.86270577, -2.4483551 , -1.68089516,\n",
       "          -2.79646166, -2.94253717, -2.25403384, -1.35732636, -2.73376738]),\n",
       "   'split2_test_Log_Loss': array([-3.26810938, -3.08680906, -2.22201886, -1.70328512, -1.81779641,\n",
       "          -2.2422132 , -1.35206753, -2.88175526, -1.27217117, -1.34863522,\n",
       "          -2.85257386, -1.45460277, -1.32055463, -1.71430579, -1.4510454 ,\n",
       "          -1.79080102, -2.81944991, -1.81458022, -2.34722881, -3.1379724 ,\n",
       "          -1.31192702, -1.6568983 , -2.86388161, -2.44194654, -1.65969719,\n",
       "          -2.79876027, -2.94948491, -2.27699398, -1.33406682, -2.75903796]),\n",
       "   'mean_test_Log_Loss': array([-3.2629587 , -3.07568739, -2.22063681, -1.69863374, -1.81850253,\n",
       "          -2.23925919, -1.3553004 , -2.87993162, -1.27437342, -1.35032158,\n",
       "          -2.83379742, -1.4573294 , -1.32226775, -1.71503247, -1.45479697,\n",
       "          -1.78953627, -2.81582369, -1.81074313, -2.34389596, -3.12932972,\n",
       "          -1.31387424, -1.65541032, -2.86458831, -2.44031587, -1.66222849,\n",
       "          -2.79798019, -2.94564482, -2.26336129, -1.33567451, -2.74443389]),\n",
       "   'std_test_Log_Loss': array([0.00798035, 0.00876162, 0.00802749, 0.00924362, 0.01258916,\n",
       "          0.00453732, 0.01483701, 0.00381875, 0.0168121 , 0.01455586,\n",
       "          0.01449089, 0.01622527, 0.01701718, 0.01203129, 0.01637505,\n",
       "          0.01080682, 0.00269619, 0.00984427, 0.00678428, 0.00680514,\n",
       "          0.01722335, 0.01293399, 0.00188703, 0.0073024 , 0.0143    ,\n",
       "          0.00107333, 0.00287742, 0.00982967, 0.01703255, 0.01066022]),\n",
       "   'rank_test_Log_Loss': array([30, 28, 16, 11, 15, 17,  6, 26,  1,  5, 24,  8,  3, 12,  7, 13, 23,\n",
       "          14, 19, 29,  2,  9, 25, 20, 10, 22, 27, 18,  4, 21]),\n",
       "   'split0_train_Log_Loss': array([-3.25242252, -3.05290561, -2.14481978, -1.57278706, -1.70468365,\n",
       "          -2.1778542 , -1.16417371, -2.84684137, -1.06922553, -1.1551125 ,\n",
       "          -2.79633186, -1.2902922 , -1.13498024, -1.59903903, -1.28824239,\n",
       "          -1.67583532, -2.78472998, -1.71105049, -2.27802617, -3.10812003,\n",
       "          -1.12366714, -1.52213434, -2.83800549, -2.37875014, -1.52993204,\n",
       "          -2.76732764, -2.92088299, -2.19301888, -1.15263136, -2.70113886]),\n",
       "   'split1_train_Log_Loss': array([-3.22623085, -3.02500635, -2.1303364 , -1.54838205, -1.69008596,\n",
       "          -2.14749187, -1.14954799, -2.83899104, -1.05453058, -1.13814628,\n",
       "          -2.76084354, -1.27572056, -1.12036979, -1.58349555, -1.27330165,\n",
       "          -1.65748003, -2.76122765, -1.68928449, -2.26479814, -3.08568952,\n",
       "          -1.10915088, -1.50629594, -2.81593925, -2.36669938, -1.51514385,\n",
       "          -2.74787595, -2.903064  , -2.15407822, -1.13801571, -2.67306956]),\n",
       "   'split2_train_Log_Loss': array([-3.2421035 , -3.04806675, -2.13553292, -1.55175979, -1.69487684,\n",
       "          -2.1662271 , -1.15686377, -2.84591088, -1.06368559, -1.14484659,\n",
       "          -2.80219612, -1.2846578 , -1.1293909 , -1.59248366, -1.2807454 ,\n",
       "          -1.66629599, -2.78079719, -1.69206858, -2.26876226, -3.10414396,\n",
       "          -1.1180057 , -1.51426822, -2.82688891, -2.37171032, -1.5226764 ,\n",
       "          -2.76043363, -2.91923845, -2.19115718, -1.14682498, -2.70380664]),\n",
       "   'mean_train_Log_Loss': array([-3.24025229, -3.0419929 , -2.13689637, -1.55764297, -1.69654882,\n",
       "          -2.16385773, -1.15686182, -2.84391443, -1.06248057, -1.14603512,\n",
       "          -2.78645717, -1.28355685, -1.12824698, -1.59167275, -1.28076315,\n",
       "          -1.66653711, -2.77558494, -1.69746785, -2.27052886, -3.09931784,\n",
       "          -1.11694124, -1.51423283, -2.82694455, -2.37238661, -1.5225841 ,\n",
       "          -2.75854574, -2.91439515, -2.17941809, -1.14582402, -2.69267168]),\n",
       "   'std_train_Log_Loss': array([0.01077253, 0.01217267, 0.0059909 , 0.01079691, 0.00607562,\n",
       "          0.01250808, 0.00597093, 0.00350203, 0.0060594 , 0.00697723,\n",
       "          0.01826912, 0.00599957, 0.00601929, 0.00637146, 0.00609954,\n",
       "          0.00749546, 0.01027831, 0.00967139, 0.00554291, 0.00977243,\n",
       "          0.00597385, 0.00646605, 0.00900859, 0.00494289, 0.00603761,\n",
       "          0.00805254, 0.00804041, 0.01793411, 0.00600865, 0.01390352])},\n",
       "  {'C': 0.23251788066116563,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.18191201859244835},\n",
       "  8,\n",
       "  -1.274373420494509),\n",
       " 'RandomForestClassifier_V09_PCA_90': ({'mean_fit_time': array([ 8.04915182,  1.6512537 ,  6.09138465,  6.97635253,  5.99996209,\n",
       "           7.47535245,  3.53355392,  4.6243058 ,  3.30549765,  3.64725073,\n",
       "           6.07875148,  6.60467951,  4.56413356,  9.48198859,  3.10702904,\n",
       "           5.85003034,  1.50564202,  5.77190487,  2.58874702, 11.76555196,\n",
       "           6.41651543,  5.76093443,  1.99367174,  6.0568107 ,  3.23568432,\n",
       "           4.37264506,  8.73531787,  5.08307942,  4.35136882, 11.35432776]),\n",
       "   'std_fit_time': array([0.00611213, 0.03195973, 0.03253542, 0.05546344, 0.02739819,\n",
       "          0.02987929, 0.03818722, 0.01873539, 0.0507389 , 0.02617304,\n",
       "          0.01925229, 0.06914734, 0.02493133, 0.09198697, 0.06279378,\n",
       "          0.04603864, 0.01318972, 0.02656759, 0.06199744, 0.11354209,\n",
       "          0.03986315, 0.01186603, 0.01914903, 0.03952549, 0.01105617,\n",
       "          0.02632869, 0.12116043, 0.04770801, 0.03026137, 0.14804274]),\n",
       "   'mean_score_time': array([0.67519546, 0.22307086, 0.37732466, 0.57446456, 0.6116991 ,\n",
       "          0.60737642, 0.34374817, 0.39361525, 0.41888014, 0.41987777,\n",
       "          0.38131452, 0.59008964, 0.37865448, 0.65225697, 0.30850911,\n",
       "          0.60172542, 0.1984702 , 0.48969173, 0.29122225, 0.65092683,\n",
       "          0.54088775, 0.54986374, 0.27227147, 0.43583504, 0.27559717,\n",
       "          0.45677932, 0.45611453, 0.50564893, 0.25598248, 0.79386806]),\n",
       "   'std_score_time': array([0.06143126, 0.02466348, 0.00782512, 0.01976228, 0.02123973,\n",
       "          0.02507281, 0.01663539, 0.00981675, 0.02905501, 0.02055245,\n",
       "          0.02961197, 0.01708843, 0.02597327, 0.01140035, 0.02462385,\n",
       "          0.02596025, 0.01216044, 0.01064792, 0.02045545, 0.0209253 ,\n",
       "          0.01506651, 0.06541193, 0.01472582, 0.01140034, 0.01326469,\n",
       "          0.02348824, 0.02164155, 0.01670816, 0.01739525, 0.04547505]),\n",
       "   'param_n_estimators': masked_array(data=[350, 100, 200, 300, 350, 350, 200, 200, 250, 250, 200,\n",
       "                      350, 200, 350, 150, 350, 100, 250, 150, 300, 300, 300,\n",
       "                      150, 200, 150, 250, 200, 300, 100, 350],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[125, 150, 50, 50, 250, 150, 125, 50, 250, 200, 50, 200,\n",
       "                      125, 75, 75, 250, 200, 50, 250, 10, 150, 200, 250, 50,\n",
       "                      150, 125, 10, 250, 10, 10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['sqrt', 'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                      'log2', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'log2', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'log2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[10, 15, 50, 85, 85, 45, 10, 35, 50, 10, 20, 100, 45,\n",
       "                      70, 40, 5, 90, 40, 85, 10, 95, 90, 35, 100, 70, 25, 40,\n",
       "                      30, 55, 90],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90}],\n",
       "   'split0_test_Accuracy': array([0.4682682 , 0.44890642, 0.55754751, 0.57009681, 0.40408749,\n",
       "          0.45141628, 0.47508067, 0.57188957, 0.40229473, 0.43097885,\n",
       "          0.56686985, 0.4209394 , 0.46253137, 0.52456077, 0.52312657,\n",
       "          0.39261384, 0.41591968, 0.56435999, 0.39476515, 0.66009322,\n",
       "          0.44137684, 0.42201506, 0.40659735, 0.5679455 , 0.45213338,\n",
       "          0.47292937, 0.69666547, 0.407673  , 0.68949444, 0.69738257]),\n",
       "   'split1_test_Accuracy': array([0.44949495, 0.43506494, 0.53427128, 0.54184704, 0.37554113,\n",
       "          0.43037518, 0.4527417 , 0.53571429, 0.38780664, 0.41414141,\n",
       "          0.54112554, 0.40764791, 0.4498557 , 0.50613276, 0.49963925,\n",
       "          0.37301587, 0.4047619 , 0.54112554, 0.36183261, 0.63419913,\n",
       "          0.43326118, 0.40440115, 0.39177489, 0.54220779, 0.43109668,\n",
       "          0.45815296, 0.67929293, 0.38672439, 0.67604618, 0.68578644]),\n",
       "   'split2_test_Accuracy': array([0.4530967 , 0.4328142 , 0.54436798, 0.55052517, 0.38645418,\n",
       "          0.4328142 , 0.4530967 , 0.54364361, 0.39659544, 0.42267294,\n",
       "          0.54255704, 0.41289388, 0.44005795, 0.50670047, 0.50380297,\n",
       "          0.37776168, 0.41470482, 0.54798986, 0.38355668, 0.64433176,\n",
       "          0.43426295, 0.41325607, 0.39406012, 0.54219486, 0.4299167 ,\n",
       "          0.45925389, 0.69721116, 0.39695762, 0.6899674 , 0.6899674 ]),\n",
       "   'mean_test_Accuracy': array([0.45698149, 0.43895698, 0.54542177, 0.5541937 , 0.38872867,\n",
       "          0.438236  , 0.46034607, 0.55046864, 0.39557799, 0.42261476,\n",
       "          0.55022831, 0.41384283, 0.45085316, 0.512497  , 0.50889209,\n",
       "          0.38115838, 0.41180005, 0.55118962, 0.3800769 , 0.64623888,\n",
       "          0.43631339, 0.41324201, 0.3975006 , 0.55082913, 0.43775535,\n",
       "          0.46347032, 0.69105984, 0.39714011, 0.68517183, 0.69105984]),\n",
       "   'std_test_Accuracy': array([0.00814672, 0.00712322, 0.00954249, 0.01183218, 0.01177715,\n",
       "          0.00941037, 0.01046222, 0.01554814, 0.00596488, 0.00688199,\n",
       "          0.0118295 , 0.00547355, 0.00920331, 0.00856813, 0.01024772,\n",
       "          0.00836009, 0.0049987 , 0.00976046, 0.01368183, 0.01066852,\n",
       "          0.00361806, 0.00719924, 0.00652533, 0.01215222, 0.01021939,\n",
       "          0.00673068, 0.00831895, 0.00856318, 0.00645222, 0.00480173]),\n",
       "   'rank_test_Accuracy': array([15, 17, 10,  5, 28, 18, 14,  8, 27, 21,  9, 22, 16, 11, 12, 29, 24,\n",
       "           6, 30,  4, 20, 23, 25,  7, 19, 13,  1, 26,  3,  1]),\n",
       "   'split0_train_Accuracy': array([0.50009037, 0.4729803 , 0.63383336, 0.65028014, 0.41659136,\n",
       "          0.47876378, 0.50659678, 0.64919573, 0.4200253 , 0.44695464,\n",
       "          0.64106271, 0.44080969, 0.49954817, 0.57979396, 0.57563709,\n",
       "          0.4061088 , 0.43358034, 0.6484728 , 0.41496476, 0.8250497 ,\n",
       "          0.47532984, 0.43321887, 0.42291704, 0.63654437, 0.47569131,\n",
       "          0.50171697, 0.92373035, 0.4200253 , 0.9170432 , 0.92861016]),\n",
       "   'split1_train_Accuracy': array([0.50846847, 0.49459459, 0.63801802, 0.64756757, 0.41891892,\n",
       "          0.48072072, 0.51585586, 0.63891892, 0.42666667, 0.4572973 ,\n",
       "          0.63477477, 0.44720721, 0.49603604, 0.57459459, 0.58036036,\n",
       "          0.41027027, 0.44522523, 0.6445045 , 0.40198198, 0.81891892,\n",
       "          0.48306306, 0.44702703, 0.43225225, 0.63459459, 0.47963964,\n",
       "          0.51711712, 0.92036036, 0.42306306, 0.91513514, 0.9245045 ]),\n",
       "   'split2_train_Accuracy': array([0.50836181, 0.47023917, 0.64035245, 0.64269016, 0.42042798,\n",
       "          0.47959   , 0.50638374, 0.6452077 , 0.42528322, 0.45333573,\n",
       "          0.63244021, 0.45063837, 0.49577414, 0.57345801, 0.57543607,\n",
       "          0.41143679, 0.44614278, 0.64538752, 0.42420428, 0.80597015,\n",
       "          0.48012947, 0.44973926, 0.42636217, 0.63621651, 0.4758137 ,\n",
       "          0.50728286, 0.92339507, 0.4288797 , 0.91674159, 0.92627225]),\n",
       "   'mean_train_Accuracy': array([0.50564021, 0.47927135, 0.63740128, 0.64684596, 0.41864609,\n",
       "          0.4796915 , 0.50961213, 0.64444078, 0.42399173, 0.45252922,\n",
       "          0.63609257, 0.44621842, 0.49711945, 0.57594886, 0.57714451,\n",
       "          0.40927195, 0.44164945, 0.64612161, 0.41371701, 0.81664626,\n",
       "          0.47950746, 0.44332838, 0.42717715, 0.63578516, 0.47704822,\n",
       "          0.50870565, 0.92249526, 0.42398935, 0.91630664, 0.9264623 ]),\n",
       "   'std_train_Accuracy': array([0.00392458, 0.0108928 , 0.0026969 , 0.00314033, 0.00157813,\n",
       "          0.00080213, 0.00441584, 0.00423039, 0.00286099, 0.00426071,\n",
       "          0.00364137, 0.004073  , 0.00172069, 0.00275821, 0.00227543,\n",
       "          0.00228682, 0.00571801, 0.00170118, 0.00911502, 0.00795324,\n",
       "          0.00318757, 0.00723375, 0.00385441, 0.00085243, 0.00183309,\n",
       "          0.00636707, 0.00151579, 0.00367365, 0.00083748, 0.0016815 ]),\n",
       "   'split0_test_F1': array([0.41899279, 0.39780937, 0.51993543, 0.53467537, 0.34794249,\n",
       "          0.39806481, 0.42581749, 0.5358668 , 0.35436601, 0.38088819,\n",
       "          0.53328049, 0.36454218, 0.40848867, 0.48491204, 0.48066295,\n",
       "          0.33712165, 0.36676453, 0.52881861, 0.34032807, 0.63868814,\n",
       "          0.38740402, 0.36634193, 0.36314945, 0.53202231, 0.39862777,\n",
       "          0.42424014, 0.68414739, 0.35003013, 0.67612714, 0.68414706]),\n",
       "   'split1_test_F1': array([0.40658683, 0.39192072, 0.50059199, 0.50957774, 0.3219787 ,\n",
       "          0.38132801, 0.40907591, 0.50468494, 0.33725712, 0.36545974,\n",
       "          0.50718334, 0.35497758, 0.40572934, 0.46874154, 0.46268434,\n",
       "          0.31427234, 0.35694758, 0.50747303, 0.29850127, 0.61545226,\n",
       "          0.38207036, 0.35058389, 0.34342051, 0.51000456, 0.38174511,\n",
       "          0.41549272, 0.66754043, 0.32700851, 0.66491732, 0.67448853]),\n",
       "   'split2_test_F1': array([0.40824968, 0.38236904, 0.51243328, 0.51766367, 0.33222608,\n",
       "          0.3834171 , 0.40973434, 0.51028593, 0.35175299, 0.37682254,\n",
       "          0.5111582 , 0.36105423, 0.39187609, 0.47000712, 0.46627413,\n",
       "          0.32472016, 0.36654728, 0.51537743, 0.32743063, 0.62963656,\n",
       "          0.38510996, 0.36287454, 0.34817953, 0.50930595, 0.380598  ,\n",
       "          0.41700857, 0.68937494, 0.34961048, 0.68127249, 0.68048892]),\n",
       "   'mean_test_F1': array([0.4112962 , 0.39072525, 0.51100327, 0.52067153, 0.33407988,\n",
       "          0.38763021, 0.41490506, 0.51699334, 0.34780023, 0.37440022,\n",
       "          0.51724817, 0.36019908, 0.40205798, 0.47458073, 0.4699006 ,\n",
       "          0.32539625, 0.36342249, 0.51724915, 0.32211686, 0.62794538,\n",
       "          0.38486631, 0.35994266, 0.35161129, 0.51715172, 0.38702251,\n",
       "          0.41892721, 0.68035008, 0.34222256, 0.67410031, 0.67971621]),\n",
       "   'std_test_F1': array([0.00550629, 0.0063609 , 0.00797008, 0.01047467, 0.01069212,\n",
       "          0.00745712, 0.00775222, 0.01359289, 0.00752708, 0.00653289,\n",
       "          0.01149734, 0.00395545, 0.0072625 , 0.00735311, 0.00777991,\n",
       "          0.00935122, 0.00457684, 0.00882358, 0.01750085, 0.00957154,\n",
       "          0.00218674, 0.0067639 , 0.00841846, 0.01056161, 0.00825272,\n",
       "          0.00382235, 0.00930113, 0.01075351, 0.00682143, 0.00398505]),\n",
       "   'rank_test_F1': array([15, 17, 10,  5, 28, 18, 14,  9, 26, 21,  7, 23, 16, 11, 12, 29, 22,\n",
       "           6, 30,  4, 20, 24, 25,  8, 19, 13,  1, 27,  3,  2]),\n",
       "   'split0_train_F1': array([0.45493259, 0.42275162, 0.60994724, 0.62860626, 0.36175234,\n",
       "          0.42923175, 0.46325995, 0.6271048 , 0.37076984, 0.39752506,\n",
       "          0.61891239, 0.3851281 , 0.45372593, 0.54846037, 0.54120844,\n",
       "          0.3524333 , 0.3838925 , 0.62667981, 0.36050678, 0.82215151,\n",
       "          0.42447752, 0.37927219, 0.37776335, 0.61552338, 0.42793716,\n",
       "          0.45492853, 0.92294778, 0.36575081, 0.91621982, 0.92798049]),\n",
       "   'split1_train_F1': array([0.46366681, 0.45390672, 0.61312643, 0.6227931 , 0.36349865,\n",
       "          0.4313413 , 0.4725978 , 0.6152964 , 0.37751345, 0.4100726 ,\n",
       "          0.60949329, 0.39360142, 0.45204753, 0.5395866 , 0.54767622,\n",
       "          0.35313401, 0.39670677, 0.61922664, 0.33816089, 0.81547741,\n",
       "          0.43579562, 0.3945984 , 0.38455785, 0.60992989, 0.43304547,\n",
       "          0.47526983, 0.91943331, 0.3668005 , 0.91407032, 0.92374002]),\n",
       "   'split2_train_F1': array([0.46324123, 0.42246641, 0.61519023, 0.61753223, 0.36712322,\n",
       "          0.4289509 , 0.46222134, 0.62011635, 0.38128158, 0.41038663,\n",
       "          0.60457669, 0.39787435, 0.44664662, 0.53864255, 0.53992325,\n",
       "          0.35839129, 0.40085394, 0.6197424 , 0.37067335, 0.80116189,\n",
       "          0.43074645, 0.39711154, 0.38181283, 0.61052429, 0.42722251,\n",
       "          0.46425785, 0.92288889, 0.37886261, 0.91622784, 0.9258808 ]),\n",
       "   'mean_train_F1': array([0.46061354, 0.43304158, 0.61275463, 0.6229772 , 0.36412474,\n",
       "          0.42984132, 0.46602636, 0.62083918, 0.37652163, 0.40599476,\n",
       "          0.61099413, 0.39220129, 0.45080669, 0.54222984, 0.54293597,\n",
       "          0.35465287, 0.39381774, 0.62188295, 0.35644701, 0.81293027,\n",
       "          0.43033986, 0.39032737, 0.38137801, 0.61199252, 0.42940171,\n",
       "          0.46481874, 0.92175666, 0.37047131, 0.91550599, 0.92586711]),\n",
       "   'std_train_F1': array([0.0040208 , 0.01475434, 0.00215653, 0.00452282, 0.0022369 ,\n",
       "          0.00106683, 0.00466601, 0.00484778, 0.00434833, 0.00599036,\n",
       "          0.00594797, 0.00529698, 0.00302036, 0.00442248, 0.00339268,\n",
       "          0.0026589 , 0.00721953, 0.00339842, 0.01358004, 0.00875622,\n",
       "          0.00462953, 0.00788424, 0.00279083, 0.00250846, 0.00259299,\n",
       "          0.00831377, 0.00164303, 0.005949  , 0.00101518, 0.00173119]),\n",
       "   'split0_test_Log_Loss': array([-2.56595367, -2.67860399, -2.18889106, -2.24868661, -2.83620803,\n",
       "          -2.6342533 , -2.62876931, -2.25749953, -2.87633064, -2.79991364,\n",
       "          -2.19246388, -2.75203311, -2.56308881, -2.35964214, -2.41783951,\n",
       "          -2.8723173 , -2.79696017, -2.25115067, -2.84319548, -1.78414356,\n",
       "          -2.63898668, -2.74248894, -2.88319558, -2.18382268, -2.64177523,\n",
       "          -2.6166116 , -1.59246425, -2.82957293, -1.58766176, -1.64441633]),\n",
       "   'split1_test_Log_Loss': array([-2.56912091, -2.70246016, -2.20982706, -2.26252155, -2.83761526,\n",
       "          -2.64414137, -2.63165135, -2.26084958, -2.88397437, -2.79670528,\n",
       "          -2.2001836 , -2.75529304, -2.57781494, -2.36295051, -2.41964291,\n",
       "          -2.87340181, -2.80119416, -2.26069768, -2.83075468, -1.81180618,\n",
       "          -2.64221865, -2.75119168, -2.89170104, -2.19968303, -2.64664218,\n",
       "          -2.62603558, -1.60563141, -2.83556855, -1.61936376, -1.6627543 ]),\n",
       "   'split2_test_Log_Loss': array([-2.56709408, -2.68004354, -2.19097681, -2.24731166, -2.83567756,\n",
       "          -2.63725102, -2.61749008, -2.25856335, -2.87978296, -2.80546008,\n",
       "          -2.1877199 , -2.74308754, -2.55764252, -2.35619463, -2.41027652,\n",
       "          -2.86762169, -2.80969001, -2.24526504, -2.83013785, -1.81229016,\n",
       "          -2.63171112, -2.74183796, -2.88163981, -2.19616572, -2.63280823,\n",
       "          -2.618566  , -1.59337964, -2.83777859, -1.59672558, -1.64383626]),\n",
       "   'mean_test_Log_Loss': array([-2.56738701, -2.68702791, -2.19655669, -2.25283876, -2.83650077,\n",
       "          -2.6385415 , -2.62598717, -2.25896835, -2.88002209, -2.80068511,\n",
       "          -2.19346135, -2.75015109, -2.56618706, -2.35960035, -2.41593102,\n",
       "          -2.87112068, -2.80259388, -2.25237803, -2.83471939, -1.80269602,\n",
       "          -2.63764941, -2.74517179, -2.88551253, -2.19320071, -2.64042138,\n",
       "          -2.62039908, -1.59715384, -2.83429243, -1.60122859, -1.65033213]),\n",
       "   'std_test_Log_Loss': array([0.00131088, 0.01092217, 0.00941708, 0.00686605, 0.00081687,\n",
       "          0.00414253, 0.00610203, 0.00139867, 0.00312872, 0.00361107,\n",
       "          0.0051305 , 0.0051524 , 0.00851329, 0.0027545 , 0.0040519 ,\n",
       "          0.00250499, 0.0052911 , 0.00635187, 0.00602308, 0.01317329,\n",
       "          0.00438782, 0.0042627 , 0.00441946, 0.00681085, 0.00572135,\n",
       "          0.0040626 , 0.00600295, 0.00346977, 0.01334021, 0.00878225]),\n",
       "   'rank_test_Log_Loss': array([14, 20,  7,  9, 27, 18, 16, 10, 29, 23,  6, 22, 13, 11, 12, 28, 24,\n",
       "           8, 26,  4, 17, 21, 30,  5, 19, 15,  1, 25,  2,  3]),\n",
       "   'split0_train_Log_Loss': array([-2.48519651, -2.6112835 , -2.03116173, -2.08802189, -2.79172525,\n",
       "          -2.56581858, -2.54777364, -2.09644876, -2.82916543, -2.74544926,\n",
       "          -2.03330284, -2.69757668, -2.48369588, -2.24043015, -2.29933147,\n",
       "          -2.83046036, -2.74024272, -2.09005393, -2.79732403, -1.47774541,\n",
       "          -2.56976773, -2.68885095, -2.83592342, -2.02783705, -2.57301293,\n",
       "          -2.53620931, -1.1656635 , -2.78376683, -1.16127468, -1.21591684]),\n",
       "   'split1_train_Log_Loss': array([-2.4797044 , -2.6216323 , -2.03190448, -2.08183265, -2.7876099 ,\n",
       "          -2.56581873, -2.53668793, -2.08070398, -2.83257327, -2.73606667,\n",
       "          -2.02245474, -2.69369187, -2.48801383, -2.23128005, -2.28809669,\n",
       "          -2.82692178, -2.73977785, -2.08051788, -2.78042836, -1.4793308 ,\n",
       "          -2.56557785, -2.68905881, -2.83925755, -2.01881001, -2.56992231,\n",
       "          -2.53549706, -1.14870289, -2.78592063, -1.15819336, -1.2033177 ]),\n",
       "   'split2_train_Log_Loss': array([-2.48932999, -2.6139291 , -2.0319656 , -2.08477502, -2.79457319,\n",
       "          -2.5692488 , -2.53673793, -2.09421811, -2.83633497, -2.74997249,\n",
       "          -2.03044115, -2.69235473, -2.47988162, -2.23775117, -2.28837118,\n",
       "          -2.82864759, -2.75611774, -2.08442161, -2.7875633 , -1.50897119,\n",
       "          -2.56566856, -2.69059134, -2.83751661, -2.03378215, -2.56580932,\n",
       "          -2.53785629, -1.15826095, -2.79541354, -1.15836541, -1.20591119]),\n",
       "   'mean_train_Log_Loss': array([-2.48474363, -2.61561497, -2.03167727, -2.08487652, -2.79130278,\n",
       "          -2.56696204, -2.54039983, -2.09045695, -2.83269122, -2.74382947,\n",
       "          -2.02873291, -2.69454109, -2.48386378, -2.23648712, -2.29193311,\n",
       "          -2.82867658, -2.74537944, -2.08499781, -2.78843856, -1.48868246,\n",
       "          -2.56700472, -2.68950036, -2.83756586, -2.02680974, -2.56958152,\n",
       "          -2.53652089, -1.15754245, -2.788367  , -1.15927782, -1.20838191]),\n",
       "   'std_train_Log_Loss': array([0.00394266, 0.00438983, 0.0003654 , 0.00252777, 0.00285841,\n",
       "          0.00161699, 0.00521411, 0.00695626, 0.00292814, 0.00579141,\n",
       "          0.00459049, 0.00221481, 0.00332208, 0.00384096, 0.00523263,\n",
       "          0.00144477, 0.0075955 , 0.00391434, 0.00692534, 0.01436089,\n",
       "          0.0019541 , 0.00077609, 0.0013616 , 0.00615537, 0.00295072,\n",
       "          0.00098803, 0.00694276, 0.00505965, 0.00141374, 0.00543219])},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40},\n",
       "  26,\n",
       "  -1.5971538358108712),\n",
       " 'DecisionTreeClassifier_V09_PCA_90': ({'mean_fit_time': array([0.08576004, 0.10337925, 0.12499913, 0.04089046, 0.09308394,\n",
       "          0.05186121, 0.04055866, 0.05219364, 0.09707371, 0.03324389,\n",
       "          0.03191479, 0.094414  , 0.22838926, 0.20678051, 0.28856158,\n",
       "          0.1668872 , 0.23570315, 0.16189988, 0.25232482, 0.18085011,\n",
       "          0.07081008, 0.0704782 , 0.10472012, 0.23370822, 0.16422709,\n",
       "          0.10206087, 0.16755168, 0.18949294, 0.13696726, 0.05618302]),\n",
       "   'std_fit_time': array([0.00080478, 0.02420178, 0.00702065, 0.00587238, 0.00204981,\n",
       "          0.00651486, 0.00663282, 0.00616613, 0.00047025, 0.00235078,\n",
       "          0.00081381, 0.00094089, 0.01508106, 0.0138512 , 0.00589136,\n",
       "          0.00462995, 0.02450172, 0.0096472 , 0.01199567, 0.01024657,\n",
       "          0.00141091, 0.00653232, 0.01279761, 0.00900728, 0.02092529,\n",
       "          0.02092527, 0.01077253, 0.01272023, 0.00204923, 0.00409801]),\n",
       "   'mean_score_time': array([0.05584017, 0.03656904, 0.03025325, 0.03789902, 0.02958783,\n",
       "          0.03257966, 0.03091701, 0.03789894, 0.03424199, 0.03557165,\n",
       "          0.03490663, 0.05019951, 0.03125024, 0.02792509, 0.03457459,\n",
       "          0.0299205 , 0.03224754, 0.03490686, 0.0329121 , 0.03158204,\n",
       "          0.0272607 , 0.03690124, 0.0302523 , 0.02992002, 0.02992042,\n",
       "          0.0329121 , 0.02992002, 0.05385629, 0.03091717, 0.02759298]),\n",
       "   'std_score_time': array([0.01058615, 0.01506715, 0.00124379, 0.01131325, 0.00094049,\n",
       "          0.00204959, 0.00423182, 0.00587208, 0.00682946, 0.00367194,\n",
       "          0.00850134, 0.01673529, 0.00169501, 0.00215457, 0.00448496,\n",
       "          0.0008141 , 0.00248795, 0.00917665, 0.00141035, 0.00463042,\n",
       "          0.00169517, 0.00453395, 0.00248759, 0.00293604, 0.00244318,\n",
       "          0.00354984, 0.00141051, 0.03457785, 0.00215428, 0.00204894]),\n",
       "   'param_min_samples_split': masked_array(data=[0.9500000000000001, 0.62, 0.44, 0.5700000000000001,\n",
       "                      0.52, 0.36, 0.64, 0.16, 0.85, 0.68, 0.43, 0.03, 0.07,\n",
       "                      0.12, 0.05, 0.32, 0.14, 0.22, 0.12, 0.26, 0.73, 0.89,\n",
       "                      0.64, 0.12, 0.35000000000000003, 0.59, 0.2, 0.32, 0.36,\n",
       "                      0.13],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['sqrt', 'sqrt', 0.5, 'log2', 'log2', 'sqrt', 'log2',\n",
       "                      'log2', 0.5, 'sqrt', 'log2', 'sqrt', 0.5, 0.5, 'sqrt',\n",
       "                      'sqrt', 0.5, 0.5, 'sqrt', 'sqrt', 'log2', 'log2', 0.5,\n",
       "                      0.5, 'sqrt', 0.5, 0.5, 0.5, 'log2', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[None, 20, 20, 20, None, None, None, None, None, None,\n",
       "                      20, None, 20, 20, None, None, None, 20, 20, 20, 20, 20,\n",
       "                      None, 20, 20, 20, None, 20, None, None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_criterion': masked_array(data=['entropy', 'entropy', 'gini', 'gini', 'entropy',\n",
       "                      'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                      'gini', 'gini', 'entropy', 'entropy', 'gini', 'gini',\n",
       "                      'entropy', 'entropy', 'entropy', 'entropy', 'gini',\n",
       "                      'gini', 'entropy', 'gini', 'gini', 'gini', 'entropy',\n",
       "                      'gini'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=['balanced', 'balanced', None, 'balanced', 'balanced',\n",
       "                      'balanced', 'balanced', 'balanced', None, None, None,\n",
       "                      None, None, None, None, None, 'balanced', None,\n",
       "                      'balanced', None, 'balanced', None, None, 'balanced',\n",
       "                      'balanced', 'balanced', None, 'balanced', 'balanced',\n",
       "                      None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'min_samples_split': 0.9500000000000001,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.62,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.44,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.5700000000000001,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.52,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.36,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.64,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.16,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.85,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.68,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.43,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.03,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.07,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.12,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.05,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.32,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.14,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.22,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.12,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.26,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.73,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.89,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.64,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.12,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.35000000000000003,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.59,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.2,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None},\n",
       "    {'min_samples_split': 0.32,\n",
       "     'max_features': 0.5,\n",
       "     'max_depth': 20,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.36,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'entropy',\n",
       "     'class_weight': 'balanced'},\n",
       "    {'min_samples_split': 0.13,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': None,\n",
       "     'criterion': 'gini',\n",
       "     'class_weight': None}],\n",
       "   'split0_test_Accuracy': array([0.04661169, 0.0501972 , 0.10469702, 0.04159197, 0.05916099,\n",
       "          0.09752599, 0.04374328, 0.11796343, 0.087128  , 0.07708856,\n",
       "          0.10613123, 0.28863392, 0.23054858, 0.21979204, 0.20795984,\n",
       "          0.08425959, 0.18895662, 0.16134815, 0.14198638, 0.09860165,\n",
       "          0.04015776, 0.06955898, 0.08999641, 0.23449265, 0.08318394,\n",
       "          0.08999641, 0.15346002, 0.14055217, 0.10469702, 0.21907494]),\n",
       "   'split1_test_Accuracy': array([0.04148629, 0.06673882, 0.0981241 , 0.06349206, 0.07323232,\n",
       "          0.0988456 , 0.06890332, 0.12878788, 0.09776335, 0.07756133,\n",
       "          0.11075036, 0.30555556, 0.25541126, 0.23232323, 0.20779221,\n",
       "          0.09992785, 0.18470418, 0.15692641, 0.12698413, 0.08585859,\n",
       "          0.0472583 , 0.07683983, 0.11219336, 0.22438672, 0.08189033,\n",
       "          0.06601732, 0.17496392, 0.12518038, 0.09415584, 0.17568543]),\n",
       "   'split2_test_Accuracy': array([0.0380297 , 0.04744658, 0.09127128, 0.04780876, 0.05795002,\n",
       "          0.09561753, 0.08982253, 0.12930098, 0.07968127, 0.06990221,\n",
       "          0.05686346, 0.3071351 , 0.30097791, 0.21115538, 0.25172039,\n",
       "          0.11046722, 0.21079319, 0.13799348, 0.14270192, 0.11372691,\n",
       "          0.04599783, 0.0673669 , 0.09090909, 0.210431  , 0.08257878,\n",
       "          0.06917783, 0.16696849, 0.10901847, 0.07062658, 0.14052879]),\n",
       "   'mean_test_Accuracy': array([0.0420572 , 0.05479452, 0.09805335, 0.05094929, 0.06344629,\n",
       "          0.09733237, 0.06741168, 0.12533045, 0.08819995, 0.07486181,\n",
       "          0.0913242 , 0.30040856, 0.26219659, 0.2211007 , 0.22242249,\n",
       "          0.09817352, 0.19478491, 0.15212689, 0.13722663, 0.09937515,\n",
       "          0.04446047, 0.07125691, 0.09769286, 0.22314348, 0.08255227,\n",
       "          0.07510214, 0.16510454, 0.12496996, 0.08988224, 0.17856285]),\n",
       "   'std_test_Accuracy': array([0.00352732, 0.00851571, 0.00548218, 0.00922058, 0.00693368,\n",
       "          0.00132323, 0.01884444, 0.00523459, 0.00741116, 0.00349999,\n",
       "          0.02435512, 0.00838448, 0.02915454, 0.0086799 , 0.02064408,\n",
       "          0.0107726 , 0.01141292, 0.01012139, 0.00724452, 0.01137505,\n",
       "          0.00309774, 0.00404583, 0.01025463, 0.00986398, 0.00052906,\n",
       "          0.0106528 , 0.00888676, 0.01287659, 0.01423561, 0.0321361 ]),\n",
       "   'rank_test_Accuracy': array([30, 27, 15, 28, 26, 17, 25, 11, 20, 23, 18,  1,  2,  5,  4, 14,  6,\n",
       "           9, 10, 13, 29, 24, 16,  3, 21, 22,  8, 12, 19,  7]),\n",
       "   'split0_train_Accuracy': array([0.04482198, 0.05060546, 0.10952467, 0.04265317, 0.06072655,\n",
       "          0.09994578, 0.04427978, 0.14061088, 0.08964395, 0.07572745,\n",
       "          0.09777697, 0.33001988, 0.25067775, 0.23639978, 0.24254473,\n",
       "          0.0936201 , 0.2022411 , 0.16934755, 0.15687692, 0.10590999,\n",
       "          0.04102657, 0.07247425, 0.09343936, 0.24796674, 0.08819808,\n",
       "          0.09072836, 0.16013013, 0.14639436, 0.10446412, 0.2295319 ]),\n",
       "   'split1_train_Accuracy': array([0.04288288, 0.06846847, 0.1       , 0.06378378, 0.07495495,\n",
       "          0.09765766, 0.06864865, 0.14036036, 0.09531532, 0.08504505,\n",
       "          0.11441441, 0.35045045, 0.27243243, 0.24432432, 0.23207207,\n",
       "          0.10432432, 0.19657658, 0.1636036 , 0.13207207, 0.09423423,\n",
       "          0.04828829, 0.07459459, 0.11423423, 0.23459459, 0.08324324,\n",
       "          0.06558559, 0.18306306, 0.12756757, 0.0972973 , 0.18288288]),\n",
       "   'split2_train_Accuracy': array([0.03794282, 0.0476533 , 0.09386801, 0.04603489, 0.05844273,\n",
       "          0.09476713, 0.09063118, 0.14619673, 0.07840316, 0.07139004,\n",
       "          0.06347779, 0.34831865, 0.32925733, 0.21650782, 0.26362165,\n",
       "          0.10879338, 0.22082359, 0.13648624, 0.14439849, 0.11149074,\n",
       "          0.04585506, 0.07049092, 0.09332854, 0.22082359, 0.08199964,\n",
       "          0.0695918 , 0.17640712, 0.11454774, 0.0703111 , 0.15482827]),\n",
       "   'mean_train_Accuracy': array([0.04188256, 0.05557574, 0.10113089, 0.05082395, 0.06470808,\n",
       "          0.09745686, 0.0678532 , 0.14238932, 0.08778748, 0.07738751,\n",
       "          0.09188973, 0.34292966, 0.2841225 , 0.23241064, 0.24607948,\n",
       "          0.10224593, 0.20654709, 0.15647913, 0.14444916, 0.10387832,\n",
       "          0.04505664, 0.07251992, 0.10033405, 0.23446164, 0.08448032,\n",
       "          0.07530191, 0.1732001 , 0.12950322, 0.09069084, 0.18908102]),\n",
       "   'std_train_Accuracy': array([0.00289611, 0.00919585, 0.00644163, 0.0092674 , 0.00730538,\n",
       "          0.00211894, 0.01893124, 0.00269418, 0.00702804, 0.00569688,\n",
       "          0.02120738, 0.00916999, 0.03312784, 0.01170112, 0.01312034,\n",
       "          0.00636642, 0.0103565 , 0.01433027, 0.0101266 , 0.00718992,\n",
       "          0.00301786, 0.00167563, 0.00982902, 0.01108154, 0.00267743,\n",
       "          0.01103007, 0.00963305, 0.01307317, 0.01470468, 0.03081094]),\n",
       "   'split0_test_F1': array([0.00422686, 0.00500259, 0.03668183, 0.00377987, 0.00864284,\n",
       "          0.03351438, 0.00414474, 0.0642915 , 0.02360387, 0.02366347,\n",
       "          0.03153856, 0.25579613, 0.16742003, 0.15028471, 0.16040906,\n",
       "          0.02233232, 0.11594014, 0.06772323, 0.06794914, 0.03409934,\n",
       "          0.00359366, 0.01030863, 0.02248809, 0.14668533, 0.01825603,\n",
       "          0.02151885, 0.06131154, 0.07113966, 0.02513542, 0.1494199 ]),\n",
       "   'split1_test_F1': array([0.00403324, 0.00947088, 0.02621896, 0.02061929, 0.01156625,\n",
       "          0.04498764, 0.01758539, 0.05767748, 0.02520648, 0.01916468,\n",
       "          0.03720316, 0.26457972, 0.21283643, 0.14800728, 0.15047754,\n",
       "          0.02765103, 0.11084297, 0.0675098 , 0.06314579, 0.02840289,\n",
       "          0.00444912, 0.01288496, 0.03113219, 0.14266483, 0.0205936 ,\n",
       "          0.01064526, 0.09724192, 0.04670725, 0.0222178 , 0.1067357 ]),\n",
       "   'split2_test_F1': array([0.00505786, 0.00437565, 0.02761469, 0.00467772, 0.00866035,\n",
       "          0.03223989, 0.02951961, 0.05996467, 0.01971746, 0.01344729,\n",
       "          0.01122779, 0.29092804, 0.24365782, 0.12366361, 0.19836564,\n",
       "          0.03025463, 0.12578665, 0.05487159, 0.06814024, 0.0365547 ,\n",
       "          0.00424023, 0.01259882, 0.02345179, 0.13023066, 0.01564326,\n",
       "          0.00928487, 0.07717191, 0.03428182, 0.01233473, 0.08219928]),\n",
       "   'mean_test_F1': array([0.00443807, 0.00628294, 0.03018851, 0.00968685, 0.00962242,\n",
       "          0.03691321, 0.01704038, 0.0606529 , 0.02284829, 0.01877552,\n",
       "          0.02668687, 0.27037764, 0.20784142, 0.140694  , 0.16969384,\n",
       "          0.02673234, 0.11750909, 0.06338833, 0.06641258, 0.03301651,\n",
       "          0.00409312, 0.01192661, 0.02568711, 0.13988694, 0.01816781,\n",
       "          0.01383805, 0.07854171, 0.05077303, 0.01991668, 0.11290022]),\n",
       "   'std_test_F1': array([0.00044383, 0.00226749, 0.00464509, 0.00773492, 0.00137378,\n",
       "          0.00573008, 0.01036814, 0.00274647, 0.00230125, 0.00418049,\n",
       "          0.01113616, 0.01491869, 0.03132868, 0.01203605, 0.02060658,\n",
       "          0.00329932, 0.00619346, 0.00600173, 0.00231004, 0.00341121,\n",
       "          0.00036469, 0.00115463, 0.00386824, 0.00699966, 0.0020192 ,\n",
       "          0.00548132, 0.01471731, 0.01532152, 0.00547389, 0.02779091]),\n",
       "   'rank_test_F1': array([29, 28, 15, 26, 27, 13, 23, 11, 19, 21, 17,  1,  2,  4,  3, 16,  6,\n",
       "          10,  9, 14, 30, 25, 18,  5, 22, 24,  8, 12, 20,  7]),\n",
       "   'split0_train_F1': array([0.00406642, 0.00501114, 0.0384912 , 0.00389662, 0.00903009,\n",
       "          0.03430131, 0.00417486, 0.07663966, 0.02437845, 0.02372554,\n",
       "          0.02886656, 0.29503294, 0.1835459 , 0.16052352, 0.18725769,\n",
       "          0.02516583, 0.12487585, 0.07213471, 0.07439598, 0.03621188,\n",
       "          0.00370605, 0.01075032, 0.02344667, 0.15326096, 0.01940882,\n",
       "          0.02204547, 0.06531489, 0.07379388, 0.02521256, 0.15534438]),\n",
       "   'split1_train_F1': array([0.00418992, 0.00975058, 0.02676012, 0.02215557, 0.01181989,\n",
       "          0.04392229, 0.01715319, 0.06292509, 0.02469089, 0.02082341,\n",
       "          0.03904843, 0.30623827, 0.22710877, 0.15880826, 0.16802245,\n",
       "          0.02796382, 0.1207231 , 0.07170854, 0.06597427, 0.0321559 ,\n",
       "          0.00452057, 0.01228254, 0.03147369, 0.15043684, 0.02071139,\n",
       "          0.01043762, 0.10088736, 0.04921493, 0.02297923, 0.11388114]),\n",
       "   'split2_train_F1': array([0.00487822, 0.00439173, 0.02753304, 0.00451123, 0.008817  ,\n",
       "          0.03372066, 0.03191152, 0.06844751, 0.01904322, 0.0137675 ,\n",
       "          0.0123072 , 0.33104771, 0.26706165, 0.12565081, 0.20574957,\n",
       "          0.02967328, 0.12931565, 0.05273719, 0.06836095, 0.0359905 ,\n",
       "          0.00417281, 0.0133119 , 0.02328337, 0.13717817, 0.01545796,\n",
       "          0.0093289 , 0.08248864, 0.03521784, 0.01232296, 0.08973281]),\n",
       "   'mean_train_F1': array([0.00437819, 0.00638448, 0.03092812, 0.01018781, 0.00988899,\n",
       "          0.03731475, 0.01774652, 0.06933742, 0.02270419, 0.01943882,\n",
       "          0.02674073, 0.31077297, 0.22590544, 0.14832753, 0.1870099 ,\n",
       "          0.02760098, 0.12497153, 0.06552682, 0.06957707, 0.03478609,\n",
       "          0.00413314, 0.01211492, 0.02606791, 0.14695866, 0.01852606,\n",
       "          0.01393733, 0.08289696, 0.05274222, 0.02017158, 0.11965278]),\n",
       "   'std_train_F1': array([0.00035716, 0.00239359, 0.00535721, 0.0084662 , 0.00136812,\n",
       "          0.00467824, 0.01133122, 0.0056342 , 0.00259184, 0.00418158,\n",
       "          0.01102006, 0.01504856, 0.03410578, 0.01605014, 0.01540303,\n",
       "          0.00185796, 0.00350855, 0.0090453 , 0.00354406, 0.00186202,\n",
       "          0.00033371, 0.00105246, 0.00382305, 0.00701129, 0.00223369,\n",
       "          0.00575116, 0.01452527, 0.01594488, 0.00562421, 0.02709494]),\n",
       "   'split0_test_Log_Loss': array([-3.48243604, -3.56790527, -3.21266661, -3.59121608, -3.52753468,\n",
       "          -3.37227892, -3.57044752, -3.50666901, -3.47693063, -3.50031465,\n",
       "          -3.35721227, -4.08567355, -3.27396957, -2.99507137, -3.5586221 ,\n",
       "          -3.40994994, -3.11793555, -3.09231478, -3.25906455, -3.26591894,\n",
       "          -3.58666149, -3.42410099, -3.36122424, -3.10667971, -3.39195832,\n",
       "          -3.23147124, -3.09758312, -3.18733407, -3.2564581 , -3.10706702]),\n",
       "   'split1_test_Log_Loss': array([-3.58542045, -3.39431685, -3.23269595, -3.56769276, -3.4423064 ,\n",
       "          -3.4084912 , -3.38872381, -3.36491945, -3.36353086, -3.43682067,\n",
       "          -3.35824168, -4.0006482 , -3.37658104, -3.01270894, -3.64014914,\n",
       "          -3.25178254, -3.28949184, -3.02919648, -3.38176731, -3.45751079,\n",
       "          -3.50282821, -3.47202059, -3.23395341, -2.96931239, -3.43841082,\n",
       "          -3.34339018, -3.08782544, -3.26956891, -3.28054984, -3.26086001]),\n",
       "   'split2_test_Log_Loss': array([-3.59743929, -3.42983167, -3.24613881, -3.6061545 , -3.4263536 ,\n",
       "          -3.39213041, -3.31427076, -3.47150064, -3.34703706, -3.47629083,\n",
       "          -3.4781886 , -4.20694579, -3.0836294 , -3.09593434, -3.65296999,\n",
       "          -3.20540846, -3.00320781, -3.06629753, -3.41712002, -3.20576198,\n",
       "          -3.52573371, -3.56087577, -3.32516681, -3.13095316, -3.40803372,\n",
       "          -3.23816233, -3.00924882, -3.09343289, -3.42945902, -3.4821242 ]),\n",
       "   'mean_test_Log_Loss': array([-3.55489419, -3.46427534, -3.23044336, -3.58833676, -3.46557677,\n",
       "          -3.39092713, -3.42492455, -3.44778537, -3.39606301, -3.47119484,\n",
       "          -3.39769162, -4.09758684, -3.24499934, -3.03440975, -3.6170801 ,\n",
       "          -3.28940451, -3.13701639, -3.06265874, -3.35237424, -3.3097785 ,\n",
       "          -3.53852312, -3.4854406 , -3.3068684 , -3.06897685, -3.41276468,\n",
       "          -3.27097056, -3.06502613, -3.18357221, -3.32187961, -3.28272756]),\n",
       "   'std_test_Log_Loss': array([0.05167642, 0.074986  , 0.01375966, 0.01581336, 0.04446687,\n",
       "          0.01482511, 0.10768453, 0.0602982 , 0.05780655, 0.02619878,\n",
       "          0.05672157, 0.08453077, 0.12119309, 0.04394693, 0.04183165,\n",
       "          0.08764786, 0.11750018, 0.02592509, 0.06779744, 0.10725653,\n",
       "          0.03542995, 0.05664703, 0.05359278, 0.07112922, 0.01927669,\n",
       "          0.05125358, 0.0395038 , 0.07185947, 0.0764398 , 0.15391991]),\n",
       "   'rank_test_Log_Loss': array([27, 22,  7, 28, 23, 16, 20, 21, 17, 24, 18, 30,  8,  1, 29, 11,  5,\n",
       "           2, 15, 13, 26, 25, 12,  4, 19,  9,  3,  6, 14, 10]),\n",
       "   'split0_train_Log_Loss': array([-3.47408739, -3.55322081, -3.10165675, -3.5708953 , -3.48983962,\n",
       "          -3.31399175, -3.56767635, -3.01454941, -3.40340169, -3.45878185,\n",
       "          -3.3227787 , -2.23213347, -2.46177357, -2.56931217, -2.50342061,\n",
       "          -3.33860378, -2.64259489, -2.81116145, -2.98202344, -3.19240235,\n",
       "          -3.57395637, -3.39549416, -3.28481292, -2.57526561, -3.28316564,\n",
       "          -3.13907053, -2.89632961, -2.97574994, -3.22507359, -2.66083418]),\n",
       "   'split1_train_Log_Loss': array([-3.57477513, -3.35552936, -3.13912279, -3.43550091, -3.38573733,\n",
       "          -3.22748903, -3.3680066 , -3.00261138, -3.36187664, -3.39529226,\n",
       "          -3.23326143, -2.16642452, -2.45848741, -2.62984205, -2.56671881,\n",
       "          -3.16516595, -2.74824615, -2.85144667, -3.02947839, -3.30487116,\n",
       "          -3.48898673, -3.47290998, -3.22112043, -2.58781608, -3.3360423 ,\n",
       "          -3.3253995 , -2.79464445, -2.98904649, -3.24332287, -2.83916118]),\n",
       "   'split2_train_Log_Loss': array([-3.58946813, -3.41117561, -3.1584769 , -3.58647163, -3.37413609,\n",
       "          -3.22839568, -3.28186161, -3.10011057, -3.29380898, -3.46194591,\n",
       "          -3.464075  , -2.22672421, -2.3631426 , -2.69067485, -2.41347479,\n",
       "          -3.09031688, -2.73985984, -2.94502986, -2.95985997, -3.13947979,\n",
       "          -3.52485584, -3.54117609, -3.28199049, -2.67882903, -3.33897572,\n",
       "          -3.23678435, -2.80432294, -3.01129008, -3.3903331 , -2.98163856]),\n",
       "   'mean_train_Log_Loss': array([-3.54611022, -3.43997526, -3.13308548, -3.53095595, -3.41657101,\n",
       "          -3.25662548, -3.40584819, -3.03909045, -3.35302911, -3.43867334,\n",
       "          -3.34003837, -2.2084274 , -2.42780119, -2.62994302, -2.49453807,\n",
       "          -3.19802887, -2.71023363, -2.86921266, -2.99045393, -3.2122511 ,\n",
       "          -3.52926632, -3.46986008, -3.26264128, -2.61397024, -3.31939455,\n",
       "          -3.23375146, -2.83176567, -2.99202884, -3.28624319, -2.82721131]),\n",
       "   'std_train_Log_Loss': array([0.05127986, 0.08323678, 0.02358628, 0.06779579, 0.05202476,\n",
       "          0.04056576, 0.11971217, 0.04342212, 0.04517632, 0.03070224,\n",
       "          0.09501631, 0.0297825 , 0.04574021, 0.04954616, 0.06287611,\n",
       "          0.10399222, 0.04795019, 0.0560768 , 0.02904004, 0.06896403,\n",
       "          0.03482862, 0.05951349, 0.02938228, 0.04614741, 0.02564569,\n",
       "          0.07609871, 0.04582427, 0.01466166, 0.07397879, 0.13124014])},\n",
       "  {'min_samples_split': 0.12,\n",
       "   'max_features': 0.5,\n",
       "   'max_depth': 20,\n",
       "   'criterion': 'gini',\n",
       "   'class_weight': None},\n",
       "  13,\n",
       "  -3.0344097538343764),\n",
       " 'KNeighborsClassifier_V09_PCA_90': ({'mean_fit_time': array([0.0182755 , 0.04089125, 0.04321853, 0.04022662, 0.04720807,\n",
       "          0.04155572, 0.04654169, 0.0428857 , 0.02028012, 0.05019887,\n",
       "          0.04321671, 0.04388356, 0.04355113, 0.04621005, 0.05119634,\n",
       "          0.04488063, 0.04488007, 0.04355105, 0.03922915, 0.04421608,\n",
       "          0.03989331, 0.04720656, 0.02194055, 0.02160923, 0.02892383,\n",
       "          0.0219415 , 0.04753908, 0.04288602, 0.05717985, 0.04288626]),\n",
       "   'std_fit_time': array([0.00047621, 0.00215439, 0.0024885 , 0.0012439 , 0.00204882,\n",
       "          0.00234971, 0.00093903, 0.00140911, 0.00094004, 0.00823739,\n",
       "          0.00047019, 0.00244337, 0.00124437, 0.00124522, 0.00542294,\n",
       "          0.00215553, 0.00162781, 0.00094066, 0.00046968, 0.00124365,\n",
       "          0.00081449, 0.01034374, 0.00081478, 0.00169505, 0.0070533 ,\n",
       "          0.00162898, 0.0024878 , 0.00141108, 0.01887657, 0.00081371]),\n",
       "   'mean_score_time': array([ 1.09407568,  9.04050152, 10.87426662,  8.8117795 , 11.05378691,\n",
       "           9.03584735, 11.11362767, 10.11961667,  1.24267769, 10.63956181,\n",
       "          10.07939196, 11.04946478,  9.43079225,  9.64023193, 11.68676233,\n",
       "          10.9590404 , 10.80378826, 10.28783401,  8.98897298, 10.97499776,\n",
       "           8.8819259 ,  9.42414347,  1.3018539 ,  1.34374118,  1.38595994,\n",
       "           1.38230435, 10.45904374, 10.49195504, 10.89388045, 10.74527844]),\n",
       "   'std_score_time': array([0.14739852, 0.04371935, 0.208118  , 0.13164389, 0.02821361,\n",
       "          0.36301947, 0.50567983, 0.11856699, 0.02026009, 0.07378109,\n",
       "          0.1160693 , 0.53264839, 0.31770005, 0.11704317, 0.1951327 ,\n",
       "          0.26070017, 0.14110118, 0.10453939, 0.15746803, 0.22145374,\n",
       "          0.12602342, 0.03802471, 0.06084283, 0.01466545, 0.02940884,\n",
       "          0.06720517, 0.05614125, 0.03965195, 0.10660182, 0.1255442 ]),\n",
       "   'param_weights': masked_array(data=['distance', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'uniform', 'uniform', 'distance',\n",
       "                      'distance', 'uniform', 'distance', 'distance',\n",
       "                      'distance', 'distance', 'uniform', 'distance',\n",
       "                      'distance', 'uniform', 'uniform', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'distance',\n",
       "                      'uniform', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[3, 8, 6, 6, 5, 4, 6, 3, 5, 5, 3, 5, 8, 5, 8, 7, 8, 3,\n",
       "                      5, 5, 6, 7, 8, 4, 5, 6, 4, 4, 7, 4],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['brute', 'ball_tree', 'kd_tree', 'ball_tree', 'auto',\n",
       "                      'ball_tree', 'kd_tree', 'kd_tree', 'brute', 'auto',\n",
       "                      'auto', 'kd_tree', 'ball_tree', 'ball_tree', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'ball_tree', 'kd_tree',\n",
       "                      'ball_tree', 'ball_tree', 'brute', 'brute', 'brute',\n",
       "                      'brute', 'auto', 'kd_tree', 'kd_tree', 'auto'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'auto'}],\n",
       "   'split0_test_Accuracy': array([0.74793833, 0.66439584, 0.72534959, 0.67837935, 0.72965221,\n",
       "          0.69666547, 0.67837935, 0.74793833, 0.72965221, 0.69451416,\n",
       "          0.74793833, 0.72965221, 0.71782001, 0.72965221, 0.66439584,\n",
       "          0.72104697, 0.71782001, 0.7038365 , 0.69451416, 0.69451416,\n",
       "          0.72534959, 0.72104697, 0.71782001, 0.7407673 , 0.69451416,\n",
       "          0.72534959, 0.7407673 , 0.69666547, 0.67300108, 0.69666547]),\n",
       "   'split1_test_Accuracy': array([0.74314574, 0.65367965, 0.71536797, 0.66666667, 0.72727273,\n",
       "          0.69444444, 0.66666667, 0.74314574, 0.72727273, 0.68470418,\n",
       "          0.74314574, 0.72727273, 0.7041847 , 0.72727273, 0.65367965,\n",
       "          0.71428571, 0.7041847 , 0.71067821, 0.68470418, 0.68470418,\n",
       "          0.71536797, 0.71428571, 0.7041847 , 0.73773449, 0.68470418,\n",
       "          0.71536797, 0.73773449, 0.69444444, 0.66414141, 0.69444444]),\n",
       "   'split2_test_Accuracy': array([0.75117711, 0.66026802, 0.73198117, 0.67113365, 0.73487867,\n",
       "          0.70300616, 0.67113365, 0.75117711, 0.73487867, 0.68851865,\n",
       "          0.75117711, 0.73487867, 0.71206085, 0.73487867, 0.66026802,\n",
       "          0.71821804, 0.71206085, 0.71749366, 0.68851865, 0.68851865,\n",
       "          0.73198117, 0.71821804, 0.71206085, 0.74429555, 0.68851865,\n",
       "          0.73198117, 0.74429555, 0.70300616, 0.66606302, 0.70300616]),\n",
       "   'mean_test_Accuracy': array([0.74741649, 0.65945686, 0.72422495, 0.67207402, 0.73059361,\n",
       "          0.69802932, 0.67207402, 0.74741649, 0.73059361, 0.68925739,\n",
       "          0.74741649, 0.73059361, 0.71136746, 0.73059361, 0.65945686,\n",
       "          0.71785628, 0.71136746, 0.71064648, 0.68925739, 0.68925739,\n",
       "          0.72422495, 0.71785628, 0.71136746, 0.74092766, 0.68925739,\n",
       "          0.72422495, 0.74092766, 0.69802932, 0.66774814, 0.69802932]),\n",
       "   'std_test_Accuracy': array([0.00329524, 0.0044171 , 0.00682003, 0.0048329 , 0.00317212,\n",
       "          0.00362239, 0.0048329 , 0.00329524, 0.00317212, 0.00404322,\n",
       "          0.00329524, 0.00317212, 0.00559446, 0.00317212, 0.0044171 ,\n",
       "          0.00277522, 0.00559446, 0.00557649, 0.00404322, 0.00404322,\n",
       "          0.00682003, 0.00277522, 0.00559446, 0.00267733, 0.00404322,\n",
       "          0.00682003, 0.00267733, 0.00362239, 0.00381086, 0.00362239]),\n",
       "   'rank_test_Accuracy': array([ 1, 29, 10, 26,  6, 19, 26,  1,  6, 22,  1,  6, 15,  6, 29, 13, 15,\n",
       "          18, 22, 22, 10, 13, 15,  4, 22, 10,  4, 19, 28, 19]),\n",
       "   'split0_train_Accuracy': array([1.        , 0.76197361, 1.        , 0.78854148, 1.        ,\n",
       "          0.82974878, 0.78854148, 1.        , 1.        , 0.80715706,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.76197361,\n",
       "          1.        , 1.        , 0.85884692, 0.80715706, 0.80715706,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.80715706,\n",
       "          1.        , 1.        , 0.82974878, 0.77697452, 0.82974878]),\n",
       "   'split1_train_Accuracy': array([1.        , 0.7636036 , 1.        , 0.79207207, 1.        ,\n",
       "          0.83747748, 0.79207207, 1.        , 1.        , 0.81369369,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.7636036 ,\n",
       "          1.        , 1.        , 0.86630631, 0.81369369, 0.81369369,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.81369369,\n",
       "          1.        , 1.        , 0.83747748, 0.77675676, 0.83747748]),\n",
       "   'split2_train_Accuracy': array([1.        , 0.75525985, 1.        , 0.78475094, 1.        ,\n",
       "          0.83186477, 0.78475094, 1.        , 1.        , 0.8093868 ,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.75525985,\n",
       "          1.        , 1.        , 0.86297429, 0.8093868 , 0.8093868 ,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.8093868 ,\n",
       "          1.        , 1.        , 0.83186477, 0.7685668 , 0.83186477]),\n",
       "   'mean_train_Accuracy': array([1.        , 0.76027902, 1.        , 0.78845483, 1.        ,\n",
       "          0.83303034, 0.78845483, 1.        , 1.        , 0.81007918,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.76027902,\n",
       "          1.        , 1.        , 0.86270917, 0.81007918, 0.81007918,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.81007918,\n",
       "          1.        , 1.        , 0.83303034, 0.77409936, 0.83303034]),\n",
       "   'std_train_Accuracy': array([0.        , 0.00361094, 0.        , 0.00298947, 0.        ,\n",
       "          0.00326109, 0.00298947, 0.        , 0.        , 0.00271311,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00361094,\n",
       "          0.        , 0.        , 0.00305105, 0.00271311, 0.00271311,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00271311,\n",
       "          0.        , 0.        , 0.00326109, 0.00391312, 0.00326109]),\n",
       "   'split0_test_F1': array([0.74607859, 0.6579279 , 0.72079882, 0.67255435, 0.72621153,\n",
       "          0.69239063, 0.67255435, 0.74607859, 0.72621153, 0.68915289,\n",
       "          0.74607859, 0.72621153, 0.71307769, 0.72621153, 0.6579279 ,\n",
       "          0.71644351, 0.71307769, 0.70070742, 0.68915289, 0.68915289,\n",
       "          0.72079882, 0.71644351, 0.71307769, 0.73852703, 0.68915289,\n",
       "          0.72079882, 0.73852703, 0.69239063, 0.66706825, 0.69239063]),\n",
       "   'split1_test_F1': array([0.74219084, 0.64710989, 0.7120996 , 0.66022475, 0.72570021,\n",
       "          0.69151563, 0.66022475, 0.74219084, 0.72570021, 0.68071615,\n",
       "          0.74219084, 0.72570021, 0.69963887, 0.72570021, 0.64710989,\n",
       "          0.71047506, 0.69963887, 0.70897617, 0.68071615, 0.68071615,\n",
       "          0.7120996 , 0.71047506, 0.69963887, 0.73638735, 0.68071615,\n",
       "          0.7120996 , 0.73638735, 0.69151563, 0.6572562 , 0.69151563]),\n",
       "   'split2_test_F1': array([0.75049453, 0.65485109, 0.72996416, 0.66798567, 0.7329174 ,\n",
       "          0.70052057, 0.66798567, 0.75049453, 0.7329174 , 0.68558595,\n",
       "          0.75049453, 0.7329174 , 0.70844894, 0.7329174 , 0.65485109,\n",
       "          0.71484251, 0.70844894, 0.71616183, 0.68558595, 0.68558595,\n",
       "          0.72996416, 0.71484251, 0.70844894, 0.74274007, 0.68558595,\n",
       "          0.72996416, 0.74274007, 0.70052057, 0.66194456, 0.70052057]),\n",
       "   'mean_test_F1': array([0.74624869, 0.6533037 , 0.72094197, 0.66693169, 0.72826603,\n",
       "          0.69479646, 0.66693169, 0.74624869, 0.72826603, 0.68515927,\n",
       "          0.74624869, 0.72826603, 0.70706562, 0.72826603, 0.6533037 ,\n",
       "          0.7139243 , 0.70706562, 0.70858901, 0.68515927, 0.68515927,\n",
       "          0.72094197, 0.7139243 , 0.70706562, 0.73921208, 0.68515927,\n",
       "          0.72094197, 0.73921208, 0.69479646, 0.66210003, 0.69479646]),\n",
       "   'std_test_F1': array([0.00338753, 0.00455403, 0.00728401, 0.00509384, 0.00328412,\n",
       "          0.00404917, 0.00509384, 0.00338753, 0.00328412, 0.00346138,\n",
       "          0.00338753, 0.00328412, 0.00557859, 0.00328412, 0.00455403,\n",
       "          0.00252379, 0.00557859, 0.00631622, 0.00346138, 0.00346138,\n",
       "          0.00728401, 0.00252379, 0.00557859, 0.00263525, 0.00346138,\n",
       "          0.00728401, 0.00263525, 0.00404917, 0.00401192, 0.00404917]),\n",
       "   'rank_test_F1': array([ 1, 29, 10, 26,  6, 19, 26,  1,  6, 22,  1,  6, 16,  6, 29, 13, 16,\n",
       "          15, 22, 22, 10, 13, 16,  4, 22, 10,  4, 19, 28, 19]),\n",
       "   'split0_train_F1': array([1.        , 0.75871758, 1.        , 0.78665901, 1.        ,\n",
       "          0.82873359, 0.78665901, 1.        , 1.        , 0.80545771,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.75871758,\n",
       "          1.        , 1.        , 0.85877345, 0.80545771, 0.80545771,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.80545771,\n",
       "          1.        , 1.        , 0.82873359, 0.77445614, 0.82873359]),\n",
       "   'split1_train_F1': array([1.        , 0.75965019, 1.        , 0.78946573, 1.        ,\n",
       "          0.83631533, 0.78946573, 1.        , 1.        , 0.81168449,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.75965019,\n",
       "          1.        , 1.        , 0.86621199, 0.81168449, 0.81168449,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.81168449,\n",
       "          1.        , 1.        , 0.83631533, 0.77367133, 0.83631533]),\n",
       "   'split2_train_F1': array([1.        , 0.75176622, 1.        , 0.7820794 , 1.        ,\n",
       "          0.83055814, 0.7820794 , 1.        , 1.        , 0.80765692,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.75176622,\n",
       "          1.        , 1.        , 0.86211701, 0.80765692, 0.80765692,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.80765692,\n",
       "          1.        , 1.        , 0.83055814, 0.76608953, 0.83055814]),\n",
       "   'mean_train_F1': array([1.        , 0.75671133, 1.        , 0.78606805, 1.        ,\n",
       "          0.83186902, 0.78606805, 1.        , 1.        , 0.80826638,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.75671133,\n",
       "          1.        , 1.        , 0.86236748, 0.80826638, 0.80826638,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.80826638,\n",
       "          1.        , 1.        , 0.83186902, 0.77140567, 0.83186902]),\n",
       "   'std_train_F1': array([0.        , 0.00351739, 0.        , 0.00304427, 0.        ,\n",
       "          0.00323105, 0.00304427, 0.        , 0.        , 0.00257834,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00351739,\n",
       "          0.        , 0.        , 0.00304193, 0.00257834, 0.00257834,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00257834,\n",
       "          0.        , 0.        , 0.00323105, 0.0037727 , 0.00323105]),\n",
       "   'split0_test_Log_Loss': array([-5.04071995, -3.27984062, -3.53999715, -3.60223412, -3.77881239,\n",
       "          -4.31921937, -3.60223412, -5.04071995, -3.77881239, -3.83194025,\n",
       "          -5.04071995, -3.77881239, -3.20298865, -3.77881239, -3.27984062,\n",
       "          -3.31969241, -3.20298865, -5.07388704, -3.83194025, -3.83194025,\n",
       "          -3.53999715, -3.31969241, -3.20298865, -4.27498591, -3.83194025,\n",
       "          -3.53999715, -4.27498591, -4.31921937, -3.38953115, -4.31921937]),\n",
       "   'split1_test_Log_Loss': array([-5.34487854, -3.43813192, -3.855862  , -3.91644923, -4.2358844 ,\n",
       "          -4.71863134, -3.91644923, -5.34487854, -4.2358844 , -4.28956919,\n",
       "          -5.34487854, -4.2358844 , -3.36408677, -4.2358844 , -3.43813192,\n",
       "          -3.62173933, -3.36408677, -5.37797446, -4.28956919, -4.28956919,\n",
       "          -3.855862  , -3.62173933, -3.36408677, -4.67440126, -4.28956919,\n",
       "          -3.855862  , -4.67440126, -4.71863134, -3.68917656, -4.71863134]),\n",
       "   'split2_test_Log_Loss': array([-4.94933009, -3.3442651 , -3.75036519, -3.81334495, -4.06450011,\n",
       "          -4.52349891, -3.81334495, -4.94933009, -4.06450011, -4.11962072,\n",
       "          -4.94933009, -4.06450011, -3.26967164, -4.06450011, -3.3442651 ,\n",
       "          -3.47918872, -3.26967164, -4.98205402, -4.11962072, -4.11962072,\n",
       "          -3.75036519, -3.47918872, -3.26967164, -4.47826082, -4.11962072,\n",
       "          -3.75036519, -4.47826082, -4.52349891, -3.54801055, -4.52349891]),\n",
       "   'mean_test_Log_Loss': array([-5.11171252, -3.35394053, -3.71500358, -3.77693747, -4.02584284,\n",
       "          -4.52003477, -3.77693747, -5.11171252, -4.02584284, -4.07981735,\n",
       "          -5.11171252, -4.02584284, -3.2787728 , -4.02584284, -3.35394053,\n",
       "          -3.47321841, -3.2787728 , -5.14470888, -4.07981735, -4.07981735,\n",
       "          -3.71500358, -3.47321841, -3.2787728 , -4.47546913, -4.07981735,\n",
       "          -3.71500358, -4.47546913, -4.52003477, -3.54191984, -4.52003477]),\n",
       "   'std_test_Log_Loss': array([0.16895648, 0.06505573, 0.13148414, 0.13096449, 0.18879182,\n",
       "          0.16326767, 0.13096449, 0.16895648, 0.18879182, 0.18913514,\n",
       "          0.16895648, 0.18879182, 0.06615628, 0.18879182, 0.06505573,\n",
       "          0.1235256 , 0.06615628, 0.16906515, 0.18913514, 0.18913514,\n",
       "          0.13148414, 0.1235256 , 0.06615628, 0.16326265, 0.18913514,\n",
       "          0.13148414, 0.16326265, 0.16326767, 0.12254756, 0.16326767]),\n",
       "   'rank_test_Log_Loss': array([27,  4,  9, 12, 14, 24, 12, 27, 14, 18, 27, 14,  1, 14,  4,  6,  1,\n",
       "          30, 18, 18,  9,  6,  1, 22, 18,  9, 22, 24,  8, 24]),\n",
       "   'split0_train_Log_Loss': array([-8.51411286e-09, -6.40302093e-01, -3.77251697e-14, -5.31437245e-01,\n",
       "          -3.77251697e-14, -3.83821447e-01, -5.31437245e-01, -3.77251697e-14,\n",
       "          -1.98699925e-08, -4.67403129e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -3.77251697e-14, -3.77251697e-14, -6.40302093e-01, -3.77251697e-14,\n",
       "          -3.77251697e-14, -2.88087189e-01, -4.67403129e-01, -4.67403129e-01,\n",
       "          -3.77251697e-14, -3.77251697e-14, -3.81061183e-08, -1.41043335e-08,\n",
       "          -4.67403129e-01, -2.58091686e-08, -3.77251697e-14, -3.83821447e-01,\n",
       "          -5.90661241e-01, -3.83821447e-01]),\n",
       "   'split1_train_Log_Loss': array([-8.40621569e-09, -6.22748758e-01, -3.77252183e-14, -5.14850307e-01,\n",
       "          -3.77252183e-14, -3.68457930e-01, -5.14850307e-01, -3.77252183e-14,\n",
       "          -1.94664209e-08, -4.46916926e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -3.77252183e-14, -3.77252183e-14, -6.22748758e-01, -3.77252183e-14,\n",
       "          -3.77252183e-14, -2.74234461e-01, -4.46916926e-01, -4.46916926e-01,\n",
       "          -3.77252183e-14, -3.77252183e-14, -3.79557914e-08, -1.37260094e-08,\n",
       "          -4.46916926e-01, -2.55426955e-08, -3.77252183e-14, -3.68457930e-01,\n",
       "          -5.71076203e-01, -3.68457930e-01]),\n",
       "   'split2_train_Log_Loss': array([-8.65310966e-09, -6.32434997e-01, -3.77251228e-14, -5.22025618e-01,\n",
       "          -3.77251228e-14, -3.79019625e-01, -5.22025618e-01, -3.77251228e-14,\n",
       "          -1.99779445e-08, -4.55558328e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -3.77251228e-14, -3.77251228e-14, -6.32434997e-01, -3.77251228e-14,\n",
       "          -3.77251228e-14, -2.81947025e-01, -4.55558328e-01, -4.55558328e-01,\n",
       "          -3.77251228e-14, -3.77251228e-14, -3.86626216e-08, -1.42388699e-08,\n",
       "          -4.55558328e-01, -2.59899374e-08, -3.77251228e-14, -3.79019625e-01,\n",
       "          -5.81364462e-01, -3.79019625e-01]),\n",
       "   'mean_train_Log_Loss': array([-8.52447940e-09, -6.31828616e-01, -3.77251703e-14, -5.22771056e-01,\n",
       "          -3.77251703e-14, -3.77099667e-01, -5.22771056e-01, -3.77251703e-14,\n",
       "          -1.97714526e-08, -4.56626127e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -3.77251703e-14, -3.77251703e-14, -6.31828616e-01, -3.77251703e-14,\n",
       "          -3.77251703e-14, -2.81422892e-01, -4.56626127e-01, -4.56626127e-01,\n",
       "          -3.77251703e-14, -3.77251703e-14, -3.82415104e-08, -1.40230709e-08,\n",
       "          -4.56626127e-01, -2.57806005e-08, -3.77251703e-14, -3.77099667e-01,\n",
       "          -5.81033969e-01, -3.77099667e-01]),\n",
       "   'std_train_Log_Loss': array([1.01060238e-10, 7.17893519e-03, 3.89952081e-20, 6.79207318e-03,\n",
       "          3.89952081e-20, 6.41737732e-03, 6.79207318e-03, 3.89952081e-20,\n",
       "          2.20146442e-10, 8.39747059e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          3.89952081e-20, 3.89952081e-20, 7.17893519e-03, 3.89952081e-20,\n",
       "          3.89952081e-20, 5.66748392e-03, 8.39747059e-03, 8.39747059e-03,\n",
       "          3.89952081e-20, 3.89952081e-20, 3.04029058e-10, 2.17116197e-10,\n",
       "          8.39747059e-03, 1.83699828e-10, 3.89952081e-20, 6.41737732e-03,\n",
       "          7.99897237e-03, 6.41737732e-03])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "  12,\n",
       "  -3.2787728022852716),\n",
       " 'MLPClassifier_V09_PCA_90': ({'mean_fit_time': array([12.45138574, 23.85656683,  3.16753443, 10.65219418, 20.66243784,\n",
       "           7.2253534 , 20.29807782,  4.73002418,  8.70639475, 14.02019231,\n",
       "           2.90290729,  5.87862047, 22.49154886,  1.17053763, 11.46369227,\n",
       "          26.10223095,  7.97135925, 13.42744342, 19.44834948, 23.65809719,\n",
       "           3.17584531,  6.23001432, 11.35564613, 21.10691611, 29.35586739,\n",
       "           5.28254747, 12.85430781, 23.57033141, 11.7180117 ,  9.36131001]),\n",
       "   'std_fit_time': array([0.14296893, 2.89961777, 0.08476674, 0.25018346, 1.4516949 ,\n",
       "          0.63182262, 0.32675422, 0.9130208 , 0.03997096, 2.09416408,\n",
       "          0.0670041 , 0.61854152, 0.67839866, 0.07536879, 0.61842481,\n",
       "          3.40782329, 0.26402544, 0.56288841, 0.7562298 , 3.96728468,\n",
       "          0.11328789, 0.16111665, 1.72630735, 0.53697269, 2.24214473,\n",
       "          1.14879788, 0.42197319, 1.14129234, 1.84414342, 1.27797772]),\n",
       "   'mean_score_time': array([0.05452116, 0.05917573, 0.04454708, 0.04687436, 0.06216685,\n",
       "          0.05984068, 0.06283196, 0.05784456, 0.06781936, 0.06316439,\n",
       "          0.07214085, 0.04754011, 0.06648866, 0.0382309 , 0.06948042,\n",
       "          0.06549168, 0.0654916 , 0.05252616, 0.05518659, 0.06382934,\n",
       "          0.07612975, 0.04055858, 0.05884314, 0.07712738, 0.08444118,\n",
       "          0.05518532, 0.057513  , 0.06216757, 0.06249976, 0.06515948]),\n",
       "   'std_score_time': array([0.00448505, 0.00124388, 0.00093987, 0.00325679, 0.00653085,\n",
       "          0.00162849, 0.00495445, 0.00081478, 0.00293723, 0.00470095,\n",
       "          0.00047008, 0.00094094, 0.00187986, 0.00046985, 0.00803404,\n",
       "          0.0033911 , 0.00204981, 0.00367111, 0.00308313, 0.00960024,\n",
       "          0.00401886, 0.00047086, 0.00293688, 0.00490855, 0.00339059,\n",
       "          0.00188144, 0.00417867, 0.00855323, 0.00600223, 0.01415887]),\n",
       "   'param_solver': masked_array(data=['lbfgs', 'sgd', 'lbfgs', 'sgd', 'sgd', 'lbfgs', 'sgd',\n",
       "                      'adam', 'lbfgs', 'adam', 'sgd', 'adam', 'adam',\n",
       "                      'lbfgs', 'adam', 'sgd', 'lbfgs', 'lbfgs', 'sgd', 'sgd',\n",
       "                      'sgd', 'lbfgs', 'lbfgs', 'lbfgs', 'adam', 'adam',\n",
       "                      'lbfgs', 'sgd', 'lbfgs', 'lbfgs'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50), (200, 50, 50, 50), (100,), (100,),\n",
       "                      (200, 50, 50), (100, 100, 50), (200, 50, 50),\n",
       "                      (200, 50, 50, 50), (200, 50, 50), (200, 50),\n",
       "                      (200, 50, 50), (100, 100, 50), (100, 100, 50), (100,),\n",
       "                      (200, 50, 50, 50), (200, 50), (100, 100, 50),\n",
       "                      (100, 100, 50), (100, 100, 50), (100, 100, 50),\n",
       "                      (200, 50, 50), (100,), (100, 100), (200, 50, 50),\n",
       "                      (200, 50, 50), (200, 50, 50), (200, 50, 50),\n",
       "                      (100, 100, 50), (100, 100), (100, 100, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0214, 0.0156, 0.0222, 0.0403, 0.008199999999999999,\n",
       "                      0.0248, 0.0095, 0.034600000000000006, 0.02, 0.0268,\n",
       "                      0.0285, 0.0023, 0.0231, 0.009899999999999999, 0.0241,\n",
       "                      0.0345, 0.034600000000000006, 0.025500000000000002,\n",
       "                      0.0148, 0.007500000000000001, 0.04120000000000001,\n",
       "                      0.027800000000000002, 0.0022, 0.0381, 0.0091,\n",
       "                      0.04510000000000001, 0.0132, 0.0252, 0.0495, 0.0286],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['identity', 'identity', 'logistic', 'relu', 'identity',\n",
       "                      'relu', 'identity', 'identity', 'relu', 'relu',\n",
       "                      'logistic', 'identity', 'logistic', 'tanh', 'tanh',\n",
       "                      'relu', 'relu', 'identity', 'tanh', 'tanh', 'logistic',\n",
       "                      'identity', 'identity', 'logistic', 'logistic',\n",
       "                      'identity', 'identity', 'identity', 'logistic', 'relu'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0214,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0156,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0222,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0403,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.008199999999999999,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0248,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0095,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.034600000000000006,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.02,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0268,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0285,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0023,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0231,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.009899999999999999,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.0241,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0345,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.034600000000000006,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.025500000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0148,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.007500000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.04120000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.027800000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0022,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0381,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0091,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.04510000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0132,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0252,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0495,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0286,\n",
       "     'activation': 'relu'}],\n",
       "   'split0_test_Accuracy': array([0.70240229, 0.68339907, 0.7651488 , 0.66260308, 0.68160631,\n",
       "          0.76012908, 0.67120832, 0.69343851, 0.78451058, 0.80674077,\n",
       "          0.05593403, 0.70060954, 0.73574758, 0.73108641, 0.78164217,\n",
       "          0.70813912, 0.78343492, 0.70634636, 0.66511294, 0.67658659,\n",
       "          0.05593403, 0.70921477, 0.70706346, 0.75761922, 0.76263894,\n",
       "          0.69702402, 0.70742202, 0.68196486, 0.79813553, 0.76371459]),\n",
       "   'split1_test_Accuracy': array([0.71536797, 0.68253968, 0.74963925, 0.64105339, 0.68073593,\n",
       "          0.76911977, 0.68145743, 0.69155844, 0.77308802, 0.8008658 ,\n",
       "          0.05591631, 0.69877345, 0.72907648, 0.73593074, 0.77200577,\n",
       "          0.69444444, 0.77092352, 0.71645022, 0.66486291, 0.65656566,\n",
       "          0.05591631, 0.71608947, 0.72186147, 0.76515152, 0.75829726,\n",
       "          0.69588745, 0.70851371, 0.67929293, 0.78463203, 0.75757576]),\n",
       "   'split2_test_Accuracy': array([0.70409272, 0.68091271, 0.7602318 , 0.65085114, 0.68598334,\n",
       "          0.76204274, 0.67946396, 0.69250272, 0.77073524, 0.80731619,\n",
       "          0.05613908, 0.69793553, 0.7222021 , 0.74139804, 0.7747193 ,\n",
       "          0.71024991, 0.76168055, 0.69721116, 0.66533865, 0.65845708,\n",
       "          0.05613908, 0.70988772, 0.70517928, 0.74357117, 0.75190148,\n",
       "          0.69793553, 0.70191959, 0.68344803, 0.79174212, 0.76964868]),\n",
       "   'mean_test_Accuracy': array([0.7072819 , 0.68228791, 0.75835136, 0.65152608, 0.68276857,\n",
       "          0.76375871, 0.67736121, 0.6925018 , 0.77613554, 0.80497477,\n",
       "          0.05599615, 0.69911079, 0.72903148, 0.73612112, 0.77613554,\n",
       "          0.70427782, 0.77204999, 0.70668109, 0.66510454, 0.66390291,\n",
       "          0.05599615, 0.71172795, 0.71136746, 0.75546744, 0.75763038,\n",
       "          0.69694785, 0.70596011, 0.68156693, 0.79151646, 0.76363855]),\n",
       "   'std_test_Accuracy': array([0.00575615, 0.00103069, 0.00647613, 0.00882071, 0.00229297,\n",
       "          0.00386852, 0.00444337, 0.00076843, 0.00602295, 0.0029134 ,\n",
       "          0.00010097, 0.00111757, 0.00553094, 0.00421256, 0.00406308,\n",
       "          0.00700273, 0.00891828, 0.00784727, 0.00019404, 0.00903807,\n",
       "          0.00010097, 0.00309461, 0.00745617, 0.00892985, 0.00440954,\n",
       "          0.00083674, 0.00288179, 0.00171741, 0.0055215 , 0.00492237]),\n",
       "   'rank_test_Accuracy': array([15, 23,  8, 28, 22,  6, 25, 21,  3,  1, 29, 19, 12, 11,  3, 18,  5,\n",
       "          16, 26, 27, 29, 13, 14, 10,  9, 20, 17, 24,  2,  7]),\n",
       "   'split0_train_Accuracy': array([0.84348455, 0.76070848, 1.        , 0.72600759, 0.75582866,\n",
       "          1.        , 0.7554672 , 0.76251581, 1.        , 0.99927706,\n",
       "          0.05602747, 0.78890295, 0.947045  , 1.        , 0.99367432,\n",
       "          0.80571119, 1.        , 0.8378818 , 0.73522501, 0.74046629,\n",
       "          0.05602747, 0.84691849, 0.84438822, 1.        , 0.98807157,\n",
       "          0.78420387, 0.8378818 , 0.75582866, 1.        , 1.        ]),\n",
       "   'split1_train_Accuracy': array([0.84504505, 0.7645045 , 1.        , 0.7227027 , 0.75873874,\n",
       "          1.        , 0.75747748, 0.77063063, 1.        , 1.        ,\n",
       "          0.05603604, 0.7972973 , 0.95315315, 1.        , 0.99477477,\n",
       "          0.80018018, 1.        , 0.84126126, 0.75027027, 0.73423423,\n",
       "          0.05603604, 0.84648649, 0.84720721, 1.        , 0.98720721,\n",
       "          0.79009009, 0.84144144, 0.75495495, 1.        , 1.        ]),\n",
       "   'split2_train_Accuracy': array([0.8464305 , 0.76299227, 1.        , 0.7246898 , 0.75849667,\n",
       "          1.        , 0.76263262, 0.76964575, 1.        , 1.        ,\n",
       "          0.05592519, 0.79410178, 0.93472397, 1.        , 0.99640352,\n",
       "          0.8101061 , 1.        , 0.84013667, 0.73943535, 0.73386082,\n",
       "          0.05592519, 0.84589103, 0.84661032, 1.        , 0.98921057,\n",
       "          0.77288258, 0.83869808, 0.75579932, 1.        , 1.        ]),\n",
       "   'mean_train_Accuracy': array([0.8449867 , 0.76273508, 1.        , 0.7244667 , 0.75768803,\n",
       "          1.        , 0.75852576, 0.7675974 , 1.        , 0.99975902,\n",
       "          0.05599623, 0.79343401, 0.94497404, 1.        , 0.99495087,\n",
       "          0.80533249, 1.        , 0.83975991, 0.74164355, 0.73618711,\n",
       "          0.05599623, 0.846432  , 0.84606858, 1.        , 0.98816312,\n",
       "          0.78239218, 0.83934044, 0.75552765, 1.        , 1.        ]),\n",
       "   'std_train_Accuracy': array([1.20338688e-03, 1.56035580e-03, 0.00000000e+00, 1.35840671e-03,\n",
       "          1.31847555e-03, 0.00000000e+00, 3.01772565e-03, 3.61564786e-03,\n",
       "          0.00000000e+00, 3.40794882e-04, 5.03546264e-05, 3.45935674e-03,\n",
       "          7.66487015e-03, 0.00000000e+00, 1.12113045e-03, 4.06107632e-03,\n",
       "          0.00000000e+00, 1.40514501e-03, 6.33756118e-03, 3.02967403e-03,\n",
       "          5.03546264e-05, 4.21225355e-04, 1.21292743e-03, 0.00000000e+00,\n",
       "          8.20428686e-04, 7.14078936e-03, 1.52254929e-03, 4.05130452e-04,\n",
       "          0.00000000e+00, 0.00000000e+00]),\n",
       "   'split0_test_F1': array([0.69573624, 0.67663936, 0.76520626, 0.65138912, 0.67668619,\n",
       "          0.75995983, 0.66524554, 0.68757444, 0.78312049, 0.80552424,\n",
       "          0.00592578, 0.69457166, 0.73137257, 0.73105638, 0.77913109,\n",
       "          0.70392532, 0.78346331, 0.70100418, 0.65318271, 0.66667623,\n",
       "          0.00592578, 0.70284752, 0.70127515, 0.75486709, 0.76085291,\n",
       "          0.69045821, 0.70256689, 0.67524625, 0.79659658, 0.76241773]),\n",
       "   'split1_test_F1': array([0.7127875 , 0.67857219, 0.75029356, 0.63180259, 0.67715627,\n",
       "          0.76867445, 0.67819258, 0.68473626, 0.77319271, 0.79955638,\n",
       "          0.00592212, 0.69421737, 0.72879471, 0.73467531, 0.77204008,\n",
       "          0.69000557, 0.77039197, 0.71363747, 0.65506546, 0.64706179,\n",
       "          0.00592212, 0.71329527, 0.71977204, 0.76363655, 0.75720934,\n",
       "          0.69531181, 0.70568543, 0.67519469, 0.78369145, 0.75854558]),\n",
       "   'split2_test_F1': array([0.70133103, 0.67561149, 0.75960314, 0.64079703, 0.68058701,\n",
       "          0.76232734, 0.67450475, 0.69055497, 0.77073818, 0.80693047,\n",
       "          0.00596815, 0.6929788 , 0.71980909, 0.73987359, 0.77415869,\n",
       "          0.70555131, 0.76300933, 0.69340111, 0.65587006, 0.64801525,\n",
       "          0.00596815, 0.70601382, 0.70185077, 0.74191011, 0.75129224,\n",
       "          0.69348803, 0.69912831, 0.67886373, 0.79104447, 0.76952473]),\n",
       "   'mean_test_F1': array([0.70327208, 0.67694215, 0.75837999, 0.64135083, 0.67813695,\n",
       "          0.76364808, 0.67263005, 0.68761791, 0.77570552, 0.80400293,\n",
       "          0.00593862, 0.69392518, 0.72667747, 0.73518712, 0.77511942,\n",
       "          0.69982821, 0.7723233 , 0.70268976, 0.65470142, 0.65395162,\n",
       "          0.00593862, 0.70737808, 0.70762731, 0.75348938, 0.75646731,\n",
       "          0.69308012, 0.70246483, 0.67642925, 0.79045594, 0.76348584]),\n",
       "   'std_test_F1': array([7.10220632e-03, 1.22605498e-03, 6.15581735e-03, 8.01499581e-03,\n",
       "          1.73702496e-03, 3.68144497e-03, 5.45415000e-03, 2.37245912e-03,\n",
       "          5.35871886e-03, 3.19451592e-03, 2.08604460e-05, 6.82384207e-04,\n",
       "          4.95298409e-03, 3.61833915e-03, 2.97627839e-03, 6.97357384e-03,\n",
       "          8.46249781e-03, 8.33660869e-03, 1.12704756e-03, 9.04252792e-03,\n",
       "          2.08604460e-05, 4.37711397e-03, 8.58619611e-03, 8.91160588e-03,\n",
       "          3.93884667e-03, 2.00449997e-03, 2.67428652e-03, 1.71551933e-03,\n",
       "          5.29091876e-03, 4.53992827e-03]),\n",
       "   'rank_test_F1': array([15, 23,  8, 28, 22,  6, 25, 21,  3,  1, 29, 19, 12, 11,  4, 18,  5,\n",
       "          16, 26, 27, 29, 14, 13, 10,  9, 20, 17, 24,  2,  7]),\n",
       "   'split0_train_F1': array([0.84229341, 0.75680121, 1.        , 0.71956444, 0.75208877,\n",
       "          1.        , 0.75158874, 0.75877335, 1.        , 0.99927692,\n",
       "          0.00594507, 0.78576788, 0.9462144 , 1.        , 0.99366217,\n",
       "          0.80263924, 1.        , 0.83674675, 0.72647091, 0.73220195,\n",
       "          0.00594507, 0.84590708, 0.84311177, 1.        , 0.9880641 ,\n",
       "          0.7798406 , 0.83634548, 0.75133131, 1.        , 1.        ]),\n",
       "   'split1_train_F1': array([0.84363578, 0.76006433, 1.        , 0.71447807, 0.75380862,\n",
       "          1.        , 0.75226406, 0.76460431, 1.        , 1.        ,\n",
       "          0.00594684, 0.79443042, 0.95279396, 1.        , 0.99482876,\n",
       "          0.7949369 , 1.        , 0.83992599, 0.74215961, 0.72395295,\n",
       "          0.00594684, 0.84568463, 0.84609291, 1.        , 0.9871717 ,\n",
       "          0.78867625, 0.84043531, 0.75035897, 1.        , 1.        ]),\n",
       "   'split2_train_F1': array([0.84481012, 0.75798091, 1.        , 0.71788067, 0.75362135,\n",
       "          1.        , 0.75779992, 0.76793374, 1.        , 1.        ,\n",
       "          0.00592396, 0.79016036, 0.93471815, 1.        , 0.99637235,\n",
       "          0.80691605, 1.        , 0.83801618, 0.73200344, 0.72540001,\n",
       "          0.00592396, 0.84427656, 0.84499858, 1.        , 0.98920462,\n",
       "          0.76844674, 0.83693531, 0.75055213, 1.        , 1.        ]),\n",
       "   'mean_train_F1': array([0.84357977, 0.75828215, 1.        , 0.71730773, 0.75317291,\n",
       "          1.        , 0.75388424, 0.76377047, 1.        , 0.99975897,\n",
       "          0.00593862, 0.79011955, 0.9445755 , 1.        , 0.99495443,\n",
       "          0.8014974 , 1.        , 0.83822964, 0.73354465, 0.72718497,\n",
       "          0.00593862, 0.84528942, 0.84473442, 1.        , 0.98814681,\n",
       "          0.77898787, 0.83790537, 0.75074747, 1.        , 1.        ]),\n",
       "   'std_train_F1': array([1.02820411e-03, 1.34908690e-03, 0.00000000e+00, 2.11565709e-03,\n",
       "          7.70409090e-04, 0.00000000e+00, 2.78249644e-03, 3.78591027e-03,\n",
       "          0.00000000e+00, 3.40865109e-04, 1.03944448e-05, 3.53658357e-03,\n",
       "          7.46985896e-03, 0.00000000e+00, 1.10998897e-03, 4.95667291e-03,\n",
       "          0.00000000e+00, 1.30666716e-03, 6.49693902e-03, 3.59639321e-03,\n",
       "          1.03944448e-05, 7.21939077e-04, 1.23129906e-03, 0.00000000e+00,\n",
       "          8.31992231e-04, 8.28064435e-03, 1.80507368e-03, 4.20303731e-04,\n",
       "          0.00000000e+00, 0.00000000e+00]),\n",
       "   'split0_test_Log_Loss': array([-1.73677412, -1.24468344, -1.43270171, -1.27617685, -1.26643192,\n",
       "          -3.40007306, -1.25579618, -1.21654016, -2.92782871, -1.15808073,\n",
       "          -3.61210932, -1.2497712 , -1.06368713, -2.05597963, -1.02159533,\n",
       "          -1.07332131, -2.90111827, -1.68915087, -1.22668307, -1.19048094,\n",
       "          -3.6120768 , -1.76407405, -1.77134263, -1.57170397, -1.03369979,\n",
       "          -1.25003233, -1.64339645, -1.23742776, -1.0575548 , -3.12303622]),\n",
       "   'split1_test_Log_Loss': array([-1.60815692, -1.26881246, -1.52639222, -1.3119853 , -1.23304117,\n",
       "          -2.91146939, -1.22457795, -1.23302883, -3.05707554, -1.1471885 ,\n",
       "          -3.61213358, -1.20906964, -1.02523686, -2.3065972 , -1.015036  ,\n",
       "          -1.13560251, -3.02383275, -1.5478295 , -1.20168708, -1.24727751,\n",
       "          -3.61184838, -1.65727579, -1.63854452, -1.52029569, -1.02600882,\n",
       "          -1.22454365, -1.57641775, -1.24159111, -1.11021714, -3.01417515]),\n",
       "   'split2_test_Log_Loss': array([-1.71748575, -1.2150049 , -1.61489401, -1.25697769, -1.20043982,\n",
       "          -3.2550811 , -1.20781221, -1.20938928, -3.18991413, -1.07794636,\n",
       "          -3.61143855, -1.20123556, -1.07654638, -2.18623861, -0.98390045,\n",
       "          -1.0868294 , -3.09254956, -1.65244459, -1.21763055, -1.24930232,\n",
       "          -3.61166269, -1.71060362, -1.68074722, -1.72528394, -1.05771403,\n",
       "          -1.18032002, -1.6380203 , -1.20073481, -1.06916789, -3.3034361 ]),\n",
       "   'mean_test_Log_Loss': array([-1.6875333 , -1.24287416, -1.52435552, -1.28173466, -1.23341541,\n",
       "          -3.18921844, -1.22947791, -1.21965997, -3.05783232, -1.12786633,\n",
       "          -3.61189486, -1.22011107, -1.05514594, -2.18267477, -1.00690439,\n",
       "          -1.09854833, -3.005505  , -1.62989962, -1.21535372, -1.22891472,\n",
       "          -3.61186332, -1.71076035, -1.69705156, -1.60553365, -1.03910521,\n",
       "          -1.21841369, -1.61930266, -1.22664088, -1.07894915, -3.14662684]),\n",
       "   'std_test_Log_Loss': array([5.66473883e-02, 2.19746635e-02, 7.44060747e-02, 2.27708377e-02,\n",
       "          2.69469734e-02, 2.05025657e-01, 1.98963311e-02, 9.88898354e-03,\n",
       "          1.07015184e-01, 3.54553657e-02, 3.21680759e-04, 2.12988308e-02,\n",
       "          2.17798593e-02, 1.02464295e-01, 1.64293191e-02, 2.67616394e-02,\n",
       "          7.92305138e-02, 5.99061410e-02, 1.03416674e-02, 2.72995599e-02,\n",
       "          1.69417060e-04, 4.36511935e-02, 5.54803212e-02, 8.69556131e-02,\n",
       "          1.34837391e-02, 2.87924818e-02, 3.03872081e-02, 1.83331545e-02,\n",
       "          2.26008869e-02, 1.19113724e-01]),\n",
       "   'rank_test_Log_Loss': array([21, 15, 17, 16, 14, 28, 13,  9, 26,  6, 30, 10,  3, 24,  1,  5, 25,\n",
       "          20,  7, 12, 29, 23, 22, 18,  2,  8, 19, 11,  4, 27]),\n",
       "   'split0_train_Log_Loss': array([-5.07027865e-01, -7.97995828e-01, -6.07729962e-03, -1.02813043e+00,\n",
       "          -8.11961741e-01, -1.86101148e-04, -8.17797086e-01, -7.76087711e-01,\n",
       "          -1.73989942e-04, -1.28673507e-02, -3.61192223e+00, -6.89445660e-01,\n",
       "          -2.69590134e-01, -2.03881527e-03, -3.49509819e-02, -7.14806611e-01,\n",
       "          -2.23223909e-04, -5.21038119e-01, -1.01638163e+00, -9.92676390e-01,\n",
       "          -3.61192447e+00, -4.94835174e-01, -5.03939916e-01, -5.68673980e-03,\n",
       "          -1.26280425e-01, -6.95510025e-01, -5.29285650e-01, -8.14980373e-01,\n",
       "          -6.80393191e-03, -1.80769698e-04]),\n",
       "   'split1_train_Log_Loss': array([-5.04938970e-01, -7.77222453e-01, -7.79828638e-03, -1.00984902e+00,\n",
       "          -7.95415839e-01, -1.87465632e-04, -8.01057006e-01, -7.50841199e-01,\n",
       "          -2.20884475e-04, -8.92677050e-03, -3.61195305e+00, -6.59824603e-01,\n",
       "          -2.50883176e-01, -2.05992457e-03, -3.43436109e-02, -7.21432694e-01,\n",
       "          -1.97279860e-04, -5.25470901e-01, -9.71686510e-01, -1.00506265e+00,\n",
       "          -3.61171498e+00, -4.91126561e-01, -5.02227638e-01, -3.85306852e-03,\n",
       "          -1.14476499e-01, -6.74621615e-01, -5.22418015e-01, -8.08661634e-01,\n",
       "          -6.93869131e-03, -2.25781716e-04]),\n",
       "   'split2_train_Log_Loss': array([-4.96519692e-01, -7.89198834e-01, -4.63098770e-03, -1.01635605e+00,\n",
       "          -8.09030890e-01, -2.12134588e-04, -8.01161684e-01, -7.48328341e-01,\n",
       "          -1.81781965e-04, -1.50562914e-02, -3.61176268e+00, -6.62450775e-01,\n",
       "          -3.23253919e-01, -2.90640936e-03, -3.16353834e-02, -7.18189831e-01,\n",
       "          -2.12429905e-04, -5.14308485e-01, -1.00418751e+00, -1.02217513e+00,\n",
       "          -3.61198437e+00, -4.85965996e-01, -4.96997268e-01, -4.54703983e-03,\n",
       "          -1.24623453e-01, -7.38615269e-01, -5.13888111e-01, -8.11469156e-01,\n",
       "          -7.04659675e-03, -1.85876336e-04]),\n",
       "   'mean_train_Log_Loss': array([-5.02828843e-01, -7.88139038e-01, -6.16885790e-03, -1.01811183e+00,\n",
       "          -8.05469490e-01, -1.95233790e-04, -8.06671925e-01, -7.58419084e-01,\n",
       "          -1.92218794e-04, -1.22834709e-02, -3.61187932e+00, -6.70573680e-01,\n",
       "          -2.81242409e-01, -2.33504973e-03, -3.36433254e-02, -7.18143046e-01,\n",
       "          -2.10977891e-04, -5.20272502e-01, -9.97418548e-01, -1.00663806e+00,\n",
       "          -3.61187461e+00, -4.90642577e-01, -5.01054941e-01, -4.69561605e-03,\n",
       "          -1.21793459e-01, -7.02915637e-01, -5.21863925e-01, -8.11703721e-01,\n",
       "          -6.92973999e-03, -1.97475917e-04]),\n",
       "   'std_train_Log_Loss': array([4.54201870e-03, 8.51373972e-03, 1.29466403e-03, 7.56591162e-03,\n",
       "          7.20899422e-03, 1.19636449e-05, 7.86679242e-03, 1.25356531e-02,\n",
       "          2.05177950e-05, 2.53619707e-03, 8.34320561e-05, 1.33875051e-02,\n",
       "          3.06726018e-02, 4.04104167e-04, 1.44131843e-03, 2.70528927e-03,\n",
       "          1.06412616e-05, 4.58908202e-03, 1.88640307e-02, 1.20942244e-02,\n",
       "          1.15492030e-04, 3.63696403e-03, 2.95313442e-03, 7.55929345e-04,\n",
       "          5.21790623e-03, 2.66449400e-02, 6.29821746e-03, 2.58494085e-03,\n",
       "          9.92694970e-05, 2.01235045e-05])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "   'alpha': 0.0241,\n",
       "   'activation': 'tanh'},\n",
       "  14,\n",
       "  -1.0069043859644276),\n",
       " 'LogisticRegression_V09_PCA_80': ({'mean_fit_time': array([0.58676513, 2.94479664, 2.72172451, 1.31481965, 2.47903999,\n",
       "          2.12432202, 0.56781642, 2.41986513, 0.52426521, 3.30915523,\n",
       "          0.48669847, 1.9328351 , 0.79520901, 2.23901518, 3.12730622,\n",
       "          2.00829816, 1.48104032, 0.44780238, 1.0644877 , 0.29388165,\n",
       "          1.35039131, 2.26693964, 2.71008937, 2.13363115, 1.40491287,\n",
       "          3.01560513, 1.30783701, 2.59606139, 1.08510025, 2.02558533]),\n",
       "   'std_fit_time': array([0.02671535, 0.03277845, 0.1946569 , 0.05528026, 0.16677733,\n",
       "          0.05234561, 0.01141062, 0.04751361, 0.00600201, 0.01797075,\n",
       "          0.00666566, 0.22156134, 0.00711425, 0.05604604, 0.14440355,\n",
       "          0.04247945, 0.04792093, 0.00354937, 0.00470157, 0.0026177 ,\n",
       "          0.04931081, 0.07118206, 0.39276047, 0.16295462, 0.08357618,\n",
       "          0.03001268, 0.14331604, 0.1502169 , 0.04213253, 0.19071993]),\n",
       "   'mean_score_time': array([0.05950769, 0.0299201 , 0.03025285, 0.02992018, 0.05784559,\n",
       "          0.0285898 , 0.0299197 , 0.02958798, 0.0315818 , 0.03058497,\n",
       "          0.0299201 , 0.03490623, 0.03191392, 0.03058473, 0.02958814,\n",
       "          0.02859036, 0.06219165, 0.03956103, 0.03191495, 0.02991939,\n",
       "          0.07014616, 0.04521283, 0.03124952, 0.0325799 , 0.03490607,\n",
       "          0.11269935, 0.03257934, 0.03191463, 0.03025206, 0.02925515]),\n",
       "   'std_score_time': array([0.00692588, 0.00081361, 0.00124339, 0.00081478, 0.03467334,\n",
       "          0.00047058, 0.0021542 , 0.00124356, 0.00204958, 0.0004703 ,\n",
       "          0.00141074, 0.00244376, 0.00081381, 0.0004698 , 0.00169467,\n",
       "          0.00124373, 0.04282563, 0.00870711, 0.00282114, 0.00162801,\n",
       "          0.02360527, 0.02092611, 0.00204924, 0.0032908 , 0.00354894,\n",
       "          0.01447732, 0.00384797, 0.000814  , 0.00169523, 0.00286039]),\n",
       "   'param_C': masked_array(data=[0.21600175733446836, 0.19671453471139363,\n",
       "                      0.014187494679743846, 0.0716900390273121,\n",
       "                      0.062116924736743184, 0.108709310907923,\n",
       "                      0.011183173856945436, 0.35081818575135704,\n",
       "                      0.08209345370897159, 0.06556185872643762,\n",
       "                      0.121222856162103, 0.002326880580267678,\n",
       "                      0.02624042098258656, 0.46523304100727886,\n",
       "                      0.09695993500721309, 0.09222552085373566,\n",
       "                      0.09730405649570312, 0.028481769506059386,\n",
       "                      0.2694909955578236, 0.012643150008975274,\n",
       "                      0.02193158418872893, 0.2322083394192065,\n",
       "                      0.018940320874262465, 0.1518715973828217,\n",
       "                      0.10302865518447935, 0.9132776793801721,\n",
       "                      0.18500756301984544, 0.15066095171244542,\n",
       "                      0.03469320235035551, 0.20286855255256042],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=[None, None, 'balanced', None, 'balanced', None,\n",
       "                      'balanced', None, 'balanced', 'balanced', 'balanced',\n",
       "                      None, None, 'balanced', 'balanced', None, None,\n",
       "                      'balanced', None, 'balanced', None, 'balanced',\n",
       "                      'balanced', None, None, 'balanced', None, 'balanced',\n",
       "                      'balanced', None],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['saga', 'newton-cg', 'newton-cg', 'liblinear',\n",
       "                      'newton-cg', 'saga', 'liblinear', 'newton-cg', 'saga',\n",
       "                      'newton-cg', 'saga', 'newton-cg', 'liblinear',\n",
       "                      'liblinear', 'newton-cg', 'newton-cg', 'saga', 'saga',\n",
       "                      'saga', 'saga', 'liblinear', 'liblinear', 'newton-cg',\n",
       "                      'newton-cg', 'liblinear', 'liblinear', 'saga',\n",
       "                      'newton-cg', 'liblinear', 'newton-cg'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.27453737569930625, 0.07796833210240114,\n",
       "                      0.19668957655475333, 0.058777346818081916,\n",
       "                      0.3141718841587189, 0.04740149054503766,\n",
       "                      0.12019616749170565, 0.27391199189187976,\n",
       "                      0.2053317352200022, 0.009888786748804775,\n",
       "                      0.2646154090856518, 0.025946826797780834,\n",
       "                      0.3830856561604625, 0.11510155959031754,\n",
       "                      0.08365501861792211, 0.20342207097164244,\n",
       "                      0.0669486392009274, 0.32749270159435095,\n",
       "                      0.09794594582430773, 1.0110877472761677,\n",
       "                      0.0293968207303368, 0.033411657667952004,\n",
       "                      0.11443915360940099, 0.38426661969172515,\n",
       "                      0.10261055598156532, 0.07119464408689996,\n",
       "                      0.09153018428644553, 0.4880365568363571,\n",
       "                      0.08557813952769945, 0.06317660851102529],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.21600175733446836,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.27453737569930625},\n",
       "    {'C': 0.19671453471139363,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.07796833210240114},\n",
       "    {'C': 0.014187494679743846,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.19668957655475333},\n",
       "    {'C': 0.0716900390273121,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.058777346818081916},\n",
       "    {'C': 0.062116924736743184,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3141718841587189},\n",
       "    {'C': 0.108709310907923,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.04740149054503766},\n",
       "    {'C': 0.011183173856945436,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.12019616749170565},\n",
       "    {'C': 0.35081818575135704,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.27391199189187976},\n",
       "    {'C': 0.08209345370897159,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.2053317352200022},\n",
       "    {'C': 0.06556185872643762,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.009888786748804775},\n",
       "    {'C': 0.121222856162103,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.2646154090856518},\n",
       "    {'C': 0.002326880580267678,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.025946826797780834},\n",
       "    {'C': 0.02624042098258656,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.3830856561604625},\n",
       "    {'C': 0.46523304100727886,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.11510155959031754},\n",
       "    {'C': 0.09695993500721309,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.08365501861792211},\n",
       "    {'C': 0.09222552085373566,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.20342207097164244},\n",
       "    {'C': 0.09730405649570312,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0669486392009274},\n",
       "    {'C': 0.028481769506059386,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.32749270159435095},\n",
       "    {'C': 0.2694909955578236,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.09794594582430773},\n",
       "    {'C': 0.012643150008975274,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 1.0110877472761677},\n",
       "    {'C': 0.02193158418872893,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.0293968207303368},\n",
       "    {'C': 0.2322083394192065,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.033411657667952004},\n",
       "    {'C': 0.018940320874262465,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.11443915360940099},\n",
       "    {'C': 0.1518715973828217,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.38426661969172515},\n",
       "    {'C': 0.10302865518447935,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.10261055598156532},\n",
       "    {'C': 0.9132776793801721,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.07119464408689996},\n",
       "    {'C': 0.18500756301984544,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.09153018428644553},\n",
       "    {'C': 0.15066095171244542,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.4880365568363571},\n",
       "    {'C': 0.03469320235035551,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.08557813952769945},\n",
       "    {'C': 0.20286855255256042,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.06317660851102529}],\n",
       "   'split0_test_Accuracy': array([0.40946576, 0.58802438, 0.5428469 , 0.53209035, 0.56149157,\n",
       "          0.44998207, 0.46647544, 0.59591251, 0.49049839, 0.56185013,\n",
       "          0.49121549, 0.43241305, 0.50161348, 0.58192901, 0.57188957,\n",
       "          0.57224812, 0.43671567, 0.48762997, 0.42129796, 0.46396558,\n",
       "          0.49802797, 0.5679455 , 0.54750807, 0.58300466, 0.5421298 ,\n",
       "          0.592327  , 0.42954464, 0.57941915, 0.51667264, 0.58838293]),\n",
       "   'split1_test_Accuracy': array([0.40367965, 0.57287157, 0.53138528, 0.52561328, 0.56060606,\n",
       "          0.4541847 , 0.4520202 , 0.58297258, 0.47655123, 0.56204906,\n",
       "          0.47727273, 0.42532468, 0.48520924, 0.57323232, 0.56926407,\n",
       "          0.56313131, 0.44660895, 0.47222222, 0.43470418, 0.4520202 ,\n",
       "          0.48160173, 0.55952381, 0.53751804, 0.57070707, 0.53607504,\n",
       "          0.58297258, 0.43686869, 0.57070707, 0.498557  , 0.57359307]),\n",
       "   'split2_test_Accuracy': array([0.40420138, 0.5758783 , 0.52589641, 0.5175661 , 0.55378486,\n",
       "          0.43933357, 0.44621514, 0.58674393, 0.47048171, 0.55414705,\n",
       "          0.45780514, 0.41035857, 0.47736327, 0.57334299, 0.56066643,\n",
       "          0.55632017, 0.4299167 , 0.4708439 , 0.41941326, 0.4444042 ,\n",
       "          0.47519015, 0.55197392, 0.53132923, 0.56863455, 0.52988048,\n",
       "          0.58529518, 0.42122419, 0.56754799, 0.48967765, 0.57624049]),\n",
       "   'mean_test_Accuracy': array([0.40579188, 0.57894737, 0.53340543, 0.52511416, 0.55863975,\n",
       "          0.44784907, 0.45493872, 0.58856044, 0.47921173, 0.55936073,\n",
       "          0.47548666, 0.42273492, 0.48810382, 0.57618361, 0.56729152,\n",
       "          0.56392694, 0.43775535, 0.47692862, 0.42513819, 0.45349676,\n",
       "          0.48497957, 0.55984138, 0.53881279, 0.57414083, 0.53604903,\n",
       "          0.58687815, 0.42922374, 0.57257871, 0.50168229, 0.57942802]),\n",
       "   'std_test_Accuracy': array([0.00261703, 0.00656001, 0.00706688, 0.00594098, 0.00343996,\n",
       "          0.00624125, 0.00852587, 0.00544154, 0.00838663, 0.00367458,\n",
       "          0.01370027, 0.00918932, 0.01011087, 0.00407935, 0.00478994,\n",
       "          0.00652791, 0.00684527, 0.00761846, 0.00680418, 0.00805511,\n",
       "          0.00962577, 0.00652532, 0.00666916, 0.00634958, 0.00500163,\n",
       "          0.00398275, 0.00638225, 0.00502443, 0.01124162, 0.00644874]),\n",
       "   'rank_test_Accuracy': array([30,  4, 15, 16, 12, 25, 23,  1, 20, 11, 22, 29, 18,  5,  8,  9, 26,\n",
       "          21, 28, 24, 19, 10, 13,  6, 14,  2, 27,  7, 17,  3]),\n",
       "   'split0_train_Accuracy': array([0.4178565 , 0.60437376, 0.55358757, 0.54545455, 0.58087837,\n",
       "          0.45996747, 0.47063076, 0.61630219, 0.50316284, 0.5821435 ,\n",
       "          0.49430689, 0.4328574 , 0.50352431, 0.60292789, 0.58937285,\n",
       "          0.58684258, 0.44912344, 0.49683716, 0.4333996 , 0.46611242,\n",
       "          0.50009037, 0.58883065, 0.56045545, 0.5966022 , 0.55684077,\n",
       "          0.62154347, 0.44099042, 0.59949395, 0.52105549, 0.60491596]),\n",
       "   'split1_train_Accuracy': array([0.41675676, 0.61369369, 0.55117117, 0.55207207, 0.57945946,\n",
       "          0.47783784, 0.48072072, 0.62594595, 0.48432432, 0.58144144,\n",
       "          0.49297297, 0.44396396, 0.51171171, 0.60756757, 0.58486486,\n",
       "          0.59081081, 0.46612613, 0.48846847, 0.45369369, 0.47567568,\n",
       "          0.50792793, 0.59387387, 0.5563964 , 0.60522523, 0.56198198,\n",
       "          0.6227027 , 0.4563964 , 0.59189189, 0.52756757, 0.61423423]),\n",
       "   'split2_train_Accuracy': array([0.41970869, 0.60222981, 0.55044057, 0.54522568, 0.57453695,\n",
       "          0.46196727, 0.46916022, 0.61373854, 0.49577414, 0.5756159 ,\n",
       "          0.48642331, 0.43283582, 0.50458551, 0.59629563, 0.58065096,\n",
       "          0.58442726, 0.44758137, 0.48570401, 0.43517353, 0.46556375,\n",
       "          0.50134868, 0.58065096, 0.55637475, 0.59557634, 0.55655458,\n",
       "          0.60852365, 0.432656  , 0.58568603, 0.51393634, 0.60258946]),\n",
       "   'mean_train_Accuracy': array([0.41810731, 0.60676576, 0.5517331 , 0.5475841 , 0.57829159,\n",
       "          0.46659086, 0.4735039 , 0.61866222, 0.49442044, 0.57973361,\n",
       "          0.49123439, 0.4365524 , 0.50660718, 0.6022637 , 0.58496289,\n",
       "          0.58736022, 0.45427698, 0.49033655, 0.44075561, 0.46911728,\n",
       "          0.50312232, 0.58778516, 0.5577422 , 0.59913459, 0.55845911,\n",
       "          0.61758994, 0.4433476 , 0.59235729, 0.52085313, 0.60724655]),\n",
       "   'std_train_Accuracy': array([0.0012181 , 0.00497637, 0.0013448 , 0.00317485, 0.00271739,\n",
       "          0.00799461, 0.00513825, 0.00525563, 0.00775013, 0.00292574,\n",
       "          0.00344526, 0.00524078, 0.00363536, 0.00462565, 0.00356137,\n",
       "          0.00263165, 0.00840223, 0.00473315, 0.00917723, 0.00464289,\n",
       "          0.00343669, 0.00544862, 0.00191858, 0.00432705, 0.00249378,\n",
       "          0.00642828, 0.00983426, 0.00564666, 0.00556676, 0.0050315 ]),\n",
       "   'split0_test_F1': array([0.35933786, 0.5656934 , 0.53545184, 0.49893328, 0.55372936,\n",
       "          0.39672046, 0.4297341 , 0.57490516, 0.4756143 , 0.55418267,\n",
       "          0.47056272, 0.38642253, 0.46162683, 0.56285966, 0.56428524,\n",
       "          0.54886714, 0.37886333, 0.46792577, 0.35744898, 0.44121903,\n",
       "          0.45721909, 0.54839448, 0.53966837, 0.56026457, 0.51102683,\n",
       "          0.57492851, 0.36701665, 0.57199923, 0.48803171, 0.56633534]),\n",
       "   'split1_test_F1': array([0.33446654, 0.54856831, 0.52752562, 0.48774135, 0.55813979,\n",
       "          0.39887817, 0.4096617 , 0.56041124, 0.4612675 , 0.5595749 ,\n",
       "          0.45903225, 0.37825308, 0.43798201, 0.55580149, 0.56655074,\n",
       "          0.53704586, 0.38785296, 0.4555069 , 0.37419026, 0.42886464,\n",
       "          0.43296576, 0.54030078, 0.5335721 , 0.5456945 , 0.50197573,\n",
       "          0.56798934, 0.37508162, 0.56748501, 0.46651042, 0.54927354]),\n",
       "   'split2_test_F1': array([0.35784415, 0.55355393, 0.52072741, 0.48294794, 0.54764974,\n",
       "          0.38952313, 0.40716526, 0.56515753, 0.45310732, 0.54802819,\n",
       "          0.44225758, 0.37344237, 0.43622157, 0.55644736, 0.55445871,\n",
       "          0.53005053, 0.37685003, 0.45181241, 0.36238028, 0.42183043,\n",
       "          0.43333791, 0.53176747, 0.52572808, 0.54553619, 0.49677477,\n",
       "          0.5706305 , 0.36431015, 0.56217351, 0.46021803, 0.55389824]),\n",
       "   'mean_test_F1': array([0.35055783, 0.55596162, 0.52792653, 0.48990185, 0.5531814 ,\n",
       "          0.39505131, 0.41556043, 0.56684335, 0.46336831, 0.5539369 ,\n",
       "          0.45733117, 0.3793949 , 0.44532217, 0.55838122, 0.5617797 ,\n",
       "          0.53868674, 0.38118976, 0.45844318, 0.36466144, 0.43067129,\n",
       "          0.44121738, 0.54018216, 0.53301276, 0.55052493, 0.50328355,\n",
       "          0.57119117, 0.36880509, 0.56723568, 0.47163534, 0.5565259 ]),\n",
       "   'std_test_F1': array([0.01138845, 0.00720211, 0.0060189 , 0.0067033 , 0.0042944 ,\n",
       "          0.00399387, 0.01011431, 0.00604194, 0.00930913, 0.00471077,\n",
       "          0.01161982, 0.0053611 , 0.01159815, 0.00319048, 0.00524098,\n",
       "          0.00777016, 0.00478026, 0.00689885, 0.00702883, 0.00801899,\n",
       "          0.01136184, 0.00678961, 0.00570576, 0.00691522, 0.0058923 ,\n",
       "          0.00286359, 0.00457136, 0.00401587, 0.01192036, 0.00721518]),\n",
       "   'rank_test_F1': array([30,  7, 14, 16,  9, 25, 24,  3, 18,  8, 20, 27, 21,  5,  4, 12, 26,\n",
       "          19, 29, 23, 22, 11, 13, 10, 15,  1, 28,  2, 17,  6]),\n",
       "   'split0_train_F1': array([0.36492736, 0.58404737, 0.54731928, 0.51331673, 0.5743401 ,\n",
       "          0.40879592, 0.43450161, 0.59725413, 0.49016737, 0.57562084,\n",
       "          0.47464719, 0.38975861, 0.46369007, 0.58612282, 0.58297575,\n",
       "          0.56377989, 0.39292449, 0.478708  , 0.37052315, 0.44444558,\n",
       "          0.45870547, 0.5702309 , 0.55400039, 0.5751712 , 0.52692417,\n",
       "          0.60695495, 0.3798407 , 0.59337431, 0.49388523, 0.58472222]),\n",
       "   'split1_train_F1': array([0.35345181, 0.59328072, 0.54509371, 0.51866913, 0.57331669,\n",
       "          0.43316822, 0.44659968, 0.60695915, 0.46810457, 0.57553898,\n",
       "          0.47486229, 0.40344329, 0.47218402, 0.59063361, 0.5789229 ,\n",
       "          0.56770696, 0.41659221, 0.47332233, 0.40169045, 0.45610722,\n",
       "          0.46793087, 0.57495015, 0.55032667, 0.58336784, 0.53086658,\n",
       "          0.60855453, 0.40464339, 0.58645714, 0.4992208 , 0.59380865]),\n",
       "   'split2_train_F1': array([0.37155602, 0.5809771 , 0.54488194, 0.51087921, 0.56896905,\n",
       "          0.4113711 , 0.43270246, 0.59405236, 0.48003652, 0.57013548,\n",
       "          0.46969275, 0.389129  , 0.4624831 , 0.57999989, 0.57556422,\n",
       "          0.56143876, 0.39241341, 0.46944212, 0.37794314, 0.44558552,\n",
       "          0.45841529, 0.56248121, 0.55113104, 0.5738275 , 0.52489897,\n",
       "          0.59403055, 0.37425223, 0.58091241, 0.48612803, 0.5813523 ]),\n",
       "   'mean_train_F1': array([0.36331173, 0.58610173, 0.54576498, 0.51428836, 0.57220861,\n",
       "          0.41777841, 0.43793458, 0.59942188, 0.47943615, 0.5737651 ,\n",
       "          0.47306741, 0.3941103 , 0.46611906, 0.58558544, 0.57915429,\n",
       "          0.56430854, 0.40064337, 0.47382415, 0.38338558, 0.44871277,\n",
       "          0.46168388, 0.56922076, 0.55181937, 0.57745552, 0.52756324,\n",
       "          0.60318001, 0.38624544, 0.58691462, 0.49307802, 0.58662772]),\n",
       "   'std_train_F1': array([0.00747879, 0.00522877, 0.00110245, 0.00325359, 0.00232851,\n",
       "          0.0109329 , 0.00617101, 0.0054876 , 0.0090171 , 0.00256675,\n",
       "          0.00238786, 0.00660443, 0.00431679, 0.0043578 , 0.00303017,\n",
       "          0.00258614, 0.01127946, 0.00379938, 0.01329324, 0.00524933,\n",
       "          0.00441888, 0.0051403 , 0.00157679, 0.00421648, 0.00247782,\n",
       "          0.00650252, 0.01320786, 0.00509782, 0.00537549, 0.00526076]),\n",
       "   'split0_test_Log_Loss': array([-3.13863037, -1.55593392, -2.20477057, -2.01410187, -2.00662247,\n",
       "          -2.59326823, -2.67095936, -1.50573814, -2.8829736 , -2.00057706,\n",
       "          -2.90874462, -2.66811971, -2.35323455, -1.64497498, -1.96222617,\n",
       "          -1.64492721, -2.72349667, -2.92891867, -2.87822226, -3.08552074,\n",
       "          -2.40587043, -1.74249319, -2.15885862, -1.58449469, -1.92204951,\n",
       "          -1.55376896, -2.84642038, -1.92510334, -2.25734851, -1.55288842]),\n",
       "   'split1_test_Log_Loss': array([-3.09668781, -1.61403345, -2.23366574, -2.05411518, -2.04244172,\n",
       "          -2.552932  , -2.69244387, -1.56704913, -2.85385933, -2.03675265,\n",
       "          -2.87193033, -2.68610687, -2.38583678, -1.69224034, -2.00070216,\n",
       "          -1.69627924, -2.68299462, -2.9049179 , -2.81272611, -3.05609007,\n",
       "          -2.4377684 , -1.78786413, -2.18878289, -1.63995859, -1.96485108,\n",
       "          -1.60601127, -2.80498384, -1.96613497, -2.28928531, -1.61119032]),\n",
       "   'split2_test_Log_Loss': array([-3.14459901, -1.57794283, -2.21705745, -2.02762695, -2.02312008,\n",
       "          -2.60307721, -2.68051128, -1.528343  , -2.88327672, -2.01723369,\n",
       "          -2.9068784 , -2.68098529, -2.36596075, -1.66268434, -1.97999739,\n",
       "          -1.66513044, -2.74722987, -2.93034051, -2.89727228, -3.08092709,\n",
       "          -2.41837658, -1.76065742, -2.17196588, -1.60606661, -1.93617323,\n",
       "          -1.57470282, -2.86633749, -1.94418048, -2.26962647, -1.57482206]),\n",
       "   'mean_test_Log_Loss': array([-3.12663982, -1.58258839, -2.21847178, -2.03191726, -2.02402704,\n",
       "          -2.58308685, -2.68128475, -1.53366004, -2.87337641, -2.01815309,\n",
       "          -2.89586288, -2.67837954, -2.36831631, -1.6665942 , -1.98093823,\n",
       "          -1.66873506, -2.71787971, -2.92139591, -2.8627262 , -3.07419355,\n",
       "          -2.4206446 , -1.7636323 , -2.1731748 , -1.61012627, -1.94099226,\n",
       "          -1.57811576, -2.83922608, -1.94509993, -2.27205991, -1.57958532]),\n",
       "   'std_test_Log_Loss': array([0.02130765, 0.02397124, 0.01185213, 0.01663147, 0.01465414,\n",
       "          0.02168427, 0.00879814, 0.02533781, 0.01379375, 0.01480003,\n",
       "          0.01693087, 0.0075776 , 0.0134283 , 0.01951395, 0.01574004,\n",
       "          0.02114195, 0.0264903 , 0.01165987, 0.03618228, 0.01293093,\n",
       "          0.01313506, 0.01866231, 0.01226041, 0.02284921, 0.01782054,\n",
       "          0.0214877 , 0.02552977, 0.01678314, 0.01316548, 0.02406461]),\n",
       "   'rank_test_Log_Loss': array([30,  4, 16, 14, 13, 20, 22,  1, 26, 12, 27, 21, 18,  6, 11,  7, 23,\n",
       "          28, 25, 29, 19,  8, 15,  5,  9,  2, 24, 10, 17,  3]),\n",
       "   'split0_train_Log_Loss': array([-3.12952654, -1.46922442, -2.17445334, -1.9626051 , -1.96511296,\n",
       "          -2.56784582, -2.65030041, -1.41096398, -2.86931086, -1.95865094,\n",
       "          -2.89321635, -2.64837799, -2.32007053, -1.56352377, -1.91742415,\n",
       "          -1.56856407, -2.7037119 , -2.91397906, -2.86291386, -3.0740529 ,\n",
       "          -2.3741972 , -1.67075149, -2.12644616, -1.50139489, -1.86532942,\n",
       "          -1.46028414, -2.83160007, -1.8771433 , -2.2196371 , -1.46573194]),\n",
       "   'split1_train_Log_Loss': array([-3.06775789, -1.44665977, -2.15496415, -1.94444336, -1.93894156,\n",
       "          -2.48692152, -2.63788088, -1.38848566, -2.81398751, -1.9322496 ,\n",
       "          -2.83046085, -2.63499075, -2.30495806, -1.54152628, -1.88934839,\n",
       "          -1.54715354, -2.62729432, -2.86353061, -2.76538897, -3.02518153,\n",
       "          -2.3597074 , -1.64935796, -2.10564976, -1.47912997, -1.84566404,\n",
       "          -1.43514973, -2.75717119, -1.84743769, -2.20359008, -1.44307327]),\n",
       "   'split2_train_Log_Loss': array([-3.12290016, -1.46006357, -2.16146621, -1.95408299, -1.94801773,\n",
       "          -2.55793124, -2.64095933, -1.40186467, -2.85838587, -1.94139932,\n",
       "          -2.88229172, -2.64062403, -2.3122018 , -1.55083365, -1.89912666,\n",
       "          -1.56047104, -2.70764335, -2.91147548, -2.86413453, -3.06565644,\n",
       "          -2.36686774, -1.66016917, -2.11254135, -1.49265395, -1.85585122,\n",
       "          -1.45035889, -2.8327708 , -1.85771728, -2.20944211, -1.45645897]),\n",
       "   'mean_train_Log_Loss': array([-3.1067282 , -1.45864925, -2.1636279 , -1.95371048, -1.95069075,\n",
       "          -2.5375662 , -2.64304688, -1.4004381 , -2.84722808, -1.94409995,\n",
       "          -2.86865631, -2.64133092, -2.31241013, -1.55196123, -1.9019664 ,\n",
       "          -1.55872955, -2.67954986, -2.89632838, -2.83081245, -3.05496362,\n",
       "          -2.36692411, -1.66009288, -2.11487909, -1.4910596 , -1.85561489,\n",
       "          -1.44859758, -2.80718069, -1.86076609, -2.21088976, -1.45508806]),\n",
       "   'std_train_Log_Loss': array([0.02768864, 0.00926611, 0.00810193, 0.00741918, 0.01085032,\n",
       "          0.03603921, 0.00528075, 0.00923201, 0.02392405, 0.01094616,\n",
       "          0.02737403, 0.00548812, 0.0061714 , 0.00901576, 0.01163644,\n",
       "          0.00882713, 0.03698509, 0.02321404, 0.04626407, 0.02133628,\n",
       "          0.00591557, 0.00873404, 0.00864952, 0.00915926, 0.00803009,\n",
       "          0.01033638, 0.03536528, 0.0123174 , 0.00663066, 0.00930101])},\n",
       "  {'C': 0.35081818575135704,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.27391199189187976},\n",
       "  7,\n",
       "  -1.5336600406689815),\n",
       " 'RandomForestClassifier_V09_PCA_80': ({'mean_fit_time': array([ 2.09638619,  1.92551963,  3.24432739,  2.72105972,  8.10068027,\n",
       "          12.2376229 ,  3.09373101,  3.02989944,  8.11298068,  6.28154373,\n",
       "           3.95775445,  1.86700932,  2.06381472, 11.48264098,  8.17781115,\n",
       "           1.40291603,  3.48535037,  1.86434944,  3.15423473,  3.15556558,\n",
       "           2.64160633,  2.00364439,  1.33310294,  3.26560442,  5.2473077 ,\n",
       "           2.49266974,  6.13859161,  2.64093971,  4.43348304,  3.11800122]),\n",
       "   'std_fit_time': array([0.04211127, 0.01123458, 0.06702801, 0.07670371, 0.02570417,\n",
       "          0.38144351, 0.0339391 , 0.01182929, 0.01693143, 0.04003826,\n",
       "          0.02036348, 0.004534  , 0.00653192, 0.08289393, 0.0251066 ,\n",
       "          0.00734391, 0.01951572, 0.0098173 , 0.0146881 , 0.03495768,\n",
       "          0.01882249, 0.02692167, 0.00823763, 0.03557328, 0.05272573,\n",
       "          0.0280359 , 0.01996367, 0.02699621, 0.02713539, 0.0951077 ]),\n",
       "   'mean_score_time': array([0.27061009, 0.22240543, 0.25199366, 0.29321663, 0.63629985,\n",
       "          0.83875783, 0.36967882, 0.38763094, 0.63497019, 0.57878653,\n",
       "          0.56848073, 0.25631523, 0.26695291, 0.81814702, 0.5568401 ,\n",
       "          0.17187516, 0.33410732, 0.24966598, 0.44281697, 0.41223121,\n",
       "          0.32812285, 0.2140948 , 0.18550428, 0.24135518, 0.53224428,\n",
       "          0.33310978, 0.59574151, 0.28424017, 0.51628741, 0.39394474]),\n",
       "   'std_score_time': array([0.03462871, 0.02647536, 0.05604252, 0.0180071 , 0.0248472 ,\n",
       "          0.02699531, 0.02263042, 0.00658233, 0.01141011, 0.02711063,\n",
       "          0.02432015, 0.0127196 , 0.00900728, 0.0388015 , 0.01299387,\n",
       "          0.00477108, 0.00636007, 0.00169501, 0.03120018, 0.047267  ,\n",
       "          0.01039616, 0.00815711, 0.00587273, 0.01914897, 0.01123458,\n",
       "          0.00880836, 0.00835739, 0.02055319, 0.01693135, 0.04119493]),\n",
       "   'param_n_estimators': masked_array(data=[100, 100, 100, 150, 350, 350, 200, 200, 350, 300, 350,\n",
       "                      150, 150, 350, 250, 100, 200, 150, 250, 250, 150, 100,\n",
       "                      100, 100, 300, 200, 350, 150, 300, 250],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[125, 125, 10, 75, 50, 10, 150, 125, 50, 75, 250, 200,\n",
       "                      150, 10, 10, 150, 125, 200, 200, 200, 75, 50, 250, 10,\n",
       "                      75, 200, 125, 75, 125, 250],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                      'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                      'sqrt', 'log2', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
       "                      'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'log2',\n",
       "                      'log2', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[55, 50, 10, 90, 50, 20, 50, 85, 70, 70, 25, 15, 65, 30,\n",
       "                      40, 30, 50, 70, 75, 95, 75, 90, 75, 25, 30, 70, 70, 50,\n",
       "                      20, 5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 100,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 75},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 25},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 70},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 5}],\n",
       "   'split0_test_Accuracy': array([0.45034062, 0.44639656, 0.64216565, 0.50053783, 0.54141269,\n",
       "          0.68698458, 0.42990319, 0.45679455, 0.54714952, 0.50878451,\n",
       "          0.38472571, 0.40301183, 0.43492291, 0.68913589, 0.67981355,\n",
       "          0.43097885, 0.44281104, 0.40588024, 0.41412693, 0.40731445,\n",
       "          0.51308713, 0.54750807, 0.35604159, 0.67837935, 0.50627465,\n",
       "          0.41520258, 0.45356759, 0.50268914, 0.45320904, 0.36464683]),\n",
       "   'split1_test_Accuracy': array([0.42388167, 0.41955267, 0.61435786, 0.48015873, 0.51875902,\n",
       "          0.66955267, 0.41847042, 0.43614719, 0.51659452, 0.48448773,\n",
       "          0.36327561, 0.38095238, 0.41702742, 0.66955267, 0.67135642,\n",
       "          0.41017316, 0.43037518, 0.39105339, 0.39105339, 0.37950938,\n",
       "          0.48015873, 0.51515152, 0.35425685, 0.66053391, 0.48593074,\n",
       "          0.38492063, 0.42712843, 0.48340548, 0.43181818, 0.35209235]),\n",
       "   'split2_test_Accuracy': array([0.43353857, 0.42484607, 0.61137269, 0.4882289 , 0.52444766,\n",
       "          0.68272365, 0.41651576, 0.43317639, 0.52263673, 0.48786671,\n",
       "          0.38065918, 0.40130388, 0.41144513, 0.67692865, 0.68055053,\n",
       "          0.40383919, 0.43534951, 0.39840637, 0.40021731, 0.40420138,\n",
       "          0.48641796, 0.52263673, 0.37305324, 0.68055053, 0.49619703,\n",
       "          0.39261137, 0.43100326, 0.48967765, 0.44042014, 0.35277074]),\n",
       "   'mean_test_Accuracy': array([0.4359529 , 0.43030522, 0.62268685, 0.48966595, 0.5282384 ,\n",
       "          0.67976448, 0.42165345, 0.44208123, 0.52883922, 0.4937515 ,\n",
       "          0.37623168, 0.39509733, 0.4211728 , 0.67856285, 0.67724105,\n",
       "          0.41504446, 0.43619322, 0.39846191, 0.40182648, 0.39701995,\n",
       "          0.49327085, 0.52847873, 0.36109108, 0.67315549, 0.49615477,\n",
       "          0.39762076, 0.43727469, 0.49194905, 0.4418409 , 0.35652487]),\n",
       "   'std_test_Accuracy': array([0.01094741, 0.01162652, 0.01388293, 0.00839076, 0.00963668,\n",
       "          0.00742369, 0.00591109, 0.01051609, 0.01323122, 0.01076162,\n",
       "          0.0093057 , 0.01002088, 0.01002404, 0.00808654, 0.00416968,\n",
       "          0.01160402, 0.00511749, 0.00606022, 0.00949863, 0.01244026,\n",
       "          0.01429865, 0.01385075, 0.00846032, 0.00896393, 0.00831511,\n",
       "          0.01287045, 0.01167494, 0.00804256, 0.00880009, 0.00577302]),\n",
       "   'rank_test_Accuracy': array([18, 19,  5, 13,  8,  1, 20, 14,  6, 10, 28, 27, 21,  2,  3, 22, 17,\n",
       "          24, 23, 26, 11,  7, 29,  4,  9, 25, 16, 12, 15, 30]),\n",
       "   'split0_train_Accuracy': array([0.47261883, 0.46828122, 0.79287909, 0.54961142, 0.60816917,\n",
       "          0.8908368 , 0.45165371, 0.484728  , 0.61232604, 0.55196096,\n",
       "          0.40140972, 0.42345924, 0.4590638 , 0.88975239, 0.8919212 ,\n",
       "          0.45526839, 0.46990783, 0.42870052, 0.42345924, 0.41876017,\n",
       "          0.55503344, 0.61304898, 0.36743177, 0.88234231, 0.5548527 ,\n",
       "          0.42237484, 0.48075185, 0.5543105 , 0.47966745, 0.38062534]),\n",
       "   'split1_train_Accuracy': array([0.46846847, 0.47495495, 0.77423423, 0.55837838, 0.60612613,\n",
       "          0.88648649, 0.46162162, 0.48396396, 0.60468468, 0.54630631,\n",
       "          0.39693694, 0.42108108, 0.45981982, 0.88666667, 0.88666667,\n",
       "          0.45261261, 0.47837838, 0.42756757, 0.42666667, 0.42306306,\n",
       "          0.55279279, 0.59711712, 0.38900901, 0.87675676, 0.55135135,\n",
       "          0.42738739, 0.48054054, 0.55153153, 0.4845045 , 0.38306306]),\n",
       "   'split2_train_Accuracy': array([0.47725229, 0.46844093, 0.76946592, 0.54720374, 0.60384823,\n",
       "          0.89066715, 0.45891027, 0.47437511, 0.60546664, 0.54594497,\n",
       "          0.41359468, 0.43823053, 0.45980939, 0.88922856, 0.88994785,\n",
       "          0.44955943, 0.47725229, 0.43139723, 0.44056824, 0.44038842,\n",
       "          0.55169933, 0.59953246, 0.39363424, 0.88401367, 0.54972127,\n",
       "          0.43013846, 0.47131811, 0.54594497, 0.48264701, 0.37709045]),\n",
       "   'mean_train_Accuracy': array([0.47277986, 0.47055903, 0.77885975, 0.55173118, 0.60604784,\n",
       "          0.88933014, 0.4573952 , 0.48102236, 0.60749246, 0.54807075,\n",
       "          0.40398045, 0.42759029, 0.45956434, 0.88854921, 0.88951191,\n",
       "          0.45248014, 0.4751795 , 0.42922177, 0.43023138, 0.42740388,\n",
       "          0.55317519, 0.60323285, 0.38335834, 0.88103758, 0.55197511,\n",
       "          0.42663356, 0.47753683, 0.55059567, 0.48227299, 0.38025962]),\n",
       "   'std_train_Accuracy': array([0.00358779, 0.00310907, 0.0101025 , 0.00480196, 0.00176488,\n",
       "          0.00201196, 0.00420804, 0.00471065, 0.00343274, 0.00275475,\n",
       "          0.00703925, 0.00758617, 0.00035396, 0.00134823, 0.00216719,\n",
       "          0.00233255, 0.00375588, 0.00160631, 0.00742563, 0.00934799,\n",
       "          0.00138774, 0.00701074, 0.01141899, 0.00310295, 0.00214082,\n",
       "          0.00321399, 0.00439815, 0.00347873, 0.00199235, 0.00245198]),\n",
       "   'split0_test_F1': array([0.39869229, 0.39187789, 0.6235433 , 0.45915728, 0.50653605,\n",
       "          0.67533732, 0.37591779, 0.40485613, 0.51460162, 0.4661048 ,\n",
       "          0.32380002, 0.34329541, 0.37861955, 0.67668853, 0.66899259,\n",
       "          0.37447588, 0.38871936, 0.34588144, 0.35297939, 0.35064187,\n",
       "          0.47180528, 0.51306508, 0.2843772 , 0.66595571, 0.46604579,\n",
       "          0.35700036, 0.40143718, 0.45695086, 0.40075092, 0.30048088]),\n",
       "   'split1_test_F1': array([0.37389471, 0.36642839, 0.59623032, 0.44150517, 0.48474963,\n",
       "          0.65864262, 0.3639328 , 0.38729843, 0.48452598, 0.4432511 ,\n",
       "          0.2997073 , 0.32350395, 0.36314757, 0.65745714, 0.66050759,\n",
       "          0.35043504, 0.38153845, 0.32950157, 0.32808851, 0.31526797,\n",
       "          0.44015013, 0.48041888, 0.29190057, 0.64828254, 0.44552138,\n",
       "          0.32426825, 0.37475735, 0.44277422, 0.38248747, 0.28490757]),\n",
       "   'split2_test_F1': array([0.38687988, 0.37278407, 0.59464185, 0.44849735, 0.49291899,\n",
       "          0.67442983, 0.36419983, 0.38425604, 0.48857792, 0.4505628 ,\n",
       "          0.32401118, 0.34898599, 0.35972633, 0.66715282, 0.67215271,\n",
       "          0.351206  , 0.38843624, 0.34571129, 0.34508469, 0.35121623,\n",
       "          0.45029642, 0.49269476, 0.31005243, 0.67020575, 0.45895437,\n",
       "          0.33772962, 0.38234763, 0.45110996, 0.39334058, 0.28511119]),\n",
       "   'mean_test_F1': array([0.38651337, 0.37706606, 0.60485687, 0.44974083, 0.49476139,\n",
       "          0.66947535, 0.36803799, 0.39217326, 0.49594972, 0.453336  ,\n",
       "          0.31584496, 0.33859098, 0.36719772, 0.66711902, 0.66721473,\n",
       "          0.35874777, 0.38623352, 0.34036897, 0.34206918, 0.33904963,\n",
       "          0.45412515, 0.49543257, 0.29540148, 0.66147894, 0.45685652,\n",
       "          0.33970405, 0.38621695, 0.45029088, 0.39220896, 0.2901943 ]),\n",
       "   'std_test_F1': array([0.01013867, 0.01083058, 0.01328272, 0.00726786, 0.00899878,\n",
       "          0.00766472, 0.00559553, 0.00908956, 0.01334505, 0.00954307,\n",
       "          0.01140521, 0.01091262, 0.00822832, 0.00786038, 0.00491259,\n",
       "          0.01117101, 0.00332013, 0.00768057, 0.01039303, 0.01680871,\n",
       "          0.0132165 , 0.01348203, 0.01077163, 0.0094863 , 0.00851807,\n",
       "          0.01345055, 0.01124036, 0.00582301, 0.00750719, 0.0073037 ]),\n",
       "   'rank_test_F1': array([16, 19,  5, 13,  8,  1, 20, 15,  6, 11, 28, 27, 21,  3,  2, 22, 17,\n",
       "          24, 23, 26, 10,  7, 29,  4,  9, 25, 18, 12, 14, 30]),\n",
       "   'split0_train_F1': array([0.42476918, 0.42111612, 0.78826184, 0.51659873, 0.5852775 ,\n",
       "          0.88950544, 0.40204659, 0.43759629, 0.58971677, 0.51847591,\n",
       "          0.34306572, 0.36535991, 0.40803842, 0.8879072 , 0.89073807,\n",
       "          0.40592935, 0.42571192, 0.37043937, 0.36445994, 0.36352543,\n",
       "          0.52297209, 0.58978865, 0.29780327, 0.88088039, 0.52354675,\n",
       "          0.36481583, 0.43643168, 0.5200812 , 0.43313794, 0.3185267 ]),\n",
       "   'split1_train_F1': array([0.41892881, 0.42634414, 0.76699327, 0.52597649, 0.58034554,\n",
       "          0.88454262, 0.4111744 , 0.4372614 , 0.57890905, 0.51007399,\n",
       "          0.33326289, 0.36045502, 0.40806036, 0.88488351, 0.88468988,\n",
       "          0.3971485 , 0.43101851, 0.36955732, 0.37024127, 0.36054994,\n",
       "          0.51820097, 0.57094709, 0.32684546, 0.8745928 , 0.51563503,\n",
       "          0.37040082, 0.43177682, 0.51692831, 0.43582671, 0.31598895]),\n",
       "   'split2_train_F1': array([0.42640006, 0.41515465, 0.76514741, 0.50901122, 0.57469014,\n",
       "          0.88954486, 0.40648499, 0.42297038, 0.57765551, 0.50772121,\n",
       "          0.35642017, 0.38475488, 0.40686369, 0.88803813, 0.8887863 ,\n",
       "          0.39339185, 0.42650377, 0.37663019, 0.38654035, 0.38738936,\n",
       "          0.51428923, 0.5729042 , 0.32780111, 0.88272463, 0.51151982,\n",
       "          0.37146895, 0.41979673, 0.5057812 , 0.43312017, 0.31130387]),\n",
       "   'mean_train_F1': array([0.42336602, 0.42087164, 0.77346751, 0.51719548, 0.58010439,\n",
       "          0.88786431, 0.40656866, 0.43260936, 0.58209378, 0.51209037,\n",
       "          0.34424959, 0.37018994, 0.40765416, 0.88694295, 0.88807141,\n",
       "          0.39882323, 0.42774473, 0.37220896, 0.37374719, 0.37048824,\n",
       "          0.51848743, 0.57787998, 0.31748328, 0.87939927, 0.51690054,\n",
       "          0.3688952 , 0.42933508, 0.51426357, 0.43402827, 0.31527317]),\n",
       "   'std_train_F1': array([0.00320744, 0.00457136, 0.01048828, 0.00693888, 0.00432563,\n",
       "          0.00234884, 0.00372688, 0.00681716, 0.00541451, 0.00461629,\n",
       "          0.00949091, 0.01049183, 0.00055901, 0.00145722, 0.00252038,\n",
       "          0.00525362, 0.00233737, 0.00314695, 0.00934897, 0.01201247,\n",
       "          0.00355054, 0.00845852, 0.01392134, 0.00348109, 0.00499085,\n",
       "          0.00291732, 0.00700723, 0.0061345 , 0.00127171, 0.00299183]),\n",
       "   'split0_test_Log_Loss': array([-2.47545664, -2.48596163, -1.70346705, -2.29083879, -2.09202348,\n",
       "          -1.49988382, -2.57684425, -2.50486391, -2.09268596, -2.25401916,\n",
       "          -2.78609274, -2.68816042, -2.59774821, -1.49821048, -1.50168319,\n",
       "          -2.58316893, -2.47477971, -2.69433481, -2.68939465, -2.6966674 ,\n",
       "          -2.2887024 , -2.12651238, -2.76149989, -1.50387112, -2.29424091,\n",
       "          -2.70017612, -2.47208677, -2.2913372 , -2.50629844, -2.79498379]),\n",
       "   'split1_test_Log_Loss': array([-2.48367818, -2.48922388, -1.72825937, -2.30874369, -2.09869394,\n",
       "          -1.51938887, -2.57834709, -2.51451406, -2.10674367, -2.26590579,\n",
       "          -2.78611623, -2.69675924, -2.58021532, -1.51841285, -1.51857389,\n",
       "          -2.58034071, -2.48258984, -2.70987688, -2.70092729, -2.68967445,\n",
       "          -2.30699194, -2.1456812 , -2.77503178, -1.53068093, -2.30319719,\n",
       "          -2.698668  , -2.4784213 , -2.31140023, -2.51019288, -2.7953135 ]),\n",
       "   'split2_test_Log_Loss': array([-2.47831063, -2.47179472, -1.73842473, -2.29615099, -2.09453424,\n",
       "          -1.50726711, -2.57580028, -2.5023152 , -2.08960756, -2.26183047,\n",
       "          -2.78482826, -2.69677442, -2.58219423, -1.50540002, -1.49935011,\n",
       "          -2.58632376, -2.47098842, -2.69510261, -2.69805661, -2.69490128,\n",
       "          -2.29840953, -2.12002612, -2.74888821, -1.50518798, -2.28711098,\n",
       "          -2.69356863, -2.47502539, -2.29732815, -2.50521655, -2.80510905]),\n",
       "   'mean_test_Log_Loss': array([-2.47914205, -2.48234809, -1.72332315, -2.29856522, -2.09507836,\n",
       "          -1.50883038, -2.57699848, -2.50723272, -2.09634716, -2.26057008,\n",
       "          -2.78568105, -2.6938825 , -2.58674777, -1.50732503, -1.50653531,\n",
       "          -2.58327355, -2.47612337, -2.6997665 , -2.69610988, -2.69375215,\n",
       "          -2.29801506, -2.13074543, -2.76182308, -1.51323817, -2.29485868,\n",
       "          -2.6974816 , -2.47517171, -2.30000768, -2.50723671, -2.79845288]),\n",
       "   'std_test_Log_Loss': array([0.00341103, 0.00755474, 0.01469393, 0.00751328, 0.00275321,\n",
       "          0.00804793, 0.00104408, 0.00525008, 0.00745421, 0.00493886,\n",
       "          0.00060097, 0.00406255, 0.00785162, 0.00836787, 0.00856113,\n",
       "          0.00244039, 0.00482509, 0.00715213, 0.0049092 , 0.00297067,\n",
       "          0.00748055, 0.01088266, 0.01066108, 0.01233894, 0.00657292,\n",
       "          0.00282523, 0.00259113, 0.0084148 , 0.00213539, 0.00469202]),\n",
       "   'rank_test_Log_Loss': array([16, 17,  5, 12,  6,  3, 20, 18,  7,  9, 29, 24, 22,  2,  1, 21, 15,\n",
       "          27, 25, 23, 11,  8, 28,  4, 10, 26, 14, 13, 19, 30]),\n",
       "   'split0_train_Log_Loss': array([-2.40124474, -2.40989992, -1.42436813, -2.1802928 , -1.94439307,\n",
       "          -1.11297228, -2.51143027, -2.4289222 , -1.94458621, -2.14357243,\n",
       "          -2.74143667, -2.63872599, -2.53114589, -1.11199617, -1.11385481,\n",
       "          -2.51612292, -2.39747724, -2.63898624, -2.63748091, -2.6448151 ,\n",
       "          -2.18035723, -1.97547573, -2.71698969, -1.11238855, -2.18366422,\n",
       "          -2.64801633, -2.39596162, -2.18018782, -2.4300351 , -2.75583486]),\n",
       "   'split1_train_Log_Loss': array([-2.40063853, -2.40385148, -1.4173385 , -2.18165965, -1.93224337,\n",
       "          -1.10209304, -2.50360517, -2.42927102, -1.93947853, -2.14191921,\n",
       "          -2.73972911, -2.63674571, -2.50644708, -1.10133626, -1.10003254,\n",
       "          -2.50731025, -2.39777908, -2.65233345, -2.64240051, -2.63220817,\n",
       "          -2.17902768, -1.97731249, -2.72846434, -1.10589236, -2.17908827,\n",
       "          -2.64094315, -2.39466155, -2.18504607, -2.4243531 , -2.75211958]),\n",
       "   'split2_train_Log_Loss': array([-2.40558461, -2.40116412, -1.45774853, -2.18577581, -1.9467531 ,\n",
       "          -1.11168518, -2.51442608, -2.42994677, -1.94291362, -2.15520519,\n",
       "          -2.7444389 , -2.64731245, -2.52128325, -1.10878876, -1.10678429,\n",
       "          -2.52375984, -2.39760804, -2.64530106, -2.64826855, -2.64657551,\n",
       "          -2.18859126, -1.97557279, -2.71187506, -1.10830672, -2.17810927,\n",
       "          -2.64292689, -2.40305664, -2.18805782, -2.43242587, -2.76734847]),\n",
       "   'mean_train_Log_Loss': array([-2.40248929, -2.40497184, -1.43315172, -2.18257609, -1.94112985,\n",
       "          -1.10891683, -2.5098205 , -2.42938   , -1.94232612, -2.14689895,\n",
       "          -2.74186823, -2.64092805, -2.51962541, -1.10737373, -1.10689055,\n",
       "          -2.515731  , -2.39762145, -2.64554025, -2.64271666, -2.64119959,\n",
       "          -2.18265872, -1.97612034, -2.7191097 , -1.10886254, -2.18028725,\n",
       "          -2.64396212, -2.39789327, -2.18443057, -2.42893802, -2.75843431]),\n",
       "   'std_train_Log_Loss': array([0.00220267, 0.00365331, 0.01762775, 0.00233034, 0.00635712,\n",
       "          0.00485368, 0.00456191, 0.00042532, 0.00212618, 0.00591205,\n",
       "          0.00194683, 0.00458627, 0.01015116, 0.00446543, 0.00564342,\n",
       "          0.00672123, 0.00012359, 0.0054516 , 0.00440971, 0.00639839,\n",
       "          0.00422991, 0.00084391, 0.00693647, 0.00268103, 0.00242109,\n",
       "          0.00297896, 0.00368943, 0.00324226, 0.00338576, 0.00648319])},\n",
       "  {'n_estimators': 250,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40},\n",
       "  14,\n",
       "  -1.50653531453819),\n",
       " 'KNeighborsClassifier_V09_PCA_80': ({'mean_fit_time': array([0.0222737 , 0.02260566, 0.02260558, 0.02094396, 0.02493302,\n",
       "          0.01230073, 0.02027917, 0.01362975, 0.01296528, 0.02360257,\n",
       "          0.01994562, 0.02094412, 0.01263245, 0.01296528, 0.02061145,\n",
       "          0.02559781, 0.02327029, 0.01329851, 0.02393651, 0.02393492,\n",
       "          0.02526538, 0.02293889, 0.02593064, 0.02559837, 0.02127719,\n",
       "          0.02160772, 0.02061041, 0.02393635, 0.01196758, 0.0216097 ]),\n",
       "   'std_fit_time': array([4.70415519e-04, 4.70021655e-04, 4.70976993e-04, 8.14490730e-04,\n",
       "          1.41130139e-03, 4.69516710e-04, 4.70359836e-04, 4.69066821e-04,\n",
       "          8.14491102e-04, 4.69235560e-04, 1.94667955e-07, 8.14782742e-04,\n",
       "          9.40492896e-04, 2.97360213e-07, 4.69459858e-04, 2.04904790e-03,\n",
       "          9.40998683e-04, 4.68336428e-04, 8.14490722e-04, 8.14685398e-04,\n",
       "          2.61740383e-03, 4.49566384e-07, 5.64110279e-03, 4.69572451e-04,\n",
       "          4.70358870e-04, 9.39481674e-04, 4.69909424e-04, 8.14685514e-04,\n",
       "          8.15561398e-04, 2.48746068e-03]),\n",
       "   'mean_score_time': array([3.54750776, 3.91420515, 4.26327173, 3.38295738, 4.40190125,\n",
       "          0.92885105, 3.36965887, 1.12399538, 1.21641596, 4.30349795,\n",
       "          3.46440752, 3.69678513, 1.06249388, 1.22073674, 3.39293114,\n",
       "          4.56180684, 3.70975169, 1.15424728, 3.87464341, 3.76194493,\n",
       "          4.60502569, 4.43580921, 4.63427949, 4.07544017, 3.52923314,\n",
       "          3.67816909, 3.72271697, 4.49797694, 1.14859708, 3.28355622]),\n",
       "   'std_score_time': array([0.16498997, 0.04390064, 0.06178352, 0.0952862 , 0.0122241 ,\n",
       "          0.05398036, 0.06662741, 0.08880119, 0.02707248, 0.05012423,\n",
       "          0.13452301, 0.20276578, 0.08515172, 0.05597653, 0.113068  ,\n",
       "          0.03073894, 0.17357436, 0.0486307 , 0.10749936, 0.0853397 ,\n",
       "          0.05526818, 0.32138977, 0.277726  , 0.1223361 , 0.12732235,\n",
       "          0.01865836, 0.02281986, 0.22740166, 0.0421751 , 0.10100358]),\n",
       "   'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                      'distance', 'distance', 'distance', 'distance',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'distance', 'distance',\n",
       "                      'distance', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'distance', 'uniform', 'distance', 'distance'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[3, 4, 6, 8, 6, 3, 4, 4, 6, 6, 6, 5, 3, 4, 7, 7, 3, 5,\n",
       "                      4, 3, 8, 4, 7, 5, 3, 4, 7, 7, 7, 3],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['auto', 'auto', 'auto', 'ball_tree', 'auto', 'brute',\n",
       "                      'ball_tree', 'brute', 'brute', 'kd_tree', 'ball_tree',\n",
       "                      'ball_tree', 'brute', 'brute', 'ball_tree', 'auto',\n",
       "                      'auto', 'brute', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                      'kd_tree', 'kd_tree', 'auto', 'ball_tree', 'ball_tree',\n",
       "                      'ball_tree', 'auto', 'brute', 'ball_tree'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'ball_tree'}],\n",
       "   'split0_test_Accuracy': array([0.71674435, 0.74937253, 0.6912872 , 0.72463248, 0.73395482,\n",
       "          0.76192184, 0.74937253, 0.74937253, 0.6912872 , 0.6912872 ,\n",
       "          0.6912872 , 0.70096809, 0.71674435, 0.70921477, 0.68053066,\n",
       "          0.7275009 , 0.76192184, 0.73574758, 0.70921477, 0.76192184,\n",
       "          0.679455  , 0.74937253, 0.68053066, 0.70096809, 0.71674435,\n",
       "          0.70921477, 0.7275009 , 0.68053066, 0.7275009 , 0.76192184]),\n",
       "   'split1_test_Accuracy': array([0.71861472, 0.74350649, 0.68073593, 0.70959596, 0.72582973,\n",
       "          0.75468975, 0.74350649, 0.74350649, 0.68073593, 0.68073593,\n",
       "          0.68073593, 0.69300144, 0.71861472, 0.7049062 , 0.66883117,\n",
       "          0.71825397, 0.75468975, 0.73629149, 0.7049062 , 0.75468975,\n",
       "          0.65367965, 0.74350649, 0.66883117, 0.69300144, 0.71861472,\n",
       "          0.7049062 , 0.71825397, 0.66883117, 0.71825397, 0.75468975]),\n",
       "   'split2_test_Accuracy': array([0.71894241, 0.74972836, 0.67656646, 0.72147773, 0.73342992,\n",
       "          0.75842086, 0.74972836, 0.74972836, 0.67656646, 0.67656646,\n",
       "          0.67656646, 0.69684897, 0.71894241, 0.70155741, 0.67113365,\n",
       "          0.72872148, 0.75842086, 0.73958711, 0.70155741, 0.75842086,\n",
       "          0.66099239, 0.74972836, 0.67113365, 0.69684897, 0.71894241,\n",
       "          0.70155741, 0.72872148, 0.67113365, 0.72872148, 0.75842086]),\n",
       "   'mean_test_Accuracy': array([0.71809661, 0.74753665, 0.68288873, 0.71857727, 0.73107426,\n",
       "          0.75835136, 0.74753665, 0.74753665, 0.68288873, 0.68288873,\n",
       "          0.68288873, 0.69694785, 0.71809661, 0.70523913, 0.67351598,\n",
       "          0.72482576, 0.75835136, 0.7372026 , 0.70523913, 0.75835136,\n",
       "          0.66474405, 0.74753665, 0.67351598, 0.69694785, 0.71809661,\n",
       "          0.70523913, 0.72482576, 0.67351598, 0.72482576, 0.75835136]),\n",
       "   'std_test_Accuracy': array([0.00096932, 0.00285191, 0.00620029, 0.0064767 , 0.00371263,\n",
       "          0.00295633, 0.00285191, 0.00285191, 0.00620029, 0.00620029,\n",
       "          0.00620029, 0.00325691, 0.00096932, 0.00313547, 0.00506795,\n",
       "          0.00467111, 0.00295633, 0.00169482, 0.00313547, 0.00295633,\n",
       "          0.01086161, 0.00285191, 0.00506795, 0.00325691, 0.00096932,\n",
       "          0.00313547, 0.00467111, 0.00506795, 0.00467111, 0.00295633]),\n",
       "   'rank_test_Accuracy': array([15,  5, 23, 14, 10,  1,  5,  5, 23, 23, 23, 21, 15, 18, 27, 11,  1,\n",
       "           9, 18,  1, 30,  5, 27, 21, 15, 18, 11, 27, 11,  1]),\n",
       "   'split0_train_Accuracy': array([0.85956985, 1.        , 0.78564974, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78564974, 0.78564974,\n",
       "          0.78564974, 0.81294054, 0.85956985, 0.83245979, 0.77589011,\n",
       "          1.        , 1.        , 1.        , 0.83245979, 1.        ,\n",
       "          0.75691307, 1.        , 0.77589011, 0.81294054, 0.85956985,\n",
       "          0.83245979, 1.        , 0.77589011, 1.        , 1.        ]),\n",
       "   'split1_train_Accuracy': array([0.86756757, 1.        , 0.79045045, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.79045045, 0.79045045,\n",
       "          0.79045045, 0.80972973, 0.86756757, 0.8354955 , 0.77243243,\n",
       "          1.        , 1.        , 1.        , 0.8354955 , 1.        ,\n",
       "          0.75513514, 1.        , 0.77243243, 0.80972973, 0.86756757,\n",
       "          0.8354955 , 1.        , 0.77243243, 1.        , 1.        ]),\n",
       "   'split2_train_Accuracy': array([0.86189534, 1.        , 0.78960619, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78960619, 0.78960619,\n",
       "          0.78960619, 0.80956662, 0.86189534, 0.8351016 , 0.77162381,\n",
       "          1.        , 1.        , 1.        , 0.8351016 , 1.        ,\n",
       "          0.75651861, 1.        , 0.77162381, 0.80956662, 0.86189534,\n",
       "          0.8351016 , 1.        , 0.77162381, 1.        , 1.        ]),\n",
       "   'mean_train_Accuracy': array([0.86301092, 1.        , 0.78856879, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78856879, 0.78856879,\n",
       "          0.78856879, 0.81074563, 0.86301092, 0.83435229, 0.77331545,\n",
       "          1.        , 1.        , 1.        , 0.83435229, 1.        ,\n",
       "          0.75618894, 1.        , 0.77331545, 0.81074563, 0.86301092,\n",
       "          0.83435229, 1.        , 0.77331545, 1.        , 1.        ]),\n",
       "   'std_train_Accuracy': array([0.00335899, 0.        , 0.00209266, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00209266, 0.00209266,\n",
       "          0.00209266, 0.00155346, 0.00335899, 0.00134783, 0.00185025,\n",
       "          0.        , 0.        , 0.        , 0.00134783, 0.        ,\n",
       "          0.00076235, 0.        , 0.00185025, 0.00155346, 0.00335899,\n",
       "          0.00134783, 0.        , 0.00185025, 0.        , 0.        ]),\n",
       "   'split0_test_F1': array([0.71397274, 0.74583921, 0.68611914, 0.72079396, 0.73008555,\n",
       "          0.75974068, 0.74583921, 0.74583921, 0.68611914, 0.68611914,\n",
       "          0.68611914, 0.69697435, 0.71397274, 0.70580933, 0.6748503 ,\n",
       "          0.72402355, 0.75974068, 0.73188126, 0.70580933, 0.75974068,\n",
       "          0.67324988, 0.74583921, 0.6748503 , 0.69697435, 0.71397274,\n",
       "          0.70580933, 0.72402355, 0.6748503 , 0.72402355, 0.75974068]),\n",
       "   'split1_test_F1': array([0.71732757, 0.74120703, 0.67549863, 0.70517533, 0.72266209,\n",
       "          0.75321431, 0.74120703, 0.74120703, 0.67549863, 0.67549863,\n",
       "          0.67549863, 0.68913351, 0.71732757, 0.70199087, 0.66359177,\n",
       "          0.71402593, 0.75321431, 0.73359608, 0.70199087, 0.75321431,\n",
       "          0.64753405, 0.74120703, 0.66359177, 0.68913351, 0.71732757,\n",
       "          0.70199087, 0.71402593, 0.66359177, 0.71402593, 0.75321431]),\n",
       "   'split2_test_F1': array([0.71810677, 0.74788557, 0.67307547, 0.71777161, 0.73018562,\n",
       "          0.75716051, 0.74788557, 0.74788557, 0.67307547, 0.67307547,\n",
       "          0.67307547, 0.69420428, 0.71810677, 0.70025054, 0.66600216,\n",
       "          0.72450708, 0.75716051, 0.73710209, 0.70025054, 0.75716051,\n",
       "          0.65523499, 0.74788557, 0.66600216, 0.69420428, 0.71810677,\n",
       "          0.70025054, 0.72450708, 0.66600216, 0.72450708, 0.75716051]),\n",
       "   'mean_test_F1': array([0.71646177, 0.74497519, 0.67825401, 0.71458877, 0.72764605,\n",
       "          0.75671077, 0.74497519, 0.74497519, 0.67825401, 0.67825401,\n",
       "          0.67825401, 0.69344359, 0.71646177, 0.70269318, 0.66816461,\n",
       "          0.72085384, 0.75671077, 0.73418457, 0.70269318, 0.75671077,\n",
       "          0.6587073 , 0.74497519, 0.66816461, 0.69344359, 0.71646177,\n",
       "          0.70269318, 0.72085384, 0.66816461, 0.72085384, 0.75671077]),\n",
       "   'std_test_F1': array([0.00179547, 0.00279105, 0.00567077, 0.0067662 , 0.00352252,\n",
       "          0.00268624, 0.00279105, 0.00279105, 0.00567077, 0.00567077,\n",
       "          0.00567077, 0.00324926, 0.00179547, 0.00232338, 0.00484734,\n",
       "          0.00482949, 0.00268624, 0.00217194, 0.00232338, 0.00268624,\n",
       "          0.0107917 , 0.00279105, 0.00484734, 0.00324926, 0.00179547,\n",
       "          0.00232338, 0.00482949, 0.00484734, 0.00482949, 0.00268624]),\n",
       "   'rank_test_F1': array([14,  5, 23, 17, 10,  1,  5,  5, 23, 23, 23, 21, 14, 18, 27, 11,  1,\n",
       "           9, 18,  1, 30,  5, 27, 21, 14, 18, 11, 27, 11,  1]),\n",
       "   'split0_train_F1': array([0.85973042, 1.        , 0.78342178, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78342178, 0.78342178,\n",
       "          0.78342178, 0.81215044, 0.85973042, 0.83213108, 0.77330699,\n",
       "          1.        , 1.        , 1.        , 0.83213108, 1.        ,\n",
       "          0.75348935, 1.        , 0.77330699, 0.81215044, 0.85973042,\n",
       "          0.83213108, 1.        , 0.77330699, 1.        , 1.        ]),\n",
       "   'split1_train_F1': array([0.86754025, 1.        , 0.78812903, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78812903, 0.78812903,\n",
       "          0.78812903, 0.80808717, 0.86754025, 0.83425686, 0.76998992,\n",
       "          1.        , 1.        , 1.        , 0.83425686, 1.        ,\n",
       "          0.75132489, 1.        , 0.76998992, 0.80808717, 0.86754025,\n",
       "          0.83425686, 1.        , 0.76998992, 1.        , 1.        ]),\n",
       "   'split2_train_F1': array([0.86146295, 1.        , 0.78737382, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78737382, 0.78737382,\n",
       "          0.78737382, 0.80801321, 0.86146295, 0.83399232, 0.76878682,\n",
       "          1.        , 1.        , 1.        , 0.83399232, 1.        ,\n",
       "          0.75321078, 1.        , 0.76878682, 0.80801321, 0.86146295,\n",
       "          0.83399232, 1.        , 0.76878682, 1.        , 1.        ]),\n",
       "   'mean_train_F1': array([0.86291121, 1.        , 0.78630821, 1.        , 1.        ,\n",
       "          1.        , 1.        , 1.        , 0.78630821, 0.78630821,\n",
       "          0.78630821, 0.80941694, 0.86291121, 0.83346009, 0.77069458,\n",
       "          1.        , 1.        , 1.        , 0.83346009, 1.        ,\n",
       "          0.75267501, 1.        , 0.77069458, 0.80941694, 0.86291121,\n",
       "          0.83346009, 1.        , 0.77069458, 1.        , 1.        ]),\n",
       "   'std_train_F1': array([0.00334878, 0.        , 0.00206417, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.00206417, 0.00206417,\n",
       "          0.00206417, 0.00193311, 0.00334878, 0.00094594, 0.00191144,\n",
       "          0.        , 0.        , 0.        , 0.00094594, 0.        ,\n",
       "          0.00096143, 0.        , 0.00191144, 0.00193311, 0.00334878,\n",
       "          0.00094594, 0.        , 0.00191144, 0.        , 0.        ]),\n",
       "   'split0_test_Log_Loss': array([-4.94706924, -4.38353953, -3.70688786, -3.23809682, -3.64058937,\n",
       "          -4.91262357, -4.38353953, -4.38353953, -3.70688786, -3.70688786,\n",
       "          -3.70688786, -4.01295548, -4.94706924, -4.43117121, -3.51480598,\n",
       "          -3.44080346, -4.91262357, -3.95539211, -4.43117121, -4.91262357,\n",
       "          -3.31857122, -4.38353953, -3.51480598, -4.01295548, -4.94706924,\n",
       "          -4.43117121, -3.44080346, -3.51480598, -3.44080346, -4.91262357]),\n",
       "   'split1_test_Log_Loss': array([-5.1736432 , -4.48807704, -3.78813915, -3.34913856, -3.72143211,\n",
       "          -5.1379788 , -4.48807704, -4.48807704, -3.78813915, -3.78813915,\n",
       "          -3.78813915, -4.10427892, -5.1736432 , -4.53405446, -3.58983466,\n",
       "          -3.51387425, -5.1379788 , -4.04656039, -4.53405446, -5.1379788 ,\n",
       "          -3.43313429, -4.48807704, -3.58983466, -4.10427892, -5.1736432 ,\n",
       "          -4.53405446, -3.51387425, -3.58983466, -3.51387425, -5.1379788 ]),\n",
       "   'split2_test_Log_Loss': array([-5.18108289, -4.39691293, -3.72978782, -3.21806289, -3.65998899,\n",
       "          -5.14462891, -4.39691293, -4.39691293, -3.72978782, -3.72978782,\n",
       "          -3.72978782, -4.07162154, -5.18108289, -4.44604532, -3.51032545,\n",
       "          -3.43340145, -5.14462891, -4.0113909 , -4.44604532, -5.14462891,\n",
       "          -3.30133122, -4.39691293, -3.51032545, -4.07162154, -5.18108289,\n",
       "          -4.44604532, -3.43340145, -3.51032545, -3.43340145, -5.14462891]),\n",
       "   'mean_test_Log_Loss': array([-5.10017843, -4.42279715, -3.74154964, -3.26843737, -3.67395376,\n",
       "          -5.06466051, -4.42279715, -4.42279715, -3.74154964, -3.74154964,\n",
       "          -3.74154964, -4.06283839, -5.10017843, -4.4703757 , -3.538311  ,\n",
       "          -3.46268706, -5.06466051, -4.00433841, -4.4703757 , -5.06466051,\n",
       "          -3.35101164, -4.42279715, -3.538311  , -4.06283839, -5.10017843,\n",
       "          -4.4703757 , -3.46268706, -3.538311  , -3.46268706, -5.06466051]),\n",
       "   'std_test_Log_Loss': array([0.10874623, 0.04645693, 0.03422789, 0.05761715, 0.03447642,\n",
       "          0.10797669, 0.04645693, 0.04645693, 0.03422789, 0.03422789,\n",
       "          0.03422789, 0.03783571, 0.10874623, 0.04541129, 0.03645896,\n",
       "          0.03630128, 0.10797669, 0.0375926 , 0.04541129, 0.10797669,\n",
       "          0.05846343, 0.04645693, 0.03645896, 0.03783571, 0.10874623,\n",
       "          0.04541129, 0.03630128, 0.03645896, 0.03630128, 0.10797669]),\n",
       "   'rank_test_Log_Loss': array([28, 17, 10,  1,  9, 24, 17, 17, 10, 10, 10, 15, 28, 21,  6,  4, 24,\n",
       "          14, 21, 24,  2, 17,  6, 15, 28, 21,  4,  6,  3, 24]),\n",
       "   'split0_train_Log_Loss': array([-2.86191296e-01, -3.77251697e-14, -5.20582554e-01, -3.77251697e-14,\n",
       "          -3.77251697e-14, -8.78397949e-09, -3.77251697e-14, -1.40119796e-08,\n",
       "          -5.20582554e-01, -5.20582554e-01, -5.20582554e-01, -4.51417767e-01,\n",
       "          -2.86191296e-01, -3.75338722e-01, -5.78782713e-01, -3.77251697e-14,\n",
       "          -3.77251697e-14, -1.96375113e-08, -3.75338722e-01, -3.77251697e-14,\n",
       "          -6.31431712e-01, -3.77251697e-14, -5.78782713e-01, -4.51417767e-01,\n",
       "          -2.86191296e-01, -3.75338722e-01, -3.77251697e-14, -5.78782713e-01,\n",
       "          -3.16142223e-08, -3.77251697e-14]),\n",
       "   'split1_train_Log_Loss': array([-2.74549975e-01, -3.77252183e-14, -5.09563502e-01, -3.77252183e-14,\n",
       "          -3.77252183e-14, -8.79773506e-09, -3.77252183e-14, -1.41704802e-08,\n",
       "          -5.09563502e-01, -5.09563502e-01, -5.09563502e-01, -4.45365277e-01,\n",
       "          -2.74549975e-01, -3.68849319e-01, -5.67351789e-01, -3.77252183e-14,\n",
       "          -3.77252183e-14, -1.96803416e-08, -3.68849319e-01, -3.77252183e-14,\n",
       "          -6.17849287e-01, -3.77252183e-14, -5.67351789e-01, -4.45365277e-01,\n",
       "          -2.74549975e-01, -3.68849319e-01, -3.77252183e-14, -5.67351789e-01,\n",
       "          -3.13280957e-08, -3.77252183e-14]),\n",
       "   'split2_train_Log_Loss': array([-2.78021571e-01, -3.77251228e-14, -5.13781801e-01, -3.77251228e-14,\n",
       "          -3.77251228e-14, -8.33636991e-09, -3.77251228e-14, -1.35542360e-08,\n",
       "          -5.13781801e-01, -5.13781801e-01, -5.13781801e-01, -4.47283536e-01,\n",
       "          -2.78021571e-01, -3.73286736e-01, -5.72162929e-01, -3.77251228e-14,\n",
       "          -3.77251228e-14, -1.87139349e-08, -3.73286736e-01, -3.77251228e-14,\n",
       "          -6.20871703e-01, -3.77251228e-14, -5.72162929e-01, -4.47283536e-01,\n",
       "          -2.78021571e-01, -3.73286736e-01, -3.77251228e-14, -5.72162929e-01,\n",
       "          -3.04220432e-08, -3.77251228e-14]),\n",
       "   'mean_train_Log_Loss': array([-2.79587614e-01, -3.77251703e-14, -5.14642619e-01, -3.77251703e-14,\n",
       "          -3.77251703e-14, -8.63936149e-09, -3.77251703e-14, -1.39122320e-08,\n",
       "          -5.14642619e-01, -5.14642619e-01, -5.14642619e-01, -4.48022194e-01,\n",
       "          -2.79587614e-01, -3.72491592e-01, -5.72765810e-01, -3.77251703e-14,\n",
       "          -3.77251703e-14, -1.93439293e-08, -3.72491592e-01, -3.77251703e-14,\n",
       "          -6.23384234e-01, -3.77251703e-14, -5.72765810e-01, -4.48022194e-01,\n",
       "          -2.79587614e-01, -3.72491592e-01, -3.77251703e-14, -5.72765810e-01,\n",
       "          -3.11214537e-08, -3.77251703e-14]),\n",
       "   'std_train_Log_Loss': array([4.87985362e-03, 3.89952081e-20, 4.53950305e-03, 3.89952081e-20,\n",
       "          3.89952081e-20, 2.14320981e-10, 3.89952081e-20, 2.61280700e-10,\n",
       "          4.53950305e-03, 4.53950305e-03, 4.53950305e-03, 2.52551912e-03,\n",
       "          4.87985362e-03, 2.70829327e-03, 4.68608623e-03, 3.89952081e-20,\n",
       "          3.89952081e-20, 4.45816299e-10, 2.70829327e-03, 3.89952081e-20,\n",
       "          5.82266718e-03, 3.89952081e-20, 4.68608623e-03, 2.52551912e-03,\n",
       "          4.87985362e-03, 2.70829327e-03, 3.89952081e-20, 4.68608623e-03,\n",
       "          5.08165602e-10, 3.89952081e-20])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "  3,\n",
       "  -3.2684373659061206),\n",
       " 'MLPClassifier_V09_PCA_80': ({'mean_fit_time': array([19.8276604 ,  2.74599346,  3.05483588, 15.57603399, 29.61650475,\n",
       "           7.84070913, 16.05974086, 13.30875969, 13.23096784,  6.88360214,\n",
       "          22.89413977, 18.3998189 , 11.50557971,  3.66586836, 19.36822955,\n",
       "           0.59108758, 12.87358944, 22.17738811, 17.81238929, 15.04545172,\n",
       "           4.44179336,  6.37795218,  5.43148208,  5.78487086,  9.16949002,\n",
       "           4.3869404 ,  7.61431607, 16.20900798, 11.03550506,  3.66487026]),\n",
       "   'std_fit_time': array([0.8563763 , 0.14717427, 0.14443241, 0.24875598, 0.82592161,\n",
       "          0.4675534 , 0.5020863 , 0.81407278, 0.37070547, 0.46706182,\n",
       "          0.41490854, 2.12430005, 0.81247819, 0.36193072, 0.50089876,\n",
       "          0.01852167, 1.42847334, 1.24950696, 0.1974693 , 1.2882894 ,\n",
       "          0.88647175, 0.40392387, 0.64302233, 0.65068484, 0.41889672,\n",
       "          0.31954479, 0.42987459, 0.23039987, 1.71979642, 1.18238438]),\n",
       "   'mean_score_time': array([0.06316559, 0.0694809 , 0.08011929, 0.06216669, 0.08643595,\n",
       "          0.05385653, 0.06648819, 0.04022598, 0.06715417, 0.03823026,\n",
       "          0.0615023 , 0.05086374, 0.06648922, 0.05585027, 0.05784599,\n",
       "          0.07812524, 0.06416154, 0.05851126, 0.05285843, 0.06116947,\n",
       "          0.05186208, 0.07313712, 0.0445478 , 0.06116954, 0.05186232,\n",
       "          0.05784543, 0.03656785, 0.05285867, 0.06183235, 0.04488047]),\n",
       "   'std_score_time': array([0.00367242, 0.00093954, 0.00235022, 0.00261794, 0.00964666,\n",
       "          0.0008141 , 0.00490754, 0.00248808, 0.00235078, 0.00261811,\n",
       "          0.00169512, 0.00215465, 0.00169516, 0.00081449, 0.0029355 ,\n",
       "          0.00261706, 0.00204971, 0.00204951, 0.00141051, 0.00893305,\n",
       "          0.00373155, 0.00907983, 0.00204955, 0.00577713, 0.00293655,\n",
       "          0.00354968, 0.00046997, 0.0021542 , 0.00733168, 0.00215557]),\n",
       "   'param_solver': masked_array(data=['sgd', 'sgd', 'sgd', 'lbfgs', 'adam', 'lbfgs', 'lbfgs',\n",
       "                      'sgd', 'lbfgs', 'lbfgs', 'sgd', 'adam', 'lbfgs',\n",
       "                      'adam', 'sgd', 'lbfgs', 'lbfgs', 'sgd', 'adam', 'adam',\n",
       "                      'adam', 'lbfgs', 'lbfgs', 'adam', 'lbfgs', 'lbfgs',\n",
       "                      'sgd', 'sgd', 'adam', 'adam'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50, 50), (200, 50, 50), (200, 50, 50, 50),\n",
       "                      (200, 50, 50, 50), (200, 50, 50), (100, 100),\n",
       "                      (100, 100, 50), (100,), (100, 100, 50), (100,),\n",
       "                      (200, 50, 50, 50), (100, 100), (200, 50, 50),\n",
       "                      (200, 50, 50), (200, 50), (200, 50, 50, 50),\n",
       "                      (200, 50, 50), (200, 50, 50), (200, 50), (200, 50),\n",
       "                      (100, 100, 50), (200, 50, 50), (100,), (200, 50, 50),\n",
       "                      (100,), (100, 100), (100,), (200, 50), (200, 50, 50),\n",
       "                      (200, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0228, 0.0115, 0.007300000000000001,\n",
       "                      0.039900000000000005, 0.0461, 0.0241, 0.0218, 0.0183,\n",
       "                      0.0364, 0.019200000000000002, 0.03560000000000001,\n",
       "                      0.0039, 0.0292, 0.0284, 0.04460000000000001,\n",
       "                      0.026600000000000002, 0.0189, 0.041100000000000005,\n",
       "                      0.0171, 0.0252, 0.0144, 0.0118, 0.0168, 0.0143,\n",
       "                      0.03880000000000001, 0.042800000000000005,\n",
       "                      0.026000000000000002, 0.03610000000000001, 0.0196,\n",
       "                      0.0292],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['tanh', 'logistic', 'logistic', 'identity', 'logistic',\n",
       "                      'relu', 'logistic', 'tanh', 'relu', 'identity', 'tanh',\n",
       "                      'tanh', 'relu', 'identity', 'tanh', 'logistic', 'relu',\n",
       "                      'tanh', 'tanh', 'relu', 'identity', 'tanh', 'relu',\n",
       "                      'identity', 'logistic', 'tanh', 'identity', 'tanh',\n",
       "                      'relu', 'identity'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0228,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0115,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.007300000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.039900000000000005,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0461,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0241,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0218,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0183,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0364,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.019200000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.03560000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0039,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0292,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0284,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.04460000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.026600000000000002,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0189,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.041100000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0171,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0252,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0144,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0118,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0168,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0143,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.03880000000000001,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.042800000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.026000000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.03610000000000001,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0196,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0292,\n",
       "     'activation': 'identity'}],\n",
       "   'split0_test_Accuracy': array([0.61491574, 0.05593403, 0.05593403, 0.64826103, 0.67551094,\n",
       "          0.78200072, 0.74112585, 0.58443887, 0.78594478, 0.65328075,\n",
       "          0.61778415, 0.80781642, 0.78486913, 0.62065256, 0.6041592 ,\n",
       "          0.05593403, 0.78200072, 0.61384009, 0.79419147, 0.79705988,\n",
       "          0.6181427 , 0.7275009 , 0.78773754, 0.62674794, 0.76120473,\n",
       "          0.76980997, 0.59125134, 0.59770527, 0.77984941, 0.63463607]),\n",
       "   'split1_test_Accuracy': array([0.59992785, 0.05591631, 0.05591631, 0.6453824 , 0.66305916,\n",
       "          0.76587302, 0.73124098, 0.57575758, 0.76334776, 0.6468254 ,\n",
       "          0.62012987, 0.78607504, 0.77525253, 0.61399711, 0.59199134,\n",
       "          0.05591631, 0.77489177, 0.6002886 , 0.79148629, 0.78463203,\n",
       "          0.61760462, 0.71536797, 0.77561328, 0.62049062, 0.75901876,\n",
       "          0.7463925 , 0.58080808, 0.59235209, 0.78932179, 0.64105339]),\n",
       "   'split2_test_Accuracy': array([0.61427019, 0.05613908, 0.05613908, 0.65266208, 0.6754799 ,\n",
       "          0.77834118, 0.72473741, 0.57913799, 0.77001087, 0.65700833,\n",
       "          0.61825426, 0.80550525, 0.78015212, 0.62006519, 0.59797175,\n",
       "          0.05613908, 0.78486056, 0.60738863, 0.78160087, 0.79137993,\n",
       "          0.61861644, 0.71532054, 0.76675118, 0.62839551, 0.75624774,\n",
       "          0.75624774, 0.58638175, 0.60304238, 0.78160087, 0.63237957]),\n",
       "   'mean_test_Accuracy': array([0.6097092 , 0.05599615, 0.05599615, 0.64876232, 0.67135304,\n",
       "          0.77541456, 0.73239606, 0.57978851, 0.77313146, 0.65236722,\n",
       "          0.61872146, 0.79980774, 0.78010094, 0.61824081, 0.59805335,\n",
       "          0.05599615, 0.78058159, 0.60718577, 0.78911319, 0.79103581,\n",
       "          0.61812064, 0.71941841, 0.77673636, 0.62521029, 0.75883201,\n",
       "          0.75751021, 0.58615717, 0.59769286, 0.78358568, 0.63602499]),\n",
       "   'std_test_Accuracy': array([0.00691775, 0.00010097, 0.00010097, 0.00298916, 0.0058615 ,\n",
       "          0.00690682, 0.00674128, 0.00357774, 0.00949409, 0.00420189,\n",
       "          0.0010137 , 0.00975101, 0.00393071, 0.0030087 , 0.00497363,\n",
       "          0.00010097, 0.00418725, 0.00554067, 0.0054076 , 0.00508535,\n",
       "          0.00041281, 0.00573841, 0.00860576, 0.00340267, 0.00202832,\n",
       "          0.00961254, 0.00427135, 0.00435839, 0.00411645, 0.00367119]),\n",
       "   'rank_test_Accuracy': array([22, 28, 28, 16, 14,  8, 12, 27,  9, 15, 19,  1,  6, 20, 24, 28,  5,\n",
       "          23,  3,  2, 21, 13,  7, 18, 10, 11, 26, 25,  4, 17]),\n",
       "   'split0_train_Accuracy': array([0.64829207, 0.05602747, 0.05602747, 0.70684981, 0.73016447,\n",
       "          1.        , 1.        , 0.61395265, 1.        , 0.71389843,\n",
       "          0.65913609, 1.        , 1.        , 0.65389481, 0.63726731,\n",
       "          0.05602747, 1.        , 0.65696729, 0.99981927, 0.99746973,\n",
       "          0.66510031, 1.        , 1.        , 0.67251039, 1.        ,\n",
       "          1.        , 0.61666365, 0.63365263, 0.99801193, 0.68064341]),\n",
       "   'split1_train_Accuracy': array([0.65513514, 0.05603604, 0.05603604, 0.71207207, 0.73855856,\n",
       "          1.        , 1.        , 0.62108108, 1.        , 0.71891892,\n",
       "          0.67585586, 1.        , 1.        , 0.66522523, 0.64144144,\n",
       "          0.05603604, 1.        , 0.64810811, 0.99981982, 0.99873874,\n",
       "          0.67423423, 1.        , 1.        , 0.67171171, 1.        ,\n",
       "          1.        , 0.6227027 , 0.64144144, 0.99117117, 0.68576577]),\n",
       "   'split2_train_Accuracy': array([0.65941377, 0.05592519, 0.05592519, 0.70526884, 0.7466283 ,\n",
       "          1.        , 1.        , 0.61032188, 1.        , 0.71066355,\n",
       "          0.66283043, 1.        , 1.        , 0.6633699 , 0.63279986,\n",
       "          0.05592519, 1.        , 0.65222082, 0.99982018, 0.99658335,\n",
       "          0.65743571, 1.        , 1.        , 0.66840496, 1.        ,\n",
       "          1.        , 0.61373854, 0.63801475, 0.99478511, 0.67128214]),\n",
       "   'mean_train_Accuracy': array([0.65428033, 0.05599623, 0.05599623, 0.70806357, 0.73845044,\n",
       "          1.        , 1.        , 0.61511854, 1.        , 0.71449363,\n",
       "          0.66594079, 1.        , 1.        , 0.66082998, 0.63716953,\n",
       "          0.05599623, 1.        , 0.65243207, 0.99981975, 0.99759727,\n",
       "          0.66559008, 1.        , 1.        , 0.67087569, 1.        ,\n",
       "          1.        , 0.61770163, 0.63770294, 0.99465607, 0.67923044]),\n",
       "   'std_train_Accuracy': array([4.58047496e-03, 5.03546264e-05, 5.03546264e-05, 2.90699368e-03,\n",
       "          6.72176787e-03, 0.00000000e+00, 0.00000000e+00, 4.46912014e-03,\n",
       "          0.00000000e+00, 3.39641786e-03, 7.17139693e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.96205279e-03, 3.52858976e-03, 5.03546264e-05,\n",
       "          0.00000000e+00, 3.61982810e-03, 3.74404687e-07, 8.84544186e-04,\n",
       "          6.86670666e-03, 0.00000000e+00, 0.00000000e+00, 1.77723332e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.73248057e-03, 3.18740383e-03,\n",
       "          2.79421767e-03, 5.99673219e-03]),\n",
       "   'split0_test_F1': array([0.5938289 , 0.00592578, 0.00592578, 0.64030853, 0.66010044,\n",
       "          0.78104845, 0.73969011, 0.56809358, 0.7850778 , 0.64565608,\n",
       "          0.59786342, 0.80629931, 0.78393368, 0.60758399, 0.58624783,\n",
       "          0.00592578, 0.78071418, 0.59761849, 0.79153257, 0.79708265,\n",
       "          0.61228845, 0.72469329, 0.78805781, 0.61659853, 0.75708856,\n",
       "          0.76881636, 0.57661877, 0.57929157, 0.77833572, 0.6267727 ]),\n",
       "   'split1_test_F1': array([0.58345689, 0.00592212, 0.00592212, 0.64104533, 0.65084375,\n",
       "          0.76669818, 0.72815039, 0.55673263, 0.76232569, 0.64269727,\n",
       "          0.6026825 , 0.78590601, 0.77558611, 0.60494307, 0.57370752,\n",
       "          0.00592212, 0.7748897 , 0.58504375, 0.7920793 , 0.78539639,\n",
       "          0.61373123, 0.71409374, 0.77624509, 0.61499373, 0.7590764 ,\n",
       "          0.74489025, 0.56514739, 0.57259529, 0.78871715, 0.63554568]),\n",
       "   'split2_test_F1': array([0.59789909, 0.00596815, 0.00596815, 0.64495093, 0.66317281,\n",
       "          0.77846473, 0.72332685, 0.56156853, 0.76988328, 0.64891265,\n",
       "          0.59879337, 0.8050061 , 0.78130574, 0.61123075, 0.58171888,\n",
       "          0.00596815, 0.78485222, 0.59184031, 0.78289424, 0.79142623,\n",
       "          0.60863144, 0.71480791, 0.76649053, 0.61752905, 0.75694026,\n",
       "          0.75540161, 0.57018199, 0.58403446, 0.78155195, 0.62302241]),\n",
       "   'mean_test_F1': array([0.59172443, 0.00593862, 0.00593862, 0.64209417, 0.65803643,\n",
       "          0.77541127, 0.73041745, 0.56214451, 0.77245812, 0.64575096,\n",
       "          0.59977715, 0.79907739, 0.78028129, 0.60791421, 0.58056816,\n",
       "          0.00593862, 0.78014697, 0.5915129 , 0.78884873, 0.7913134 ,\n",
       "          0.61155574, 0.71788297, 0.77696767, 0.6163727 , 0.7577015 ,\n",
       "          0.75639611, 0.57066219, 0.57863464, 0.78286075, 0.62845068]),\n",
       "   'std_test_F1': array([6.07463193e-03, 2.08604460e-05, 2.08604460e-05, 2.03534386e-03,\n",
       "          5.23575248e-03, 6.24747522e-03, 6.87080944e-03, 4.66120020e-03,\n",
       "          9.47467147e-03, 2.53487706e-03, 2.08809663e-03, 9.32350228e-03,\n",
       "          3.48737978e-03, 2.57415798e-03, 5.18926463e-03, 2.08604460e-05,\n",
       "          4.08158776e-03, 5.14477792e-03, 4.20162093e-03, 4.77712164e-03,\n",
       "          2.14325262e-03, 4.84392644e-03, 8.82107396e-03, 1.04600116e-03,\n",
       "          9.73564763e-04, 9.80426155e-03, 4.70082481e-03, 4.68696206e-03,\n",
       "          4.34220574e-03, 5.24282464e-03]),\n",
       "   'rank_test_F1': array([22, 28, 28, 16, 14,  8, 12, 27,  9, 15, 21,  1,  5, 20, 24, 28,  6,\n",
       "          23,  3,  2, 19, 13,  7, 18, 10, 11, 26, 25,  4, 17]),\n",
       "   'split0_train_F1': array([0.63076506, 0.00594507, 0.00594507, 0.70136617, 0.71523323,\n",
       "          1.        , 1.        , 0.59951258, 1.        , 0.70821131,\n",
       "          0.64467892, 1.        , 1.        , 0.6422657 , 0.62214904,\n",
       "          0.00594507, 1.        , 0.64211213, 0.99981909, 0.99748825,\n",
       "          0.659699  , 1.        , 1.        , 0.66375741, 1.        ,\n",
       "          1.        , 0.60270778, 0.61834948, 0.99801257, 0.67329528]),\n",
       "   'split1_train_F1': array([0.63842292, 0.00594684, 0.00594684, 0.70725338, 0.72902331,\n",
       "          1.        , 1.        , 0.60467665, 1.        , 0.71388409,\n",
       "          0.65959695, 1.        , 1.        , 0.65726318, 0.62527162,\n",
       "          0.00594684, 1.        , 0.63272526, 0.9998198 , 0.99874565,\n",
       "          0.66785645, 1.        , 1.        , 0.66585511, 1.        ,\n",
       "          1.        , 0.60919967, 0.62462958, 0.99112442, 0.67860251]),\n",
       "   'split2_train_F1': array([0.64455566, 0.00592396, 0.00592396, 0.69831783, 0.73651547,\n",
       "          1.        , 1.        , 0.59476546, 1.        , 0.70480871,\n",
       "          0.64516087, 1.        , 1.        , 0.65466232, 0.6174086 ,\n",
       "          0.00592396, 1.        , 0.63706157, 0.99982018, 0.99657528,\n",
       "          0.64793194, 1.        , 1.        , 0.65841016, 1.        ,\n",
       "          1.        , 0.60078214, 0.62154285, 0.99482663, 0.6628224 ]),\n",
       "   'mean_train_F1': array([0.63791455, 0.00593862, 0.00593862, 0.70231246, 0.72692401,\n",
       "          1.        , 1.        , 0.59965156, 1.        , 0.70896803,\n",
       "          0.64981224, 1.        , 1.        , 0.65139707, 0.62160975,\n",
       "          0.00593862, 1.        , 0.63729965, 0.99981969, 0.99760306,\n",
       "          0.6584958 , 1.        , 1.        , 0.66267423, 1.        ,\n",
       "          1.        , 0.60422986, 0.6215073 , 0.99465454, 0.6715734 ]),\n",
       "   'std_train_F1': array([5.64145452e-03, 1.03944448e-05, 1.03944448e-05, 3.70878395e-03,\n",
       "          8.81433457e-03, 0.00000000e+00, 0.00000000e+00, 4.04742008e-03,\n",
       "          0.00000000e+00, 3.74344844e-03, 6.92162952e-03, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.54357197e-03, 3.23263369e-03, 1.03944448e-05,\n",
       "          0.00000000e+00, 3.83586895e-03, 4.49164116e-07, 8.89761158e-04,\n",
       "          8.17851825e-03, 0.00000000e+00, 0.00000000e+00, 3.13440710e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.60104384e-03, 2.56396259e-03,\n",
       "          2.81470944e-03, 6.55624804e-03]),\n",
       "   'split0_test_Log_Loss': array([-1.40099941, -3.61192932, -3.61209481, -1.35328825, -1.15693643,\n",
       "          -2.77444862, -1.85772851, -1.49814011, -2.86847793, -1.35637787,\n",
       "          -1.39214727, -0.8981437 , -3.22179268, -1.38109574, -1.44237942,\n",
       "          -3.61184917, -3.10019741, -1.40541892, -0.88024033, -1.02590459,\n",
       "          -1.37230012, -2.26096973, -2.66024922, -1.37019666, -1.47123034,\n",
       "          -1.53349955, -1.49408365, -1.43873672, -1.34873127, -1.32376564]),\n",
       "   'split1_test_Log_Loss': array([-1.44622032, -3.6119474 , -3.61209353, -1.38367381, -1.1537785 ,\n",
       "          -3.09705208, -1.80325909, -1.53610124, -3.32140413, -1.3635347 ,\n",
       "          -1.37446223, -0.95581127, -3.08515896, -1.40204065, -1.46501045,\n",
       "          -3.61184119, -3.23946695, -1.43328128, -0.89538554, -1.15250738,\n",
       "          -1.3894163 , -2.189866  , -2.87912134, -1.37525252, -1.49234441,\n",
       "          -1.76047014, -1.5471115 , -1.46327647, -1.16607197, -1.34494091]),\n",
       "   'split2_test_Log_Loss': array([-1.39055773, -3.61184424, -3.61182029, -1.3670035 , -1.13279059,\n",
       "          -2.77722881, -1.95666829, -1.52134447, -3.11363992, -1.36151087,\n",
       "          -1.37137853, -0.91012917, -2.89508674, -1.38022188, -1.440792  ,\n",
       "          -3.61155944, -3.11237198, -1.38222412, -0.91758897, -1.11742562,\n",
       "          -1.38140609, -2.27664074, -2.93694629, -1.3565903 , -1.42301217,\n",
       "          -1.60500449, -1.49923298, -1.42242848, -1.33018038, -1.35487064]),\n",
       "   'mean_test_Log_Loss': array([-1.41259793, -3.61190711, -3.61200331, -1.36795979, -1.14787365,\n",
       "          -2.88282796, -1.8724105 , -1.51848324, -3.10068217, -1.36046474,\n",
       "          -1.37936604, -0.9213288 , -3.06788932, -1.38778242, -1.449391  ,\n",
       "          -3.61175039, -3.15062629, -1.40700431, -0.8976763 , -1.09843914,\n",
       "          -1.3810225 , -2.24248476, -2.82495411, -1.36736653, -1.46226589,\n",
       "          -1.63282514, -1.51345525, -1.44150014, -1.28173408, -1.34113872]),\n",
       "   'std_test_Log_Loss': array([2.41412305e-02, 4.49171282e-05, 1.28960779e-04, 1.24375827e-02,\n",
       "          1.07059604e-02, 1.51401676e-01, 6.34068916e-02, 1.56460759e-02,\n",
       "          1.85347013e-01, 3.01661911e-03, 9.16104993e-03, 2.48561392e-02,\n",
       "          1.33956637e-01, 1.00829555e-02, 1.10576624e-02, 1.34585524e-04,\n",
       "          6.29823503e-02, 2.08461703e-02, 1.53357645e-02, 5.34470912e-02,\n",
       "          7.00102153e-03, 3.77334639e-02, 1.19289335e-01, 7.86934560e-03,\n",
       "          2.89740943e-02, 9.48169801e-02, 2.38784406e-02, 1.67687023e-02,\n",
       "          8.20914482e-02, 1.29818336e-02]),\n",
       "   'rank_test_Log_Loss': array([14, 29, 30,  9,  4, 24, 21, 19, 26,  7, 10,  2, 25, 12, 16, 28, 27,\n",
       "          13,  1,  3, 11, 22, 23,  8, 17, 20, 18, 15,  5,  6]),\n",
       "   'split0_train_Log_Loss': array([-1.27770138e+00, -3.61182052e+00, -3.61195334e+00, -9.82833612e-01,\n",
       "          -9.54345377e-01, -3.57450067e-04, -3.21675236e-03, -1.39683434e+00,\n",
       "          -2.98507537e-04, -9.50688781e-01, -1.24633198e+00, -2.05444821e-02,\n",
       "          -2.78006172e-04, -1.13778763e+00, -1.32560246e+00, -3.61169615e+00,\n",
       "          -1.78881803e-04, -1.26955949e+00, -3.48644494e-02, -3.93196259e-02,\n",
       "          -1.12176268e+00, -1.84554991e-03, -1.48752196e-03, -1.12835089e+00,\n",
       "          -1.66337580e-02, -2.76435732e-03, -1.35152843e+00, -1.31579359e+00,\n",
       "          -3.27983855e-02, -1.07744002e+00]),\n",
       "   'split1_train_Log_Loss': array([-1.27505157e+00, -3.61174469e+00, -3.61196389e+00, -9.63949016e-01,\n",
       "          -9.25411946e-01, -3.69974518e-04, -4.13135541e-03, -1.38499410e+00,\n",
       "          -3.14611707e-04, -9.31530110e-01, -1.21033023e+00, -1.93929947e-02,\n",
       "          -1.58334819e-04, -1.12518891e+00, -1.30873225e+00, -3.61167695e+00,\n",
       "          -2.17508187e-04, -1.28623631e+00, -3.24470923e-02, -2.87282878e-02,\n",
       "          -1.07862613e+00, -2.67467485e-03, -1.50565831e-03, -1.07978564e+00,\n",
       "          -1.67005212e-02, -2.88042944e-03, -1.33539377e+00, -1.30537743e+00,\n",
       "          -6.52656246e-02, -1.03653469e+00]),\n",
       "   'split2_train_Log_Loss': array([-1.26204414e+00, -3.61214907e+00, -3.61212995e+00, -9.81122356e-01,\n",
       "          -9.06959194e-01, -3.72888360e-04, -4.80202457e-03, -1.40815778e+00,\n",
       "          -2.51623185e-04, -9.46716771e-01, -1.24417923e+00, -2.08441915e-02,\n",
       "          -2.24278736e-04, -1.12455868e+00, -1.31668436e+00, -3.61184848e+00,\n",
       "          -1.57381789e-04, -1.25628966e+00, -3.22825203e-02, -5.55872839e-02,\n",
       "          -1.12495993e+00, -1.96612115e-03, -1.47091195e-03, -1.09567706e+00,\n",
       "          -1.65014731e-02, -2.18049341e-03, -1.34911765e+00, -1.30033580e+00,\n",
       "          -4.34481833e-02, -1.10171406e+00]),\n",
       "   'mean_train_Log_Loss': array([-1.27159903e+00, -3.61190476e+00, -3.61201573e+00, -9.75968328e-01,\n",
       "          -9.28905506e-01, -3.66770982e-04, -4.05004411e-03, -1.39666207e+00,\n",
       "          -2.88247476e-04, -9.42978554e-01, -1.23361381e+00, -2.02605561e-02,\n",
       "          -2.20206576e-04, -1.12917841e+00, -1.31700636e+00, -3.61174053e+00,\n",
       "          -1.84590593e-04, -1.27069515e+00, -3.31980207e-02, -4.12117325e-02,\n",
       "          -1.10844958e+00, -2.16211530e-03, -1.48803074e-03, -1.10127120e+00,\n",
       "          -1.66119174e-02, -2.60842672e-03, -1.34534662e+00, -1.30716894e+00,\n",
       "          -4.71707311e-02, -1.07189626e+00]),\n",
       "   'std_train_Log_Loss': array([6.84238153e-03, 1.75504137e-04, 8.08849483e-05, 8.52760194e-03,\n",
       "          1.95024153e-02, 6.69737287e-06, 6.49733606e-04, 9.45731751e-03,\n",
       "          2.67187841e-05, 8.25608328e-03, 1.64874195e-02, 6.25541654e-04,\n",
       "          4.89404066e-05, 6.09307385e-03, 6.89099743e-03, 7.67350272e-05,\n",
       "          2.48762088e-05, 1.22520135e-02, 1.18025688e-03, 1.10464616e-02,\n",
       "          2.11287202e-02, 3.65761603e-04, 1.41897015e-05, 2.02174278e-02,\n",
       "          8.27155687e-05, 3.06282414e-04, 7.10620947e-03, 6.43650931e-03,\n",
       "          1.35135346e-02, 2.68965616e-02])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (200, 50),\n",
       "   'alpha': 0.0171,\n",
       "   'activation': 'tanh'},\n",
       "  18,\n",
       "  -0.89767629588089),\n",
       " 'LogisticRegression_V09_PCA_5components': ({'mean_fit_time': array([0.09640487, 0.26861008, 0.0930841 , 0.59407822, 0.48304192,\n",
       "          0.3121655 , 0.32047645, 0.09906824, 0.20910748, 0.78855856,\n",
       "          0.68383861, 0.08111548, 0.99101679, 0.08743246, 0.80850538,\n",
       "          0.28390733, 0.08710082, 0.23603495, 0.43284241, 0.48237673,\n",
       "          0.08876228, 0.12333647, 0.80119181, 0.0874331 , 0.85305254,\n",
       "          0.07579764, 0.35637967, 0.10438649, 0.11735185, 0.34939885]),\n",
       "   'std_fit_time': array([0.00448002, 0.00621464, 0.00611194, 0.04504861, 0.00658229,\n",
       "          0.01976376, 0.00803469, 0.00285971, 0.00204894, 0.00497535,\n",
       "          0.01581876, 0.00124343, 0.03195991, 0.00248825, 0.02010104,\n",
       "          0.01272902, 0.00235067, 0.00401731, 0.02895151, 0.05608978,\n",
       "          0.00141023, 0.00542189, 0.03416631, 0.00188093, 0.01581867,\n",
       "          0.00162849, 0.03038543, 0.00577742, 0.00047008, 0.00823767]),\n",
       "   'mean_score_time': array([0.05817795, 0.03623684, 0.03191463, 0.03357712, 0.03257958,\n",
       "          0.04355033, 0.04089038, 0.03025238, 0.02726046, 0.02593112,\n",
       "          0.02958822, 0.02659583, 0.02659575, 0.02726062, 0.02792517,\n",
       "          0.0299201 , 0.02991954, 0.0445474 , 0.07579788, 0.02925571,\n",
       "          0.03124952, 0.02925507, 0.03058457, 0.02825761, 0.03224715,\n",
       "          0.02925491, 0.05152965, 0.0418884 , 0.02892303, 0.02559813]),\n",
       "   'std_score_time': array([0.01316458, 0.00964668, 0.00081459, 0.00799245, 0.00308254,\n",
       "          0.01502353, 0.00977243, 0.00124435, 0.00046991, 0.00081449,\n",
       "          0.00204889, 0.00094004, 0.00046997, 0.00047013, 0.00081439,\n",
       "          0.00081449, 0.00162859, 0.01934493, 0.0186588 , 0.00261796,\n",
       "          0.00339045, 0.00261822, 0.00448492, 0.00169539, 0.00497543,\n",
       "          0.00124401, 0.01617017, 0.01340557, 0.000814  , 0.00046991]),\n",
       "   'param_C': masked_array(data=[0.03404540317008553, 0.8138203067611219,\n",
       "                      0.13299823048350254, 0.07156923276592718,\n",
       "                      0.31482004999939184, 0.30247559657297185,\n",
       "                      0.29672614531326097, 0.2799774938074519,\n",
       "                      0.5594444713706584, 0.12092100144533023,\n",
       "                      0.40347675303882957, 0.02323976128170535,\n",
       "                      0.2582013999945038, 0.055283599025984724,\n",
       "                      0.028930598179639513, 0.1713993994948344,\n",
       "                      0.2034979038445171, 0.35127233930833357,\n",
       "                      0.7273942833585647, 0.3966193340705995,\n",
       "                      0.2349651200281367, 0.095905668807507,\n",
       "                      0.008107260809007208, 0.09332150427983399,\n",
       "                      0.0913329371946428, 0.3296245934248145,\n",
       "                      0.1562019952478574, 0.3729070831961557,\n",
       "                      0.31260217447454214, 0.10903677836221182],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_class_weight': masked_array(data=['balanced', None, None, None, 'balanced', 'balanced',\n",
       "                      None, 'balanced', 'balanced', 'balanced', None, None,\n",
       "                      'balanced', 'balanced', None, None, None, None,\n",
       "                      'balanced', None, 'balanced', 'balanced', 'balanced',\n",
       "                      None, None, 'balanced', None, None, 'balanced',\n",
       "                      'balanced'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                      'l2', 'l2', 'l2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'saga',\n",
       "                      'saga', 'saga', 'liblinear', 'saga', 'newton-cg',\n",
       "                      'newton-cg', 'liblinear', 'newton-cg', 'liblinear',\n",
       "                      'newton-cg', 'saga', 'liblinear', 'saga', 'saga',\n",
       "                      'saga', 'liblinear', 'liblinear', 'newton-cg',\n",
       "                      'liblinear', 'newton-cg', 'liblinear', 'saga',\n",
       "                      'liblinear', 'liblinear', 'saga'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_tol': masked_array(data=[0.22041388489421201, 0.3190187241458926,\n",
       "                      0.45027587129485, 0.039305045383961096,\n",
       "                      0.03865357657698106, 0.7046670675302469,\n",
       "                      0.26252095632185396, 0.25505947441830157,\n",
       "                      1.0780313531559464, 0.24862943157055067,\n",
       "                      0.7081131682707159, 0.08081510399310901,\n",
       "                      0.02715832838108197, 0.1829671330718848,\n",
       "                      0.07425191361020177, 0.23193975825544888,\n",
       "                      0.4866828721091272, 0.561298478350305,\n",
       "                      0.0829496648919104, 0.0656885026618198,\n",
       "                      0.6103757209180944, 0.012849873393623807,\n",
       "                      0.06365632404050231, 0.25107209533659797,\n",
       "                      0.3817312637889041, 1.0012268312478707,\n",
       "                      0.11384715530258566, 0.26067208583359797,\n",
       "                      0.06856857573375569, 0.0859051100612026],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 0.03404540317008553,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.22041388489421201},\n",
       "    {'C': 0.8138203067611219,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.3190187241458926},\n",
       "    {'C': 0.13299823048350254,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.45027587129485},\n",
       "    {'C': 0.07156923276592718,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.039305045383961096},\n",
       "    {'C': 0.31482004999939184,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.03865357657698106},\n",
       "    {'C': 0.30247559657297185,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.7046670675302469},\n",
       "    {'C': 0.29672614531326097,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.26252095632185396},\n",
       "    {'C': 0.2799774938074519,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.25505947441830157},\n",
       "    {'C': 0.5594444713706584,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 1.0780313531559464},\n",
       "    {'C': 0.12092100144533023,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.24862943157055067},\n",
       "    {'C': 0.40347675303882957,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.7081131682707159},\n",
       "    {'C': 0.02323976128170535,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.08081510399310901},\n",
       "    {'C': 0.2582013999945038,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.02715832838108197},\n",
       "    {'C': 0.055283599025984724,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.1829671330718848},\n",
       "    {'C': 0.028930598179639513,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.07425191361020177},\n",
       "    {'C': 0.1713993994948344,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.23193975825544888},\n",
       "    {'C': 0.2034979038445171,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.4866828721091272},\n",
       "    {'C': 0.35127233930833357,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.561298478350305},\n",
       "    {'C': 0.7273942833585647,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0829496648919104},\n",
       "    {'C': 0.3966193340705995,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0656885026618198},\n",
       "    {'C': 0.2349651200281367,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.6103757209180944},\n",
       "    {'C': 0.095905668807507,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.012849873393623807},\n",
       "    {'C': 0.008107260809007208,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.06365632404050231},\n",
       "    {'C': 0.09332150427983399,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.25107209533659797},\n",
       "    {'C': 0.0913329371946428,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'newton-cg',\n",
       "     'tol': 0.3817312637889041},\n",
       "    {'C': 0.3296245934248145,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 1.0012268312478707},\n",
       "    {'C': 0.1562019952478574,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.11384715530258566},\n",
       "    {'C': 0.3729070831961557,\n",
       "     'class_weight': None,\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.26067208583359797},\n",
       "    {'C': 0.31260217447454214,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'liblinear',\n",
       "     'tol': 0.06856857573375569},\n",
       "    {'C': 0.10903677836221182,\n",
       "     'class_weight': 'balanced',\n",
       "     'penalty': 'l2',\n",
       "     'solver': 'saga',\n",
       "     'tol': 0.0859051100612026}],\n",
       "   'split0_test_Accuracy': array([0.19074937, 0.20509143, 0.22373611, 0.22050914, 0.22517031,\n",
       "          0.21548942, 0.19971316, 0.23951237, 0.18680531, 0.22660452,\n",
       "          0.2481176 , 0.20043026, 0.22875583, 0.20150592, 0.22337755,\n",
       "          0.20150592, 0.22624597, 0.184654  , 0.21692363, 0.21979204,\n",
       "          0.21835783, 0.223019  , 0.21548942, 0.22696307, 0.24130513,\n",
       "          0.20509143, 0.20831839, 0.24058802, 0.24919326, 0.22050914]),\n",
       "   'split1_test_Accuracy': array([0.19047619, 0.2034632 , 0.21103896, 0.22222222, 0.22835498,\n",
       "          0.21608947, 0.20743146, 0.23556999, 0.21067821, 0.22546898,\n",
       "          0.25108225, 0.18939394, 0.22619048, 0.20815296, 0.22186147,\n",
       "          0.20454545, 0.21320346, 0.20707071, 0.21825397, 0.22041847,\n",
       "          0.22113997, 0.22510823, 0.21608947, 0.21500722, 0.23701299,\n",
       "          0.20562771, 0.21067821, 0.22943723, 0.24278499, 0.22258297]),\n",
       "   'split2_test_Accuracy': array([0.20101413, 0.20210069, 0.23071351, 0.2281782 , 0.22129663,\n",
       "          0.22600507, 0.19775444, 0.24664976, 0.18797537, 0.24049258,\n",
       "          0.25679102, 0.20065194, 0.24339008, 0.21477725, 0.23650851,\n",
       "          0.19413256, 0.23180007, 0.1752988 , 0.23288664, 0.21984788,\n",
       "          0.23143788, 0.23324882, 0.22274538, 0.22745382, 0.24628758,\n",
       "          0.21079319, 0.21187975, 0.24447664, 0.25787758, 0.20898225]),\n",
       "   'mean_test_Accuracy': array([0.19406393, 0.20355684, 0.22182168, 0.22362413, 0.22494593,\n",
       "          0.21917808, 0.20163422, 0.24056717, 0.1951454 , 0.23083393,\n",
       "          0.2519827 , 0.19682769, 0.23275655, 0.20812305, 0.22722903,\n",
       "          0.2000721 , 0.22374429, 0.18901706, 0.22266282, 0.22001923,\n",
       "          0.22362413, 0.22710887, 0.21809661, 0.22314348, 0.24152848,\n",
       "          0.20716174, 0.21028599, 0.2381639 , 0.24993992, 0.21737563]),\n",
       "   'std_test_Accuracy': array([0.00489854, 0.00122296, 0.00813556, 0.0032844 , 0.00288206,\n",
       "          0.0048167 , 0.00417438, 0.00457883, 0.01098781, 0.00682151,\n",
       "          0.00359822, 0.00525439, 0.00756564, 0.00541895, 0.00656783,\n",
       "          0.00436563, 0.00778701, 0.0133185 , 0.00722442, 0.00028308,\n",
       "          0.00562195, 0.00440982, 0.0032848 , 0.00575358, 0.00378453,\n",
       "          0.00256817, 0.00148035, 0.00636846, 0.00617597, 0.0059746 ]),\n",
       "   'rank_test_Accuracy': array([29, 24, 16, 12, 10, 18, 25,  4, 28,  7,  1, 27,  6, 22,  8, 26, 11,\n",
       "          30, 15, 17, 12,  9, 19, 14,  3, 23, 21,  5,  2, 20]),\n",
       "   'split0_train_Accuracy': array([0.19736129, 0.20730164, 0.2289897 , 0.22429062, 0.22826676,\n",
       "          0.20965118, 0.19916862, 0.24019519, 0.18236038, 0.23423098,\n",
       "          0.25320802, 0.19609615, 0.23405024, 0.21145852, 0.23151997,\n",
       "          0.20151816, 0.23097777, 0.18145671, 0.21416953, 0.22537502,\n",
       "          0.22627869, 0.2306163 , 0.21977228, 0.23043557, 0.24597867,\n",
       "          0.20748238, 0.20910898, 0.24254473, 0.25212362, 0.22248328]),\n",
       "   'split1_train_Accuracy': array([0.19315315, 0.22108108, 0.22486486, 0.2354955 , 0.24306306,\n",
       "          0.22306306, 0.22144144, 0.24882883, 0.22144144, 0.24198198,\n",
       "          0.26468468, 0.20054054, 0.24486486, 0.21081081, 0.23693694,\n",
       "          0.21765766, 0.22900901, 0.22      , 0.23441441, 0.23405405,\n",
       "          0.22810811, 0.23297297, 0.22468468, 0.22630631, 0.25405405,\n",
       "          0.20990991, 0.22378378, 0.24648649, 0.26054054, 0.23387387]),\n",
       "   'split2_train_Accuracy': array([0.19241144, 0.20356051, 0.22531919, 0.22442007, 0.21542888,\n",
       "          0.21506923, 0.19978421, 0.23988491, 0.19402985, 0.2231613 ,\n",
       "          0.24851645, 0.20050351, 0.22477972, 0.2087754 , 0.23179284,\n",
       "          0.19672721, 0.22801654, 0.1792843 , 0.22190254, 0.22118324,\n",
       "          0.22459989, 0.22711742, 0.21381047, 0.22711742, 0.24366121,\n",
       "          0.20643769, 0.21147276, 0.24240245, 0.24905593, 0.20643769]),\n",
       "   'mean_train_Accuracy': array([0.19430863, 0.21064775, 0.22639125, 0.22806873, 0.22891957,\n",
       "          0.21592783, 0.20679809, 0.24296964, 0.19927723, 0.23312475,\n",
       "          0.25546972, 0.19904673, 0.23456494, 0.21034824, 0.23341658,\n",
       "          0.20530101, 0.22933444, 0.19358034, 0.22349549, 0.22687077,\n",
       "          0.2263289 , 0.23023557, 0.21942248, 0.2279531 , 0.24789798,\n",
       "          0.20794333, 0.21478851, 0.24381122, 0.2539067 , 0.22093162]),\n",
       "   'std_train_Accuracy': array([0.00217969, 0.00753392, 0.00184672, 0.00525178, 0.01129105,\n",
       "          0.00550893, 0.01035746, 0.004145  , 0.01638055, 0.00772322,\n",
       "          0.00679163, 0.00208643, 0.0082078 , 0.00114317, 0.00249176,\n",
       "          0.00895371, 0.00123062, 0.01870256, 0.00834134, 0.00535988,\n",
       "          0.00143266, 0.00240563, 0.00444627, 0.00178633, 0.00445463,\n",
       "          0.00145452, 0.00643341, 0.00189259, 0.00485514, 0.01125439]),\n",
       "   'split0_test_F1': array([0.12905573, 0.13852471, 0.15715803, 0.15753985, 0.1937964 ,\n",
       "          0.18432866, 0.13654197, 0.18391432, 0.15316827, 0.19693147,\n",
       "          0.19480236, 0.13325535, 0.19808409, 0.14064145, 0.16586266,\n",
       "          0.13872939, 0.1598443 , 0.11268071, 0.18189745, 0.15396388,\n",
       "          0.16291865, 0.16615732, 0.18002385, 0.16063324, 0.18639933,\n",
       "          0.13843545, 0.14182711, 0.17922302, 0.19538686, 0.18880927]),\n",
       "   'split1_test_F1': array([0.1300784 , 0.13580126, 0.1478558 , 0.16400065, 0.19668758,\n",
       "          0.18080683, 0.14101332, 0.18184584, 0.17966558, 0.19440471,\n",
       "          0.20256158, 0.12207833, 0.19395748, 0.15009725, 0.16514078,\n",
       "          0.14189986, 0.1497198 , 0.14259274, 0.18762736, 0.16225254,\n",
       "          0.16627888, 0.17204083, 0.18477838, 0.14953984, 0.18440116,\n",
       "          0.14236144, 0.1501179 , 0.17196678, 0.19269664, 0.19079498]),\n",
       "   'split2_test_F1': array([0.1424812 , 0.13857104, 0.17283938, 0.17126054, 0.19241234,\n",
       "          0.19186356, 0.13528842, 0.19359672, 0.14426338, 0.20979978,\n",
       "          0.20753455, 0.13804466, 0.21279831, 0.15839224, 0.18472433,\n",
       "          0.1311366 , 0.17381669, 0.10859189, 0.19754788, 0.16130793,\n",
       "          0.17876316, 0.17909159, 0.19158317, 0.16891584, 0.19570679,\n",
       "          0.14780223, 0.15042359, 0.18923503, 0.20711785, 0.17346795]),\n",
       "   'mean_test_F1': array([0.13385056, 0.13763292, 0.15926214, 0.16424403, 0.19430024,\n",
       "          0.18565543, 0.13761545, 0.18643767, 0.15903995, 0.20035916,\n",
       "          0.20161108, 0.13112132, 0.2015913 , 0.14968031, 0.17187996,\n",
       "          0.13726638, 0.16110753, 0.12128765, 0.1889984 , 0.15916132,\n",
       "          0.16929467, 0.17240829, 0.1854426 , 0.15968604, 0.1888217 ,\n",
       "          0.1428508 , 0.14744078, 0.18012771, 0.19838277, 0.18438089]),\n",
       "   'std_test_F1': array([0.0060957 , 0.00129462, 0.01029465, 0.00560503, 0.00177932,\n",
       "          0.00460515, 0.0024553 , 0.00511479, 0.01502328, 0.00673177,\n",
       "          0.00524199, 0.0066834 , 0.00807483, 0.00725393, 0.00905524,\n",
       "          0.00450939, 0.00986504, 0.01514911, 0.00646338, 0.0037101 ,\n",
       "          0.00681161, 0.00528766, 0.00474315, 0.00792808, 0.00491966,\n",
       "          0.00384021, 0.00398752, 0.00706942, 0.00625238, 0.00773222]),\n",
       "   'rank_test_F1': array([28, 25, 19, 16,  5,  9, 26,  8, 21,  3,  1, 29,  2, 22, 14, 27, 17,\n",
       "          30,  6, 20, 15, 13, 10, 18,  7, 24, 23, 12,  4, 11]),\n",
       "   'split0_train_F1': array([0.13734407, 0.14281686, 0.16546754, 0.16291761, 0.19764579,\n",
       "          0.179487  , 0.13517472, 0.18645525, 0.14759699, 0.20411525,\n",
       "          0.20237221, 0.12889961, 0.20284926, 0.15294968, 0.17588484,\n",
       "          0.13847701, 0.16821868, 0.11079437, 0.18037991, 0.1611477 ,\n",
       "          0.17056433, 0.17462561, 0.18657365, 0.16661877, 0.19173439,\n",
       "          0.14326982, 0.14473518, 0.1823482 , 0.19927522, 0.19216991]),\n",
       "   'split1_train_F1': array([0.13182965, 0.15058945, 0.15661233, 0.17348475, 0.21067242,\n",
       "          0.18982952, 0.1533705 , 0.19254797, 0.1882101 , 0.21027112,\n",
       "          0.21257297, 0.12850155, 0.21266708, 0.15262837, 0.17868631,\n",
       "          0.15409599, 0.16204939, 0.15252928, 0.20316   , 0.1707494 ,\n",
       "          0.17167673, 0.17640608, 0.19241527, 0.15858538, 0.19755649,\n",
       "          0.14511948, 0.1600406 , 0.18360112, 0.20702432, 0.20196573]),\n",
       "   'split2_train_F1': array([0.13318028, 0.14030483, 0.16647809, 0.16741971, 0.1850241 ,\n",
       "          0.18379865, 0.13656586, 0.18717189, 0.15250029, 0.19275782,\n",
       "          0.19773245, 0.13608025, 0.19453473, 0.15194604, 0.17922808,\n",
       "          0.13384388, 0.16975781, 0.11103049, 0.18822706, 0.16071405,\n",
       "          0.17261034, 0.17419287, 0.18019807, 0.16734736, 0.19175998,\n",
       "          0.14456193, 0.14820684, 0.18708937, 0.19825051, 0.17017955]),\n",
       "   'mean_train_F1': array([0.134118  , 0.14457038, 0.16285265, 0.16794069, 0.19778077,\n",
       "          0.18437172, 0.14170369, 0.18872503, 0.16276913, 0.2023814 ,\n",
       "          0.20422588, 0.13116047, 0.20335035, 0.15250803, 0.17793308,\n",
       "          0.14213896, 0.16667529, 0.12478472, 0.19058899, 0.16420372,\n",
       "          0.17161713, 0.17507485, 0.18639566, 0.16418383, 0.19368362,\n",
       "          0.14431708, 0.1509942 , 0.18434623, 0.20151668, 0.18810507]),\n",
       "   'std_train_F1': array([0.00234687, 0.00437794, 0.00443182, 0.00432972, 0.01047132,\n",
       "          0.00424172, 0.0082692 , 0.00271901, 0.01810051, 0.00725413,\n",
       "          0.00619878, 0.00348261, 0.00741098, 0.00041848, 0.00146511,\n",
       "          0.00866389, 0.00333081, 0.01961861, 0.00944871, 0.00463188,\n",
       "          0.00083634, 0.00095775, 0.00498924, 0.00396987, 0.00273855,\n",
       "          0.00077471, 0.0065519 , 0.002006  , 0.00391689, 0.01329116]),\n",
       "   'split0_test_Log_Loss': array([-3.05065764, -2.99786466, -2.88505457, -2.86883699, -2.88830342,\n",
       "          -2.92891771, -2.98836507, -2.82277002, -2.97493553, -2.86796091,\n",
       "          -2.6991501 , -3.09668633, -2.86059571, -2.97916988, -2.83431604,\n",
       "          -2.98795243, -2.86196541, -3.0500939 , -2.90271076, -2.87671783,\n",
       "          -2.87561883, -2.88602066, -2.97508191, -2.89614265, -2.74673287,\n",
       "          -2.96202956, -2.93200603, -2.78847573, -2.7853348 , -2.90849779]),\n",
       "   'split1_test_Log_Loss': array([-3.04760783, -2.90085716, -2.8861832 , -2.83404155, -2.88823493,\n",
       "          -2.907095  , -2.88277241, -2.82476233, -2.9378206 , -2.88206925,\n",
       "          -2.70664169, -3.09463371, -2.87493621, -2.9774447 , -2.83758851,\n",
       "          -2.8922035 , -2.86375429, -2.91689067, -2.89515367, -2.82760934,\n",
       "          -2.87503718, -2.88621643, -2.98440063, -2.89822839, -2.75322189,\n",
       "          -2.95900941, -2.86412474, -2.79282871, -2.7859894 , -2.90062511]),\n",
       "   'split2_test_Log_Loss': array([-3.04352717, -2.99872604, -2.87987215, -2.86341905, -2.88819426,\n",
       "          -2.92397938, -2.98017128, -2.8199448 , -2.97750133, -2.86891323,\n",
       "          -2.6992412 , -3.09075597, -2.86139209, -2.97260205, -2.83041552,\n",
       "          -2.9783461 , -2.85694288, -3.04835618, -2.89908896, -2.87014862,\n",
       "          -2.86889851, -2.8813562 , -2.97442379, -2.89105746, -2.7458489 ,\n",
       "          -2.96604953, -2.92655149, -2.7855881 , -2.78264485, -2.91088061]),\n",
       "   'mean_test_Log_Loss': array([-3.04727609, -2.96583792, -2.88371113, -2.85544936, -2.88824439,\n",
       "          -2.92001032, -2.95047443, -2.82249632, -2.96342407, -2.87297625,\n",
       "          -2.70167572, -3.09403509, -2.86563665, -2.97641622, -2.834112  ,\n",
       "          -2.95287202, -2.86089494, -3.00514831, -2.89899194, -2.85818066,\n",
       "          -2.87319548, -2.88453834, -2.97796757, -2.89515028, -2.74860104,\n",
       "          -2.96235728, -2.90758559, -2.78896764, -2.78466039, -2.90666601]),\n",
       "   'std_test_Log_Loss': array([2.92091423e-03, 4.59248411e-02, 2.74408367e-03, 1.52903009e-02,\n",
       "          4.50719152e-05, 9.34764437e-03, 4.79635016e-02, 1.97367448e-03,\n",
       "          1.81248960e-02, 6.43800009e-03, 3.50976900e-03, 2.45814589e-03,\n",
       "          6.58027202e-03, 2.77851152e-03, 2.92798148e-03, 4.30549752e-02,\n",
       "          2.87910030e-03, 6.23778663e-02, 3.08952449e-03, 2.17713701e-02,\n",
       "          3.03706100e-03, 2.24363566e-03, 4.55433735e-03, 3.00725301e-03,\n",
       "          3.28555307e-03, 2.87963980e-03, 3.07954870e-02, 2.97255298e-03,\n",
       "          1.44517927e-03, 4.37870996e-03]),\n",
       "   'rank_test_Log_Loss': array([29, 25, 13,  7, 15, 20, 21,  5, 24, 11,  1, 30, 10, 26,  6, 22,  9,\n",
       "          28, 17,  8, 12, 14, 27, 16,  2, 23, 19,  4,  3, 18]),\n",
       "   'split0_train_Log_Loss': array([-3.0459507 , -2.99412873, -2.88017702, -2.86476969, -2.88832849,\n",
       "          -2.92835092, -2.98351849, -2.81619338, -2.9737854 , -2.86596467,\n",
       "          -2.69327808, -3.09340045, -2.85807016, -2.97413853, -2.83004921,\n",
       "          -2.98371438, -2.85690333, -3.04556665, -2.9016984 , -2.87290541,\n",
       "          -2.86885772, -2.88104089, -2.97376815, -2.89235607, -2.74236294,\n",
       "          -2.95620593, -2.92793301, -2.78415039, -2.77975674, -2.90873587]),\n",
       "   'split1_train_Log_Loss': array([-3.02805963, -2.8717726 , -2.85852744, -2.80152738, -2.85763567,\n",
       "          -2.87892956, -2.85364878, -2.79317285, -2.90918508, -2.8516326 ,\n",
       "          -2.66266219, -3.07681506, -2.84382983, -2.95462209, -2.80595863,\n",
       "          -2.86245106, -2.83469637, -2.889143  , -2.86540704, -2.79368767,\n",
       "          -2.84750639, -2.85821498, -2.96165059, -2.87063546, -2.71444355,\n",
       "          -2.93560797, -2.83219982, -2.75848862, -2.7506889 , -2.87304924]),\n",
       "   'split2_train_Log_Loss': array([-3.04442843, -2.99800795, -2.87962121, -2.86286066, -2.8819036 ,\n",
       "          -2.92221442, -2.98092106, -2.81949927, -2.97436364, -2.86179393,\n",
       "          -2.69819806, -3.09157039, -2.8539463 , -2.97300562, -2.83030996,\n",
       "          -2.97863082, -2.85655838, -3.04936802, -2.89395881, -2.86905919,\n",
       "          -2.86871964, -2.88100381, -2.97122837, -2.89139071, -2.74490326,\n",
       "          -2.96820581, -2.92667704, -2.78590711, -2.78155664, -2.90525176]),\n",
       "   'mean_train_Log_Loss': array([-3.03947959, -2.95463643, -2.87277522, -2.84305258, -2.87595592,\n",
       "          -2.90983163, -2.93936278, -2.80962183, -2.95244471, -2.85979706,\n",
       "          -2.68471277, -3.08726197, -2.85194876, -2.96725541, -2.82210593,\n",
       "          -2.94159875, -2.84938603, -2.99469256, -2.88702142, -2.84521742,\n",
       "          -2.86169458, -2.87341989, -2.96888237, -2.88479408, -2.73390325,\n",
       "          -2.95333991, -2.89560329, -2.77618204, -2.77066743, -2.89567896]),\n",
       "   'std_train_Log_Loss': array([0.00809901, 0.05861497, 0.01007726, 0.02937309, 0.01321725,\n",
       "          0.02199421, 0.06061822, 0.01170923, 0.03059009, 0.006019  ,\n",
       "          0.01572096, 0.00742477, 0.00598272, 0.00894507, 0.01141837,\n",
       "          0.05600434, 0.01038811, 0.07465094, 0.01560686, 0.03647086,\n",
       "          0.01003273, 0.01075151, 0.0052177 , 0.01001941, 0.01379911,\n",
       "          0.01346144, 0.04483596, 0.01253168, 0.01414605, 0.01606472])},\n",
       "  {'C': 0.40347675303882957,\n",
       "   'class_weight': None,\n",
       "   'penalty': 'l2',\n",
       "   'solver': 'newton-cg',\n",
       "   'tol': 0.7081131682707159},\n",
       "  10,\n",
       "  -2.70167572068911),\n",
       " 'RandomForestClassifier_V09_PCA_5components': ({'mean_fit_time': array([1.18349886, 1.20810294, 1.41056164, 1.23037823, 2.80417037,\n",
       "          0.98569822, 1.65092047, 1.77292713, 1.48669187, 1.07080356,\n",
       "          4.60170007, 2.88163002, 1.2001245 , 1.43616033, 2.15856314,\n",
       "          0.87432933, 3.06181598, 1.78422944, 1.77259549, 0.6509254 ,\n",
       "          2.07545249, 2.47338796, 1.23602891, 1.29952653, 1.75165097,\n",
       "          0.60405151, 1.81813947, 2.15424148, 1.95145035, 0.96674959]),\n",
       "   'std_fit_time': array([0.02808756, 0.00384795, 0.0228347 , 0.00409905, 0.00542219,\n",
       "          0.01754728, 0.0065819 , 0.0155847 , 0.01293658, 0.02974513,\n",
       "          0.08361406, 0.13555069, 0.01011607, 0.03231703, 0.03795402,\n",
       "          0.03058055, 0.01553564, 0.02905456, 0.02310866, 0.00870754,\n",
       "          0.00939128, 0.00709786, 0.02260157, 0.01345557, 0.01448361,\n",
       "          0.00169519, 0.02666264, 0.05914399, 0.06930056, 0.01326384]),\n",
       "   'mean_score_time': array([0.34607625, 0.344081  , 0.40624817, 0.28689981, 0.59673913,\n",
       "          0.28324389, 0.44747098, 0.37566241, 0.41389298, 0.27127552,\n",
       "          0.89593871, 0.66522272, 0.27991907, 0.346409  , 0.49866748,\n",
       "          0.20112912, 0.66090012, 0.34773747, 0.50032918, 0.19647511,\n",
       "          0.48437254, 0.60438538, 0.30252449, 0.29288419, 0.38463863,\n",
       "          0.18351038, 0.38563641, 0.63829398, 0.57978336, 0.26429359]),\n",
       "   'std_score_time': array([0.01740822, 0.01925313, 0.01316426, 0.0038497 , 0.00692526,\n",
       "          0.01862292, 0.00261825, 0.02634102, 0.01465791, 0.00746372,\n",
       "          0.00616583, 0.00939052, 0.01316375, 0.03927612, 0.00564211,\n",
       "          0.00611146, 0.05058198, 0.00542257, 0.02010083, 0.01914936,\n",
       "          0.00752248, 0.03039344, 0.01466486, 0.00401727, 0.01175414,\n",
       "          0.01095594, 0.02001881, 0.01733185, 0.03601739, 0.02321806]),\n",
       "   'param_n_estimators': masked_array(data=[200, 200, 250, 150, 350, 150, 250, 200, 250, 150, 350,\n",
       "                      350, 150, 200, 300, 100, 350, 150, 300, 100, 300, 350,\n",
       "                      150, 150, 200, 100, 200, 350, 350, 150],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[200, 200, 250, 75, 75, 150, 150, 50, 200, 125, 10, 75,\n",
       "                      75, 125, 125, 50, 50, 10, 200, 150, 125, 125, 75, 50,\n",
       "                      50, 200, 50, 200, 250, 150],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
       "                      'log2', 'sqrt', 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
       "                      'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'sqrt',\n",
       "                      'log2', 'sqrt'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[50, 10, 95, 20, 100, 60, 55, 40, 30, 65, 50, 35, 85,\n",
       "                      40, 65, 60, 60, 85, 35, 45, 65, 100, 35, 90, 30, 65,\n",
       "                      45, 90, 5, 20],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 200,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 10},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 95},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 20},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 60},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 55},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 250,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 50},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 40},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 60},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 60},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 10,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 85},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 300,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 125,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 100},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 75,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 35},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 30},\n",
       "    {'n_estimators': 100,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 65},\n",
       "    {'n_estimators': 200,\n",
       "     'min_samples_leaf': 50,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 45},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 200,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 90},\n",
       "    {'n_estimators': 350,\n",
       "     'min_samples_leaf': 250,\n",
       "     'max_features': 'log2',\n",
       "     'max_depth': 5},\n",
       "    {'n_estimators': 150,\n",
       "     'min_samples_leaf': 150,\n",
       "     'max_features': 'sqrt',\n",
       "     'max_depth': 20}],\n",
       "   'split0_test_Accuracy': array([0.26998924, 0.27034779, 0.25636429, 0.34671925, 0.34922911,\n",
       "          0.29437074, 0.28863392, 0.39153819, 0.26461097, 0.3079957 ,\n",
       "          0.53209035, 0.34779491, 0.34994622, 0.29759771, 0.30297598,\n",
       "          0.38651847, 0.38831122, 0.53495877, 0.26998924, 0.28935102,\n",
       "          0.30620294, 0.30225887, 0.34887056, 0.39225529, 0.39261384,\n",
       "          0.26819649, 0.38795267, 0.26998924, 0.25349588, 0.29508785]),\n",
       "   'split1_test_Accuracy': array([0.27489177, 0.26479076, 0.24494949, 0.3531746 , 0.3488456 ,\n",
       "          0.2987013 , 0.29292929, 0.37842713, 0.27272727, 0.30772006,\n",
       "          0.50252525, 0.3546176 , 0.35209235, 0.30483405, 0.30916306,\n",
       "          0.37914863, 0.38311688, 0.5036075 , 0.27164502, 0.29437229,\n",
       "          0.30555556, 0.30699856, 0.3452381 , 0.37698413, 0.37987013,\n",
       "          0.26659452, 0.37987013, 0.26984127, 0.24531025, 0.2979798 ]),\n",
       "   'split2_test_Accuracy': array([0.26765665, 0.27055415, 0.25606664, 0.35168417, 0.36001449,\n",
       "          0.28866353, 0.2893879 , 0.40239044, 0.27236509, 0.30061572,\n",
       "          0.52988048, 0.35747917, 0.35204636, 0.3071351 , 0.30278884,\n",
       "          0.39840637, 0.40565013, 0.5320536 , 0.2691054 , 0.29264759,\n",
       "          0.30532416, 0.30025353, 0.35023542, 0.39876856, 0.39985512,\n",
       "          0.27164071, 0.39876856, 0.26946758, 0.24918508, 0.29011228]),\n",
       "   'mean_test_Accuracy': array([0.27084835, 0.26856525, 0.25246335, 0.3505167 , 0.35267964,\n",
       "          0.29391973, 0.29031483, 0.39077145, 0.26988705, 0.30545542,\n",
       "          0.52150925, 0.35328046, 0.35135785, 0.30317231, 0.30497477,\n",
       "          0.38800769, 0.39233357, 0.52355203, 0.27024754, 0.29211728,\n",
       "          0.30569575, 0.30317231, 0.34811343, 0.38932949, 0.39077145,\n",
       "          0.26880558, 0.38884883, 0.26976688, 0.2493391 , 0.29440038]),\n",
       "   'std_test_Accuracy': array([0.00301213, 0.00266885, 0.00531162, 0.00276373, 0.00517068,\n",
       "          0.00410486, 0.00187318, 0.00978488, 0.0037488 , 0.00341202,\n",
       "          0.01344677, 0.0040656 , 0.0010024 , 0.0040675 , 0.00296096,\n",
       "          0.00792216, 0.00962033, 0.01414511, 0.00105151, 0.00208606,\n",
       "          0.00037225, 0.00282535, 0.00210711, 0.0091211 , 0.00825212,\n",
       "          0.00210227, 0.00773103, 0.00021939, 0.00334743, 0.00324447]),\n",
       "   'rank_test_Accuracy': array([23, 28, 29, 12, 10, 20, 22,  4, 25, 15,  2,  9, 11, 17, 16,  8,  3,\n",
       "           1, 24, 21, 14, 17, 13,  6,  4, 27,  7, 26, 30, 19]),\n",
       "   'split0_train_Accuracy': array([0.28989698, 0.29170432, 0.26694379, 0.38496295, 0.38893909,\n",
       "          0.31899512, 0.31230797, 0.44243629, 0.28790891, 0.32857401,\n",
       "          0.70052413, 0.39020423, 0.3921923 , 0.32459787, 0.32550154,\n",
       "          0.4339418 , 0.43882162, 0.69058377, 0.28863185, 0.3097777 ,\n",
       "          0.33164648, 0.32983915, 0.38857763, 0.43773721, 0.43900235,\n",
       "          0.28086029, 0.43629134, 0.28736671, 0.26170251, 0.31556118]),\n",
       "   'split1_train_Accuracy': array([0.29423423, 0.28522523, 0.26504505, 0.40054054, 0.39801802,\n",
       "          0.3154955 , 0.32468468, 0.44216216, 0.29351351, 0.33279279,\n",
       "          0.69207207, 0.40432432, 0.39477477, 0.33405405, 0.33891892,\n",
       "          0.44396396, 0.44324324, 0.68792793, 0.28882883, 0.32036036,\n",
       "          0.33333333, 0.33207207, 0.39369369, 0.43927928, 0.44306306,\n",
       "          0.28486486, 0.44396396, 0.28954955, 0.2590991 , 0.31945946]),\n",
       "   'split2_train_Accuracy': array([0.28106456, 0.28645927, 0.2677576 , 0.38284481, 0.38734041,\n",
       "          0.30893724, 0.30965654, 0.44524366, 0.2821435 , 0.3191872 ,\n",
       "          0.69735659, 0.38194569, 0.38320446, 0.33051609, 0.3191872 ,\n",
       "          0.43751124, 0.4470419 , 0.69196188, 0.28250315, 0.31307319,\n",
       "          0.32638015, 0.3253012 , 0.3767308 , 0.44398489, 0.4425463 ,\n",
       "          0.2852005 , 0.44416472, 0.28448121, 0.25768747, 0.30875742]),\n",
       "   'mean_train_Accuracy': array([0.28839859, 0.28779627, 0.26658214, 0.38944943, 0.39143251,\n",
       "          0.31447595, 0.31554973, 0.4432807 , 0.28785531, 0.32685133,\n",
       "          0.69665093, 0.39215808, 0.39005718, 0.32972267, 0.32786922,\n",
       "          0.43847234, 0.44303559, 0.69015786, 0.28665461, 0.31440375,\n",
       "          0.33045332, 0.32907081, 0.38633404, 0.4403338 , 0.44153724,\n",
       "          0.28364189, 0.44147334, 0.28713249, 0.25949636, 0.31459269]),\n",
       "   'std_train_Accuracy': array([0.0054799 , 0.00280896, 0.00113654, 0.00789012, 0.00470218,\n",
       "          0.00416892, 0.00654946, 0.00139252, 0.00464194, 0.00568646,\n",
       "          0.00348643, 0.00923991, 0.00495897, 0.00390103, 0.00822758,\n",
       "          0.00414759, 0.00335913, 0.00167416, 0.00293663, 0.00442161,\n",
       "          0.00296135, 0.00281708, 0.00710447, 0.00265737, 0.00180481,\n",
       "          0.00197165, 0.00366514, 0.00207576, 0.00166303, 0.00442244]),\n",
       "   'split0_test_F1': array([0.20050956, 0.20032673, 0.18290455, 0.30457771, 0.30721009,\n",
       "          0.22792674, 0.2218422 , 0.3586297 , 0.19607314, 0.24838043,\n",
       "          0.51943333, 0.30718106, 0.30825342, 0.23427288, 0.24055864,\n",
       "          0.35156037, 0.35634786, 0.52159432, 0.20043662, 0.22141927,\n",
       "          0.24645374, 0.24025341, 0.30551297, 0.36205642, 0.36173171,\n",
       "          0.19929476, 0.35371527, 0.20131587, 0.17825231, 0.22870754]),\n",
       "   'split1_test_F1': array([0.20395779, 0.18963379, 0.17075661, 0.31082857, 0.30546591,\n",
       "          0.23053883, 0.22785208, 0.3481212 , 0.19765017, 0.24692332,\n",
       "          0.49179197, 0.3123966 , 0.30935785, 0.24597342, 0.25188052,\n",
       "          0.34753562, 0.35213989, 0.49218739, 0.19738354, 0.22705377,\n",
       "          0.24656428, 0.24677307, 0.30137642, 0.34478136, 0.3490938 ,\n",
       "          0.19127357, 0.34859195, 0.19524527, 0.17015717, 0.23626629]),\n",
       "   'split2_test_F1': array([0.18790758, 0.19134718, 0.17997031, 0.30278419, 0.31089234,\n",
       "          0.21526277, 0.21312296, 0.37100017, 0.19505463, 0.22932573,\n",
       "          0.51737171, 0.31127645, 0.30436215, 0.2399697 , 0.23171468,\n",
       "          0.36910032, 0.37463912, 0.52028672, 0.18866774, 0.21887459,\n",
       "          0.23511733, 0.22698569, 0.29844528, 0.36836847, 0.36789306,\n",
       "          0.19713978, 0.3682111 , 0.19229535, 0.16912954, 0.2185448 ]),\n",
       "   'mean_test_F1': array([0.19747716, 0.19378583, 0.17788466, 0.30606479, 0.30785078,\n",
       "          0.22459527, 0.22095126, 0.35923356, 0.19626053, 0.24157328,\n",
       "          0.5095422 , 0.31027705, 0.30733029, 0.24006029, 0.24139571,\n",
       "          0.356039  , 0.36101473, 0.51136525, 0.19551508, 0.22245183,\n",
       "          0.24272947, 0.23802321, 0.30179026, 0.35839637, 0.35956627,\n",
       "          0.195908  , 0.35681803, 0.19630105, 0.17252921, 0.2278536 ]),\n",
       "   'std_test_F1': array([0.00688867, 0.00469613, 0.00517808, 0.00344541, 0.00225861,\n",
       "          0.006662  , 0.00603821, 0.00933749, 0.00106652, 0.00865043,\n",
       "          0.01257274, 0.00224502, 0.00213958, 0.00478272, 0.00824297,\n",
       "          0.00934916, 0.00975291, 0.01356398, 0.00498356, 0.00341425,\n",
       "          0.00536388, 0.00822114, 0.00290064, 0.00996126, 0.00781704,\n",
       "          0.0033914 , 0.00829644, 0.00375805, 0.00408481, 0.00725036]),\n",
       "   'rank_test_F1': array([23, 28, 29, 12, 10, 20, 22,  5, 25, 15,  2,  9, 11, 17, 16,  8,  3,\n",
       "           1, 27, 21, 14, 18, 13,  6,  4, 26,  7, 24, 30, 19]),\n",
       "   'split0_train_F1': array([0.21623397, 0.2153402 , 0.18853028, 0.33832094, 0.34163805,\n",
       "          0.24714699, 0.24165167, 0.40907076, 0.21301177, 0.26381104,\n",
       "          0.69439909, 0.34419934, 0.34470083, 0.25711259, 0.25799591,\n",
       "          0.3975383 , 0.40542438, 0.68323441, 0.21412582, 0.23886552,\n",
       "          0.26656264, 0.26360211, 0.34168609, 0.40492872, 0.40522207,\n",
       "          0.20666183, 0.40043815, 0.21334302, 0.18217878, 0.2434874 ]),\n",
       "   'split1_train_F1': array([0.22333549, 0.2104956 , 0.18638993, 0.36262333, 0.35910515,\n",
       "          0.24812938, 0.26061184, 0.41437688, 0.21838635, 0.2707864 ,\n",
       "          0.68598487, 0.36567643, 0.35456162, 0.27411568, 0.27891951,\n",
       "          0.41618895, 0.41541587, 0.68208156, 0.21275758, 0.25249221,\n",
       "          0.27305125, 0.27121625, 0.35451605, 0.41069236, 0.41466061,\n",
       "          0.2085991 , 0.41535771, 0.21563596, 0.17983662, 0.2556331 ]),\n",
       "   'split2_train_F1': array([0.20017556, 0.20721324, 0.19185945, 0.33429447, 0.34033877,\n",
       "          0.23347617, 0.23582697, 0.41475222, 0.20341268, 0.2466582 ,\n",
       "          0.69023772, 0.33393946, 0.33424101, 0.26157659, 0.24700385,\n",
       "          0.40825678, 0.41727859, 0.68409166, 0.20229059, 0.24088209,\n",
       "          0.2566822 , 0.25150194, 0.3253526 , 0.41493591, 0.41216132,\n",
       "          0.21085064, 0.41509764, 0.20539759, 0.1759866 , 0.23565224]),\n",
       "   'mean_train_F1': array([0.21324834, 0.21101635, 0.18892656, 0.34507958, 0.34702733,\n",
       "          0.24291751, 0.24603016, 0.41273329, 0.2116036 , 0.26041855,\n",
       "          0.69020722, 0.34793841, 0.34450115, 0.26426829, 0.26130642,\n",
       "          0.40732801, 0.41270628, 0.68313588, 0.20972466, 0.24407994,\n",
       "          0.26543203, 0.26210677, 0.34051824, 0.41018567, 0.41068133,\n",
       "          0.20870386, 0.41029784, 0.21145886, 0.179334  , 0.24492425]),\n",
       "   'std_train_F1': array([0.00968783, 0.00333818, 0.00225043, 0.01251374, 0.00855677,\n",
       "          0.00668807, 0.01058146, 0.00259433, 0.00619354, 0.01013819,\n",
       "          0.00343516, 0.01322357, 0.00829705, 0.0071977 , 0.01323812,\n",
       "          0.00764237, 0.00520493, 0.00082357, 0.00528628, 0.00600507,\n",
       "          0.00673028, 0.00811749, 0.01193453, 0.0041011 , 0.00399285,\n",
       "          0.00171168, 0.00697266, 0.004387  , 0.00255281, 0.00822018]),\n",
       "   'split0_test_Log_Loss': array([-2.63374738, -2.64180882, -2.7132642 , -2.30111339, -2.29798114,\n",
       "          -2.54192872, -2.53742253, -2.15956712, -2.6418705 , -2.47571911,\n",
       "          -1.68927636, -2.29623722, -2.29029626, -2.47737201, -2.47630999,\n",
       "          -2.16446557, -2.1593078 , -1.70279245, -2.63825322, -2.53641997,\n",
       "          -2.47154234, -2.472928  , -2.29445035, -2.16065775, -2.15857474,\n",
       "          -2.64339257, -2.16560136, -2.64078442, -2.73720553, -2.54350618]),\n",
       "   'split1_test_Log_Loss': array([-2.65001589, -2.64551288, -2.72116258, -2.30523935, -2.29939909,\n",
       "          -2.54469578, -2.5463705 , -2.16873679, -2.64551943, -2.47707699,\n",
       "          -1.71246043, -2.29729743, -2.30557311, -2.48292481, -2.47807148,\n",
       "          -2.17337807, -2.16640563, -1.73310672, -2.64093799, -2.54975489,\n",
       "          -2.48163144, -2.48253146, -2.30637299, -2.16828677, -2.16907319,\n",
       "          -2.63893971, -2.16806856, -2.64056677, -2.73317822, -2.54802823]),\n",
       "   'split2_test_Log_Loss': array([-2.63628088, -2.63684407, -2.70235337, -2.28040805, -2.27772688,\n",
       "          -2.53435068, -2.53451821, -2.14466331, -2.63627168, -2.45882511,\n",
       "          -1.67864252, -2.27945591, -2.28282139, -2.46507433, -2.46559243,\n",
       "          -2.14095511, -2.13873341, -1.67644743, -2.63399936, -2.52827112,\n",
       "          -2.46235023, -2.46638083, -2.27926831, -2.14101077, -2.14243729,\n",
       "          -2.63443723, -2.14383576, -2.63990707, -2.72681359, -2.53927921]),\n",
       "   'mean_test_Log_Loss': array([-2.64000685, -2.64139545, -2.7122752 , -2.29561828, -2.29173367,\n",
       "          -2.54033623, -2.53943947, -2.15767682, -2.6412284 , -2.47056647,\n",
       "          -1.69347081, -2.29102281, -2.29290493, -2.47514159, -2.47334096,\n",
       "          -2.15963417, -2.15484605, -1.7041494 , -2.63773619, -2.53815818,\n",
       "          -2.47185327, -2.47395468, -2.29338473, -2.15668062, -2.15671776,\n",
       "          -2.63893823, -2.15920197, -2.64042085, -2.73241631, -2.54361006]),\n",
       "   'std_test_Log_Loss': array([0.00714887, 0.0035464 , 0.00770051, 0.01084934, 0.00988651,\n",
       "          0.00436656, 0.00503984, 0.00990597, 0.00379772, 0.00829183,\n",
       "          0.01410534, 0.00816182, 0.00945887, 0.00744785, 0.00550705,\n",
       "          0.01365649, 0.01171812, 0.0231198 , 0.00285256, 0.00884534,\n",
       "          0.00786396, 0.00662476, 0.01107632, 0.01147319, 0.01093907,\n",
       "          0.00365661, 0.01087424, 0.00037279, 0.00427723, 0.00356769]),\n",
       "   'rank_test_Log_Loss': array([25, 28, 29, 13, 10, 21, 20,  6, 27, 14,  1,  9, 11, 18, 16,  8,  3,\n",
       "           2, 23, 19, 15, 17, 12,  4,  5, 24,  7, 26, 30, 22]),\n",
       "   'split0_train_Log_Loss': array([-2.57953126, -2.58740527, -2.66882342, -2.18436565, -2.18100824,\n",
       "          -2.47385176, -2.47214007, -2.00823933, -2.58772764, -2.39806895,\n",
       "          -1.26997669, -2.17913185, -2.17414881, -2.39867951, -2.39948596,\n",
       "          -2.01029054, -2.00598201, -1.27216769, -2.58413708, -2.47114251,\n",
       "          -2.3949765 , -2.3953842 , -2.1813144 , -2.00748319, -2.00527683,\n",
       "          -2.58897825, -2.01038323, -2.58714477, -2.69628416, -2.47792384]),\n",
       "   'split1_train_Log_Loss': array([-2.5924809 , -2.58875668, -2.67556495, -2.18127782, -2.1747542 ,\n",
       "          -2.4713988 , -2.47323863, -2.00212208, -2.58900928, -2.39232418,\n",
       "          -1.26137988, -2.17393984, -2.17894037, -2.3988521 , -2.39338022,\n",
       "          -2.00263016, -2.00194969, -1.26460111, -2.58338663, -2.47924167,\n",
       "          -2.39662043, -2.39764602, -2.18194661, -2.00148592, -2.00168225,\n",
       "          -2.58289831, -2.0013002 , -2.58168541, -2.69116695, -2.47444315]),\n",
       "   'split2_train_Log_Loss': array([-2.59426127, -2.59688272, -2.66820257, -2.19252767, -2.18909605,\n",
       "          -2.48167889, -2.48282348, -2.02109098, -2.59531982, -2.39891265,\n",
       "          -1.27110887, -2.19008998, -2.19097404, -2.40429693, -2.40541579,\n",
       "          -2.01923008, -2.01492091, -1.27056852, -2.59304339, -2.47810875,\n",
       "          -2.40254045, -2.40551655, -2.19063135, -2.01706392, -2.01726649,\n",
       "          -2.5943223 , -2.01811311, -2.59790827, -2.69382536, -2.48750865]),\n",
       "   'mean_train_Log_Loss': array([-2.58875781, -2.59101489, -2.67086365, -2.18605705, -2.1816195 ,\n",
       "          -2.47564315, -2.47606739, -2.01048413, -2.59068558, -2.39643526,\n",
       "          -1.26748848, -2.18105389, -2.18135441, -2.40060951, -2.39942732,\n",
       "          -2.01071693, -2.00761753, -1.26911244, -2.5868557 , -2.47616431,\n",
       "          -2.39804579, -2.39951559, -2.18463079, -2.00867768, -2.00807519,\n",
       "          -2.58873296, -2.00993218, -2.58891282, -2.69375882, -2.47995855]),\n",
       "   'std_train_Log_Loss': array([0.00656452, 0.00418571, 0.00333397, 0.0047459 , 0.00587096,\n",
       "          0.00438382, 0.00479828, 0.00790503, 0.00331841, 0.00292731,\n",
       "          0.00434409, 0.00673188, 0.00707779, 0.00260835, 0.00491367,\n",
       "          0.00678359, 0.00542029, 0.00325611, 0.00438607, 0.00358095,\n",
       "          0.00324829, 0.00434263, 0.00425088, 0.00641553, 0.00666284,\n",
       "          0.00466705, 0.00687125, 0.00673992, 0.00208962, 0.0055246 ])},\n",
       "  {'n_estimators': 350,\n",
       "   'min_samples_leaf': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50},\n",
       "  10,\n",
       "  -1.6934708071119922),\n",
       " 'KNeighborsClassifier_V09_PCA_5components': ({'mean_fit_time': array([0.00930842, 0.00964038, 0.00930802, 0.00964077, 0.00631642,\n",
       "          0.01063776, 0.01163514, 0.01329835, 0.00897598, 0.00897559,\n",
       "          0.00565132, 0.00498605, 0.00964101, 0.00831103, 0.0066491 ,\n",
       "          0.00897566, 0.00698121, 0.0079778 , 0.00930802, 0.0066479 ,\n",
       "          0.00698098, 0.00631579, 0.0079786 , 0.0103066 , 0.00930858,\n",
       "          0.00964046, 0.00731341, 0.00797868, 0.00831103, 0.007646  ]),\n",
       "   'std_fit_time': array([4.70134046e-04, 9.40605267e-04, 1.24351795e-03, 9.40492896e-04,\n",
       "          4.69853561e-04, 1.24445292e-03, 4.69572088e-04, 2.61753512e-03,\n",
       "          8.14198738e-04, 1.41034597e-03, 4.69909424e-04, 5.15042996e-07,\n",
       "          4.70078102e-04, 2.61763596e-03, 9.41167306e-04, 1.62878678e-03,\n",
       "          4.05233662e-07, 8.14588058e-04, 4.70077941e-04, 4.69740766e-04,\n",
       "          1.62830011e-03, 9.40268092e-04, 8.14588058e-04, 4.70358870e-04,\n",
       "          1.24457994e-03, 4.70023106e-04, 9.39987239e-04, 3.37174788e-07,\n",
       "          1.24387901e-03, 9.40942462e-04]),\n",
       "   'mean_score_time': array([0.11369626, 0.10206   , 0.1017286 , 0.09208711, 1.25730602,\n",
       "          0.12100967, 0.1073796 , 0.14727283, 0.09374889, 0.10970688,\n",
       "          1.30285168, 1.2190756 , 0.1110359 , 1.26063093, 1.25364852,\n",
       "          0.26894808, 0.24368199, 0.23936097, 0.10339046, 0.25797757,\n",
       "          1.29188021, 1.24833035, 0.3144927 , 0.12400182, 0.1113685 ,\n",
       "          0.12200753, 1.37299736, 0.26795014, 0.33311049, 0.26363087]),\n",
       "   'std_score_time': array([0.01340523, 0.01769754, 0.00244289, 0.00571959, 0.01186673,\n",
       "          0.00738847, 0.01793938, 0.02303696, 0.00215417, 0.00215476,\n",
       "          0.02725643, 0.06165844, 0.00409838, 0.0582282 , 0.04833317,\n",
       "          0.01192161, 0.01050219, 0.01302932, 0.00523497, 0.00893234,\n",
       "          0.05352425, 0.12015673, 0.026328  , 0.02391312, 0.01192119,\n",
       "          0.01264977, 0.04396029, 0.03083986, 0.03546642, 0.0291905 ]),\n",
       "   'param_weights': masked_array(data=['distance', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'distance',\n",
       "                      'distance', 'distance', 'distance', 'uniform'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[4, 4, 6, 3, 4, 7, 3, 8, 4, 6, 6, 4, 6, 5, 6, 5, 5, 4,\n",
       "                      5, 6, 7, 8, 8, 7, 5, 5, 7, 3, 8, 4],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_algorithm': masked_array(data=['kd_tree', 'kd_tree', 'auto', 'kd_tree', 'brute',\n",
       "                      'auto', 'kd_tree', 'kd_tree', 'auto', 'auto', 'brute',\n",
       "                      'brute', 'kd_tree', 'brute', 'brute', 'ball_tree',\n",
       "                      'ball_tree', 'ball_tree', 'auto', 'ball_tree', 'brute',\n",
       "                      'brute', 'ball_tree', 'kd_tree', 'auto', 'kd_tree',\n",
       "                      'brute', 'ball_tree', 'ball_tree', 'ball_tree'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'weights': 'distance',\n",
       "     'n_neighbors': 4,\n",
       "     'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 4, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 6, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'brute'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 7, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'},\n",
       "    {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'kd_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 7, 'algorithm': 'brute'},\n",
       "    {'weights': 'distance', 'n_neighbors': 3, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'ball_tree'},\n",
       "    {'weights': 'uniform', 'n_neighbors': 4, 'algorithm': 'ball_tree'}],\n",
       "   'split0_test_Accuracy': array([0.62136967, 0.57224812, 0.56113302, 0.57475798, 0.57224812,\n",
       "          0.55898171, 0.61778415, 0.61491574, 0.57224812, 0.61455719,\n",
       "          0.61455719, 0.62136967, 0.56113302, 0.57045536, 0.56113302,\n",
       "          0.61706705, 0.57045536, 0.62136967, 0.61706705, 0.56113302,\n",
       "          0.55898171, 0.55216924, 0.55216924, 0.55898171, 0.57045536,\n",
       "          0.61706705, 0.61276443, 0.61778415, 0.61491574, 0.57224812]),\n",
       "   'split1_test_Accuracy': array([0.62193362, 0.56529582, 0.55772006, 0.56890332, 0.56529582,\n",
       "          0.5450938 , 0.62554113, 0.60606061, 0.56529582, 0.61111111,\n",
       "          0.61111111, 0.62193362, 0.55772006, 0.56529582, 0.55772006,\n",
       "          0.61688312, 0.56529582, 0.62193362, 0.61688312, 0.55772006,\n",
       "          0.5450938 , 0.54292929, 0.54292929, 0.5450938 , 0.56529582,\n",
       "          0.61688312, 0.60642136, 0.62554113, 0.60606061, 0.56529582]),\n",
       "   'split2_test_Accuracy': array([0.62078957, 0.57080768, 0.55957986, 0.57406737, 0.57080768,\n",
       "          0.54943861, 0.61970301, 0.60775081, 0.57080768, 0.61427019,\n",
       "          0.61427019, 0.62078957, 0.55957986, 0.56972112, 0.55957986,\n",
       "          0.61245925, 0.56972112, 0.62078957, 0.61245925, 0.55957986,\n",
       "          0.54943861, 0.54328142, 0.54328142, 0.54943861, 0.56972112,\n",
       "          0.61245925, 0.60702644, 0.61970301, 0.60775081, 0.57080768]),\n",
       "   'mean_test_Accuracy': array([0.62136506, 0.56945446, 0.55948089, 0.57257871, 0.56945446,\n",
       "          0.55118962, 0.62100457, 0.60958904, 0.56945446, 0.61331411,\n",
       "          0.61331411, 0.62136506, 0.55948089, 0.56849315, 0.55948089,\n",
       "          0.61547705, 0.56849315, 0.62136506, 0.61547705, 0.55948089,\n",
       "          0.55118962, 0.54614275, 0.54614275, 0.55118962, 0.56849315,\n",
       "          0.61547705, 0.6087479 , 0.62100457, 0.60958904, 0.56945446]),\n",
       "   'std_test_Accuracy': array([0.00046644, 0.00299729, 0.0013967 , 0.00261275, 0.00299729,\n",
       "          0.00580887, 0.00330044, 0.0038441 , 0.00299729, 0.00156132,\n",
       "          0.00156132, 0.00046644, 0.0013967 , 0.00227944, 0.0013967 ,\n",
       "          0.00212774, 0.00227944, 0.00046644, 0.00212774, 0.0013967 ,\n",
       "          0.00580887, 0.00428107, 0.00428107, 0.00580887, 0.00227944,\n",
       "          0.00212774, 0.0028623 , 0.00330044, 0.0038441 , 0.00299729]),\n",
       "   'rank_test_Accuracy': array([ 1, 15, 22, 14, 15, 26,  4, 11, 15,  9,  9,  1, 22, 19, 22,  6, 19,\n",
       "           1,  6, 22, 26, 29, 29, 26, 19,  6, 13,  4, 11, 15]),\n",
       "   'split0_train_Accuracy': array([1.        , 0.74118923, 0.68263148, 0.77607085, 0.74118923,\n",
       "          0.66419664, 1.        , 1.        , 0.74118923, 1.        ,\n",
       "          1.        , 1.        , 0.68263148, 0.71769384, 0.68263148,\n",
       "          1.        , 0.71769384, 1.        , 1.        , 0.68263148,\n",
       "          0.66419664, 0.649015  , 0.649015  , 0.66419664, 0.71769384,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.74118923]),\n",
       "   'split1_train_Accuracy': array([1.        , 0.74324324, 0.69495495, 0.77603604, 0.74324324,\n",
       "          0.67747748, 1.        , 1.        , 0.74324324, 1.        ,\n",
       "          1.        , 1.        , 0.69495495, 0.72      , 0.69495495,\n",
       "          1.        , 0.72      , 1.        , 1.        , 0.69495495,\n",
       "          0.67747748, 0.65693694, 0.65693694, 0.67747748, 0.72      ,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.74324324]),\n",
       "   'split2_train_Accuracy': array([1.        , 0.73655817, 0.69106276, 0.77935623, 0.73655817,\n",
       "          0.67451897, 1.        , 1.        , 0.73655817, 1.        ,\n",
       "          1.        , 1.        , 0.69106276, 0.71641791, 0.69106276,\n",
       "          1.        , 0.71641791, 1.        , 1.        , 0.69106276,\n",
       "          0.67451897, 0.65401906, 0.65401906, 0.67451897, 0.71641791,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.73655817]),\n",
       "   'mean_train_Accuracy': array([1.        , 0.74033021, 0.68954973, 0.77715437, 0.74033021,\n",
       "          0.67206436, 1.        , 1.        , 0.74033021, 1.        ,\n",
       "          1.        , 1.        , 0.68954973, 0.71803725, 0.68954973,\n",
       "          1.        , 0.71803725, 1.        , 1.        , 0.68954973,\n",
       "          0.67206436, 0.65332367, 0.65332367, 0.67206436, 0.71803725,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.74033021]),\n",
       "   'std_train_Accuracy': array([0.        , 0.00279595, 0.00514353, 0.00155701, 0.00279595,\n",
       "          0.00569292, 0.        , 0.        , 0.00279595, 0.        ,\n",
       "          0.        , 0.        , 0.00514353, 0.00148241, 0.00514353,\n",
       "          0.        , 0.00148241, 0.        , 0.        , 0.00514353,\n",
       "          0.00569292, 0.00327128, 0.00327128, 0.00569292, 0.00148241,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00279595]),\n",
       "   'split0_test_F1': array([0.61546474, 0.56639228, 0.55151951, 0.56902492, 0.56639228,\n",
       "          0.54999526, 0.61286289, 0.60646223, 0.56639228, 0.60735788,\n",
       "          0.60735788, 0.61546474, 0.55151951, 0.56304837, 0.55151951,\n",
       "          0.61059251, 0.56304837, 0.61546474, 0.61059251, 0.55151951,\n",
       "          0.54999526, 0.54241787, 0.54241787, 0.54999526, 0.56304837,\n",
       "          0.61059251, 0.6041646 , 0.61286289, 0.60646223, 0.56639228]),\n",
       "   'split1_test_F1': array([0.61688969, 0.55983029, 0.55044676, 0.56455245, 0.55983029,\n",
       "          0.53657516, 0.62067687, 0.59885709, 0.55983029, 0.60509002,\n",
       "          0.60509002, 0.61688969, 0.55044676, 0.55857468, 0.55044676,\n",
       "          0.61160392, 0.55857468, 0.61688969, 0.61160392, 0.55044676,\n",
       "          0.53657516, 0.53351364, 0.53351364, 0.53657516, 0.55857468,\n",
       "          0.61160392, 0.59966678, 0.62067687, 0.59885709, 0.55983029]),\n",
       "   'split2_test_F1': array([0.61492104, 0.56519149, 0.55239593, 0.56986134, 0.56519149,\n",
       "          0.54027336, 0.61460714, 0.599154  , 0.56519149, 0.60656877,\n",
       "          0.60656877, 0.61492104, 0.55239593, 0.5622034 , 0.55239593,\n",
       "          0.60563298, 0.5622034 , 0.61492104, 0.60563298, 0.55239593,\n",
       "          0.54027336, 0.53492306, 0.53492306, 0.54027336, 0.5622034 ,\n",
       "          0.60563298, 0.59902197, 0.61460714, 0.599154  , 0.56519149]),\n",
       "   'mean_test_F1': array([0.615759  , 0.56380814, 0.55145295, 0.56781267, 0.56380814,\n",
       "          0.54229967, 0.61604436, 0.60150435, 0.56380814, 0.60634067,\n",
       "          0.60634067, 0.615759  , 0.55145295, 0.56127788, 0.55145295,\n",
       "          0.60928398, 0.56127788, 0.615759  , 0.60928398, 0.55145295,\n",
       "          0.54229967, 0.53696537, 0.53696537, 0.54229967, 0.56127788,\n",
       "          0.60928398, 0.60096023, 0.61604436, 0.60150435, 0.56380814]),\n",
       "   'std_test_F1': array([0.00082935, 0.00285368, 0.00079607, 0.00232925, 0.00285368,\n",
       "          0.0056679 , 0.00335048, 0.00352206, 0.00285368, 0.00094076,\n",
       "          0.00094076, 0.00082935, 0.00079607, 0.00194132, 0.00079607,\n",
       "          0.00260558, 0.00194132, 0.00082935, 0.00260558, 0.00079607,\n",
       "          0.0056679 , 0.00391356, 0.00391356, 0.0056679 , 0.00194132,\n",
       "          0.00260558, 0.00229016, 0.00335048, 0.00352206, 0.00285368]),\n",
       "   'rank_test_F1': array([ 3, 15, 22, 14, 15, 26,  1, 11, 15,  9,  9,  3, 22, 19, 22,  6, 19,\n",
       "           3,  6, 22, 26, 29, 29, 26, 19,  6, 13,  1, 11, 15]),\n",
       "   'split0_train_F1': array([1.        , 0.73848624, 0.67785112, 0.77363243, 0.73848624,\n",
       "          0.65798656, 1.        , 1.        , 0.73848624, 1.        ,\n",
       "          1.        , 1.        , 0.67785112, 0.71386441, 0.67785112,\n",
       "          1.        , 0.71386441, 1.        , 1.        , 0.67785112,\n",
       "          0.65798656, 0.64199006, 0.64199006, 0.65798656, 0.71386441,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.73848624]),\n",
       "   'split1_train_F1': array([1.        , 0.73999695, 0.68965109, 0.77357332, 0.73999695,\n",
       "          0.67194002, 1.        , 1.        , 0.73999695, 1.        ,\n",
       "          1.        , 1.        , 0.68965109, 0.71572293, 0.68965109,\n",
       "          1.        , 0.71572293, 1.        , 1.        , 0.68965109,\n",
       "          0.67194002, 0.65033214, 0.65033214, 0.67194002, 0.71572293,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.73999695]),\n",
       "   'split2_train_F1': array([1.        , 0.73393645, 0.68676348, 0.77771275, 0.73393645,\n",
       "          0.6698671 , 1.        , 1.        , 0.73393645, 1.        ,\n",
       "          1.        , 1.        , 0.68676348, 0.71267825, 0.68676348,\n",
       "          1.        , 0.71267825, 1.        , 1.        , 0.68676348,\n",
       "          0.6698671 , 0.64898217, 0.64898217, 0.6698671 , 0.71267825,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.73393645]),\n",
       "   'mean_train_F1': array([1.        , 0.73747321, 0.68475523, 0.77497283, 0.73747321,\n",
       "          0.66659789, 1.        , 1.        , 0.73747321, 1.        ,\n",
       "          1.        , 1.        , 0.68475523, 0.71408853, 0.68475523,\n",
       "          1.        , 0.71408853, 1.        , 1.        , 0.68475523,\n",
       "          0.66659789, 0.64710146, 0.64710146, 0.66659789, 0.71408853,\n",
       "          1.        , 1.        , 1.        , 1.        , 0.73747321]),\n",
       "   'std_train_F1': array([0.        , 0.00257579, 0.00502226, 0.00193756, 0.00257579,\n",
       "          0.00614766, 0.        , 0.        , 0.00257579, 0.        ,\n",
       "          0.        , 0.        , 0.00502226, 0.00125305, 0.00502226,\n",
       "          0.        , 0.00125305, 0.        , 0.        , 0.00502226,\n",
       "          0.00614766, 0.00365608, 0.00365608, 0.00614766, 0.00125305,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.00257579]),\n",
       "   'split0_test_Log_Loss': array([-7.40866775, -7.46411001, -6.07135993, -8.51438578, -7.46411001,\n",
       "          -5.71770894, -8.4727092 , -5.19077801, -7.46411001, -5.99229109,\n",
       "          -5.99229109, -7.40866775, -6.07135993, -6.7540782 , -6.07135993,\n",
       "          -6.68491103, -6.7540782 , -7.40866775, -6.68491103, -6.07135993,\n",
       "          -5.71770894, -5.29134967, -5.29134967, -5.71770894, -6.7540782 ,\n",
       "          -6.68491103, -5.62701974, -8.4727092 , -5.19077801, -7.46411001]),\n",
       "   'split1_test_Log_Loss': array([-7.42705679, -7.48343308, -6.11292916, -8.69189495, -7.48343308,\n",
       "          -5.68900954, -8.6491269 , -5.22849705, -7.48343308, -6.03080873,\n",
       "          -6.03080873, -7.42705679, -6.11292916, -6.70020077, -6.11292916,\n",
       "          -6.62986513, -6.70020077, -7.42705679, -6.62986513, -6.11292916,\n",
       "          -5.68900954, -5.33125795, -5.33125795, -5.68900954, -6.70020077,\n",
       "          -6.62986513, -5.59616029, -8.6491269 , -5.22849705, -7.48343308]),\n",
       "   'split2_test_Log_Loss': array([-7.4448009 , -7.50010767, -6.05216557, -8.57243077, -7.50010767,\n",
       "          -5.69494088, -8.5311972 , -5.3163743 , -7.50010767, -5.97311586,\n",
       "          -5.97311586, -7.4448009 , -6.05216557, -6.72624923, -6.05216557,\n",
       "          -6.65694042, -6.72624923, -7.4448009 , -6.65694042, -6.05216557,\n",
       "          -5.69494088, -5.41564822, -5.41564822, -5.69494088, -6.72624923,\n",
       "          -6.65694042, -5.60510778, -8.5311972 , -5.3163743 , -7.50010767]),\n",
       "   'mean_test_Log_Loss': array([-7.42678095, -7.48248938, -6.07883822, -8.5927705 , -7.48248938,\n",
       "          -5.70059558, -8.55087734, -5.24501119, -7.48248938, -5.99875926,\n",
       "          -5.99875926, -7.42678095, -6.07883822, -6.72689916, -6.07883822,\n",
       "          -6.65729578, -6.72689916, -7.42678095, -6.65729578, -6.07883822,\n",
       "          -5.70059558, -5.34588152, -5.34588152, -5.70059558, -6.72689916,\n",
       "          -6.65729578, -5.60947091, -8.55087734, -5.24501119, -7.48248938]),\n",
       "   'std_test_Log_Loss': array([0.01475505, 0.01471357, 0.0253356 , 0.07395432, 0.01471357,\n",
       "          0.01238838, 0.07342753, 0.05259432, 0.01471357, 0.02396521,\n",
       "          0.02396521, 0.01475505, 0.0253356 , 0.02202578, 0.0253356 ,\n",
       "          0.02249999, 0.02202578, 0.01475505, 0.02249999, 0.0253356 ,\n",
       "          0.01238838, 0.05179472, 0.05179472, 0.01238838, 0.02202578,\n",
       "          0.02249999, 0.01298228, 0.07342753, 0.05259432, 0.01471357]),\n",
       "   'rank_test_Log_Loss': array([21, 24, 11, 30, 24,  6, 28,  1, 24,  9, 10, 23, 11, 18, 11, 15, 18,\n",
       "          21, 15, 11,  6,  3,  3,  6, 18, 15,  5, 28,  1, 24]),\n",
       "   'split0_train_Log_Loss': array([-3.77251697e-14, -5.46118271e-01, -7.25315659e-01, -4.26302380e-01,\n",
       "          -5.46118271e-01, -7.93410984e-01, -3.77251697e-14, -3.77251697e-14,\n",
       "          -5.46118271e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -7.25315659e-01, -6.44514126e-01, -7.25315659e-01, -3.77251697e-14,\n",
       "          -6.44514126e-01, -3.77251697e-14, -3.77251697e-14, -7.25315659e-01,\n",
       "          -7.93410984e-01, -8.52138293e-01, -8.52138293e-01, -7.93410984e-01,\n",
       "          -6.44514126e-01, -3.77251697e-14, -3.77251697e-14, -3.77251697e-14,\n",
       "          -3.77251697e-14, -5.46118271e-01]),\n",
       "   'split1_train_Log_Loss': array([-3.77252183e-14, -5.43946287e-01, -7.14056842e-01, -4.22116762e-01,\n",
       "          -5.43946287e-01, -7.82031042e-01, -3.77252183e-14, -3.77252183e-14,\n",
       "          -5.43946287e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -7.14056842e-01, -6.37450113e-01, -7.14056842e-01, -3.77252183e-14,\n",
       "          -6.37450113e-01, -3.77252183e-14, -3.77252183e-14, -7.14056842e-01,\n",
       "          -7.82031042e-01, -8.37536424e-01, -8.37536424e-01, -7.82031042e-01,\n",
       "          -6.37450113e-01, -3.77252183e-14, -3.77252183e-14, -3.77252183e-14,\n",
       "          -3.77252183e-14, -5.43946287e-01]),\n",
       "   'split2_train_Log_Loss': array([-3.77251228e-14, -5.49069931e-01, -7.18419903e-01, -4.29904180e-01,\n",
       "          -5.49069931e-01, -7.85668815e-01, -3.77251228e-14, -3.77251228e-14,\n",
       "          -5.49069931e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -7.18419903e-01, -6.41901747e-01, -7.18419903e-01, -3.77251228e-14,\n",
       "          -6.41901747e-01, -3.77251228e-14, -3.77251228e-14, -7.18419903e-01,\n",
       "          -7.85668815e-01, -8.42175178e-01, -8.42175178e-01, -7.85668815e-01,\n",
       "          -6.41901747e-01, -3.77251228e-14, -3.77251228e-14, -3.77251228e-14,\n",
       "          -3.77251228e-14, -5.49069931e-01]),\n",
       "   'mean_train_Log_Loss': array([-3.77251703e-14, -5.46378163e-01, -7.19264134e-01, -4.26107774e-01,\n",
       "          -5.46378163e-01, -7.87036947e-01, -3.77251703e-14, -3.77251703e-14,\n",
       "          -5.46378163e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -7.19264134e-01, -6.41288662e-01, -7.19264134e-01, -3.77251703e-14,\n",
       "          -6.41288662e-01, -3.77251703e-14, -3.77251703e-14, -7.19264134e-01,\n",
       "          -7.87036947e-01, -8.43949965e-01, -8.43949965e-01, -7.87036947e-01,\n",
       "          -6.41288662e-01, -3.77251703e-14, -3.77251703e-14, -3.77251703e-14,\n",
       "          -3.77251703e-14, -5.46378163e-01]),\n",
       "   'std_train_Log_Loss': array([3.89952081e-20, 2.09977644e-03, 4.63499640e-03, 3.18217668e-03,\n",
       "          2.09977644e-03, 4.74549696e-03, 3.89952081e-20, 3.89952081e-20,\n",
       "          2.09977644e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          4.63499640e-03, 2.91627324e-03, 4.63499640e-03, 3.89952081e-20,\n",
       "          2.91627324e-03, 3.89952081e-20, 3.89952081e-20, 4.63499640e-03,\n",
       "          4.74549696e-03, 6.09185498e-03, 6.09185498e-03, 4.74549696e-03,\n",
       "          2.91627324e-03, 3.89952081e-20, 3.89952081e-20, 3.89952081e-20,\n",
       "          3.89952081e-20, 2.09977644e-03])},\n",
       "  {'weights': 'distance', 'n_neighbors': 8, 'algorithm': 'kd_tree'},\n",
       "  7,\n",
       "  -5.245011193018042),\n",
       " 'MLPClassifier_V09_PCA_5components': ({'mean_fit_time': array([ 1.76494813, 12.70371064,  2.76660371,  7.59170763, 10.26024206,\n",
       "          20.66709121, 15.97696241,  2.85968963,  9.53883576,  7.31843837,\n",
       "          10.98364186, 16.83899053,  2.61633952,  6.83938535, 16.86625091,\n",
       "          14.03082911, 14.03980645,  4.86067367, 17.70501041, 22.96395254,\n",
       "           8.37195698,  3.83209014, 12.67478752,  8.27687653,  2.52990445,\n",
       "          16.62123919,  8.45174233,  2.1326321 , 17.19337567, 11.58170978]),\n",
       "   'std_fit_time': array([0.18775273, 0.13214717, 0.74235025, 0.42749498, 0.49035443,\n",
       "          1.45390814, 1.81702669, 0.2224165 , 0.4883251 , 0.05917678,\n",
       "          2.15417461, 1.32972366, 0.29501845, 0.24813975, 4.36437924,\n",
       "          0.86075231, 1.29164592, 1.06053538, 0.44196639, 0.98709354,\n",
       "          1.25595654, 0.3361221 , 0.31880711, 0.83191645, 0.13179992,\n",
       "          0.22109389, 0.95591126, 0.40285713, 0.09170597, 4.7345228 ]),\n",
       "   'mean_score_time': array([0.05219356, 0.06648866, 0.05751324, 0.04321861, 0.04687564,\n",
       "          0.0884316 , 0.06416233, 0.06515964, 0.05252608, 0.03623668,\n",
       "          0.06183465, 0.05452029, 0.04654249, 0.03856397, 0.0618341 ,\n",
       "          0.05817811, 0.04886937, 0.04853773, 0.05418793, 0.07845688,\n",
       "          0.05485209, 0.05119713, 0.0468746 , 0.04321822, 0.06848343,\n",
       "          0.07014577, 0.04587777, 0.05950809, 0.06416361, 0.0611697 ]),\n",
       "   'std_score_time': array([0.00823684, 0.00803312, 0.00169497, 0.00477189, 0.00564133,\n",
       "          0.01348854, 0.0033899 , 0.00169537, 0.00401678, 0.00124428,\n",
       "          0.00081371, 0.00384842, 0.00589065, 0.00124362, 0.00495263,\n",
       "          0.00542231, 0.00282114, 0.00204897, 0.0012432 , 0.00308389,\n",
       "          0.00215306, 0.00235067, 0.00293615, 0.00683015, 0.00094016,\n",
       "          0.00409804, 0.00141029, 0.00285953, 0.00329004, 0.00384902]),\n",
       "   'param_solver': masked_array(data=['adam', 'lbfgs', 'adam', 'lbfgs', 'sgd', 'lbfgs',\n",
       "                      'lbfgs', 'sgd', 'sgd', 'adam', 'adam', 'sgd', 'lbfgs',\n",
       "                      'lbfgs', 'adam', 'lbfgs', 'sgd', 'lbfgs', 'sgd',\n",
       "                      'adam', 'sgd', 'lbfgs', 'sgd', 'sgd', 'sgd', 'lbfgs',\n",
       "                      'lbfgs', 'adam', 'lbfgs', 'adam'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[(200, 50), (100, 100), (200, 50), (100,), (100,),\n",
       "                      (200, 50, 50, 50), (100, 100, 50), (200, 50),\n",
       "                      (200, 50, 50), (100,), (200, 50, 50), (100, 100),\n",
       "                      (100, 100), (100,), (100, 100), (200, 50, 50),\n",
       "                      (100, 100, 50), (100, 100, 50), (100, 100, 50),\n",
       "                      (200, 50, 50, 50), (200, 50, 50, 50), (200, 50),\n",
       "                      (100, 100), (100,), (200, 50, 50), (200, 50), (100,),\n",
       "                      (200, 50, 50), (200, 50, 50), (200, 50, 50)],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.0079, 0.0242, 0.0302, 0.0285, 0.044800000000000006,\n",
       "                      0.049300000000000004, 0.0279, 0.0025, 0.0088, 0.027,\n",
       "                      0.0279, 0.0081, 0.0274, 0.009, 0.0155, 0.0106,\n",
       "                      0.04000000000000001, 0.034300000000000004, 0.0212,\n",
       "                      0.002, 0.04290000000000001, 0.049,\n",
       "                      0.036500000000000005, 0.0241, 0.0269, 0.0197, 0.0246,\n",
       "                      0.029500000000000002, 0.036300000000000006,\n",
       "                      0.04120000000000001],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_activation': masked_array(data=['identity', 'relu', 'identity', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'logistic', 'identity', 'tanh', 'relu', 'relu',\n",
       "                      'identity', 'relu', 'relu', 'tanh', 'identity',\n",
       "                      'identity', 'relu', 'logistic', 'identity', 'identity',\n",
       "                      'tanh', 'relu', 'logistic', 'logistic', 'relu',\n",
       "                      'identity', 'relu', 'relu'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0079,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0242,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0302,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0285,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.044800000000000006,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.049300000000000004,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0279,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0025,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0088,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.027,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0279,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0081,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0274,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.009,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.0155,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0106,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.04000000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.034300000000000004,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100, 50),\n",
       "     'alpha': 0.0212,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.002,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50, 50),\n",
       "     'alpha': 0.04290000000000001,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.049,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100, 100),\n",
       "     'alpha': 0.036500000000000005,\n",
       "     'activation': 'tanh'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0241,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'sgd',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.0269,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50),\n",
       "     'alpha': 0.0197,\n",
       "     'activation': 'logistic'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (100,),\n",
       "     'alpha': 0.0246,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.029500000000000002,\n",
       "     'activation': 'identity'},\n",
       "    {'solver': 'lbfgs',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.036300000000000006,\n",
       "     'activation': 'relu'},\n",
       "    {'solver': 'adam',\n",
       "     'hidden_layer_sizes': (200, 50, 50),\n",
       "     'alpha': 0.04120000000000001,\n",
       "     'activation': 'relu'}],\n",
       "   'split0_test_Accuracy': array([0.26963069, 0.58730728, 0.26353532, 0.55898171, 0.30010757,\n",
       "          0.53926138, 0.57296522, 0.05593403, 0.26532807, 0.45141628,\n",
       "          0.54499821, 0.32628182, 0.2828971 , 0.55647185, 0.55145213,\n",
       "          0.56113302, 0.27787738, 0.28074579, 0.34420939, 0.33739692,\n",
       "          0.26783793, 0.28074579, 0.30978845, 0.29652205, 0.05593403,\n",
       "          0.55790606, 0.56364288, 0.26102546, 0.56471854, 0.52778774]),\n",
       "   'split1_test_Accuracy': array([0.26984127, 0.57287157, 0.28643579, 0.5465368 , 0.29906205,\n",
       "          0.55916306, 0.56349206, 0.05591631, 0.27813853, 0.43867244,\n",
       "          0.48629149, 0.33694084, 0.28751804, 0.5479798 , 0.53138528,\n",
       "          0.56457431, 0.28499278, 0.28751804, 0.32972583, 0.36724387,\n",
       "          0.28571429, 0.28715729, 0.30772006, 0.30194805, 0.05591631,\n",
       "          0.5530303 , 0.53896104, 0.26803752, 0.5508658 , 0.51226551]),\n",
       "   'split2_test_Accuracy': array([0.27743571, 0.59145237, 0.27997102, 0.56537486, 0.30930822,\n",
       "          0.56972112, 0.57986237, 0.05613908, 0.2806954 , 0.46939515,\n",
       "          0.53929736, 0.3274176 , 0.29300978, 0.57406737, 0.52806954,\n",
       "          0.55921767, 0.2806954 , 0.28975009, 0.32705541, 0.37486418,\n",
       "          0.27707352, 0.29264759, 0.31148135, 0.30822166, 0.05613908,\n",
       "          0.55233611, 0.56609924, 0.26222383, 0.57116987, 0.55197392]),\n",
       "   'mean_test_Accuracy': array([0.27229031, 0.58387407, 0.2766162 , 0.55695746, 0.30281182,\n",
       "          0.55599615, 0.57209805, 0.05599615, 0.27469358, 0.45313627,\n",
       "          0.52355203, 0.33020908, 0.2877914 , 0.55948089, 0.53701033,\n",
       "          0.56164384, 0.28118241, 0.28598894, 0.33369382, 0.35976929,\n",
       "          0.27685652, 0.28683009, 0.30966114, 0.30221101, 0.05599615,\n",
       "          0.55443403, 0.55623648, 0.26375871, 0.56224465, 0.53064167]),\n",
       "   'std_test_Accuracy': array([0.00362659, 0.0079578 , 0.00965387, 0.0078135 , 0.00459741,\n",
       "          0.01263699, 0.00670243, 0.00010097, 0.00673051, 0.01258489,\n",
       "          0.02643562, 0.00478004, 0.00413369, 0.01084821, 0.01034207,\n",
       "          0.00221378, 0.00292842, 0.00383213, 0.00754477, 0.01618483,\n",
       "          0.0073081 , 0.0048652 , 0.00153612, 0.00478076, 0.00010097,\n",
       "          0.00248125, 0.01225011, 0.00306327, 0.00846216, 0.01631524]),\n",
       "   'rank_test_Accuracy': array([27,  1, 25,  6, 18,  8,  2, 29, 26, 13, 12, 16, 20,  5, 10,  4, 23,\n",
       "          22, 15, 14, 24, 21, 17, 19, 29,  9,  7, 28,  3, 11]),\n",
       "   'split0_train_Accuracy': array([0.28284836, 0.73016447, 0.27887222, 0.66600398, 0.31068137,\n",
       "          0.64015905, 0.69257184, 0.05602747, 0.27796855, 0.49051148,\n",
       "          0.62298934, 0.34755106, 0.29495753, 0.65967829, 0.64594253,\n",
       "          0.83553226, 0.29188505, 0.295319  , 0.35767215, 0.35568408,\n",
       "          0.27995662, 0.29513826, 0.32206759, 0.30869329, 0.05602747,\n",
       "          0.69690945, 0.66744985, 0.26676306, 0.67431773, 0.60112055]),\n",
       "   'split1_train_Accuracy': array([0.28306306, 0.7190991 , 0.29765766, 0.67441441, 0.30774775,\n",
       "          0.65315315, 0.67873874, 0.05603604, 0.29063063, 0.49927928,\n",
       "          0.56936937, 0.34504505, 0.30522523, 0.67207207, 0.62648649,\n",
       "          0.83387387, 0.29459459, 0.30630631, 0.35423423, 0.39945946,\n",
       "          0.29513514, 0.30486486, 0.32828829, 0.31621622, 0.05603604,\n",
       "          0.68198198, 0.66594595, 0.27675676, 0.65783784, 0.58810811]),\n",
       "   'split2_train_Accuracy': array([0.27477072, 0.71929509, 0.2745909 , 0.66211113, 0.30749865,\n",
       "          0.66031289, 0.66822514, 0.05592519, 0.27692861, 0.4871426 ,\n",
       "          0.58460709, 0.33303363, 0.2852005 , 0.66822514, 0.57237907,\n",
       "          0.83923755, 0.27566984, 0.2859198 , 0.33303363, 0.388779  ,\n",
       "          0.27117425, 0.28789786, 0.30731883, 0.307139  , 0.05592519,\n",
       "          0.67541809, 0.66498831, 0.25750764, 0.648984  , 0.608164  ]),\n",
       "   'mean_train_Accuracy': array([0.28022738, 0.72285289, 0.28370693, 0.66750984, 0.30864259,\n",
       "          0.65120836, 0.67984524, 0.05599623, 0.2818426 , 0.49231112,\n",
       "          0.59232193, 0.34187658, 0.29512775, 0.6666585 , 0.61493603,\n",
       "          0.83621456, 0.28738316, 0.29584837, 0.34831334, 0.38130751,\n",
       "          0.28208867, 0.295967  , 0.3192249 , 0.31068284, 0.05599623,\n",
       "          0.68476984, 0.66612803, 0.26700915, 0.66037985, 0.59913089]),\n",
       "   'std_train_Accuracy': array([3.85943626e-03, 5.17068823e-03, 1.00183032e-02, 5.13442083e-03,\n",
       "          1.44521594e-03, 8.34190414e-03, 9.97024697e-03, 5.03546264e-05,\n",
       "          6.22856393e-03, 5.11558262e-03, 2.25597629e-02, 6.33605241e-03,\n",
       "          8.17594448e-03, 5.17958811e-03, 3.11229329e-02, 2.24223067e-03,\n",
       "          8.35610784e-03, 8.33117038e-03, 1.08951659e-02, 1.86357781e-02,\n",
       "          9.89748207e-03, 6.95149446e-03, 8.79356735e-03, 3.96380784e-03,\n",
       "          5.03546264e-05, 8.99254439e-03, 1.01313235e-03, 7.86034442e-03,\n",
       "          1.04974889e-02, 8.30777805e-03]),\n",
       "   'split0_test_F1': array([0.2317193 , 0.58071412, 0.23012464, 0.54973703, 0.25320558,\n",
       "          0.52984385, 0.56555793, 0.00592578, 0.22848277, 0.43139251,\n",
       "          0.53178186, 0.28908432, 0.2486546 , 0.54867373, 0.54129528,\n",
       "          0.5558974 , 0.24315853, 0.24622924, 0.30712233, 0.30170103,\n",
       "          0.23226685, 0.2473492 , 0.26745325, 0.2484939 , 0.00592578,\n",
       "          0.54963823, 0.55634924, 0.23100973, 0.55627819, 0.51662223]),\n",
       "   'split1_test_F1': array([0.23730387, 0.56878877, 0.25793467, 0.54082258, 0.25560714,\n",
       "          0.55143617, 0.55749012, 0.00592212, 0.24191245, 0.41976238,\n",
       "          0.47177803, 0.30250955, 0.25270517, 0.54317972, 0.52280868,\n",
       "          0.56366693, 0.24915145, 0.25260639, 0.29484563, 0.32936936,\n",
       "          0.25041952, 0.25176678, 0.26447613, 0.25642121, 0.00592212,\n",
       "          0.54407104, 0.53185004, 0.22704431, 0.5450391 , 0.4965326 ]),\n",
       "   'split2_test_F1': array([0.24558765, 0.58625804, 0.25015912, 0.5604375 , 0.26623004,\n",
       "          0.56271829, 0.57117106, 0.00596815, 0.24955622, 0.45165024,\n",
       "          0.52591871, 0.28585553, 0.26094202, 0.56859968, 0.514426  ,\n",
       "          0.55503487, 0.24912725, 0.25839873, 0.28631337, 0.34090845,\n",
       "          0.2431965 , 0.26003609, 0.26752494, 0.26906792, 0.00596815,\n",
       "          0.54252584, 0.55806102, 0.22858644, 0.56448872, 0.54166986]),\n",
       "   'mean_test_F1': array([0.2381806 , 0.57858118, 0.24603483, 0.5503178 , 0.25832666,\n",
       "          0.54794289, 0.56473287, 0.00593862, 0.23994767, 0.43423953,\n",
       "          0.50984978, 0.29248495, 0.25408043, 0.55345457, 0.52622307,\n",
       "          0.55819922, 0.24713498, 0.25239091, 0.29612924, 0.32392505,\n",
       "          0.24193952, 0.25302981, 0.26648538, 0.2579603 , 0.00593862,\n",
       "          0.54542416, 0.54875665, 0.2288849 , 0.55525854, 0.5182406 ]),\n",
       "   'std_test_F1': array([5.69647479e-03, 7.28135106e-03, 1.17322490e-02, 8.00753166e-03,\n",
       "          5.65474487e-03, 1.36483227e-02, 5.60833063e-03, 2.08604460e-05,\n",
       "          8.71595879e-03, 1.31567270e-02, 2.70125339e-02, 7.20625078e-03,\n",
       "          5.11043452e-03, 1.09052900e-02, 1.12334043e-02, 3.88018676e-03,\n",
       "          2.82320203e-03, 4.97133743e-03, 8.54493554e-03, 1.64649231e-02,\n",
       "          7.47211483e-03, 5.25660637e-03, 1.42028504e-03, 8.47083992e-03,\n",
       "          2.08604460e-05, 3.05750000e-03, 1.19687394e-02, 1.63434940e-03,\n",
       "          7.96249430e-03, 1.84380793e-02]),\n",
       "   'rank_test_F1': array([27,  1, 24,  6, 18,  8,  2, 29, 26, 13, 12, 16, 20,  5, 10,  3, 23,\n",
       "          22, 15, 14, 25, 21, 17, 19, 29,  9,  7, 28,  4, 11]),\n",
       "   'split0_train_F1': array([0.24607939, 0.72661076, 0.24645782, 0.66083048, 0.26463799,\n",
       "          0.63400316, 0.68747921, 0.00594507, 0.24170305, 0.47232787,\n",
       "          0.61301709, 0.30792071, 0.26049002, 0.65604425, 0.63700614,\n",
       "          0.83454539, 0.25572917, 0.26086666, 0.3201264 , 0.31781828,\n",
       "          0.2450381 , 0.26067539, 0.27971314, 0.26164159, 0.00594507,\n",
       "          0.69188802, 0.66323705, 0.23848204, 0.66898703, 0.59142824]),\n",
       "   'split1_train_F1': array([0.24609979, 0.71538596, 0.26891237, 0.67032398, 0.26216875,\n",
       "          0.6459756 , 0.67369774, 0.00594684, 0.25172928, 0.48251575,\n",
       "          0.55548218, 0.30928799, 0.26745686, 0.66656273, 0.61835536,\n",
       "          0.83398729, 0.25674016, 0.26906338, 0.31942631, 0.3619327 ,\n",
       "          0.25830762, 0.26742947, 0.28430974, 0.27003626, 0.00594684,\n",
       "          0.67601603, 0.66035889, 0.237505  , 0.65253584, 0.573077  ]),\n",
       "   'split2_train_F1': array([0.24172829, 0.71597759, 0.24472201, 0.65725877, 0.26578067,\n",
       "          0.65557403, 0.66244317, 0.00592396, 0.24409093, 0.46937795,\n",
       "          0.57278714, 0.2951652 , 0.25057409, 0.6639404 , 0.55607255,\n",
       "          0.83790449, 0.2428115 , 0.25152692, 0.2947796 , 0.35581654,\n",
       "          0.234887  , 0.2545186 , 0.26522334, 0.26887707, 0.00592396,\n",
       "          0.66904478, 0.66028365, 0.2207281 , 0.64397091, 0.5987144 ]),\n",
       "   'mean_train_F1': array([0.24463582, 0.71932477, 0.25336407, 0.66280441, 0.2641958 ,\n",
       "          0.64518426, 0.67454004, 0.00593862, 0.24584108, 0.47474052,\n",
       "          0.5804288 , 0.30412463, 0.25950699, 0.66218246, 0.60381135,\n",
       "          0.83547906, 0.25176027, 0.26048566, 0.3114441 , 0.34518917,\n",
       "          0.24607757, 0.26087449, 0.27641541, 0.26685164, 0.00593862,\n",
       "          0.67898294, 0.6612932 , 0.23223838, 0.65516459, 0.58773988]),\n",
       "   'std_train_F1': array([2.05595345e-03, 5.15763049e-03, 1.10171245e-02, 5.51344959e-03,\n",
       "          1.50734279e-03, 8.82403201e-03, 1.02382617e-02, 1.03944448e-05,\n",
       "          4.27618143e-03, 5.62827064e-03, 2.41020452e-02, 6.35981887e-03,\n",
       "          6.92732534e-03, 4.47044989e-03, 3.46045056e-02, 1.73010961e-03,\n",
       "          6.34118446e-03, 7.16429752e-03, 1.17870490e-02, 1.95145452e-02,\n",
       "          9.58963909e-03, 5.27272081e-03, 8.13342511e-03, 3.71433327e-03,\n",
       "          1.03944448e-05, 9.55877810e-03, 1.37485841e-03, 8.14876727e-03,\n",
       "          1.03805687e-02, 1.07864763e-02]),\n",
       "   'split0_test_Log_Loss': array([-2.56376815, -1.6438238 , -2.56948908, -1.61768525, -2.50754797,\n",
       "          -1.63927974, -1.62183199, -3.61101236, -2.57036382, -1.83154731,\n",
       "          -1.56143088, -2.31772521, -2.55635152, -1.6465921 , -1.51008509,\n",
       "          -2.11569456, -2.56617872, -2.55348508, -2.24171281, -2.18071679,\n",
       "          -2.56561914, -2.55518638, -2.41401711, -2.49836661, -3.61199188,\n",
       "          -1.61838425, -1.69176672, -2.58110736, -1.62660437, -1.59338757]),\n",
       "   'split1_test_Log_Loss': array([-2.58682844, -1.61039427, -2.58308881, -1.70819785, -2.53949648,\n",
       "          -1.62588057, -1.60522604, -3.6115669 , -2.59053829, -1.85415751,\n",
       "          -1.68697827, -2.35495419, -2.57311807, -1.67629417, -1.60897943,\n",
       "          -2.00687394, -2.58280343, -2.57296092, -2.30498831, -2.10254792,\n",
       "          -2.58399985, -2.57370234, -2.44952328, -2.52022253, -3.6120022 ,\n",
       "          -1.64647846, -1.64871532, -2.59317192, -1.65084317, -1.6775786 ]),\n",
       "   'split2_test_Log_Loss': array([-2.54604166, -1.59878745, -2.55461376, -1.60002092, -2.4820442 ,\n",
       "          -1.55213782, -1.58118101, -3.61084591, -2.55171142, -1.79153159,\n",
       "          -1.58385035, -2.31001086, -2.5299212 , -1.58316999, -1.57882346,\n",
       "          -2.0707639 , -2.54724938, -2.52967118, -2.23548778, -2.07548332,\n",
       "          -2.55444165, -2.52900654, -2.42921647, -2.47117646, -3.61181718,\n",
       "          -1.58719662, -1.60865686, -2.55648211, -1.57243883, -1.54496689]),\n",
       "   'mean_test_Log_Loss': array([-2.56556823, -1.61774689, -2.56908385, -1.64197385, -2.50972838,\n",
       "          -1.60590539, -1.60281384, -3.61114185, -2.57089547, -1.82580254,\n",
       "          -1.61068798, -2.32756653, -2.55316752, -1.63544402, -1.56583152,\n",
       "          -2.06454047, -2.56543609, -2.55207158, -2.26072415, -2.11976585,\n",
       "          -2.56803326, -2.5526682 , -2.43088668, -2.49662575, -3.61193735,\n",
       "          -1.61739508, -1.64985314, -2.57695603, -1.61670758, -1.60536642]),\n",
       "   'std_test_Log_Loss': array([1.66776153e-02, 1.91091601e-02, 1.16127043e-02, 4.73546292e-02,\n",
       "          2.34741191e-02, 3.82796470e-02, 1.66857912e-02, 3.07987238e-04,\n",
       "          1.58340318e-02, 2.58560035e-02, 5.46878317e-02, 1.96101640e-02,\n",
       "          1.77556484e-02, 3.87825199e-02, 4.14442139e-02, 4.46932934e-02,\n",
       "          1.45048026e-02, 1.76775305e-02, 3.13856557e-02, 4.46583391e-02,\n",
       "          1.21720154e-02, 1.83097584e-02, 1.45598773e-02, 2.00340122e-02,\n",
       "          8.47858633e-05, 2.41791240e-02, 3.39446670e-02, 1.52458669e-02,\n",
       "          3.27282379e-02, 5.47299883e-02]),\n",
       "   'rank_test_Log_Loss': array([24,  8, 26, 10, 19,  4,  2, 29, 27, 12,  5, 16, 22,  9,  1, 13, 23,\n",
       "          20, 15, 14, 25, 21, 17, 18, 30,  7, 11, 28,  6,  3]),\n",
       "   'split0_train_Log_Loss': array([-2.53672846, -0.86402967, -2.54611396, -1.05232921, -2.48760034,\n",
       "          -1.12527409, -0.96534654, -3.6108421 , -2.55082917, -1.68361782,\n",
       "          -1.18086976, -2.2880411 , -2.52721991, -1.07176462, -1.10635618,\n",
       "          -0.5263745 , -2.54599011, -2.52629146, -2.20210277, -2.0944815 ,\n",
       "          -2.54845927, -2.52635731, -2.39747644, -2.4757004 , -3.61184534,\n",
       "          -0.97883743, -1.0309973 , -2.55805068, -1.0281143 , -1.26143944]),\n",
       "   'split1_train_Log_Loss': array([-2.51840831, -0.86058398, -2.51669686, -1.0524168 , -2.46287024,\n",
       "          -1.10939767, -1.03533567, -3.61133339, -2.52517571, -1.67972789,\n",
       "          -1.3724938 , -2.25389375, -2.50485202, -1.06233196, -1.1993093 ,\n",
       "          -0.54647247, -2.51657893, -2.50466325, -2.17688489, -1.97739229,\n",
       "          -2.5168247 , -2.50507831, -2.38149143, -2.44165093, -3.61178891,\n",
       "          -1.00795122, -1.05902447, -2.52701562, -1.10853723, -1.31955619]),\n",
       "   'split2_train_Log_Loss': array([-2.55927657, -0.86519088, -2.56508871, -1.0650255 , -2.4839328 ,\n",
       "          -1.07680275, -1.04331094, -3.61119238, -2.56464382, -1.68896466,\n",
       "          -1.30788341, -2.30435591, -2.5443928 , -1.04477747, -1.32405984,\n",
       "          -0.52304381, -2.56002835, -2.54453187, -2.22580402, -2.00380809,\n",
       "          -2.56954148, -2.54424851, -2.41635734, -2.46762534, -3.61210217,\n",
       "          -1.04306262, -1.06538561, -2.56735518, -1.10197434, -1.24997031]),\n",
       "   'mean_train_Log_Loss': array([-2.53813778, -0.86326818, -2.54263318, -1.05659051, -2.47813446,\n",
       "          -1.10382484, -1.01466439, -3.61112262, -2.5468829 , -1.68410346,\n",
       "          -1.28708232, -2.28209692, -2.52548824, -1.05962468, -1.20990844,\n",
       "          -0.53196359, -2.5408658 , -2.52516219, -2.20159723, -2.0252273 ,\n",
       "          -2.54494181, -2.52522804, -2.39844174, -2.46165889, -3.61191214,\n",
       "          -1.00995042, -1.05180246, -2.55080716, -1.07954196, -1.27698864]),\n",
       "   'std_train_Log_Loss': array([0.01671413, 0.00195632, 0.01990862, 0.00596455, 0.01089679,\n",
       "          0.02017688, 0.03502464, 0.00020654, 0.01635263, 0.0037865 ,\n",
       "          0.07960091, 0.0210255 , 0.01618883, 0.01118253, 0.08919259,\n",
       "          0.01034905, 0.01810446, 0.01629587, 0.01997435, 0.05014351,\n",
       "          0.02166478, 0.01601109, 0.01425031, 0.01452677, 0.00013633,\n",
       "          0.0262579 , 0.01493892, 0.01724667, 0.03646341, 0.0304618 ])},\n",
       "  {'solver': 'adam',\n",
       "   'hidden_layer_sizes': (100, 100),\n",
       "   'alpha': 0.0155,\n",
       "   'activation': 'relu'},\n",
       "  14,\n",
       "  -1.565831517460762)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.models_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_V001_PCA_70': LogisticRegression(C=0.4546229691182355, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.22473909055263924, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V001_PCA_70': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'DecisionTreeClassifier_V001_PCA_70': DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "             max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=0.21,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'KNeighborsClassifier_V001_PCA_70': KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V001_PCA_70': MLPClassifier(activation='logistic', alpha=0.0256, batch_size='auto',\n",
       "        beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V001_PCA_5components': LogisticRegression(C=0.3926555469145107, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.469574405665668, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V001_PCA_5components': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'DecisionTreeClassifier_V001_PCA_5components': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=0.11,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'KNeighborsClassifier_V001_PCA_5components': KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V001_PCA_5components': MLPClassifier(activation='tanh', alpha=0.035800000000000005,\n",
       "        batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "        epsilon=1e-08, hidden_layer_sizes=(100, 100),\n",
       "        learning_rate='constant', learning_rate_init=0.001, max_iter=200,\n",
       "        momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "        random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V01_PCA_85': LogisticRegression(C=0.7309066607697216, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='liblinear', tol=0.03768105472203877, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V01_PCA_85': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'DecisionTreeClassifier_V01_PCA_85': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features=0.5, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=0.26,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'KNeighborsClassifier_V01_PCA_85': KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V01_PCA_85': MLPClassifier(activation='tanh', alpha=0.0456, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V01_PCA_80': LogisticRegression(C=0.5081305158193191, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.2444512599516575, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V01_PCA_80': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'KNeighborsClassifier_V01_PCA_80': KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V01_PCA_80': MLPClassifier(activation='logistic', alpha=0.0284, batch_size='auto',\n",
       "        beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(200, 50), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V01_PCA_5components': LogisticRegression(C=0.578399543948392, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.3152014417209951, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V01_PCA_5components': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=100, max_features='log2', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'DecisionTreeClassifier_V01_PCA_5components': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "             max_features='log2', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=0.15,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'KNeighborsClassifier_V01_PCA_5components': KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V01_PCA_5components': MLPClassifier(activation='tanh', alpha=0.0064, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100, 100, 50), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V09_PCA_90': LogisticRegression(C=0.23251788066116563, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.18191201859244835, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V09_PCA_90': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'DecisionTreeClassifier_V09_PCA_90': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "             max_features=0.5, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=0.12,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'KNeighborsClassifier_V09_PCA_90': KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V09_PCA_90': MLPClassifier(activation='tanh', alpha=0.0241, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(200, 50, 50, 50), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V09_PCA_80': LogisticRegression(C=0.35081818575135704, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.27391199189187976, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V09_PCA_80': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'KNeighborsClassifier_V09_PCA_80': KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V09_PCA_80': MLPClassifier(activation='tanh', alpha=0.0171, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(200, 50), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'LogisticRegression_V09_PCA_5components': LogisticRegression(C=0.40347675303882957, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           solver='newton-cg', tol=0.7081131682707159, verbose=0,\n",
       "           warm_start=False),\n",
       " 'RandomForestClassifier_V09_PCA_5components': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=10, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'KNeighborsClassifier_V09_PCA_5components': KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "            weights='distance'),\n",
       " 'MLPClassifier_V09_PCA_5components': MLPClassifier(activation='relu', alpha=0.0155, batch_size='auto', beta_1=0.9,\n",
       "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.best_models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_V001_PCA_70': (0.7772170151405912,\n",
       "  0.7742983725062028,\n",
       "  0.8608661957702183,\n",
       "  array([[285,   3,   0, ...,   2,  21,   2],\n",
       "         [  0, 172,   0, ...,   6,   0,   0],\n",
       "         [  0,   0, 197, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 197,   0,   0],\n",
       "         [ 11,   0,   0, ...,   0, 188,   2],\n",
       "         [  4,   0,   2, ...,   0,   0, 166]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.65      0.61      0.63       466\\n    APRICOT       0.79      0.85      0.82       202\\n  AUBERGINE       0.95      0.98      0.97       200\\n    AVOCADO       0.92      0.97      0.95       209\\n     BANANA       0.59      0.45      0.51       213\\n       BEAN       0.92      0.94      0.93       195\\n      BREAD       0.81      0.85      0.82       220\\n        BUN       0.87      0.84      0.86       205\\n     CARROT       0.80      0.67      0.73       199\\n     CHEESE       0.99      0.99      0.99       194\\n   CUCUMBER       0.85      0.90      0.87       196\\n      DATES       0.92      0.95      0.93       223\\n   DOUGHNUT       0.55      0.58      0.57       197\\n        EGG       0.83      0.83      0.83       265\\n      FIRED       0.74      0.74      0.74       209\\n      GRAPE       0.72      0.55      0.62       201\\n GRAPEFRUIT       0.66      0.63      0.65       196\\n       KIWI       0.87      0.89      0.88       212\\n      LEMON       0.61      0.61      0.61       193\\n     LITCHI       0.98      1.00      0.99       192\\n      MANGO       0.55      0.61      0.58       203\\n   MOONCAKE       0.63      0.72      0.67       201\\n      OLIVE       0.85      0.89      0.87       196\\n      ONION       0.93      0.94      0.94       279\\n     ORANGE       0.66      0.69      0.67       406\\n     PAPAYA       0.80      0.75      0.78       192\\n      PASTA       0.94      1.00      0.97       193\\n      PEACH       0.68      0.57      0.62       196\\n       PEAR       0.46      0.39      0.43       195\\n     PEPPER       0.81      0.74      0.77       189\\n       PLUM       0.81      0.89      0.85       208\\nPOMEGRANATE       0.95      0.98      0.96       206\\n       QIWI       0.65      0.64      0.64       200\\n    SACHIMA       0.63      0.67      0.65       202\\n      SAUCE       0.90      0.96      0.93       195\\n      SWEET       0.88      0.95      0.91       208\\n     TOMATO       0.69      0.71      0.70       266\\n WATERMELON       0.79      0.83      0.81       200\\n\\navg / total       0.77      0.78      0.77      8322\\n'),\n",
       " 'RandomForestClassifier_V001_PCA_70': (0.9482095650084115,\n",
       "  0.9478690449953088,\n",
       "  1.1338001941266578,\n",
       "  array([[451,   0,   0, ...,   1,   0,   1],\n",
       "         [  0, 185,   0, ...,   8,   0,   0],\n",
       "         [  0,   0, 199, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 202,   0,   0],\n",
       "         [  2,   0,   0, ...,   0, 244,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 192]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.95      0.97      0.96       466\\n    APRICOT       0.92      0.92      0.92       202\\n  AUBERGINE       0.99      0.99      0.99       200\\n    AVOCADO       0.95      0.99      0.97       209\\n     BANANA       0.98      0.96      0.97       213\\n       BEAN       0.96      0.98      0.97       195\\n      BREAD       1.00      0.92      0.96       220\\n        BUN       0.99      0.97      0.98       205\\n     CARROT       0.98      0.83      0.90       199\\n     CHEESE       0.98      0.99      0.99       194\\n   CUCUMBER       0.95      0.98      0.96       196\\n      DATES       0.92      0.98      0.95       223\\n   DOUGHNUT       0.96      0.92      0.94       197\\n        EGG       0.98      0.96      0.97       265\\n      FIRED       1.00      0.89      0.94       209\\n      GRAPE       0.98      0.82      0.89       201\\n GRAPEFRUIT       0.89      0.91      0.90       196\\n       KIWI       0.95      0.97      0.96       212\\n      LEMON       0.91      0.91      0.91       193\\n     LITCHI       0.97      1.00      0.98       192\\n      MANGO       0.90      0.92      0.91       203\\n   MOONCAKE       0.89      0.99      0.94       201\\n      OLIVE       0.96      0.95      0.95       196\\n      ONION       0.97      0.97      0.97       279\\n     ORANGE       0.92      0.98      0.95       406\\n     PAPAYA       0.97      0.98      0.97       192\\n      PASTA       0.93      1.00      0.96       193\\n      PEACH       0.96      0.85      0.90       196\\n       PEAR       0.94      0.89      0.92       195\\n     PEPPER       0.99      0.87      0.92       189\\n       PLUM       0.94      1.00      0.97       208\\nPOMEGRANATE       0.93      0.98      0.96       206\\n       QIWI       0.94      0.94      0.94       200\\n    SACHIMA       0.92      0.96      0.94       202\\n      SAUCE       0.95      0.99      0.97       195\\n      SWEET       0.93      0.97      0.95       208\\n     TOMATO       0.96      0.92      0.94       266\\n WATERMELON       0.88      0.96      0.92       200\\n\\navg / total       0.95      0.95      0.95      8322\\n'),\n",
       " 'DecisionTreeClassifier_V001_PCA_70': (0.1457582311944244,\n",
       "  0.056722623636216794,\n",
       "  2.791806529607071,\n",
       "  array([[  0,   0, 128, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 121, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,  28, ...,   0,   0,   0],\n",
       "         [  0,   0,  44, ...,   0,   0,   0]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.00      0.00      0.00       466\\n    APRICOT       0.00      0.00      0.00       202\\n  AUBERGINE       0.11      0.60      0.19       200\\n    AVOCADO       0.00      0.00      0.00       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.00      0.00      0.00       195\\n      BREAD       0.00      0.00      0.00       220\\n        BUN       0.29      0.48      0.36       205\\n     CARROT       0.00      0.00      0.00       199\\n     CHEESE       0.13      0.71      0.23       194\\n   CUCUMBER       0.20      0.88      0.33       196\\n      DATES       0.00      0.00      0.00       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.00      0.00      0.00       265\\n      FIRED       0.00      0.00      0.00       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.00      0.00      0.00       196\\n       KIWI       0.00      0.00      0.00       212\\n      LEMON       0.09      0.77      0.17       193\\n     LITCHI       0.27      0.91      0.42       192\\n      MANGO       0.00      0.00      0.00       203\\n   MOONCAKE       0.00      0.00      0.00       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.14      0.26      0.19       279\\n     ORANGE       0.00      0.00      0.00       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.11      0.93      0.20       193\\n      PEACH       0.00      0.00      0.00       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.00      0.00      0.00       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.00      0.00      0.00       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.15      0.53      0.24       202\\n      SAUCE       0.00      0.00      0.00       195\\n      SWEET       0.00      0.00      0.00       208\\n     TOMATO       0.00      0.00      0.00       266\\n WATERMELON       0.00      0.00      0.00       200\\n\\navg / total       0.04      0.15      0.06      8322\\n'),\n",
       " 'KNeighborsClassifier_V001_PCA_70': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V001_PCA_70': (0.9954337899543378,\n",
       "  0.9954184148723713,\n",
       "  0.1072114495663708,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 198]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       0.99      0.98      0.98       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      0.99      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       0.99      0.97      0.98       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      0.99      0.99       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       0.97      0.99      0.98       193\\n     LITCHI       0.99      1.00      1.00       192\\n      MANGO       0.97      0.94      0.96       203\\n   MOONCAKE       0.98      0.99      0.98       201\\n      OLIVE       0.99      1.00      0.99       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       0.99      1.00      1.00       193\\n      PEACH       0.99      1.00      1.00       196\\n       PEAR       0.99      0.99      0.99       195\\n     PEPPER       0.99      1.00      0.99       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       0.99      0.99      0.99       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       0.99      0.99      0.99       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'LogisticRegression_V001_PCA_5components': (0.27457341985099737,\n",
       "  0.23961967580324425,\n",
       "  2.464730476864277,\n",
       "  array([[133,   8,   2, ...,   0,   1,   7],\n",
       "         [  2,  92,   0, ...,  11,   0,   0],\n",
       "         [  0,   0, 115, ...,   0,   0,  11],\n",
       "         ...,\n",
       "         [  0,  33,   0, ...,  33,   0,   0],\n",
       "         [ 84,   1,   0, ...,   0,   0,  14],\n",
       "         [  2,   0,  36, ...,   0,   0,  58]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.10      0.29      0.15       466\\n    APRICOT       0.32      0.46      0.37       202\\n  AUBERGINE       0.45      0.57      0.51       200\\n    AVOCADO       0.55      0.54      0.54       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.68      0.27      0.38       195\\n      BREAD       0.28      0.17      0.21       220\\n        BUN       0.31      0.24      0.27       205\\n     CARROT       0.09      0.08      0.08       199\\n     CHEESE       0.36      0.59      0.45       194\\n   CUCUMBER       0.38      0.74      0.50       196\\n      DATES       0.24      0.31      0.27       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.23      0.29      0.25       265\\n      FIRED       0.08      0.00      0.01       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.25      0.27      0.26       196\\n       KIWI       0.33      0.33      0.33       212\\n      LEMON       0.17      0.07      0.10       193\\n     LITCHI       0.48      0.53      0.50       192\\n      MANGO       0.09      0.24      0.13       203\\n   MOONCAKE       0.18      0.11      0.13       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.51      0.72      0.60       279\\n     ORANGE       0.11      0.21      0.15       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.44      0.77      0.56       193\\n      PEACH       0.00      0.00      0.00       196\\n       PEAR       0.19      0.02      0.03       195\\n     PEPPER       0.36      0.14      0.20       189\\n       PLUM       0.37      0.26      0.31       208\\nPOMEGRANATE       0.54      0.82      0.65       206\\n       QIWI       0.22      0.34      0.27       200\\n    SACHIMA       0.12      0.02      0.03       202\\n      SAUCE       0.42      0.57      0.48       195\\n      SWEET       0.23      0.16      0.19       208\\n     TOMATO       0.00      0.00      0.00       266\\n WATERMELON       0.38      0.29      0.33       200\\n\\navg / total       0.24      0.27      0.24      8322\\n'),\n",
       " 'RandomForestClassifier_V001_PCA_5components': (0.7386445565969719,\n",
       "  0.7354492965638494,\n",
       "  1.112584704496361,\n",
       "  array([[314,   5,   1, ...,   2,   7,   1],\n",
       "         [  0, 174,   0, ...,   6,   0,   0],\n",
       "         [  1,   0, 186, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   3,   0, ..., 172,   0,   0],\n",
       "         [  5,   0,   0, ...,   0, 188,   3],\n",
       "         [  1,   0,   0, ...,   0,   2, 155]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.82      0.67      0.74       466\\n    APRICOT       0.71      0.86      0.78       202\\n  AUBERGINE       0.94      0.93      0.93       200\\n    AVOCADO       0.75      0.83      0.78       209\\n     BANANA       0.65      0.60      0.62       213\\n       BEAN       0.78      0.86      0.82       195\\n      BREAD       0.77      0.62      0.69       220\\n        BUN       0.86      0.65      0.74       205\\n     CARROT       0.76      0.63      0.69       199\\n     CHEESE       0.73      0.86      0.79       194\\n   CUCUMBER       0.76      0.83      0.79       196\\n      DATES       0.74      0.74      0.74       223\\n   DOUGHNUT       0.70      0.72      0.71       197\\n        EGG       0.78      0.80      0.79       265\\n      FIRED       0.88      0.49      0.63       209\\n      GRAPE       0.83      0.57      0.67       201\\n GRAPEFRUIT       0.71      0.52      0.60       196\\n       KIWI       0.77      0.90      0.83       212\\n      LEMON       0.59      0.64      0.61       193\\n     LITCHI       0.73      0.98      0.84       192\\n      MANGO       0.64      0.58      0.61       203\\n   MOONCAKE       0.70      0.75      0.73       201\\n      OLIVE       0.84      0.79      0.82       196\\n      ONION       0.81      0.85      0.83       279\\n     ORANGE       0.63      0.66      0.65       406\\n     PAPAYA       0.74      0.77      0.75       192\\n      PASTA       0.72      0.96      0.82       193\\n      PEACH       0.64      0.61      0.62       196\\n       PEAR       0.57      0.65      0.61       195\\n     PEPPER       0.81      0.62      0.70       189\\n       PLUM       0.75      0.88      0.81       208\\nPOMEGRANATE       0.84      0.92      0.88       206\\n       QIWI       0.65      0.68      0.67       200\\n    SACHIMA       0.70      0.68      0.69       202\\n      SAUCE       0.75      0.78      0.76       195\\n      SWEET       0.73      0.83      0.77       208\\n     TOMATO       0.75      0.71      0.73       266\\n WATERMELON       0.68      0.78      0.72       200\\n\\navg / total       0.74      0.74      0.74      8322\\n'),\n",
       " 'DecisionTreeClassifier_V001_PCA_5components': (0.18433068973804373,\n",
       "  0.10458719299906097,\n",
       "  2.595375230575929,\n",
       "  array([[130,  18,   0, ...,   5,   0,  32],\n",
       "         [  0, 142,   0, ...,  21,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   3],\n",
       "         ...,\n",
       "         [  0,  56,   0, ...,  71,   0,   0],\n",
       "         [ 75,   4,   0, ...,  10,   0,  28],\n",
       "         [  0,   0,   0, ...,   2,   0,  88]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.14      0.28      0.19       466\\n    APRICOT       0.22      0.70      0.33       202\\n  AUBERGINE       0.00      0.00      0.00       200\\n    AVOCADO       0.14      0.50      0.22       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.16      0.41      0.23       195\\n      BREAD       0.00      0.00      0.00       220\\n        BUN       0.29      0.48      0.36       205\\n     CARROT       0.19      0.55      0.28       199\\n     CHEESE       0.00      0.00      0.00       194\\n   CUCUMBER       0.00      0.00      0.00       196\\n      DATES       0.00      0.00      0.00       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.00      0.00      0.00       265\\n      FIRED       0.00      0.00      0.00       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.00      0.00      0.00       196\\n       KIWI       0.00      0.00      0.00       212\\n      LEMON       0.14      0.31      0.19       193\\n     LITCHI       0.27      0.91      0.42       192\\n      MANGO       0.00      0.00      0.00       203\\n   MOONCAKE       0.00      0.00      0.00       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.16      0.71      0.25       279\\n     ORANGE       0.10      0.20      0.14       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.00      0.00      0.00       193\\n      PEACH       0.00      0.00      0.00       196\\n       PEAR       0.17      0.17      0.17       195\\n     PEPPER       0.00      0.00      0.00       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.45      0.79      0.57       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.00      0.00      0.00       202\\n      SAUCE       0.00      0.00      0.00       195\\n      SWEET       0.16      0.34      0.22       208\\n     TOMATO       0.00      0.00      0.00       266\\n WATERMELON       0.17      0.44      0.25       200\\n\\navg / total       0.08      0.18      0.10      8322\\n'),\n",
       " 'KNeighborsClassifier_V001_PCA_5components': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V001_PCA_5components': (0.682648401826484,\n",
       "  0.6795881372560096,\n",
       "  1.0077793857302209,\n",
       "  array([[260,   4,   2, ...,   0,  13,   1],\n",
       "         [  0, 162,   0, ...,   5,   0,   0],\n",
       "         [  0,   0, 192, ...,   0,   0,   1],\n",
       "         ...,\n",
       "         [  0,  10,   0, ..., 152,   0,   0],\n",
       "         [  2,   0,   0, ...,   0, 189,   2],\n",
       "         [  1,   0,   0, ...,   0,   3, 158]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.71      0.56      0.62       466\\n    APRICOT       0.66      0.80      0.72       202\\n  AUBERGINE       0.96      0.96      0.96       200\\n    AVOCADO       0.87      0.79      0.83       209\\n     BANANA       0.47      0.45      0.46       213\\n       BEAN       0.77      0.85      0.81       195\\n      BREAD       0.71      0.66      0.68       220\\n        BUN       0.78      0.64      0.71       205\\n     CARROT       0.69      0.59      0.63       199\\n     CHEESE       0.92      0.87      0.89       194\\n   CUCUMBER       0.74      0.86      0.80       196\\n      DATES       0.81      0.72      0.76       223\\n   DOUGHNUT       0.53      0.50      0.51       197\\n        EGG       0.77      0.72      0.75       265\\n      FIRED       0.74      0.49      0.59       209\\n      GRAPE       0.60      0.61      0.60       201\\n GRAPEFRUIT       0.63      0.58      0.60       196\\n       KIWI       0.73      0.87      0.79       212\\n      LEMON       0.42      0.57      0.49       193\\n     LITCHI       0.89      0.98      0.94       192\\n      MANGO       0.53      0.35      0.42       203\\n   MOONCAKE       0.59      0.66      0.62       201\\n      OLIVE       0.80      0.86      0.83       196\\n      ONION       0.82      0.84      0.83       279\\n     ORANGE       0.55      0.53      0.54       406\\n     PAPAYA       0.70      0.76      0.73       192\\n      PASTA       0.71      0.85      0.78       193\\n      PEACH       0.43      0.37      0.40       196\\n       PEAR       0.41      0.39      0.40       195\\n     PEPPER       0.76      0.53      0.63       189\\n       PLUM       0.75      0.90      0.82       208\\nPOMEGRANATE       0.88      0.96      0.91       206\\n       QIWI       0.56      0.52      0.54       200\\n    SACHIMA       0.38      0.54      0.45       202\\n      SAUCE       0.71      0.85      0.77       195\\n      SWEET       0.76      0.73      0.75       208\\n     TOMATO       0.65      0.71      0.68       266\\n WATERMELON       0.67      0.79      0.72       200\\n\\navg / total       0.69      0.68      0.68      8322\\n'),\n",
       " 'LogisticRegression_V01_PCA_85': (0.7178562845469839,\n",
       "  0.7104444720658714,\n",
       "  1.0775001761598084,\n",
       "  array([[314,   3,   1, ...,   0,  20,   1],\n",
       "         [  1, 186,   0, ...,   2,   0,   0],\n",
       "         [  0,   0, 196, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 196,   0,   0],\n",
       "         [ 22,   0,   0, ...,   0, 178,   1],\n",
       "         [  2,   0,   0, ...,   0,   3, 130]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.59      0.67      0.63       466\\n    APRICOT       0.87      0.92      0.89       202\\n  AUBERGINE       0.92      0.98      0.95       200\\n    AVOCADO       0.89      0.97      0.93       209\\n     BANANA       0.53      0.37      0.44       213\\n       BEAN       0.85      0.96      0.90       195\\n      BREAD       0.72      0.62      0.67       220\\n        BUN       0.77      0.79      0.78       205\\n     CARROT       0.64      0.62      0.63       199\\n     CHEESE       0.95      0.97      0.96       194\\n   CUCUMBER       0.76      0.85      0.80       196\\n      DATES       0.92      0.99      0.95       223\\n   DOUGHNUT       0.46      0.32      0.38       197\\n        EGG       0.65      0.67      0.66       265\\n      FIRED       0.76      0.62      0.68       209\\n      GRAPE       0.68      0.40      0.50       201\\n GRAPEFRUIT       0.77      0.69      0.73       196\\n       KIWI       0.85      0.89      0.87       212\\n      LEMON       0.54      0.52      0.53       193\\n     LITCHI       0.90      0.99      0.95       192\\n      MANGO       0.39      0.43      0.41       203\\n   MOONCAKE       0.55      0.47      0.51       201\\n      OLIVE       0.90      0.92      0.91       196\\n      ONION       0.85      0.93      0.89       279\\n     ORANGE       0.63      0.68      0.65       406\\n     PAPAYA       0.84      0.88      0.85       192\\n      PASTA       0.88      0.98      0.93       193\\n      PEACH       0.45      0.39      0.42       196\\n       PEAR       0.38      0.27      0.32       195\\n     PEPPER       0.79      0.65      0.71       189\\n       PLUM       0.54      0.66      0.59       208\\nPOMEGRANATE       0.93      1.00      0.96       206\\n       QIWI       0.51      0.50      0.50       200\\n    SACHIMA       0.55      0.54      0.55       202\\n      SAUCE       0.85      0.95      0.90       195\\n      SWEET       0.89      0.94      0.92       208\\n     TOMATO       0.58      0.67      0.62       266\\n WATERMELON       0.69      0.65      0.67       200\\n\\navg / total       0.71      0.72      0.71      8322\\n'),\n",
       " 'RandomForestClassifier_V01_PCA_85': (0.9305455419370343,\n",
       "  0.930070114809629,\n",
       "  1.1580966277072882,\n",
       "  array([[454,   0,   1, ...,   0,   2,   0],\n",
       "         [  1, 199,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 196, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 204,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 245,   0],\n",
       "         [  1,   0,   0, ...,   0,   1, 187]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.90      0.97      0.94       466\\n    APRICOT       0.96      0.99      0.97       202\\n  AUBERGINE       0.96      0.98      0.97       200\\n    AVOCADO       1.00      0.99      0.99       209\\n     BANANA       0.95      0.88      0.91       213\\n       BEAN       0.91      0.98      0.95       195\\n      BREAD       0.99      0.95      0.97       220\\n        BUN       0.97      0.92      0.94       205\\n     CARROT       0.93      0.82      0.87       199\\n     CHEESE       0.99      1.00      0.99       194\\n   CUCUMBER       0.93      0.92      0.93       196\\n      DATES       0.95      1.00      0.97       223\\n   DOUGHNUT       0.95      0.85      0.90       197\\n        EGG       0.92      0.92      0.92       265\\n      FIRED       0.98      0.79      0.88       209\\n      GRAPE       0.99      0.82      0.90       201\\n GRAPEFRUIT       0.97      0.95      0.96       196\\n       KIWI       0.96      0.99      0.97       212\\n      LEMON       0.90      0.89      0.89       193\\n     LITCHI       0.91      1.00      0.96       192\\n      MANGO       0.82      0.87      0.85       203\\n   MOONCAKE       0.83      0.95      0.89       201\\n      OLIVE       0.97      0.96      0.97       196\\n      ONION       0.97      0.98      0.98       279\\n     ORANGE       0.88      0.98      0.92       406\\n     PAPAYA       0.94      0.95      0.95       192\\n      PASTA       0.95      0.99      0.97       193\\n      PEACH       0.88      0.79      0.83       196\\n       PEAR       0.98      0.90      0.94       195\\n     PEPPER       0.98      0.84      0.90       189\\n       PLUM       0.91      0.90      0.91       208\\nPOMEGRANATE       0.96      1.00      0.98       206\\n       QIWI       0.95      0.82      0.88       200\\n    SACHIMA       0.86      0.88      0.87       202\\n      SAUCE       0.92      0.97      0.94       195\\n      SWEET       0.99      0.98      0.98       208\\n     TOMATO       0.88      0.92      0.90       266\\n WATERMELON       0.86      0.94      0.90       200\\n\\navg / total       0.93      0.93      0.93      8322\\n'),\n",
       " 'DecisionTreeClassifier_V01_PCA_85': (0.12496995914443643,\n",
       "  0.034712628360044746,\n",
       "  3.0666085511607086,\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.00      0.00      0.00       466\\n    APRICOT       0.00      0.00      0.00       202\\n  AUBERGINE       0.00      0.00      0.00       200\\n    AVOCADO       0.00      0.00      0.00       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.00      0.00      0.00       195\\n      BREAD       0.00      0.00      0.00       220\\n        BUN       0.00      0.00      0.00       205\\n     CARROT       0.00      0.00      0.00       199\\n     CHEESE       0.00      0.00      0.00       194\\n   CUCUMBER       0.00      0.00      0.00       196\\n      DATES       0.11      0.82      0.19       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.00      0.00      0.00       265\\n      FIRED       0.00      0.00      0.00       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.00      0.00      0.00       196\\n       KIWI       0.15      0.67      0.25       212\\n      LEMON       0.00      0.00      0.00       193\\n     LITCHI       0.16      0.98      0.28       192\\n      MANGO       0.00      0.00      0.00       203\\n   MOONCAKE       0.00      0.00      0.00       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.15      0.86      0.25       279\\n     ORANGE       0.10      0.70      0.17       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.00      0.00      0.00       193\\n      PEACH       0.00      0.00      0.00       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.00      0.00      0.00       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.00      0.00      0.00       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.00      0.00      0.00       202\\n      SAUCE       0.00      0.00      0.00       195\\n      SWEET       0.00      0.00      0.00       208\\n     TOMATO       0.00      0.00      0.00       266\\n WATERMELON       0.00      0.00      0.00       200\\n\\navg / total       0.02      0.12      0.03      8322\\n'),\n",
       " 'KNeighborsClassifier_V01_PCA_85': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V01_PCA_85': (1.0,\n",
       "  1.0,\n",
       "  0.02465236429179296,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'LogisticRegression_V01_PCA_80': (0.692621965873588,\n",
       "  0.6844077629892783,\n",
       "  1.1346776848113571,\n",
       "  array([[301,   4,   0, ...,   0,  21,   1],\n",
       "         [  0, 186,   0, ...,   2,   0,   0],\n",
       "         [  0,   0, 195, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 194,   0,   0],\n",
       "         [ 22,   0,   0, ...,   0, 169,   0],\n",
       "         [  1,   0,   0, ...,   0,   4, 128]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.54      0.65      0.59       466\\n    APRICOT       0.86      0.92      0.89       202\\n  AUBERGINE       0.93      0.97      0.95       200\\n    AVOCADO       0.88      0.96      0.92       209\\n     BANANA       0.45      0.30      0.36       213\\n       BEAN       0.85      0.94      0.89       195\\n      BREAD       0.73      0.61      0.66       220\\n        BUN       0.78      0.71      0.74       205\\n     CARROT       0.65      0.67      0.66       199\\n     CHEESE       0.92      0.96      0.94       194\\n   CUCUMBER       0.73      0.81      0.77       196\\n      DATES       0.92      0.99      0.95       223\\n   DOUGHNUT       0.37      0.31      0.34       197\\n        EGG       0.63      0.62      0.62       265\\n      FIRED       0.72      0.60      0.65       209\\n      GRAPE       0.65      0.34      0.45       201\\n GRAPEFRUIT       0.70      0.64      0.67       196\\n       KIWI       0.79      0.86      0.83       212\\n      LEMON       0.51      0.50      0.51       193\\n     LITCHI       0.92      0.99      0.95       192\\n      MANGO       0.38      0.38      0.38       203\\n   MOONCAKE       0.52      0.42      0.46       201\\n      OLIVE       0.86      0.91      0.89       196\\n      ONION       0.84      0.92      0.88       279\\n     ORANGE       0.57      0.65      0.61       406\\n     PAPAYA       0.79      0.82      0.81       192\\n      PASTA       0.89      0.98      0.94       193\\n      PEACH       0.40      0.37      0.38       196\\n       PEAR       0.36      0.22      0.27       195\\n     PEPPER       0.78      0.61      0.68       189\\n       PLUM       0.51      0.63      0.56       208\\nPOMEGRANATE       0.94      0.99      0.96       206\\n       QIWI       0.47      0.43      0.45       200\\n    SACHIMA       0.50      0.51      0.51       202\\n      SAUCE       0.86      0.95      0.91       195\\n      SWEET       0.88      0.93      0.91       208\\n     TOMATO       0.54      0.64      0.59       266\\n WATERMELON       0.69      0.64      0.66       200\\n\\navg / total       0.68      0.69      0.68      8322\\n'),\n",
       " 'RandomForestClassifier_V01_PCA_80': (0.918649363133862,\n",
       "  0.9179624260557143,\n",
       "  1.1109274994718432,\n",
       "  array([[450,   0,   1, ...,   0,   3,   0],\n",
       "         [  1, 199,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 196, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 205,   0,   0],\n",
       "         [  1,   0,   0, ...,   0, 241,   0],\n",
       "         [  1,   0,   0, ...,   0,   1, 187]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.86      0.97      0.91       466\\n    APRICOT       0.95      0.99      0.97       202\\n  AUBERGINE       0.98      0.98      0.98       200\\n    AVOCADO       0.98      0.99      0.99       209\\n     BANANA       0.95      0.87      0.91       213\\n       BEAN       0.92      0.98      0.95       195\\n      BREAD       1.00      0.93      0.96       220\\n        BUN       0.95      0.91      0.93       205\\n     CARROT       0.93      0.82      0.87       199\\n     CHEESE       0.99      1.00      0.99       194\\n   CUCUMBER       0.92      0.92      0.92       196\\n      DATES       0.96      0.99      0.97       223\\n   DOUGHNUT       0.93      0.80      0.86       197\\n        EGG       0.92      0.90      0.91       265\\n      FIRED       0.97      0.76      0.85       209\\n      GRAPE       0.99      0.79      0.88       201\\n GRAPEFRUIT       0.96      0.91      0.93       196\\n       KIWI       0.96      0.98      0.97       212\\n      LEMON       0.86      0.89      0.87       193\\n     LITCHI       0.91      1.00      0.96       192\\n      MANGO       0.76      0.85      0.80       203\\n   MOONCAKE       0.83      0.93      0.88       201\\n      OLIVE       0.96      0.98      0.97       196\\n      ONION       0.96      0.97      0.97       279\\n     ORANGE       0.87      0.97      0.92       406\\n     PAPAYA       0.94      0.94      0.94       192\\n      PASTA       0.95      0.99      0.97       193\\n      PEACH       0.86      0.74      0.79       196\\n       PEAR       0.94      0.84      0.89       195\\n     PEPPER       0.98      0.83      0.90       189\\n       PLUM       0.90      0.86      0.88       208\\nPOMEGRANATE       0.95      1.00      0.98       206\\n       QIWI       0.92      0.82      0.87       200\\n    SACHIMA       0.85      0.86      0.86       202\\n      SAUCE       0.90      0.97      0.94       195\\n      SWEET       0.98      0.99      0.98       208\\n     TOMATO       0.85      0.91      0.87       266\\n WATERMELON       0.87      0.94      0.90       200\\n\\navg / total       0.92      0.92      0.92      8322\\n'),\n",
       " 'KNeighborsClassifier_V01_PCA_80': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V01_PCA_80': (0.972001922614756,\n",
       "  0.9718309162753648,\n",
       "  0.2242658546980865,\n",
       "  array([[463,   0,   0, ...,   0,   1,   0],\n",
       "         [  0, 201,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  4,   0,   0, ...,   0, 260,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 195]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.95      0.99      0.97       466\\n    APRICOT       0.99      1.00      0.99       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       0.98      1.00      0.99       209\\n     BANANA       0.91      0.91      0.91       213\\n       BEAN       0.99      1.00      1.00       195\\n      BREAD       0.97      0.96      0.97       220\\n        BUN       0.99      0.99      0.99       205\\n     CARROT       0.99      0.97      0.98       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       0.98      1.00      0.99       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       0.93      0.86      0.89       197\\n        EGG       0.99      1.00      0.99       265\\n      FIRED       0.96      0.93      0.95       209\\n      GRAPE       0.98      0.95      0.96       201\\n GRAPEFRUIT       0.98      0.97      0.98       196\\n       KIWI       1.00      0.99      1.00       212\\n      LEMON       0.89      0.95      0.92       193\\n     LITCHI       0.99      1.00      1.00       192\\n      MANGO       0.93      0.85      0.89       203\\n   MOONCAKE       0.94      0.92      0.93       201\\n      OLIVE       1.00      0.99      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      0.99      0.99       406\\n     PAPAYA       0.97      1.00      0.99       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       0.95      0.92      0.94       196\\n       PEAR       0.92      0.89      0.90       195\\n     PEPPER       0.98      0.97      0.97       189\\n       PLUM       0.95      0.98      0.96       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       0.93      0.99      0.96       200\\n    SACHIMA       0.94      0.95      0.95       202\\n      SAUCE       0.99      0.99      0.99       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       0.99      0.98      0.98       266\\n WATERMELON       0.97      0.97      0.97       200\\n\\navg / total       0.97      0.97      0.97      8322\\n'),\n",
       " 'LogisticRegression_V01_PCA_5components': (0.2445325642874309,\n",
       "  0.2003330133879575,\n",
       "  2.667896264138106,\n",
       "  array([[157,   7,   1, ...,   0,  24,   0],\n",
       "         [  5,  53,   0, ...,   5,   0,   0],\n",
       "         [  0,   0, 133, ...,   0,   0,   1],\n",
       "         ...,\n",
       "         [  1,   4,   0, ...,   1,   0,   0],\n",
       "         [126,   0,   5, ...,   0,  11,   0],\n",
       "         [  2,   0,  26, ...,   4,   5,  65]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.11      0.34      0.16       466\\n    APRICOT       0.39      0.26      0.31       202\\n  AUBERGINE       0.37      0.67      0.47       200\\n    AVOCADO       0.35      0.24      0.29       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.05      0.01      0.01       195\\n      BREAD       0.35      0.38      0.37       220\\n        BUN       0.35      0.21      0.26       205\\n     CARROT       0.04      0.01      0.02       199\\n     CHEESE       0.63      0.12      0.21       194\\n   CUCUMBER       0.24      0.04      0.06       196\\n      DATES       0.12      0.33      0.18       223\\n   DOUGHNUT       0.12      0.02      0.03       197\\n        EGG       0.18      0.17      0.18       265\\n      FIRED       0.12      0.02      0.04       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.55      0.17      0.26       196\\n       KIWI       0.29      0.66      0.40       212\\n      LEMON       0.33      0.01      0.01       193\\n     LITCHI       0.62      0.91      0.74       192\\n      MANGO       0.11      0.27      0.16       203\\n   MOONCAKE       0.17      0.05      0.08       201\\n      OLIVE       0.16      0.11      0.13       196\\n      ONION       0.31      0.39      0.34       279\\n     ORANGE       0.27      0.48      0.34       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.43      0.81      0.57       193\\n      PEACH       0.24      0.24      0.24       196\\n       PEAR       0.01      0.01      0.01       195\\n     PEPPER       0.22      0.11      0.15       189\\n       PLUM       0.15      0.01      0.02       208\\nPOMEGRANATE       0.33      0.78      0.46       206\\n       QIWI       0.06      0.05      0.05       200\\n    SACHIMA       0.12      0.05      0.07       202\\n      SAUCE       0.44      0.65      0.53       195\\n      SWEET       0.02      0.00      0.01       208\\n     TOMATO       0.06      0.04      0.05       266\\n WATERMELON       0.32      0.33      0.32       200\\n\\navg / total       0.22      0.24      0.20      8322\\n'),\n",
       " 'RandomForestClassifier_V01_PCA_5components': (0.7178562845469839,\n",
       "  0.7120835809765,\n",
       "  1.1866570263608733,\n",
       "  array([[342,   7,   3, ...,   0,  10,   0],\n",
       "         [  3, 183,   0, ...,   5,   0,   0],\n",
       "         [  0,   0, 188, ...,   0,   0,   1],\n",
       "         ...,\n",
       "         [  1,   3,   0, ..., 172,   0,   0],\n",
       "         [ 16,   1,   1, ...,   0, 162,   0],\n",
       "         [  4,   0,   1, ...,   0,   1, 157]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.63      0.73      0.68       466\\n    APRICOT       0.73      0.91      0.81       202\\n  AUBERGINE       0.84      0.94      0.89       200\\n    AVOCADO       0.82      0.87      0.84       209\\n     BANANA       0.60      0.41      0.49       213\\n       BEAN       0.78      0.81      0.80       195\\n      BREAD       0.73      0.73      0.73       220\\n        BUN       0.77      0.66      0.71       205\\n     CARROT       0.66      0.63      0.64       199\\n     CHEESE       0.76      0.82      0.79       194\\n   CUCUMBER       0.79      0.77      0.78       196\\n      DATES       0.80      0.83      0.81       223\\n   DOUGHNUT       0.57      0.49      0.53       197\\n        EGG       0.71      0.55      0.62       265\\n      FIRED       0.82      0.56      0.66       209\\n      GRAPE       0.67      0.51      0.58       201\\n GRAPEFRUIT       0.69      0.74      0.72       196\\n       KIWI       0.81      0.83      0.82       212\\n      LEMON       0.66      0.65      0.65       193\\n     LITCHI       0.82      0.97      0.89       192\\n      MANGO       0.47      0.62      0.54       203\\n   MOONCAKE       0.59      0.75      0.66       201\\n      OLIVE       0.89      0.86      0.88       196\\n      ONION       0.75      0.90      0.82       279\\n     ORANGE       0.64      0.79      0.71       406\\n     PAPAYA       0.85      0.76      0.80       192\\n      PASTA       0.76      0.97      0.85       193\\n      PEACH       0.66      0.49      0.56       196\\n       PEAR       0.65      0.47      0.54       195\\n     PEPPER       0.90      0.50      0.64       189\\n       PLUM       0.64      0.67      0.65       208\\nPOMEGRANATE       0.80      0.92      0.85       206\\n       QIWI       0.74      0.39      0.51       200\\n    SACHIMA       0.62      0.63      0.63       202\\n      SAUCE       0.83      0.86      0.84       195\\n      SWEET       0.83      0.83      0.83       208\\n     TOMATO       0.60      0.61      0.61       266\\n WATERMELON       0.75      0.79      0.77       200\\n\\navg / total       0.72      0.72      0.71      8322\\n'),\n",
       " 'DecisionTreeClassifier_V01_PCA_5components': (0.14467676039413602,\n",
       "  0.0665583266818413,\n",
       "  2.803624773212794,\n",
       "  array([[ 78,   0,  10, ...,   0,  34,   0],\n",
       "         [  7,   0,   0, ...,   0,   2,   0],\n",
       "         [  3,   0, 175, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [ 18,   0,   1, ...,   0,  10,   0],\n",
       "         [ 64,   0,  22, ...,   0,  54,   0],\n",
       "         [ 18,   0, 151, ...,   0,   2,   0]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.07      0.17      0.10       466\\n    APRICOT       0.00      0.00      0.00       202\\n  AUBERGINE       0.16      0.88      0.27       200\\n    AVOCADO       0.00      0.00      0.00       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.00      0.00      0.00       195\\n      BREAD       0.00      0.00      0.00       220\\n        BUN       0.00      0.00      0.00       205\\n     CARROT       0.00      0.00      0.00       199\\n     CHEESE       0.00      0.00      0.00       194\\n   CUCUMBER       0.00      0.00      0.00       196\\n      DATES       0.00      0.00      0.00       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.00      0.00      0.00       265\\n      FIRED       0.17      0.21      0.18       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.20      0.34      0.25       196\\n       KIWI       0.17      0.61      0.27       212\\n      LEMON       0.00      0.00      0.00       193\\n     LITCHI       0.10      0.58      0.18       192\\n      MANGO       0.12      0.57      0.20       203\\n   MOONCAKE       0.00      0.00      0.00       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.20      0.48      0.28       279\\n     ORANGE       0.00      0.00      0.00       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.00      0.00      0.00       193\\n      PEACH       0.00      0.00      0.00       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.00      0.00      0.00       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.18      0.72      0.28       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.00      0.00      0.00       202\\n      SAUCE       0.17      0.77      0.28       195\\n      SWEET       0.00      0.00      0.00       208\\n     TOMATO       0.12      0.20      0.15       266\\n WATERMELON       0.00      0.00      0.00       200\\n\\navg / total       0.05      0.14      0.07      8322\\n'),\n",
       " 'KNeighborsClassifier_V01_PCA_5components': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V01_PCA_5components': (0.7510213890891613,\n",
       "  0.7480836520004321,\n",
       "  0.823489596976135,\n",
       "  array([[330,   9,   1, ...,   0,   8,   0],\n",
       "         [  1, 190,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 195, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  2,   1,   0, ..., 194,   0,   0],\n",
       "         [ 19,   0,   0, ...,   0, 172,   0],\n",
       "         [  4,   0,   0, ...,   0,   1, 162]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.60      0.71      0.65       466\\n    APRICOT       0.86      0.94      0.90       202\\n  AUBERGINE       0.93      0.97      0.95       200\\n    AVOCADO       0.95      0.95      0.95       209\\n     BANANA       0.49      0.40      0.44       213\\n       BEAN       0.85      0.86      0.85       195\\n      BREAD       0.75      0.76      0.76       220\\n        BUN       0.76      0.68      0.72       205\\n     CARROT       0.73      0.64      0.68       199\\n     CHEESE       0.87      0.94      0.90       194\\n   CUCUMBER       0.82      0.90      0.86       196\\n      DATES       0.94      0.91      0.93       223\\n   DOUGHNUT       0.51      0.53      0.52       197\\n        EGG       0.70      0.59      0.64       265\\n      FIRED       0.80      0.62      0.70       209\\n      GRAPE       0.85      0.72      0.78       201\\n GRAPEFRUIT       0.83      0.78      0.80       196\\n       KIWI       0.92      0.93      0.93       212\\n      LEMON       0.56      0.69      0.62       193\\n     LITCHI       0.96      1.00      0.98       192\\n      MANGO       0.43      0.43      0.43       203\\n   MOONCAKE       0.65      0.65      0.65       201\\n      OLIVE       0.96      0.96      0.96       196\\n      ONION       0.82      0.92      0.87       279\\n     ORANGE       0.70      0.71      0.70       406\\n     PAPAYA       0.94      0.88      0.91       192\\n      PASTA       0.86      0.96      0.91       193\\n      PEACH       0.60      0.52      0.56       196\\n       PEAR       0.50      0.42      0.46       195\\n     PEPPER       0.80      0.67      0.73       189\\n       PLUM       0.64      0.78      0.70       208\\nPOMEGRANATE       0.85      0.96      0.90       206\\n       QIWI       0.57      0.39      0.46       200\\n    SACHIMA       0.52      0.63      0.57       202\\n      SAUCE       0.93      0.86      0.89       195\\n      SWEET       0.87      0.93      0.90       208\\n     TOMATO       0.66      0.65      0.65       266\\n WATERMELON       0.80      0.81      0.80       200\\n\\navg / total       0.75      0.75      0.75      8322\\n'),\n",
       " 'LogisticRegression_V09_PCA_90': (0.7189377553472723,\n",
       "  0.7092855008462485,\n",
       "  1.0633046078924175,\n",
       "  array([[331,   3,   1, ...,   0,  17,   0],\n",
       "         [  1, 189,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 196, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   1,   0, ..., 196,   0,   0],\n",
       "         [ 32,   0,   0, ...,   0, 176,   0],\n",
       "         [  1,   0,   0, ...,   0,   3, 132]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.55      0.71      0.62       466\\n    APRICOT       0.89      0.94      0.91       202\\n  AUBERGINE       0.92      0.98      0.95       200\\n    AVOCADO       0.91      0.95      0.93       209\\n     BANANA       0.48      0.37      0.42       213\\n       BEAN       0.87      0.96      0.91       195\\n      BREAD       0.71      0.66      0.69       220\\n        BUN       0.80      0.73      0.77       205\\n     CARROT       0.63      0.66      0.65       199\\n     CHEESE       0.93      0.95      0.94       194\\n   CUCUMBER       0.80      0.85      0.82       196\\n      DATES       0.94      1.00      0.97       223\\n   DOUGHNUT       0.38      0.20      0.27       197\\n        EGG       0.66      0.70      0.68       265\\n      FIRED       0.74      0.59      0.66       209\\n      GRAPE       0.72      0.41      0.52       201\\n GRAPEFRUIT       0.78      0.76      0.77       196\\n       KIWI       0.87      0.92      0.89       212\\n      LEMON       0.53      0.56      0.55       193\\n     LITCHI       0.90      1.00      0.95       192\\n      MANGO       0.36      0.35      0.36       203\\n   MOONCAKE       0.58      0.46      0.52       201\\n      OLIVE       0.91      0.92      0.92       196\\n      ONION       0.84      0.92      0.88       279\\n     ORANGE       0.62      0.76      0.68       406\\n     PAPAYA       0.85      0.89      0.87       192\\n      PASTA       0.88      0.99      0.93       193\\n      PEACH       0.43      0.38      0.40       196\\n       PEAR       0.41      0.21      0.27       195\\n     PEPPER       0.78      0.67      0.72       189\\n       PLUM       0.54      0.58      0.56       208\\nPOMEGRANATE       0.96      1.00      0.98       206\\n       QIWI       0.48      0.39      0.43       200\\n    SACHIMA       0.59      0.56      0.58       202\\n      SAUCE       0.90      0.97      0.93       195\\n      SWEET       0.92      0.94      0.93       208\\n     TOMATO       0.57      0.66      0.61       266\\n WATERMELON       0.64      0.66      0.65       200\\n\\navg / total       0.71      0.72      0.71      8322\\n'),\n",
       " 'RandomForestClassifier_V09_PCA_90': (0.928142273491949,\n",
       "  0.9275274416170685,\n",
       "  1.0564899334341498,\n",
       "  array([[453,   0,   0, ...,   0,   3,   0],\n",
       "         [  1, 198,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 196, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 205,   0,   0],\n",
       "         [  1,   0,   0, ...,   0, 243,   0],\n",
       "         [  0,   0,   0, ...,   0,   1, 186]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.88      0.97      0.92       466\\n    APRICOT       0.97      0.98      0.98       202\\n  AUBERGINE       0.99      0.98      0.98       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       0.93      0.85      0.89       213\\n       BEAN       0.93      0.99      0.96       195\\n      BREAD       0.98      0.95      0.96       220\\n        BUN       0.97      0.94      0.96       205\\n     CARROT       0.92      0.87      0.90       199\\n     CHEESE       0.98      1.00      0.99       194\\n   CUCUMBER       0.94      0.94      0.94       196\\n      DATES       0.99      1.00      1.00       223\\n   DOUGHNUT       0.94      0.79      0.86       197\\n        EGG       0.94      0.93      0.93       265\\n      FIRED       0.99      0.78      0.87       209\\n      GRAPE       1.00      0.78      0.88       201\\n GRAPEFRUIT       0.95      0.95      0.95       196\\n       KIWI       0.96      1.00      0.98       212\\n      LEMON       0.87      0.88      0.87       193\\n     LITCHI       0.92      1.00      0.96       192\\n      MANGO       0.87      0.86      0.86       203\\n   MOONCAKE       0.81      0.91      0.85       201\\n      OLIVE       0.97      0.99      0.98       196\\n      ONION       0.95      0.97      0.96       279\\n     ORANGE       0.85      0.99      0.92       406\\n     PAPAYA       0.97      0.97      0.97       192\\n      PASTA       0.92      1.00      0.96       193\\n      PEACH       0.87      0.80      0.84       196\\n       PEAR       0.98      0.84      0.90       195\\n     PEPPER       0.98      0.85      0.91       189\\n       PLUM       0.92      0.88      0.90       208\\nPOMEGRANATE       0.96      1.00      0.98       206\\n       QIWI       0.94      0.81      0.87       200\\n    SACHIMA       0.86      0.88      0.87       202\\n      SAUCE       0.93      0.98      0.96       195\\n      SWEET       1.00      0.99      0.99       208\\n     TOMATO       0.83      0.91      0.87       266\\n WATERMELON       0.85      0.93      0.89       200\\n\\navg / total       0.93      0.93      0.93      8322\\n'),\n",
       " 'DecisionTreeClassifier_V09_PCA_90': (0.23131458783946166,\n",
       "  0.15968304734720698,\n",
       "  2.6312156497062325,\n",
       "  array([[ 88,  15,   0, ...,   0,  69,  35],\n",
       "         [  9, 140,   0, ...,   0,   3,   0],\n",
       "         [  0,   0,  45, ...,   0,   0,  21],\n",
       "         ...,\n",
       "         [  8,  60,   0, ...,  21,   3,   0],\n",
       "         [  6,   5,   1, ...,   0,  99,  34],\n",
       "         [  0,   6,   0, ...,   0,   3, 107]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.13      0.19      0.15       466\\n    APRICOT       0.20      0.69      0.30       202\\n  AUBERGINE       0.85      0.23      0.36       200\\n    AVOCADO       0.19      0.42      0.26       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.68      0.44      0.53       195\\n      BREAD       0.00      0.00      0.00       220\\n        BUN       0.20      0.50      0.28       205\\n     CARROT       0.16      0.64      0.25       199\\n     CHEESE       0.55      0.55      0.55       194\\n   CUCUMBER       0.00      0.00      0.00       196\\n      DATES       0.00      0.00      0.00       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.00      0.00      0.00       265\\n      FIRED       0.00      0.00      0.00       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.00      0.00      0.00       196\\n       KIWI       0.00      0.00      0.00       212\\n      LEMON       0.00      0.00      0.00       193\\n     LITCHI       0.37      0.95      0.53       192\\n      MANGO       0.00      0.00      0.00       203\\n   MOONCAKE       0.00      0.00      0.00       201\\n      OLIVE       0.00      0.00      0.00       196\\n      ONION       0.34      0.80      0.47       279\\n     ORANGE       0.13      0.17      0.15       406\\n     PAPAYA       0.00      0.00      0.00       192\\n      PASTA       0.12      0.60      0.20       193\\n      PEACH       0.13      0.31      0.18       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.00      0.00      0.00       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.47      0.89      0.62       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.00      0.00      0.00       202\\n      SAUCE       0.56      0.41      0.47       195\\n      SWEET       0.84      0.10      0.18       208\\n     TOMATO       0.15      0.37      0.22       266\\n WATERMELON       0.25      0.54      0.34       200\\n\\navg / total       0.16      0.23      0.16      8322\\n'),\n",
       " 'KNeighborsClassifier_V09_PCA_90': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V09_PCA_90': (0.9966354241768806,\n",
       "  0.9966573591359174,\n",
       "  0.03398505800721411,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      0.95      0.98       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       0.98      1.00      0.99       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      0.99      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      0.99      0.99       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       0.99      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      0.97      0.98       189\\n       PLUM       0.99      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      0.95      0.98       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       0.91      1.00      0.95       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'LogisticRegression_V09_PCA_80': (0.6149963950973324,\n",
       "  0.5961521362473655,\n",
       "  1.3983725871305837,\n",
       "  array([[264,   5,   0, ...,   0,  23,   6],\n",
       "         [  1, 181,   0, ...,   0,   1,   0],\n",
       "         [  0,   0, 190, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 195,   0,   0],\n",
       "         [ 45,   0,   0, ...,   0, 141,   1],\n",
       "         [  3,   0,   0, ...,   0,   4, 113]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.38      0.57      0.46       466\\n    APRICOT       0.83      0.90      0.86       202\\n  AUBERGINE       0.88      0.95      0.91       200\\n    AVOCADO       0.76      0.91      0.83       209\\n     BANANA       0.38      0.21      0.27       213\\n       BEAN       0.76      0.91      0.83       195\\n      BREAD       0.67      0.54      0.59       220\\n        BUN       0.69      0.68      0.69       205\\n     CARROT       0.54      0.53      0.53       199\\n     CHEESE       0.88      0.89      0.89       194\\n   CUCUMBER       0.63      0.76      0.69       196\\n      DATES       0.91      1.00      0.95       223\\n   DOUGHNUT       0.25      0.08      0.12       197\\n        EGG       0.51      0.48      0.50       265\\n      FIRED       0.68      0.54      0.60       209\\n      GRAPE       0.52      0.18      0.27       201\\n GRAPEFRUIT       0.66      0.59      0.62       196\\n       KIWI       0.69      0.77      0.73       212\\n      LEMON       0.39      0.33      0.35       193\\n     LITCHI       0.75      0.98      0.85       192\\n      MANGO       0.29      0.29      0.29       203\\n   MOONCAKE       0.53      0.30      0.38       201\\n      OLIVE       0.83      0.83      0.83       196\\n      ONION       0.73      0.89      0.80       279\\n     ORANGE       0.45      0.64      0.53       406\\n     PAPAYA       0.73      0.73      0.73       192\\n      PASTA       0.81      0.98      0.89       193\\n      PEACH       0.29      0.30      0.30       196\\n       PEAR       0.26      0.07      0.11       195\\n     PEPPER       0.61      0.52      0.56       189\\n       PLUM       0.44      0.33      0.38       208\\nPOMEGRANATE       0.93      1.00      0.96       206\\n       QIWI       0.39      0.31      0.34       200\\n    SACHIMA       0.47      0.41      0.43       202\\n      SAUCE       0.80      0.96      0.88       195\\n      SWEET       0.84      0.94      0.89       208\\n     TOMATO       0.40      0.53      0.45       266\\n WATERMELON       0.61      0.56      0.59       200\\n\\navg / total       0.60      0.61      0.60      8322\\n'),\n",
       " 'RandomForestClassifier_V09_PCA_80': (0.8971401105503485,\n",
       "  0.8960771769790665,\n",
       "  1.0026902614894675,\n",
       "  array([[438,   1,   1, ...,   0,   8,   0],\n",
       "         [  1, 199,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 195, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 203,   0,   0],\n",
       "         [  3,   0,   0, ...,   0, 238,   0],\n",
       "         [  1,   0,   0, ...,   0,   2, 181]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.83      0.94      0.88       466\\n    APRICOT       0.94      0.99      0.96       202\\n  AUBERGINE       0.98      0.97      0.98       200\\n    AVOCADO       0.98      0.99      0.99       209\\n     BANANA       0.88      0.78      0.83       213\\n       BEAN       0.91      0.98      0.94       195\\n      BREAD       0.97      0.89      0.93       220\\n        BUN       0.94      0.87      0.90       205\\n     CARROT       0.90      0.85      0.87       199\\n     CHEESE       0.97      0.99      0.98       194\\n   CUCUMBER       0.95      0.93      0.94       196\\n      DATES       0.99      1.00      0.99       223\\n   DOUGHNUT       0.89      0.72      0.79       197\\n        EGG       0.91      0.87      0.89       265\\n      FIRED       0.98      0.71      0.83       209\\n      GRAPE       0.99      0.70      0.82       201\\n GRAPEFRUIT       0.94      0.89      0.91       196\\n       KIWI       0.95      0.98      0.97       212\\n      LEMON       0.83      0.84      0.84       193\\n     LITCHI       0.89      1.00      0.94       192\\n      MANGO       0.71      0.80      0.75       203\\n   MOONCAKE       0.79      0.88      0.83       201\\n      OLIVE       0.97      0.99      0.98       196\\n      ONION       0.95      0.97      0.96       279\\n     ORANGE       0.81      0.97      0.88       406\\n     PAPAYA       0.96      0.96      0.96       192\\n      PASTA       0.88      0.99      0.94       193\\n      PEACH       0.80      0.71      0.75       196\\n       PEAR       0.92      0.77      0.84       195\\n     PEPPER       0.95      0.83      0.89       189\\n       PLUM       0.89      0.85      0.87       208\\nPOMEGRANATE       0.98      1.00      0.99       206\\n       QIWI       0.88      0.75      0.81       200\\n    SACHIMA       0.82      0.81      0.82       202\\n      SAUCE       0.89      0.97      0.93       195\\n      SWEET       0.99      0.98      0.98       208\\n     TOMATO       0.79      0.89      0.84       266\\n WATERMELON       0.85      0.91      0.87       200\\n\\navg / total       0.90      0.90      0.90      8322\\n'),\n",
       " 'KNeighborsClassifier_V09_PCA_80': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V09_PCA_80': (0.9997596731554914,\n",
       "  0.9997599602762061,\n",
       "  0.024123640985566904,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      0.99      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      0.99      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       0.99      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'LogisticRegression_V09_PCA_5components': (0.25462629175678925,\n",
       "  0.2028320829326687,\n",
       "  2.682001719161579,\n",
       "  array([[163,   9,   1, ...,   0,  19,   0],\n",
       "         [  5,  42,   0, ...,   1,   0,   0],\n",
       "         [  0,   0, 128, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  1,   3,   0, ...,   2,   0,   0],\n",
       "         [125,   0,   6, ...,   0,   5,   0],\n",
       "         [  3,   0,  35, ...,   0,   1,  62]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.12      0.35      0.18       466\\n    APRICOT       0.33      0.21      0.25       202\\n  AUBERGINE       0.35      0.64      0.45       200\\n    AVOCADO       0.50      0.33      0.40       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.33      0.09      0.14       195\\n      BREAD       0.32      0.45      0.38       220\\n        BUN       0.35      0.18      0.24       205\\n     CARROT       0.14      0.02      0.03       199\\n     CHEESE       0.69      0.05      0.09       194\\n   CUCUMBER       0.00      0.00      0.00       196\\n      DATES       0.15      0.41      0.22       223\\n   DOUGHNUT       0.25      0.02      0.03       197\\n        EGG       0.12      0.05      0.07       265\\n      FIRED       0.08      0.01      0.02       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.47      0.16      0.24       196\\n       KIWI       0.27      0.66      0.38       212\\n      LEMON       0.00      0.00      0.00       193\\n     LITCHI       0.57      0.90      0.70       192\\n      MANGO       0.10      0.24      0.14       203\\n   MOONCAKE       0.26      0.03      0.06       201\\n      OLIVE       0.14      0.10      0.11       196\\n      ONION       0.33      0.66      0.44       279\\n     ORANGE       0.25      0.49      0.33       406\\n     PAPAYA       1.00      0.07      0.13       192\\n      PASTA       0.41      0.73      0.53       193\\n      PEACH       0.22      0.20      0.21       196\\n       PEAR       0.03      0.01      0.01       195\\n     PEPPER       0.31      0.31      0.31       189\\n       PLUM       0.00      0.00      0.00       208\\nPOMEGRANATE       0.33      0.78      0.46       206\\n       QIWI       0.04      0.04      0.04       200\\n    SACHIMA       0.14      0.05      0.07       202\\n      SAUCE       0.50      0.71      0.58       195\\n      SWEET       0.07      0.01      0.02       208\\n     TOMATO       0.03      0.02      0.02       266\\n WATERMELON       0.34      0.31      0.33       200\\n\\navg / total       0.24      0.25      0.20      8322\\n'),\n",
       " 'RandomForestClassifier_V09_PCA_5components': (0.714732035568373,\n",
       "  0.7090092073371068,\n",
       "  1.1733398341393961,\n",
       "  array([[326,   4,   3, ...,   0,  18,   2],\n",
       "         [  0, 178,   0, ...,   5,   0,   0],\n",
       "         [  0,   0, 180, ...,   0,   0,   4],\n",
       "         ...,\n",
       "         [  1,   9,   0, ..., 176,   0,   0],\n",
       "         [ 15,   0,   2, ...,   0, 182,   2],\n",
       "         [  3,   0,   0, ...,   0,   1, 159]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.61      0.70      0.65       466\\n    APRICOT       0.71      0.88      0.79       202\\n  AUBERGINE       0.88      0.90      0.89       200\\n    AVOCADO       0.83      0.89      0.86       209\\n     BANANA       0.57      0.41      0.48       213\\n       BEAN       0.80      0.89      0.84       195\\n      BREAD       0.74      0.75      0.74       220\\n        BUN       0.75      0.72      0.73       205\\n     CARROT       0.72      0.69      0.70       199\\n     CHEESE       0.70      0.75      0.73       194\\n   CUCUMBER       0.87      0.78      0.82       196\\n      DATES       0.86      0.84      0.85       223\\n   DOUGHNUT       0.65      0.43      0.52       197\\n        EGG       0.74      0.59      0.66       265\\n      FIRED       0.80      0.52      0.63       209\\n      GRAPE       0.71      0.41      0.52       201\\n GRAPEFRUIT       0.69      0.67      0.68       196\\n       KIWI       0.87      0.89      0.88       212\\n      LEMON       0.61      0.61      0.61       193\\n     LITCHI       0.81      0.98      0.89       192\\n      MANGO       0.45      0.60      0.51       203\\n   MOONCAKE       0.57      0.75      0.64       201\\n      OLIVE       0.91      0.80      0.85       196\\n      ONION       0.77      0.90      0.83       279\\n     ORANGE       0.61      0.75      0.67       406\\n     PAPAYA       0.81      0.70      0.75       192\\n      PASTA       0.75      0.96      0.85       193\\n      PEACH       0.67      0.53      0.59       196\\n       PEAR       0.64      0.45      0.53       195\\n     PEPPER       0.83      0.57      0.68       189\\n       PLUM       0.64      0.65      0.65       208\\nPOMEGRANATE       0.81      0.94      0.87       206\\n       QIWI       0.74      0.39      0.51       200\\n    SACHIMA       0.64      0.58      0.61       202\\n      SAUCE       0.80      0.91      0.85       195\\n      SWEET       0.77      0.85      0.81       208\\n     TOMATO       0.56      0.68      0.62       266\\n WATERMELON       0.69      0.80      0.74       200\\n\\navg / total       0.72      0.71      0.71      8322\\n'),\n",
       " 'KNeighborsClassifier_V09_PCA_5components': (1.0,\n",
       "  1.0,\n",
       "  3.772517025997449e-14,\n",
       "  array([[466,   0,   0, ...,   0,   0,   0],\n",
       "         [  0, 202,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 200, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 208,   0,   0],\n",
       "         [  0,   0,   0, ...,   0, 266,   0],\n",
       "         [  0,   0,   0, ...,   0,   0, 200]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'MLPClassifier_V09_PCA_5components': (0.6558519586637828,\n",
       "  0.647270350878414,\n",
       "  1.068914962532863,\n",
       "  array([[224,   8,   3, ...,   0,  28,   5],\n",
       "         [  1, 179,   0, ...,   4,   0,   0],\n",
       "         [  0,   0, 184, ...,   0,   2,   2],\n",
       "         ...,\n",
       "         [  2,   5,   0, ..., 178,   0,   0],\n",
       "         [ 18,   0,   0, ...,   0, 168,   2],\n",
       "         [  0,   0,   1, ...,   0,   2, 150]], dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.62      0.48      0.54       466\\n    APRICOT       0.76      0.89      0.82       202\\n  AUBERGINE       0.90      0.92      0.91       200\\n    AVOCADO       0.89      0.91      0.90       209\\n     BANANA       0.49      0.22      0.30       213\\n       BEAN       0.73      0.93      0.82       195\\n      BREAD       0.71      0.69      0.70       220\\n        BUN       0.63      0.69      0.66       205\\n     CARROT       0.66      0.57      0.61       199\\n     CHEESE       0.78      0.78      0.78       194\\n   CUCUMBER       0.70      0.69      0.70       196\\n      DATES       0.88      0.85      0.87       223\\n   DOUGHNUT       0.37      0.24      0.29       197\\n        EGG       0.75      0.58      0.65       265\\n      FIRED       0.62      0.60      0.61       209\\n      GRAPE       0.50      0.24      0.33       201\\n GRAPEFRUIT       0.64      0.68      0.66       196\\n       KIWI       0.85      0.90      0.87       212\\n      LEMON       0.39      0.69      0.49       193\\n     LITCHI       0.89      0.99      0.94       192\\n      MANGO       0.41      0.28      0.33       203\\n   MOONCAKE       0.53      0.52      0.53       201\\n      OLIVE       0.94      0.88      0.91       196\\n      ONION       0.80      0.91      0.85       279\\n     ORANGE       0.63      0.56      0.59       406\\n     PAPAYA       0.86      0.70      0.77       192\\n      PASTA       0.78      0.91      0.84       193\\n      PEACH       0.41      0.38      0.39       196\\n       PEAR       0.32      0.38      0.35       195\\n     PEPPER       0.68      0.53      0.60       189\\n       PLUM       0.69      0.39      0.50       208\\nPOMEGRANATE       0.79      0.95      0.87       206\\n       QIWI       0.55      0.32      0.41       200\\n    SACHIMA       0.37      0.76      0.50       202\\n      SAUCE       0.75      0.89      0.81       195\\n      SWEET       0.81      0.86      0.83       208\\n     TOMATO       0.48      0.63      0.55       266\\n WATERMELON       0.55      0.75      0.63       200\\n\\navg / total       0.66      0.66      0.65      8322\\n')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.best_models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_filename = rootDir + \"_best_results_\" + '_randomized_results_much_more' + '.sav'\n",
    "pickle.dump(mlp_bench.best_models_results, open(best_results_filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.best_models_dict['KNeighborsClassifier_V09_PCA_5components'].fit(\n",
    "    mlp_bench.transformators['V09_PCA_5components'].transform(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('LogisticRegression_V001_PCA_70', LogisticRegression(C=0.4546229691182355, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.22473909055263924, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V001_PCA_70', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('DecisionTreeClassifier_V001_PCA_70', DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.21,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')), ('KNeighborsClassifier_V001_PCA_70', KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V001_PCA_70', MLPClassifier(activation='logistic', alpha=0.0256, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V001_PCA_5components', LogisticRegression(C=0.3926555469145107, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.469574405665668, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V001_PCA_5components', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=35, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('DecisionTreeClassifier_V001_PCA_5components', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.11,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')), ('KNeighborsClassifier_V001_PCA_5components', KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V001_PCA_5components', MLPClassifier(activation='tanh', alpha=0.035800000000000005,\n",
       "       batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(100, 100),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=200,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)), ('LogisticRegression_V01_PCA_85', LogisticRegression(C=0.7309066607697216, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.03768105472203877, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V01_PCA_85', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('DecisionTreeClassifier_V01_PCA_85', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.26,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')), ('KNeighborsClassifier_V01_PCA_85', KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V01_PCA_85', MLPClassifier(activation='tanh', alpha=0.0456, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V01_PCA_80', LogisticRegression(C=0.5081305158193191, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.2444512599516575, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V01_PCA_80', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('KNeighborsClassifier_V01_PCA_80', KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V01_PCA_80', MLPClassifier(activation='logistic', alpha=0.0284, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V01_PCA_5components', LogisticRegression(C=0.578399543948392, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.3152014417209951, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V01_PCA_5components', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('DecisionTreeClassifier_V01_PCA_5components', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.15,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')), ('KNeighborsClassifier_V01_PCA_5components', KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V01_PCA_5components', MLPClassifier(activation='tanh', alpha=0.0064, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V09_PCA_90', LogisticRegression(C=0.23251788066116563, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.18191201859244835, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V09_PCA_90', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('DecisionTreeClassifier_V09_PCA_90', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
       "            max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.12,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')), ('KNeighborsClassifier_V09_PCA_90', KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V09_PCA_90', MLPClassifier(activation='tanh', alpha=0.0241, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 50, 50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V09_PCA_80', LogisticRegression(C=0.35081818575135704, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.27391199189187976, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V09_PCA_80', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('KNeighborsClassifier_V09_PCA_80', KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V09_PCA_80', MLPClassifier(activation='tanh', alpha=0.0171, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)), ('LogisticRegression_V09_PCA_5components', LogisticRegression(C=0.40347675303882957, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.7081131682707159, verbose=0,\n",
       "          warm_start=False)), ('RandomForestClassifier_V09_PCA_5components', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)), ('KNeighborsClassifier_V09_PCA_5components', KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
       "           weights='distance')), ('MLPClassifier_V09_PCA_5components', MLPClassifier(activation='relu', alpha=0.0155, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.best_models_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 3.772517025997449e-14, array([[466,   0,   0, ...,   0,   0,   0],\n",
       "        [  0, 202,   0, ...,   0,   0,   0],\n",
       "        [  0,   0, 200, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ..., 208,   0,   0],\n",
       "        [  0,   0,   0, ...,   0, 266,   0],\n",
       "        [  0,   0,   0, ...,   0,   0, 200]], dtype=int64), '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.evaluate_model(mlp_bench.transformators['V09_PCA_5components'].transform(X_train),y_train,\n",
    "                         np.unique(y_train),mlp_bench.best_models_dict['KNeighborsClassifier_V09_PCA_5components'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6463238827486785,\n",
       " 0.6400731226694368,\n",
       " 4.467182043098239,\n",
       " array([[55,  2,  0, ...,  0, 10,  1],\n",
       "        [ 0, 43,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0, 45, ...,  0,  0,  1],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ..., 36,  0,  0],\n",
       "        [ 3,  0,  0, ...,  0, 45,  0],\n",
       "        [ 1,  0,  0, ...,  0,  0, 38]], dtype=int64),\n",
       " '             precision    recall  f1-score   support\\n\\n      APPLE       0.50      0.43      0.46       127\\n    APRICOT       0.74      0.90      0.81        48\\n  AUBERGINE       0.88      0.90      0.89        50\\n    AVOCADO       0.81      0.85      0.83        41\\n     BANANA       0.35      0.30      0.32        37\\n       BEAN       0.74      0.76      0.75        55\\n      BREAD       0.65      0.58      0.61        67\\n        BUN       0.73      0.49      0.59        45\\n     CARROT       0.62      0.55      0.58        51\\n     CHEESE       0.71      0.80      0.76        56\\n   CUCUMBER       0.67      0.80      0.73        54\\n      DATES       0.72      0.85      0.78        27\\n   DOUGHNUT       0.46      0.36      0.40        53\\n        EGG       0.64      0.53      0.58        70\\n      FIRED       0.74      0.41      0.53        41\\n      GRAPE       0.50      0.35      0.41        49\\n GRAPEFRUIT       0.86      0.78      0.82        54\\n       KIWI       0.83      0.89      0.86        38\\n      LEMON       0.45      0.44      0.45        57\\n     LITCHI       0.88      0.98      0.93        58\\n      MANGO       0.24      0.28      0.25        47\\n   MOONCAKE       0.53      0.61      0.57        49\\n      OLIVE       0.89      0.87      0.88        54\\n      ONION       0.71      0.94      0.81        62\\n     ORANGE       0.61      0.60      0.60       110\\n     PAPAYA       0.82      0.84      0.83        58\\n      PASTA       0.84      0.91      0.87        57\\n      PEACH       0.42      0.59      0.49        54\\n       PEAR       0.42      0.36      0.39        55\\n     PEPPER       0.82      0.61      0.70        61\\n       PLUM       0.44      0.59      0.51        41\\nPOMEGRANATE       0.85      0.93      0.89        44\\n       QIWI       0.42      0.26      0.32        50\\n    SACHIMA       0.49      0.46      0.47        48\\n      SAUCE       0.78      0.78      0.78        55\\n      SWEET       0.82      0.86      0.84        42\\n     TOMATO       0.51      0.68      0.58        66\\n WATERMELON       0.67      0.76      0.71        50\\n\\navg / total       0.65      0.65      0.64      2081\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bench.evaluate_model(mlp_bench.transformators['V09_PCA_5components'].transform(X_val),y_val,\n",
    "                         np.unique(y_val),mlp_bench.best_models_dict['KNeighborsClassifier_V09_PCA_5components'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8322, 16680)\n",
      "(8322, 3142)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.01)\n",
    "selector.fit(X_train)\n",
    "Xs_train = selector.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(Xs_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cluster: 0 cspace: RGB; sortCH1; X' 'Cluster: 0 cspace: RGB; sortCH1; Y'\n",
      " 'Cluster: 0 cspace: RGB; sortCH2; X' 'Cluster: 0 cspace: RGB; sortCH2; Y'\n",
      " 'Cluster: 0 cspace: RGB; sortCH3; X' 'Cluster: 0 cspace: RGB; sortCH3; Y'\n",
      " 'Cluster: 0 cspace: RGB; sortX; X' 'Cluster: 0 cspace: RGB; sortX; Y'\n",
      " 'Cluster: 0 cspace: RGB; sortY; X' 'Cluster: 0 cspace: RGB; sortY; Y'\n",
      " 'Cluster: 0 cspace: RGB; sortSize; X'\n",
      " 'Cluster: 0 cspace: RGB; sortSize; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortCH1; X' 'Cluster: 1 cspace: RGB; sortCH1; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortCH2; X' 'Cluster: 1 cspace: RGB; sortCH2; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortCH3; X' 'Cluster: 1 cspace: RGB; sortCH3; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortX; X' 'Cluster: 1 cspace: RGB; sortX; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortY; X' 'Cluster: 1 cspace: RGB; sortY; Y'\n",
      " 'Cluster: 1 cspace: RGB; sortSize; X'\n",
      " 'Cluster: 1 cspace: RGB; sortSize; Y'\n",
      " 'Cluster: 2 cspace: RGB; sortCH1; X' 'Cluster: 2 cspace: RGB; sortCH1; Y'\n",
      " 'Cluster: 2 cspace: RGB; sortCH2; X' 'Cluster: 2 cspace: RGB; sortCH2; Y'\n",
      " 'Cluster: 2 cspace: RGB; sortCH3; X' 'Cluster: 2 cspace: RGB; sortCH3; Y'\n",
      " 'Cluster: 2 cspace: RGB; sortX; Y' 'Cluster: 2 cspace: RGB; sortY; X'\n",
      " 'Cluster: 2 cspace: RGB; sortY; Y' 'Cluster: 2 cspace: RGB; sortSize; X'\n",
      " 'Cluster: 2 cspace: RGB; sortSize; Y'\n",
      " 'Cluster: 3 cspace: RGB; sortCH1; X' 'Cluster: 3 cspace: RGB; sortCH1; Y'\n",
      " 'Cluster: 3 cspace: RGB; sortCH2; X' 'Cluster: 3 cspace: RGB; sortCH2; Y'\n",
      " 'Cluster: 3 cspace: RGB; sortCH3; X' 'Cluster: 3 cspace: RGB; sortX; X'\n",
      " 'Cluster: 3 cspace: RGB; sortY; X' 'Cluster: 3 cspace: RGB; sortY; Y'\n",
      " 'Cluster: 3 cspace: RGB; sortSize; X'\n",
      " 'Cluster: 3 cspace: RGB; sortSize; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortCH1; X' 'Cluster: 4 cspace: RGB; sortCH1; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortCH2; X' 'Cluster: 4 cspace: RGB; sortCH2; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortCH3; X' 'Cluster: 4 cspace: RGB; sortCH3; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortX; X' 'Cluster: 4 cspace: RGB; sortX; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortY; X' 'Cluster: 4 cspace: RGB; sortY; Y'\n",
      " 'Cluster: 4 cspace: RGB; sortSize; X'\n",
      " 'Cluster: 4 cspace: RGB; sortSize; Y' 'HSV-CH1-0' 'HSV-CH1-1' 'HSV-CH1-2'\n",
      " 'HSV-CH1-3' 'HSV-CH1-4' 'HSV-CH1-5' 'HSV-CH1-6' 'HSV-CH1-7' 'HSV-CH1-8'\n",
      " 'HSV-CH1-9' 'HSV-CH1-10' 'HSV-CH1-11' 'HSV-CH1-12' 'HSV-CH1-13'\n",
      " 'HSV-CH1-14' 'HSV-CH1-15' 'HSV-CH1-16' 'HSV-CH1-17' 'HSV-CH1-18'\n",
      " 'HSV-CH1-19' 'HSV-CH1-20' 'HSV-CH1-21' 'HSV-CH1-22' 'HSV-CH1-23'\n",
      " 'HSV-CH1-24' 'HSV-CH1-25' 'HSV-CH1-26' 'HSV-CH1-27' 'HSV-CH1-28'\n",
      " 'HSV-CH1-29' 'HSV-CH1-30' 'HSV-CH1-31' 'HSV-CH1-32' 'HSV-CH1-33'\n",
      " 'HSV-CH1-34' 'HSV-CH1-35' 'HSV-CH1-36' 'HSV-CH1-37' 'HSV-CH1-38'\n",
      " 'HSV-CH1-39' 'HSV-CH1-40' 'HSV-CH1-41' 'HSV-CH1-42' 'HSV-CH1-43'\n",
      " 'HSV-CH1-44' 'HSV-CH1-45' 'HSV-CH1-46' 'HSV-CH1-47' 'HSV-CH1-48'\n",
      " 'HSV-CH1-49' 'HSV-CH2-0' 'HSV-CH2-1' 'HSV-CH2-2' 'HSV-CH2-3' 'HSV-CH2-4'\n",
      " 'HSV-CH2-5' 'HSV-CH2-6' 'HSV-CH2-7' 'HSV-CH2-8' 'HSV-CH2-9' 'HSV-CH2-10'\n",
      " 'HSV-CH2-11' 'HSV-CH2-12' 'HSV-CH2-13' 'HSV-CH2-14' 'HSV-CH2-15'\n",
      " 'HSV-CH2-16' 'HSV-CH2-17' 'HSV-CH2-18' 'HSV-CH2-19' 'HSV-CH2-20'\n",
      " 'HSV-CH2-21' 'HSV-CH2-22' 'HSV-CH2-23' 'HSV-CH2-24' 'HSV-CH2-25'\n",
      " 'HSV-CH2-26' 'HSV-CH2-27' 'HSV-CH2-28' 'HSV-CH2-29' 'HSV-CH2-30'\n",
      " 'HSV-CH2-31' 'HSV-CH2-32' 'HSV-CH2-33' 'HSV-CH2-34' 'HSV-CH2-35'\n",
      " 'HSV-CH2-36' 'HSV-CH2-37' 'HSV-CH2-38' 'HSV-CH2-39' 'HSV-CH2-40'\n",
      " 'HSV-CH2-41' 'HSV-CH2-42' 'HSV-CH2-43' 'HSV-CH2-44' 'HSV-CH2-45'\n",
      " 'HSV-CH2-46' 'HSV-CH2-47' 'HSV-CH2-48' 'HSV-CH2-49' 'HSV-CH3-0'\n",
      " 'HSV-CH3-1' 'HSV-CH3-2' 'HSV-CH3-3' 'HSV-CH3-4' 'HSV-CH3-5' 'HSV-CH3-6'\n",
      " 'HSV-CH3-7' 'HSV-CH3-8' 'HSV-CH3-9' 'HSV-CH3-10' 'HSV-CH3-11'\n",
      " 'HSV-CH3-12' 'HSV-CH3-13' 'HSV-CH3-14' 'HSV-CH3-15' 'HSV-CH3-16'\n",
      " 'HSV-CH3-17' 'HSV-CH3-18' 'HSV-CH3-19' 'HSV-CH3-20' 'HSV-CH3-21'\n",
      " 'HSV-CH3-22' 'HSV-CH3-23' 'HSV-CH3-24' 'HSV-CH3-25' 'HSV-CH3-26'\n",
      " 'HSV-CH3-27' 'HSV-CH3-28' 'HSV-CH3-29' 'HSV-CH3-30' 'HSV-CH3-31'\n",
      " 'HSV-CH3-32' 'HSV-CH3-33' 'HSV-CH3-34' 'HSV-CH3-35' 'HSV-CH3-36'\n",
      " 'HSV-CH3-37' 'HSV-CH3-38' 'HSV-CH3-39' 'HSV-CH3-40' 'HSV-CH3-41'\n",
      " 'HSV-CH3-42' 'HSV-CH3-43' 'HSV-CH3-44' 'HSV-CH3-45' 'HSV-CH3-46'\n",
      " 'HSV-CH3-47' 'HSV-CH3-48' 'HSV-CH3-49' 'HSV-Mean-Block: CH1 1'\n",
      " 'HSV-Mean-Block: CH1 2' 'HSV-Mean-Block: CH1 3' 'HSV-Mean-Block: CH1 4'\n",
      " 'HSV-Mean-Block: CH1 5' 'HSV-Mean-Block: CH1 6' 'HSV-Mean-Block: CH1 7'\n",
      " 'HSV-Mean-Block: CH1 8' 'HSV-Mean-Block: CH1 9' 'HSV-Mean-Block: CH1 10'\n",
      " 'HSV-Mean-Block: CH1 11' 'HSV-Mean-Block: CH1 12'\n",
      " 'HSV-Mean-Block: CH1 13' 'HSV-Mean-Block: CH1 14'\n",
      " 'HSV-Mean-Block: CH1 15' 'HSV-Mean-Block: CH1 16'\n",
      " 'HSV-Mean-Block: CH1 17' 'HSV-Mean-Block: CH1 18'\n",
      " 'HSV-Mean-Block: CH1 19' 'HSV-Mean-Block: CH1 20'\n",
      " 'HSV-Mean-Block: CH1 21' 'HSV-Mean-Block: CH1 22'\n",
      " 'HSV-Mean-Block: CH1 23' 'HSV-Mean-Block: CH1 24'\n",
      " 'HSV-Mean-Block: CH1 25' 'HSV-Mean-Block: CH1 26'\n",
      " 'HSV-Mean-Block: CH1 27' 'HSV-Mean-Block: CH1 28'\n",
      " 'HSV-Mean-Block: CH1 29' 'HSV-Mean-Block: CH1 30'\n",
      " 'HSV-Mean-Block: CH1 31' 'HSV-Mean-Block: CH1 32'\n",
      " 'HSV-Mean-Block: CH1 33' 'HSV-Mean-Block: CH1 34'\n",
      " 'HSV-Mean-Block: CH1 35' 'HSV-Mean-Block: CH1 36'\n",
      " 'HSV-Mean-Block: CH1 37' 'HSV-Mean-Block: CH1 38'\n",
      " 'HSV-Mean-Block: CH1 39' 'HSV-Mean-Block: CH1 40'\n",
      " 'HSV-Mean-Block: CH1 41' 'HSV-Mean-Block: CH1 42'\n",
      " 'HSV-Mean-Block: CH1 43' 'HSV-Mean-Block: CH1 44'\n",
      " 'HSV-Mean-Block: CH1 45' 'HSV-Mean-Block: CH1 46'\n",
      " 'HSV-Mean-Block: CH1 47' 'HSV-Mean-Block: CH1 48'\n",
      " 'HSV-Mean-Block: CH1 49' 'HSV-Mean-Block: CH1 50'\n",
      " 'HSV-Mean-Block: CH1 51' 'HSV-Mean-Block: CH1 52'\n",
      " 'HSV-Mean-Block: CH1 53' 'HSV-Mean-Block: CH1 54'\n",
      " 'HSV-Mean-Block: CH1 55' 'HSV-Mean-Block: CH1 56'\n",
      " 'HSV-Mean-Block: CH1 57' 'HSV-Mean-Block: CH1 58'\n",
      " 'HSV-Mean-Block: CH1 59' 'HSV-Mean-Block: CH1 60'\n",
      " 'HSV-Mean-Block: CH1 61' 'HSV-Mean-Block: CH1 62'\n",
      " 'HSV-Mean-Block: CH1 63' 'HSV-Mean-Block: CH1 64' 'HSV-Std-Block: CH1 1'\n",
      " 'HSV-Std-Block: CH1 2' 'HSV-Std-Block: CH1 3' 'HSV-Std-Block: CH1 4'\n",
      " 'HSV-Std-Block: CH1 5' 'HSV-Std-Block: CH1 6' 'HSV-Std-Block: CH1 7'\n",
      " 'HSV-Std-Block: CH1 8' 'HSV-Std-Block: CH1 9' 'HSV-Std-Block: CH1 10'\n",
      " 'HSV-Std-Block: CH1 11' 'HSV-Std-Block: CH1 12' 'HSV-Std-Block: CH1 13'\n",
      " 'HSV-Std-Block: CH1 14' 'HSV-Std-Block: CH1 15' 'HSV-Std-Block: CH1 16'\n",
      " 'HSV-Std-Block: CH1 17' 'HSV-Std-Block: CH1 18' 'HSV-Std-Block: CH1 19'\n",
      " 'HSV-Std-Block: CH1 20' 'HSV-Std-Block: CH1 21' 'HSV-Std-Block: CH1 22'\n",
      " 'HSV-Std-Block: CH1 23' 'HSV-Std-Block: CH1 24' 'HSV-Std-Block: CH1 25'\n",
      " 'HSV-Std-Block: CH1 26' 'HSV-Std-Block: CH1 27' 'HSV-Std-Block: CH1 28'\n",
      " 'HSV-Std-Block: CH1 29' 'HSV-Std-Block: CH1 30' 'HSV-Std-Block: CH1 31'\n",
      " 'HSV-Std-Block: CH1 32' 'HSV-Std-Block: CH1 33' 'HSV-Std-Block: CH1 34'\n",
      " 'HSV-Std-Block: CH1 35' 'HSV-Std-Block: CH1 36' 'HSV-Std-Block: CH1 37'\n",
      " 'HSV-Std-Block: CH1 38' 'HSV-Std-Block: CH1 39' 'HSV-Std-Block: CH1 40'\n",
      " 'HSV-Std-Block: CH1 41' 'HSV-Std-Block: CH1 42' 'HSV-Std-Block: CH1 43'\n",
      " 'HSV-Std-Block: CH1 44' 'HSV-Std-Block: CH1 45' 'HSV-Std-Block: CH1 46'\n",
      " 'HSV-Std-Block: CH1 47' 'HSV-Std-Block: CH1 48' 'HSV-Std-Block: CH1 49'\n",
      " 'HSV-Std-Block: CH1 50' 'HSV-Std-Block: CH1 51' 'HSV-Std-Block: CH1 52'\n",
      " 'HSV-Std-Block: CH1 53' 'HSV-Std-Block: CH1 54' 'HSV-Std-Block: CH1 55'\n",
      " 'HSV-Std-Block: CH1 56' 'HSV-Std-Block: CH1 57' 'HSV-Std-Block: CH1 58'\n",
      " 'HSV-Std-Block: CH1 59' 'HSV-Std-Block: CH1 60' 'HSV-Std-Block: CH1 61'\n",
      " 'HSV-Std-Block: CH1 62' 'HSV-Std-Block: CH1 63' 'HSV-Std-Block: CH1 64'\n",
      " 'HSV-Std_Sorted-Block: CH1 1' 'HSV-Std_Sorted-Block: CH1 2'\n",
      " 'HSV-Std_Sorted-Block: CH1 3' 'HSV-Std_Sorted-Block: CH1 4'\n",
      " 'HSV-Std_Sorted-Block: CH1 5' 'HSV-Std_Sorted-Block: CH1 6'\n",
      " 'HSV-Std_Sorted-Block: CH1 7' 'HSV-Std_Sorted-Block: CH1 8'\n",
      " 'HSV-Std_Sorted-Block: CH1 9' 'HSV-Std_Sorted-Block: CH1 10'\n",
      " 'HSV-Std_Sorted-Block: CH1 11' 'HSV-Std_Sorted-Block: CH1 12'\n",
      " 'HSV-Std_Sorted-Block: CH1 13' 'HSV-Std_Sorted-Block: CH1 14'\n",
      " 'HSV-Std_Sorted-Block: CH1 15' 'HSV-Std_Sorted-Block: CH1 16'\n",
      " 'HSV-Std_Sorted-Block: CH1 17' 'HSV-Std_Sorted-Block: CH1 18'\n",
      " 'HSV-Std_Sorted-Block: CH1 19' 'HSV-Std_Sorted-Block: CH1 20'\n",
      " 'HSV-Std_Sorted-Block: CH1 21' 'HSV-Std_Sorted-Block: CH1 22'\n",
      " 'HSV-Std_Sorted-Block: CH1 23' 'HSV-Std_Sorted-Block: CH1 24'\n",
      " 'HSV-Std_Sorted-Block: CH1 25' 'HSV-Std_Sorted-Block: CH1 26'\n",
      " 'HSV-Std_Sorted-Block: CH1 27' 'HSV-Std_Sorted-Block: CH1 28'\n",
      " 'HSV-Std_Sorted-Block: CH1 29' 'HSV-Std_Sorted-Block: CH1 30'\n",
      " 'HSV-Std_Sorted-Block: CH1 31' 'HSV-Std_Sorted-Block: CH1 32'\n",
      " 'HSV-Std_Sorted-Block: CH1 33' 'HSV-Std_Sorted-Block: CH1 34'\n",
      " 'HSV-Std_Sorted-Block: CH1 35' 'HSV-Std_Sorted-Block: CH1 36'\n",
      " 'HSV-Std_Sorted-Block: CH1 37' 'HSV-Std_Sorted-Block: CH1 38'\n",
      " 'HSV-Std_Sorted-Block: CH1 39' 'HSV-Std_Sorted-Block: CH1 40'\n",
      " 'HSV-Std_Sorted-Block: CH1 41' 'HSV-Std_Sorted-Block: CH1 42'\n",
      " 'HSV-Std_Sorted-Block: CH1 43' 'HSV-Std_Sorted-Block: CH1 44'\n",
      " 'HSV-Std_Sorted-Block: CH1 45' 'HSV-Std_Sorted-Block: CH1 46'\n",
      " 'HSV-Std_Sorted-Block: CH1 47' 'HSV-Std_Sorted-Block: CH1 48'\n",
      " 'HSV-Std_Sorted-Block: CH1 49' 'HSV-Std_Sorted-Block: CH1 50'\n",
      " 'HSV-Std_Sorted-Block: CH1 51' 'HSV-Std_Sorted-Block: CH1 52'\n",
      " 'HSV-Std_Sorted-Block: CH1 53' 'HSV-Std_Sorted-Block: CH1 54'\n",
      " 'HSV-Std_Sorted-Block: CH1 55' 'HSV-Std_Sorted-Block: CH1 56'\n",
      " 'HSV-Std_Sorted-Block: CH1 57' 'HSV-Std_Sorted-Block: CH1 58'\n",
      " 'HSV-Std_Sorted-Block: CH1 59' 'HSV-Std_Sorted-Block: CH1 60'\n",
      " 'HSV-Std_Sorted-Block: CH1 61' 'HSV-Std_Sorted-Block: CH1 62'\n",
      " 'HSV-Std_Sorted-Block: CH1 63' 'HSV-Std_Sorted-Block: CH1 64'\n",
      " 'HSV-Mean-Block: CH2 32' 'HSV-Mean-Block: CH2 40'\n",
      " 'HSV-Mean-Block: CH2 60' 'HSV-Mean-Block: CH2 61'\n",
      " 'HSV-Mean-Block: CH2 62' 'HSV-Std_Sorted-Block: CH2 39'\n",
      " 'HSV-Std_Sorted-Block: CH2 40' 'HSV-Std_Sorted-Block: CH2 41'\n",
      " 'HSV-Std_Sorted-Block: CH2 42' 'HSV-Std_Sorted-Block: CH2 43'\n",
      " 'HSV-Std_Sorted-Block: CH2 44' 'HSV-Std_Sorted-Block: CH2 45'\n",
      " 'HSV-Std_Sorted-Block: CH2 46' 'HSV-Std_Sorted-Block: CH2 47'\n",
      " 'HSV-Std_Sorted-Block: CH2 48' 'HSV-Std_Sorted-Block: CH2 49'\n",
      " 'HSV-Std_Sorted-Block: CH2 50' 'HSV-Std_Sorted-Block: CH2 51'\n",
      " 'HSV-Std_Sorted-Block: CH2 52' 'HSV-Std_Sorted-Block: CH2 53'\n",
      " 'HSV-Std_Sorted-Block: CH2 54' 'HSV-Std_Sorted-Block: CH2 55'\n",
      " 'HSV-Std_Sorted-Block: CH2 56' 'HSV-Std_Sorted-Block: CH2 57'\n",
      " 'HSV-Std_Sorted-Block: CH2 58' 'HSV-Std_Sorted-Block: CH2 59'\n",
      " 'HSV-Std_Sorted-Block: CH2 60' 'HSV-Std_Sorted-Block: CH2 61'\n",
      " 'HSV-Std_Sorted-Block: CH2 62' 'HSV-Std_Sorted-Block: CH2 63'\n",
      " 'HSV-Std_Sorted-Block: CH2 64' 'HSV-Mean-Block: CH3 1'\n",
      " 'HSV-Mean-Block: CH3 2' 'HSV-Mean-Block: CH3 3' 'HSV-Mean-Block: CH3 4'\n",
      " 'HSV-Mean-Block: CH3 5' 'HSV-Mean-Block: CH3 6' 'HSV-Mean-Block: CH3 7'\n",
      " 'HSV-Mean-Block: CH3 8' 'HSV-Mean-Block: CH3 9' 'HSV-Mean-Block: CH3 10'\n",
      " 'HSV-Mean-Block: CH3 11' 'HSV-Mean-Block: CH3 12'\n",
      " 'HSV-Mean-Block: CH3 13' 'HSV-Mean-Block: CH3 14'\n",
      " 'HSV-Mean-Block: CH3 15' 'HSV-Mean-Block: CH3 16'\n",
      " 'HSV-Mean-Block: CH3 17' 'HSV-Mean-Block: CH3 18'\n",
      " 'HSV-Mean-Block: CH3 19' 'HSV-Mean-Block: CH3 20'\n",
      " 'HSV-Mean-Block: CH3 21' 'HSV-Mean-Block: CH3 22'\n",
      " 'HSV-Mean-Block: CH3 23' 'HSV-Mean-Block: CH3 24'\n",
      " 'HSV-Mean-Block: CH3 25' 'HSV-Mean-Block: CH3 26'\n",
      " 'HSV-Mean-Block: CH3 27' 'HSV-Mean-Block: CH3 28'\n",
      " 'HSV-Mean-Block: CH3 29' 'HSV-Mean-Block: CH3 30'\n",
      " 'HSV-Mean-Block: CH3 31' 'HSV-Mean-Block: CH3 32'\n",
      " 'HSV-Mean-Block: CH3 33' 'HSV-Mean-Block: CH3 34'\n",
      " 'HSV-Mean-Block: CH3 35' 'HSV-Mean-Block: CH3 36'\n",
      " 'HSV-Mean-Block: CH3 37' 'HSV-Mean-Block: CH3 38'\n",
      " 'HSV-Mean-Block: CH3 39' 'HSV-Mean-Block: CH3 40'\n",
      " 'HSV-Mean-Block: CH3 41' 'HSV-Mean-Block: CH3 42'\n",
      " 'HSV-Mean-Block: CH3 43' 'HSV-Mean-Block: CH3 44'\n",
      " 'HSV-Mean-Block: CH3 45' 'HSV-Mean-Block: CH3 46'\n",
      " 'HSV-Mean-Block: CH3 47' 'HSV-Mean-Block: CH3 48'\n",
      " 'HSV-Mean-Block: CH3 49' 'HSV-Mean-Block: CH3 50'\n",
      " 'HSV-Mean-Block: CH3 51' 'HSV-Mean-Block: CH3 52'\n",
      " 'HSV-Mean-Block: CH3 53' 'HSV-Mean-Block: CH3 54'\n",
      " 'HSV-Mean-Block: CH3 55' 'HSV-Mean-Block: CH3 56'\n",
      " 'HSV-Mean-Block: CH3 57' 'HSV-Mean-Block: CH3 58'\n",
      " 'HSV-Mean-Block: CH3 59' 'HSV-Mean-Block: CH3 60'\n",
      " 'HSV-Mean-Block: CH3 61' 'HSV-Mean-Block: CH3 62'\n",
      " 'HSV-Mean-Block: CH3 63' 'HSV-Mean-Block: CH3 64'\n",
      " 'Cluster: 0 cspace: HSV; sortCH1; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortCH1; X' 'Cluster: 0 cspace: HSV; sortCH1; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortCH1; SIZE'\n",
      " 'Cluster: 0 cspace: HSV; sortCH2; CH1'\n",
      " 'Cluster: 0 cspace: HSV; sortCH2; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortCH2; X' 'Cluster: 0 cspace: HSV; sortCH2; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortCH2; SIZE'\n",
      " 'Cluster: 0 cspace: HSV; sortCH3; CH1'\n",
      " 'Cluster: 0 cspace: HSV; sortCH3; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortCH3; X' 'Cluster: 0 cspace: HSV; sortCH3; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortCH3; SIZE'\n",
      " 'Cluster: 0 cspace: HSV; sortX; CH1' 'Cluster: 0 cspace: HSV; sortX; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortX; X' 'Cluster: 0 cspace: HSV; sortX; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortY; CH1' 'Cluster: 0 cspace: HSV; sortY; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortY; X' 'Cluster: 0 cspace: HSV; sortY; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortY; SIZE'\n",
      " 'Cluster: 0 cspace: HSV; sortSize; CH1'\n",
      " 'Cluster: 0 cspace: HSV; sortSize; CH2'\n",
      " 'Cluster: 0 cspace: HSV; sortSize; X'\n",
      " 'Cluster: 0 cspace: HSV; sortSize; Y'\n",
      " 'Cluster: 0 cspace: HSV; sortSize; SIZE'\n",
      " 'Cluster: 1 cspace: HSV; sortCH1; CH1'\n",
      " 'Cluster: 1 cspace: HSV; sortCH1; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortCH1; X' 'Cluster: 1 cspace: HSV; sortCH1; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortCH1; SIZE'\n",
      " 'Cluster: 1 cspace: HSV; sortCH2; CH1'\n",
      " 'Cluster: 1 cspace: HSV; sortCH2; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortCH2; X' 'Cluster: 1 cspace: HSV; sortCH2; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortCH3; CH1'\n",
      " 'Cluster: 1 cspace: HSV; sortCH3; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortCH3; X' 'Cluster: 1 cspace: HSV; sortCH3; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortCH3; SIZE'\n",
      " 'Cluster: 1 cspace: HSV; sortX; CH1' 'Cluster: 1 cspace: HSV; sortX; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortX; X' 'Cluster: 1 cspace: HSV; sortX; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortX; SIZE'\n",
      " 'Cluster: 1 cspace: HSV; sortY; CH1' 'Cluster: 1 cspace: HSV; sortY; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortY; X' 'Cluster: 1 cspace: HSV; sortY; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortY; SIZE'\n",
      " 'Cluster: 1 cspace: HSV; sortSize; CH1'\n",
      " 'Cluster: 1 cspace: HSV; sortSize; CH2'\n",
      " 'Cluster: 1 cspace: HSV; sortSize; X'\n",
      " 'Cluster: 1 cspace: HSV; sortSize; Y'\n",
      " 'Cluster: 1 cspace: HSV; sortSize; SIZE'\n",
      " 'Cluster: 2 cspace: HSV; sortCH1; CH1'\n",
      " 'Cluster: 2 cspace: HSV; sortCH1; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortCH1; X' 'Cluster: 2 cspace: HSV; sortCH1; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortCH1; SIZE'\n",
      " 'Cluster: 2 cspace: HSV; sortCH2; CH1'\n",
      " 'Cluster: 2 cspace: HSV; sortCH2; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortCH2; X' 'Cluster: 2 cspace: HSV; sortCH2; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortCH2; SIZE'\n",
      " 'Cluster: 2 cspace: HSV; sortCH3; CH1'\n",
      " 'Cluster: 2 cspace: HSV; sortCH3; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortCH3; X' 'Cluster: 2 cspace: HSV; sortCH3; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortCH3; SIZE'\n",
      " 'Cluster: 2 cspace: HSV; sortX; CH1' 'Cluster: 2 cspace: HSV; sortX; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortX; X' 'Cluster: 2 cspace: HSV; sortX; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortY; CH1' 'Cluster: 2 cspace: HSV; sortY; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortY; X' 'Cluster: 2 cspace: HSV; sortY; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortY; SIZE'\n",
      " 'Cluster: 2 cspace: HSV; sortSize; CH1'\n",
      " 'Cluster: 2 cspace: HSV; sortSize; CH2'\n",
      " 'Cluster: 2 cspace: HSV; sortSize; X'\n",
      " 'Cluster: 2 cspace: HSV; sortSize; Y'\n",
      " 'Cluster: 2 cspace: HSV; sortSize; SIZE'\n",
      " 'Cluster: 3 cspace: HSV; sortCH1; CH1'\n",
      " 'Cluster: 3 cspace: HSV; sortCH1; CH2'\n",
      " 'Cluster: 3 cspace: HSV; sortCH1; X' 'Cluster: 3 cspace: HSV; sortCH1; Y'\n",
      " 'Cluster: 3 cspace: HSV; sortCH1; SIZE'\n",
      " 'Cluster: 3 cspace: HSV; sortCH2; CH1'\n",
      " 'Cluster: 3 cspace: HSV; sortCH2; CH2'\n",
      " 'Cluster: 3 cspace: HSV; sortCH2; X' 'Cluster: 3 cspace: HSV; sortCH2; Y'\n",
      " 'Cluster: 3 cspace: HSV; sortCH3; CH1'\n",
      " 'Cluster: 3 cspace: HSV; sortCH3; CH2'\n",
      " 'Cluster: 3 cspace: HSV; sortCH3; X' 'Cluster: 3 cspace: HSV; sortX; CH1'\n",
      " 'Cluster: 3 cspace: HSV; sortX; CH2' 'Cluster: 3 cspace: HSV; sortX; X'\n",
      " 'Cluster: 3 cspace: HSV; sortX; Y' 'Cluster: 3 cspace: HSV; sortX; SIZE'\n",
      " 'Cluster: 3 cspace: HSV; sortY; CH1' 'Cluster: 3 cspace: HSV; sortY; CH2'\n",
      " 'Cluster: 3 cspace: HSV; sortY; X' 'Cluster: 3 cspace: HSV; sortY; Y'\n",
      " 'Cluster: 3 cspace: HSV; sortY; SIZE'\n",
      " 'Cluster: 3 cspace: HSV; sortSize; CH1'\n",
      " 'Cluster: 3 cspace: HSV; sortSize; CH2'\n",
      " 'Cluster: 3 cspace: HSV; sortSize; X'\n",
      " 'Cluster: 3 cspace: HSV; sortSize; Y'\n",
      " 'Cluster: 3 cspace: HSV; sortSize; SIZE'\n",
      " 'Cluster: 4 cspace: HSV; sortCH1; CH1'\n",
      " 'Cluster: 4 cspace: HSV; sortCH1; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortCH1; X' 'Cluster: 4 cspace: HSV; sortCH1; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortCH2; CH1'\n",
      " 'Cluster: 4 cspace: HSV; sortCH2; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortCH2; X' 'Cluster: 4 cspace: HSV; sortCH2; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortCH3; CH1'\n",
      " 'Cluster: 4 cspace: HSV; sortCH3; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortCH3; X' 'Cluster: 4 cspace: HSV; sortCH3; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortX; CH1' 'Cluster: 4 cspace: HSV; sortX; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortX; X' 'Cluster: 4 cspace: HSV; sortX; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortY; CH1' 'Cluster: 4 cspace: HSV; sortY; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortY; X' 'Cluster: 4 cspace: HSV; sortY; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortSize; CH1'\n",
      " 'Cluster: 4 cspace: HSV; sortSize; CH2'\n",
      " 'Cluster: 4 cspace: HSV; sortSize; X'\n",
      " 'Cluster: 4 cspace: HSV; sortSize; Y'\n",
      " 'Cluster: 4 cspace: HSV; sortSize; SIZE' 'RawPix_HSV0' 'RawPix_HSV1'\n",
      " 'RawPix_HSV3' 'RawPix_HSV4' 'RawPix_HSV6' 'RawPix_HSV7' 'RawPix_HSV9'\n",
      " 'RawPix_HSV10' 'RawPix_HSV12' 'RawPix_HSV13' 'RawPix_HSV15'\n",
      " 'RawPix_HSV16' 'RawPix_HSV18' 'RawPix_HSV19' 'RawPix_HSV21'\n",
      " 'RawPix_HSV22' 'RawPix_HSV24' 'RawPix_HSV25' 'RawPix_HSV27'\n",
      " 'RawPix_HSV28' 'RawPix_HSV30' 'RawPix_HSV31' 'RawPix_HSV33'\n",
      " 'RawPix_HSV34' 'RawPix_HSV36' 'RawPix_HSV37' 'RawPix_HSV39'\n",
      " 'RawPix_HSV40' 'RawPix_HSV42' 'RawPix_HSV43' 'RawPix_HSV45'\n",
      " 'RawPix_HSV46' 'RawPix_HSV48' 'RawPix_HSV49' 'RawPix_HSV51'\n",
      " 'RawPix_HSV52' 'RawPix_HSV54' 'RawPix_HSV55' 'RawPix_HSV57'\n",
      " 'RawPix_HSV58' 'RawPix_HSV60' 'RawPix_HSV61' 'RawPix_HSV63'\n",
      " 'RawPix_HSV64' 'RawPix_HSV66' 'RawPix_HSV67' 'RawPix_HSV69'\n",
      " 'RawPix_HSV70' 'RawPix_HSV72' 'RawPix_HSV73' 'RawPix_HSV75'\n",
      " 'RawPix_HSV76' 'RawPix_HSV78' 'RawPix_HSV79' 'RawPix_HSV81'\n",
      " 'RawPix_HSV82' 'RawPix_HSV84' 'RawPix_HSV85' 'RawPix_HSV87'\n",
      " 'RawPix_HSV88' 'RawPix_HSV90' 'RawPix_HSV91' 'RawPix_HSV93'\n",
      " 'RawPix_HSV94' 'RawPix_HSV96' 'RawPix_HSV97' 'RawPix_HSV99'\n",
      " 'RawPix_HSV100' 'RawPix_HSV102' 'RawPix_HSV103' 'RawPix_HSV105'\n",
      " 'RawPix_HSV106' 'RawPix_HSV108' 'RawPix_HSV109' 'RawPix_HSV111'\n",
      " 'RawPix_HSV112' 'RawPix_HSV114' 'RawPix_HSV115' 'RawPix_HSV117'\n",
      " 'RawPix_HSV118' 'RawPix_HSV120' 'RawPix_HSV121' 'RawPix_HSV123'\n",
      " 'RawPix_HSV124' 'RawPix_HSV126' 'RawPix_HSV127' 'RawPix_HSV129'\n",
      " 'RawPix_HSV130' 'RawPix_HSV132' 'RawPix_HSV133' 'RawPix_HSV135'\n",
      " 'RawPix_HSV136' 'RawPix_HSV138' 'RawPix_HSV139' 'RawPix_HSV141'\n",
      " 'RawPix_HSV142' 'RawPix_HSV144' 'RawPix_HSV145' 'RawPix_HSV147'\n",
      " 'RawPix_HSV148' 'RawPix_HSV150' 'RawPix_HSV151' 'RawPix_HSV153'\n",
      " 'RawPix_HSV154' 'RawPix_HSV156' 'RawPix_HSV157' 'RawPix_HSV159'\n",
      " 'RawPix_HSV160' 'RawPix_HSV162' 'RawPix_HSV163' 'RawPix_HSV165'\n",
      " 'RawPix_HSV166' 'RawPix_HSV168' 'RawPix_HSV169' 'RawPix_HSV171'\n",
      " 'RawPix_HSV172' 'RawPix_HSV174' 'RawPix_HSV175' 'RawPix_HSV177'\n",
      " 'RawPix_HSV178' 'RawPix_HSV180' 'RawPix_HSV181' 'RawPix_HSV183'\n",
      " 'RawPix_HSV184' 'RawPix_HSV186' 'RawPix_HSV187' 'RawPix_HSV189'\n",
      " 'RawPix_HSV190' 'RawPix_HSV192' 'RawPix_HSV193' 'RawPix_HSV195'\n",
      " 'RawPix_HSV196' 'RawPix_HSV198' 'RawPix_HSV199' 'RawPix_HSV201'\n",
      " 'RawPix_HSV202' 'RawPix_HSV204' 'RawPix_HSV205' 'RawPix_HSV207'\n",
      " 'RawPix_HSV208' 'RawPix_HSV210' 'RawPix_HSV211' 'RawPix_HSV213'\n",
      " 'RawPix_HSV214' 'RawPix_HSV216' 'RawPix_HSV217' 'RawPix_HSV219'\n",
      " 'RawPix_HSV220' 'RawPix_HSV222' 'RawPix_HSV223' 'RawPix_HSV225'\n",
      " 'RawPix_HSV226' 'RawPix_HSV228' 'RawPix_HSV229' 'RawPix_HSV231'\n",
      " 'RawPix_HSV232' 'RawPix_HSV234' 'RawPix_HSV235' 'RawPix_HSV237'\n",
      " 'RawPix_HSV238' 'RawPix_HSV240' 'RawPix_HSV241' 'RawPix_HSV243'\n",
      " 'RawPix_HSV244' 'RawPix_HSV246' 'RawPix_HSV247' 'RawPix_HSV249'\n",
      " 'RawPix_HSV250' 'RawPix_HSV252' 'RawPix_HSV253' 'RawPix_HSV255'\n",
      " 'RawPix_HSV256' 'RawPix_HSV258' 'RawPix_HSV259' 'RawPix_HSV261'\n",
      " 'RawPix_HSV262' 'RawPix_HSV264' 'RawPix_HSV265' 'RawPix_HSV267'\n",
      " 'RawPix_HSV268' 'RawPix_HSV270' 'RawPix_HSV271' 'RawPix_HSV273'\n",
      " 'RawPix_HSV274' 'RawPix_HSV276' 'RawPix_HSV277' 'RawPix_HSV279'\n",
      " 'RawPix_HSV280' 'RawPix_HSV282' 'RawPix_HSV283' 'RawPix_HSV285'\n",
      " 'RawPix_HSV286' 'RawPix_HSV288' 'RawPix_HSV289' 'RawPix_HSV291'\n",
      " 'RawPix_HSV292' 'RawPix_HSV294' 'RawPix_HSV295' 'RawPix_HSV297'\n",
      " 'RawPix_HSV298' 'RawPix_HSV300' 'RawPix_HSV301' 'RawPix_HSV303'\n",
      " 'RawPix_HSV304' 'RawPix_HSV306' 'RawPix_HSV307' 'RawPix_HSV309'\n",
      " 'RawPix_HSV310' 'RawPix_HSV312' 'RawPix_HSV313' 'RawPix_HSV315'\n",
      " 'RawPix_HSV316' 'RawPix_HSV318' 'RawPix_HSV319' 'RawPix_HSV321'\n",
      " 'RawPix_HSV322' 'RawPix_HSV324' 'RawPix_HSV325' 'RawPix_HSV327'\n",
      " 'RawPix_HSV328' 'RawPix_HSV330' 'RawPix_HSV331' 'RawPix_HSV333'\n",
      " 'RawPix_HSV334' 'RawPix_HSV336' 'RawPix_HSV337' 'RawPix_HSV339'\n",
      " 'RawPix_HSV340' 'RawPix_HSV342' 'RawPix_HSV343' 'RawPix_HSV345'\n",
      " 'RawPix_HSV346' 'RawPix_HSV348' 'RawPix_HSV349' 'RawPix_HSV351'\n",
      " 'RawPix_HSV352' 'RawPix_HSV354' 'RawPix_HSV355' 'RawPix_HSV357'\n",
      " 'RawPix_HSV358' 'RawPix_HSV360' 'RawPix_HSV361' 'RawPix_HSV363'\n",
      " 'RawPix_HSV364' 'RawPix_HSV366' 'RawPix_HSV367' 'RawPix_HSV369'\n",
      " 'RawPix_HSV370' 'RawPix_HSV372' 'RawPix_HSV373' 'RawPix_HSV375'\n",
      " 'RawPix_HSV376' 'RawPix_HSV378' 'RawPix_HSV379' 'RawPix_HSV381'\n",
      " 'RawPix_HSV382' 'RawPix_HSV384' 'RawPix_HSV385' 'RawPix_HSV387'\n",
      " 'RawPix_HSV388' 'RawPix_HSV390' 'RawPix_HSV391' 'RawPix_HSV393'\n",
      " 'RawPix_HSV394' 'RawPix_HSV396' 'RawPix_HSV397' 'RawPix_HSV399'\n",
      " 'RawPix_HSV400' 'RawPix_HSV402' 'RawPix_HSV403' 'RawPix_HSV405'\n",
      " 'RawPix_HSV406' 'RawPix_HSV408' 'RawPix_HSV409' 'RawPix_HSV411'\n",
      " 'RawPix_HSV412' 'RawPix_HSV414' 'RawPix_HSV415' 'RawPix_HSV417'\n",
      " 'RawPix_HSV418' 'RawPix_HSV420' 'RawPix_HSV421' 'RawPix_HSV423'\n",
      " 'RawPix_HSV424' 'RawPix_HSV426' 'RawPix_HSV427' 'RawPix_HSV429'\n",
      " 'RawPix_HSV430' 'RawPix_HSV432' 'RawPix_HSV433' 'RawPix_HSV435'\n",
      " 'RawPix_HSV436' 'RawPix_HSV438' 'RawPix_HSV439' 'RawPix_HSV441'\n",
      " 'RawPix_HSV442' 'RawPix_HSV444' 'RawPix_HSV445' 'RawPix_HSV447'\n",
      " 'RawPix_HSV448' 'RawPix_HSV450' 'RawPix_HSV451' 'RawPix_HSV453'\n",
      " 'RawPix_HSV454' 'RawPix_HSV456' 'RawPix_HSV457' 'RawPix_HSV459'\n",
      " 'RawPix_HSV460' 'RawPix_HSV462' 'RawPix_HSV463' 'RawPix_HSV465'\n",
      " 'RawPix_HSV466' 'RawPix_HSV468' 'RawPix_HSV469' 'RawPix_HSV471'\n",
      " 'RawPix_HSV472' 'RawPix_HSV474' 'RawPix_HSV475' 'RawPix_HSV477'\n",
      " 'RawPix_HSV478' 'RawPix_HSV480' 'RawPix_HSV481' 'RawPix_HSV483'\n",
      " 'RawPix_HSV484' 'RawPix_HSV486' 'RawPix_HSV487' 'RawPix_HSV489'\n",
      " 'RawPix_HSV490' 'RawPix_HSV492' 'RawPix_HSV493' 'RawPix_HSV495'\n",
      " 'RawPix_HSV496' 'RawPix_HSV498' 'RawPix_HSV499' 'RawPix_HSV501'\n",
      " 'RawPix_HSV502' 'RawPix_HSV504' 'RawPix_HSV505' 'RawPix_HSV507'\n",
      " 'RawPix_HSV508' 'RawPix_HSV510' 'RawPix_HSV511' 'RawPix_HSV513'\n",
      " 'RawPix_HSV514' 'RawPix_HSV516' 'RawPix_HSV517' 'RawPix_HSV519'\n",
      " 'RawPix_HSV520' 'RawPix_HSV522' 'RawPix_HSV523' 'RawPix_HSV525'\n",
      " 'RawPix_HSV526' 'RawPix_HSV528' 'RawPix_HSV529' 'RawPix_HSV531'\n",
      " 'RawPix_HSV532' 'RawPix_HSV534' 'RawPix_HSV535' 'RawPix_HSV537'\n",
      " 'RawPix_HSV538' 'RawPix_HSV540' 'RawPix_HSV541' 'RawPix_HSV543'\n",
      " 'RawPix_HSV544' 'RawPix_HSV546' 'RawPix_HSV547' 'RawPix_HSV549'\n",
      " 'RawPix_HSV550' 'RawPix_HSV552' 'RawPix_HSV553' 'RawPix_HSV555'\n",
      " 'RawPix_HSV556' 'RawPix_HSV558' 'RawPix_HSV559' 'RawPix_HSV561'\n",
      " 'RawPix_HSV562' 'RawPix_HSV564' 'RawPix_HSV565' 'RawPix_HSV567'\n",
      " 'RawPix_HSV568' 'RawPix_HSV570' 'RawPix_HSV571' 'RawPix_HSV573'\n",
      " 'RawPix_HSV574' 'RawPix_HSV576' 'RawPix_HSV577' 'RawPix_HSV579'\n",
      " 'RawPix_HSV580' 'RawPix_HSV582' 'RawPix_HSV583' 'RawPix_HSV585'\n",
      " 'RawPix_HSV586' 'RawPix_HSV588' 'RawPix_HSV589' 'RawPix_HSV591'\n",
      " 'RawPix_HSV592' 'RawPix_HSV594' 'RawPix_HSV595' 'RawPix_HSV597'\n",
      " 'RawPix_HSV598' 'RawPix_HSV600' 'RawPix_HSV601' 'RawPix_HSV603'\n",
      " 'RawPix_HSV604' 'RawPix_HSV606' 'RawPix_HSV607' 'RawPix_HSV609'\n",
      " 'RawPix_HSV610' 'RawPix_HSV612' 'RawPix_HSV613' 'RawPix_HSV615'\n",
      " 'RawPix_HSV616' 'RawPix_HSV618' 'RawPix_HSV619' 'RawPix_HSV621'\n",
      " 'RawPix_HSV622' 'RawPix_HSV624' 'RawPix_HSV625' 'RawPix_HSV627'\n",
      " 'RawPix_HSV628' 'RawPix_HSV630' 'RawPix_HSV631' 'RawPix_HSV633'\n",
      " 'RawPix_HSV634' 'RawPix_HSV636' 'RawPix_HSV637' 'RawPix_HSV639'\n",
      " 'RawPix_HSV640' 'RawPix_HSV642' 'RawPix_HSV643' 'RawPix_HSV645'\n",
      " 'RawPix_HSV646' 'RawPix_HSV648' 'RawPix_HSV649' 'RawPix_HSV651'\n",
      " 'RawPix_HSV652' 'RawPix_HSV654' 'RawPix_HSV655' 'RawPix_HSV657'\n",
      " 'RawPix_HSV658' 'RawPix_HSV660' 'RawPix_HSV661' 'RawPix_HSV663'\n",
      " 'RawPix_HSV664' 'RawPix_HSV666' 'RawPix_HSV667' 'RawPix_HSV669'\n",
      " 'RawPix_HSV670' 'RawPix_HSV672' 'RawPix_HSV673' 'RawPix_HSV675'\n",
      " 'RawPix_HSV676' 'RawPix_HSV678' 'RawPix_HSV679' 'RawPix_HSV681'\n",
      " 'RawPix_HSV682' 'RawPix_HSV684' 'RawPix_HSV685' 'RawPix_HSV687'\n",
      " 'RawPix_HSV688' 'RawPix_HSV690' 'RawPix_HSV691' 'RawPix_HSV693'\n",
      " 'RawPix_HSV694' 'RawPix_HSV696' 'RawPix_HSV697' 'RawPix_HSV699'\n",
      " 'RawPix_HSV700' 'RawPix_HSV702' 'RawPix_HSV703' 'RawPix_HSV705'\n",
      " 'RawPix_HSV706' 'RawPix_HSV708' 'RawPix_HSV709' 'RawPix_HSV711'\n",
      " 'RawPix_HSV712' 'RawPix_HSV714' 'RawPix_HSV715' 'RawPix_HSV717'\n",
      " 'RawPix_HSV718' 'RawPix_HSV720' 'RawPix_HSV721' 'RawPix_HSV723'\n",
      " 'RawPix_HSV724' 'RawPix_HSV726' 'RawPix_HSV727' 'RawPix_HSV729'\n",
      " 'RawPix_HSV730' 'RawPix_HSV732' 'RawPix_HSV733' 'RawPix_HSV735'\n",
      " 'RawPix_HSV736' 'RawPix_HSV738' 'RawPix_HSV739' 'RawPix_HSV741'\n",
      " 'RawPix_HSV742' 'RawPix_HSV744' 'RawPix_HSV745' 'RawPix_HSV747'\n",
      " 'RawPix_HSV748' 'RawPix_HSV750' 'RawPix_HSV751' 'RawPix_HSV753'\n",
      " 'RawPix_HSV754' 'RawPix_HSV756' 'RawPix_HSV757' 'RawPix_HSV759'\n",
      " 'RawPix_HSV760' 'RawPix_HSV762' 'RawPix_HSV763' 'RawPix_HSV765'\n",
      " 'RawPix_HSV766' 'RawPix_HSV768' 'RawPix_HSV769' 'RawPix_HSV771'\n",
      " 'RawPix_HSV772' 'RawPix_HSV774' 'RawPix_HSV775' 'RawPix_HSV777'\n",
      " 'RawPix_HSV778' 'RawPix_HSV780' 'RawPix_HSV781' 'RawPix_HSV783'\n",
      " 'RawPix_HSV784' 'RawPix_HSV786' 'RawPix_HSV787' 'RawPix_HSV789'\n",
      " 'RawPix_HSV790' 'RawPix_HSV792' 'RawPix_HSV793' 'RawPix_HSV795'\n",
      " 'RawPix_HSV796' 'RawPix_HSV798' 'RawPix_HSV799' 'RawPix_HSV801'\n",
      " 'RawPix_HSV802' 'RawPix_HSV804' 'RawPix_HSV805' 'RawPix_HSV807'\n",
      " 'RawPix_HSV808' 'RawPix_HSV810' 'RawPix_HSV811' 'RawPix_HSV813'\n",
      " 'RawPix_HSV814' 'RawPix_HSV816' 'RawPix_HSV817' 'RawPix_HSV819'\n",
      " 'RawPix_HSV820' 'RawPix_HSV822' 'RawPix_HSV823' 'RawPix_HSV825'\n",
      " 'RawPix_HSV826' 'RawPix_HSV828' 'RawPix_HSV829' 'RawPix_HSV831'\n",
      " 'RawPix_HSV832' 'RawPix_HSV834' 'RawPix_HSV835' 'RawPix_HSV837'\n",
      " 'RawPix_HSV838' 'RawPix_HSV840' 'RawPix_HSV841' 'RawPix_HSV843'\n",
      " 'RawPix_HSV844' 'RawPix_HSV846' 'RawPix_HSV847' 'RawPix_HSV849'\n",
      " 'RawPix_HSV850' 'RawPix_HSV852' 'RawPix_HSV853' 'RawPix_HSV855'\n",
      " 'RawPix_HSV856' 'RawPix_HSV858' 'RawPix_HSV859' 'RawPix_HSV861'\n",
      " 'RawPix_HSV862' 'RawPix_HSV864' 'RawPix_HSV865' 'RawPix_HSV867'\n",
      " 'RawPix_HSV868' 'RawPix_HSV870' 'RawPix_HSV871' 'RawPix_HSV873'\n",
      " 'RawPix_HSV874' 'RawPix_HSV876' 'RawPix_HSV877' 'RawPix_HSV879'\n",
      " 'RawPix_HSV880' 'RawPix_HSV882' 'RawPix_HSV883' 'RawPix_HSV885'\n",
      " 'RawPix_HSV886' 'RawPix_HSV888' 'RawPix_HSV889' 'RawPix_HSV891'\n",
      " 'RawPix_HSV892' 'RawPix_HSV894' 'RawPix_HSV895' 'RawPix_HSV897'\n",
      " 'RawPix_HSV898' 'RawPix_HSV900' 'RawPix_HSV901' 'RawPix_HSV903'\n",
      " 'RawPix_HSV904' 'RawPix_HSV906' 'RawPix_HSV907' 'RawPix_HSV909'\n",
      " 'RawPix_HSV910' 'RawPix_HSV912' 'RawPix_HSV913' 'RawPix_HSV915'\n",
      " 'RawPix_HSV916' 'RawPix_HSV918' 'RawPix_HSV919' 'RawPix_HSV921'\n",
      " 'RawPix_HSV922' 'RawPix_HSV924' 'RawPix_HSV925' 'RawPix_HSV927'\n",
      " 'RawPix_HSV928' 'RawPix_HSV930' 'RawPix_HSV931' 'RawPix_HSV933'\n",
      " 'RawPix_HSV934' 'RawPix_HSV936' 'RawPix_HSV937' 'RawPix_HSV939'\n",
      " 'RawPix_HSV940' 'RawPix_HSV942' 'RawPix_HSV943' 'RawPix_HSV945'\n",
      " 'RawPix_HSV946' 'RawPix_HSV948' 'RawPix_HSV949' 'RawPix_HSV951'\n",
      " 'RawPix_HSV952' 'RawPix_HSV954' 'RawPix_HSV955' 'RawPix_HSV957'\n",
      " 'RawPix_HSV958' 'RawPix_HSV960' 'RawPix_HSV961' 'RawPix_HSV963'\n",
      " 'RawPix_HSV964' 'RawPix_HSV966' 'RawPix_HSV967' 'RawPix_HSV969'\n",
      " 'RawPix_HSV970' 'RawPix_HSV972' 'RawPix_HSV973' 'RawPix_HSV975'\n",
      " 'RawPix_HSV976' 'RawPix_HSV978' 'RawPix_HSV979' 'RawPix_HSV981'\n",
      " 'RawPix_HSV982' 'RawPix_HSV984' 'RawPix_HSV985' 'RawPix_HSV987'\n",
      " 'RawPix_HSV988' 'RawPix_HSV990' 'RawPix_HSV991' 'RawPix_HSV993'\n",
      " 'RawPix_HSV994' 'RawPix_HSV996' 'RawPix_HSV997' 'RawPix_HSV999'\n",
      " 'RawPix_HSV1000' 'RawPix_HSV1002' 'RawPix_HSV1003' 'RawPix_HSV1005'\n",
      " 'RawPix_HSV1006' 'RawPix_HSV1008' 'RawPix_HSV1009' 'RawPix_HSV1011'\n",
      " 'RawPix_HSV1012' 'RawPix_HSV1014' 'RawPix_HSV1015' 'RawPix_HSV1017'\n",
      " 'RawPix_HSV1018' 'RawPix_HSV1020' 'RawPix_HSV1021' 'RawPix_HSV1023'\n",
      " 'RawPix_HSV1024' 'RawPix_HSV1026' 'RawPix_HSV1027' 'RawPix_HSV1029'\n",
      " 'RawPix_HSV1030' 'RawPix_HSV1032' 'RawPix_HSV1033' 'RawPix_HSV1035'\n",
      " 'RawPix_HSV1036' 'RawPix_HSV1038' 'RawPix_HSV1039' 'RawPix_HSV1041'\n",
      " 'RawPix_HSV1042' 'RawPix_HSV1044' 'RawPix_HSV1045' 'RawPix_HSV1047'\n",
      " 'RawPix_HSV1048' 'RawPix_HSV1050' 'RawPix_HSV1051' 'RawPix_HSV1053'\n",
      " 'RawPix_HSV1054' 'RawPix_HSV1056' 'RawPix_HSV1057' 'RawPix_HSV1059'\n",
      " 'RawPix_HSV1060' 'RawPix_HSV1062' 'RawPix_HSV1063' 'RawPix_HSV1065'\n",
      " 'RawPix_HSV1066' 'RawPix_HSV1068' 'RawPix_HSV1069' 'RawPix_HSV1071'\n",
      " 'RawPix_HSV1072' 'RawPix_HSV1074' 'RawPix_HSV1075' 'RawPix_HSV1077'\n",
      " 'RawPix_HSV1078' 'RawPix_HSV1080' 'RawPix_HSV1081' 'RawPix_HSV1083'\n",
      " 'RawPix_HSV1084' 'RawPix_HSV1086' 'RawPix_HSV1087' 'RawPix_HSV1089'\n",
      " 'RawPix_HSV1090' 'RawPix_HSV1092' 'RawPix_HSV1093' 'RawPix_HSV1095'\n",
      " 'RawPix_HSV1096' 'RawPix_HSV1098' 'RawPix_HSV1099' 'RawPix_HSV1101'\n",
      " 'RawPix_HSV1102' 'RawPix_HSV1104' 'RawPix_HSV1105' 'RawPix_HSV1107'\n",
      " 'RawPix_HSV1108' 'RawPix_HSV1110' 'RawPix_HSV1111' 'RawPix_HSV1113'\n",
      " 'RawPix_HSV1114' 'RawPix_HSV1116' 'RawPix_HSV1117' 'RawPix_HSV1119'\n",
      " 'RawPix_HSV1120' 'RawPix_HSV1122' 'RawPix_HSV1123' 'RawPix_HSV1125'\n",
      " 'RawPix_HSV1126' 'RawPix_HSV1128' 'RawPix_HSV1129' 'RawPix_HSV1131'\n",
      " 'RawPix_HSV1132' 'RawPix_HSV1134' 'RawPix_HSV1135' 'RawPix_HSV1137'\n",
      " 'RawPix_HSV1138' 'RawPix_HSV1140' 'RawPix_HSV1141' 'RawPix_HSV1143'\n",
      " 'RawPix_HSV1144' 'RawPix_HSV1146' 'RawPix_HSV1147' 'RawPix_HSV1149'\n",
      " 'RawPix_HSV1150' 'RawPix_HSV1152' 'RawPix_HSV1153' 'RawPix_HSV1155'\n",
      " 'RawPix_HSV1156' 'RawPix_HSV1158' 'RawPix_HSV1159' 'RawPix_HSV1161'\n",
      " 'RawPix_HSV1162' 'RawPix_HSV1164' 'RawPix_HSV1165' 'RawPix_HSV1167'\n",
      " 'RawPix_HSV1168' 'RawPix_HSV1170' 'RawPix_HSV1171' 'RawPix_HSV1173'\n",
      " 'RawPix_HSV1174' 'RawPix_HSV1176' 'RawPix_HSV1177' 'RawPix_HSV1179'\n",
      " 'RawPix_HSV1180' 'RawPix_HSV1182' 'RawPix_HSV1183' 'RawPix_HSV1185'\n",
      " 'RawPix_HSV1186' 'RawPix_HSV1188' 'RawPix_HSV1189' 'RawPix_HSV1191'\n",
      " 'RawPix_HSV1192' 'RawPix_HSV1194' 'RawPix_HSV1195' 'RawPix_HSV1197'\n",
      " 'RawPix_HSV1198' 'RawPix_HSV1200' 'RawPix_HSV1201' 'RawPix_HSV1203'\n",
      " 'RawPix_HSV1204' 'RawPix_HSV1206' 'RawPix_HSV1207' 'RawPix_HSV1209'\n",
      " 'RawPix_HSV1210' 'RawPix_HSV1212' 'RawPix_HSV1213' 'RawPix_HSV1215'\n",
      " 'RawPix_HSV1216' 'RawPix_HSV1218' 'RawPix_HSV1219' 'RawPix_HSV1221'\n",
      " 'RawPix_HSV1222' 'RawPix_HSV1224' 'RawPix_HSV1225' 'RawPix_HSV1227'\n",
      " 'RawPix_HSV1228' 'RawPix_HSV1230' 'RawPix_HSV1231' 'RawPix_HSV1233'\n",
      " 'RawPix_HSV1234' 'RawPix_HSV1236' 'RawPix_HSV1237' 'RawPix_HSV1239'\n",
      " 'RawPix_HSV1240' 'RawPix_HSV1242' 'RawPix_HSV1243' 'RawPix_HSV1245'\n",
      " 'RawPix_HSV1246' 'RawPix_HSV1248' 'RawPix_HSV1249' 'RawPix_HSV1251'\n",
      " 'RawPix_HSV1252' 'RawPix_HSV1254' 'RawPix_HSV1255' 'RawPix_HSV1257'\n",
      " 'RawPix_HSV1258' 'RawPix_HSV1260' 'RawPix_HSV1261' 'RawPix_HSV1263'\n",
      " 'RawPix_HSV1264' 'RawPix_HSV1266' 'RawPix_HSV1267' 'RawPix_HSV1269'\n",
      " 'RawPix_HSV1270' 'RawPix_HSV1272' 'RawPix_HSV1273' 'RawPix_HSV1275'\n",
      " 'RawPix_HSV1276' 'RawPix_HSV1278' 'RawPix_HSV1279' 'RawPix_HSV1281'\n",
      " 'RawPix_HSV1282' 'RawPix_HSV1284' 'RawPix_HSV1285' 'RawPix_HSV1287'\n",
      " 'RawPix_HSV1288' 'RawPix_HSV1290' 'RawPix_HSV1291' 'RawPix_HSV1293'\n",
      " 'RawPix_HSV1294' 'RawPix_HSV1296' 'RawPix_HSV1297' 'RawPix_HSV1299'\n",
      " 'RawPix_HSV1300' 'RawPix_HSV1302' 'RawPix_HSV1303' 'RawPix_HSV1305'\n",
      " 'RawPix_HSV1306' 'RawPix_HSV1308' 'RawPix_HSV1309' 'RawPix_HSV1311'\n",
      " 'RawPix_HSV1312' 'RawPix_HSV1314' 'RawPix_HSV1315' 'RawPix_HSV1317'\n",
      " 'RawPix_HSV1318' 'RawPix_HSV1320' 'RawPix_HSV1321' 'RawPix_HSV1323'\n",
      " 'RawPix_HSV1324' 'RawPix_HSV1326' 'RawPix_HSV1327' 'RawPix_HSV1329'\n",
      " 'RawPix_HSV1330' 'RawPix_HSV1332' 'RawPix_HSV1333' 'RawPix_HSV1335'\n",
      " 'RawPix_HSV1336' 'RawPix_HSV1338' 'RawPix_HSV1339' 'RawPix_HSV1341'\n",
      " 'RawPix_HSV1342' 'RawPix_HSV1344' 'RawPix_HSV1345' 'RawPix_HSV1347'\n",
      " 'RawPix_HSV1348' 'RawPix_HSV1350' 'RawPix_HSV1351' 'RawPix_HSV1353'\n",
      " 'RawPix_HSV1354' 'RawPix_HSV1356' 'RawPix_HSV1357' 'RawPix_HSV1359'\n",
      " 'RawPix_HSV1360' 'RawPix_HSV1362' 'RawPix_HSV1363' 'RawPix_HSV1365'\n",
      " 'RawPix_HSV1366' 'RawPix_HSV1368' 'RawPix_HSV1369' 'RawPix_HSV1371'\n",
      " 'RawPix_HSV1372' 'RawPix_HSV1374' 'RawPix_HSV1375' 'RawPix_HSV1377'\n",
      " 'RawPix_HSV1378' 'RawPix_HSV1380' 'RawPix_HSV1381' 'RawPix_HSV1383'\n",
      " 'RawPix_HSV1384' 'RawPix_HSV1386' 'RawPix_HSV1387' 'RawPix_HSV1389'\n",
      " 'RawPix_HSV1390' 'RawPix_HSV1392' 'RawPix_HSV1393' 'RawPix_HSV1395'\n",
      " 'RawPix_HSV1396' 'RawPix_HSV1398' 'RawPix_HSV1399' 'RawPix_HSV1401'\n",
      " 'RawPix_HSV1402' 'RawPix_HSV1404' 'RawPix_HSV1405' 'RawPix_HSV1407'\n",
      " 'RawPix_HSV1408' 'RawPix_HSV1410' 'RawPix_HSV1411' 'RawPix_HSV1413'\n",
      " 'RawPix_HSV1414' 'RawPix_HSV1416' 'RawPix_HSV1417' 'RawPix_HSV1419'\n",
      " 'RawPix_HSV1420' 'RawPix_HSV1422' 'RawPix_HSV1423' 'RawPix_HSV1425'\n",
      " 'RawPix_HSV1426' 'RawPix_HSV1428' 'RawPix_HSV1429' 'RawPix_HSV1431'\n",
      " 'RawPix_HSV1432' 'RawPix_HSV1434' 'RawPix_HSV1435' 'RawPix_HSV1437'\n",
      " 'RawPix_HSV1438' 'RawPix_HSV1440' 'RawPix_HSV1441' 'RawPix_HSV1443'\n",
      " 'RawPix_HSV1444' 'RawPix_HSV1446' 'RawPix_HSV1447' 'RawPix_HSV1449'\n",
      " 'RawPix_HSV1450' 'RawPix_HSV1452' 'RawPix_HSV1453' 'RawPix_HSV1455'\n",
      " 'RawPix_HSV1456' 'RawPix_HSV1458' 'RawPix_HSV1459' 'RawPix_HSV1461'\n",
      " 'RawPix_HSV1462' 'RawPix_HSV1464' 'RawPix_HSV1465' 'RawPix_HSV1467'\n",
      " 'RawPix_HSV1468' 'RawPix_HSV1470' 'RawPix_HSV1471' 'RawPix_HSV1473'\n",
      " 'RawPix_HSV1474' 'RawPix_HSV1476' 'RawPix_HSV1477' 'RawPix_HSV1479'\n",
      " 'RawPix_HSV1480' 'RawPix_HSV1482' 'RawPix_HSV1483' 'RawPix_HSV1485'\n",
      " 'RawPix_HSV1486' 'RawPix_HSV1488' 'RawPix_HSV1489' 'RawPix_HSV1491'\n",
      " 'RawPix_HSV1492' 'RawPix_HSV1494' 'RawPix_HSV1495' 'RawPix_HSV1497'\n",
      " 'RawPix_HSV1498' 'RawPix_HSV1500' 'RawPix_HSV1501' 'RawPix_HSV1503'\n",
      " 'RawPix_HSV1504' 'RawPix_HSV1506' 'RawPix_HSV1507' 'RawPix_HSV1509'\n",
      " 'RawPix_HSV1510' 'RawPix_HSV1512' 'RawPix_HSV1513' 'RawPix_HSV1515'\n",
      " 'RawPix_HSV1516' 'RawPix_HSV1518' 'RawPix_HSV1519' 'RawPix_HSV1521'\n",
      " 'RawPix_HSV1522' 'RawPix_HSV1524' 'RawPix_HSV1525' 'RawPix_HSV1527'\n",
      " 'RawPix_HSV1528' 'RawPix_HSV1530' 'RawPix_HSV1531' 'RawPix_HSV1533'\n",
      " 'RawPix_HSV1534' 'RawPix_HSV1536' 'RawPix_HSV1537' 'RawPix_HSV1539'\n",
      " 'RawPix_HSV1540' 'RawPix_HSV1542' 'RawPix_HSV1543' 'RawPix_HSV1545'\n",
      " 'RawPix_HSV1546' 'RawPix_HSV1548' 'RawPix_HSV1549' 'RawPix_HSV1551'\n",
      " 'RawPix_HSV1552' 'RawPix_HSV1554' 'RawPix_HSV1555' 'RawPix_HSV1557'\n",
      " 'RawPix_HSV1558' 'RawPix_HSV1560' 'RawPix_HSV1561' 'RawPix_HSV1563'\n",
      " 'RawPix_HSV1564' 'RawPix_HSV1566' 'RawPix_HSV1567' 'RawPix_HSV1569'\n",
      " 'RawPix_HSV1570' 'RawPix_HSV1572' 'RawPix_HSV1573' 'RawPix_HSV1575'\n",
      " 'RawPix_HSV1576' 'RawPix_HSV1578' 'RawPix_HSV1579' 'RawPix_HSV1581'\n",
      " 'RawPix_HSV1582' 'RawPix_HSV1584' 'RawPix_HSV1585' 'RawPix_HSV1587'\n",
      " 'RawPix_HSV1588' 'RawPix_HSV1590' 'RawPix_HSV1591' 'RawPix_HSV1593'\n",
      " 'RawPix_HSV1594' 'RawPix_HSV1596' 'RawPix_HSV1597' 'RawPix_HSV1599'\n",
      " 'RawPix_HSV1600' 'RawPix_HSV1602' 'RawPix_HSV1603' 'RawPix_HSV1605'\n",
      " 'RawPix_HSV1606' 'RawPix_HSV1608' 'RawPix_HSV1609' 'RawPix_HSV1611'\n",
      " 'RawPix_HSV1612' 'RawPix_HSV1614' 'RawPix_HSV1615' 'RawPix_HSV1617'\n",
      " 'RawPix_HSV1618' 'RawPix_HSV1620' 'RawPix_HSV1621' 'RawPix_HSV1623'\n",
      " 'RawPix_HSV1624' 'RawPix_HSV1626' 'RawPix_HSV1627' 'RawPix_HSV1629'\n",
      " 'RawPix_HSV1630' 'RawPix_HSV1632' 'RawPix_HSV1633' 'RawPix_HSV1635'\n",
      " 'RawPix_HSV1636' 'RawPix_HSV1638' 'RawPix_HSV1639' 'RawPix_HSV1641'\n",
      " 'RawPix_HSV1642' 'RawPix_HSV1644' 'RawPix_HSV1645' 'RawPix_HSV1647'\n",
      " 'RawPix_HSV1648' 'RawPix_HSV1650' 'RawPix_HSV1651' 'RawPix_HSV1653'\n",
      " 'RawPix_HSV1654' 'RawPix_HSV1656' 'RawPix_HSV1657' 'RawPix_HSV1659'\n",
      " 'RawPix_HSV1660' 'RawPix_HSV1662' 'RawPix_HSV1663' 'RawPix_HSV1665'\n",
      " 'RawPix_HSV1666' 'RawPix_HSV1668' 'RawPix_HSV1669' 'RawPix_HSV1671'\n",
      " 'RawPix_HSV1672' 'RawPix_HSV1674' 'RawPix_HSV1675' 'RawPix_HSV1677'\n",
      " 'RawPix_HSV1678' 'RawPix_HSV1680' 'RawPix_HSV1681' 'RawPix_HSV1683'\n",
      " 'RawPix_HSV1684' 'RawPix_HSV1686' 'RawPix_HSV1687' 'RawPix_HSV1689'\n",
      " 'RawPix_HSV1690' 'RawPix_HSV1692' 'RawPix_HSV1693' 'RawPix_HSV1695'\n",
      " 'RawPix_HSV1696' 'RawPix_HSV1698' 'RawPix_HSV1699' 'RawPix_HSV1701'\n",
      " 'RawPix_HSV1702' 'RawPix_HSV1704' 'RawPix_HSV1705' 'RawPix_HSV1707'\n",
      " 'RawPix_HSV1708' 'RawPix_HSV1710' 'RawPix_HSV1711' 'RawPix_HSV1713'\n",
      " 'RawPix_HSV1714' 'RawPix_HSV1716' 'RawPix_HSV1717' 'RawPix_HSV1719'\n",
      " 'RawPix_HSV1720' 'RawPix_HSV1722' 'RawPix_HSV1723' 'RawPix_HSV1725'\n",
      " 'RawPix_HSV1726' 'RawPix_HSV1728' 'RawPix_HSV1729' 'RawPix_HSV1731'\n",
      " 'RawPix_HSV1732' 'RawPix_HSV1734' 'RawPix_HSV1735' 'RawPix_HSV1737'\n",
      " 'RawPix_HSV1738' 'RawPix_HSV1740' 'RawPix_HSV1741' 'RawPix_HSV1743'\n",
      " 'RawPix_HSV1744' 'RawPix_HSV1746' 'RawPix_HSV1747' 'RawPix_HSV1749'\n",
      " 'RawPix_HSV1750' 'RawPix_HSV1752' 'RawPix_HSV1753' 'RawPix_HSV1755'\n",
      " 'RawPix_HSV1756' 'RawPix_HSV1758' 'RawPix_HSV1759' 'RawPix_HSV1761'\n",
      " 'RawPix_HSV1762' 'RawPix_HSV1764' 'RawPix_HSV1765' 'RawPix_HSV1767'\n",
      " 'RawPix_HSV1768' 'RawPix_HSV1770' 'RawPix_HSV1771' 'RawPix_HSV1773'\n",
      " 'RawPix_HSV1774' 'RawPix_HSV1776' 'RawPix_HSV1777' 'RawPix_HSV1779'\n",
      " 'RawPix_HSV1780' 'RawPix_HSV1782' 'RawPix_HSV1783' 'RawPix_HSV1785'\n",
      " 'RawPix_HSV1786' 'RawPix_HSV1788' 'RawPix_HSV1789' 'RawPix_HSV1791'\n",
      " 'RawPix_HSV1792' 'RawPix_HSV1794' 'RawPix_HSV1795' 'RawPix_HSV1797'\n",
      " 'RawPix_HSV1798' 'RawPix_HSV1800' 'RawPix_HSV1801' 'RawPix_HSV1803'\n",
      " 'RawPix_HSV1804' 'RawPix_HSV1806' 'RawPix_HSV1807' 'RawPix_HSV1809'\n",
      " 'RawPix_HSV1810' 'RawPix_HSV1812' 'RawPix_HSV1813' 'RawPix_HSV1815'\n",
      " 'RawPix_HSV1816' 'RawPix_HSV1818' 'RawPix_HSV1819' 'RawPix_HSV1821'\n",
      " 'RawPix_HSV1822' 'RawPix_HSV1824' 'RawPix_HSV1825' 'RawPix_HSV1827'\n",
      " 'RawPix_HSV1828' 'RawPix_HSV1830' 'RawPix_HSV1831' 'RawPix_HSV1833'\n",
      " 'RawPix_HSV1834' 'RawPix_HSV1836' 'RawPix_HSV1837' 'RawPix_HSV1839'\n",
      " 'RawPix_HSV1840' 'RawPix_HSV1842' 'RawPix_HSV1843' 'RawPix_HSV1845'\n",
      " 'RawPix_HSV1846' 'RawPix_HSV1848' 'RawPix_HSV1849' 'RawPix_HSV1851'\n",
      " 'RawPix_HSV1852' 'RawPix_HSV1854' 'RawPix_HSV1855' 'RawPix_HSV1857'\n",
      " 'RawPix_HSV1858' 'RawPix_HSV1860' 'RawPix_HSV1861' 'RawPix_HSV1863'\n",
      " 'RawPix_HSV1864' 'RawPix_HSV1866' 'RawPix_HSV1867' 'RawPix_HSV1869'\n",
      " 'RawPix_HSV1870' 'RawPix_HSV1872' 'RawPix_HSV1873' 'RawPix_HSV1875'\n",
      " 'RawPix_HSV1876' 'RawPix_HSV1878' 'RawPix_HSV1879' 'RawPix_HSV1881'\n",
      " 'RawPix_HSV1882' 'RawPix_HSV1884' 'RawPix_HSV1885' 'RawPix_HSV1887'\n",
      " 'RawPix_HSV1888' 'RawPix_HSV1890' 'RawPix_HSV1891' 'RawPix_HSV1893'\n",
      " 'RawPix_HSV1894' 'RawPix_HSV1896' 'RawPix_HSV1897' 'RawPix_HSV1899'\n",
      " 'RawPix_HSV1900' 'RawPix_HSV1902' 'RawPix_HSV1903' 'RawPix_HSV1905'\n",
      " 'RawPix_HSV1906' 'RawPix_HSV1908' 'RawPix_HSV1909' 'RawPix_HSV1911'\n",
      " 'RawPix_HSV1912' 'RawPix_HSV1914' 'RawPix_HSV1915' 'RawPix_HSV1917'\n",
      " 'RawPix_HSV1918' 'RawPix_HSV1920' 'RawPix_HSV1921' 'RawPix_HSV1923'\n",
      " 'RawPix_HSV1924' 'RawPix_HSV1926' 'RawPix_HSV1927' 'RawPix_HSV1929'\n",
      " 'RawPix_HSV1930' 'RawPix_HSV1932' 'RawPix_HSV1933' 'RawPix_HSV1935'\n",
      " 'RawPix_HSV1936' 'RawPix_HSV1938' 'RawPix_HSV1939' 'RawPix_HSV1941'\n",
      " 'RawPix_HSV1942' 'RawPix_HSV1944' 'RawPix_HSV1945' 'RawPix_HSV1947'\n",
      " 'RawPix_HSV1948' 'RawPix_HSV1950' 'RawPix_HSV1951' 'RawPix_HSV1953'\n",
      " 'RawPix_HSV1954' 'RawPix_HSV1956' 'RawPix_HSV1957' 'RawPix_HSV1959'\n",
      " 'RawPix_HSV1960' 'RawPix_HSV1962' 'RawPix_HSV1963' 'RawPix_HSV1965'\n",
      " 'RawPix_HSV1966' 'RawPix_HSV1968' 'RawPix_HSV1969' 'RawPix_HSV1971'\n",
      " 'RawPix_HSV1972' 'RawPix_HSV1974' 'RawPix_HSV1975' 'RawPix_HSV1977'\n",
      " 'RawPix_HSV1978' 'RawPix_HSV1980' 'RawPix_HSV1981' 'RawPix_HSV1983'\n",
      " 'RawPix_HSV1984' 'RawPix_HSV1986' 'RawPix_HSV1987' 'RawPix_HSV1989'\n",
      " 'RawPix_HSV1990' 'RawPix_HSV1992' 'RawPix_HSV1993' 'RawPix_HSV1995'\n",
      " 'RawPix_HSV1996' 'RawPix_HSV1998' 'RawPix_HSV1999' 'RawPix_HSV2001'\n",
      " 'RawPix_HSV2002' 'RawPix_HSV2004' 'RawPix_HSV2005' 'RawPix_HSV2007'\n",
      " 'RawPix_HSV2008' 'RawPix_HSV2010' 'RawPix_HSV2011' 'RawPix_HSV2013'\n",
      " 'RawPix_HSV2014' 'RawPix_HSV2016' 'RawPix_HSV2017' 'RawPix_HSV2019'\n",
      " 'RawPix_HSV2020' 'RawPix_HSV2022' 'RawPix_HSV2023' 'RawPix_HSV2025'\n",
      " 'RawPix_HSV2026' 'RawPix_HSV2028' 'RawPix_HSV2029' 'RawPix_HSV2031'\n",
      " 'RawPix_HSV2032' 'RawPix_HSV2034' 'RawPix_HSV2035' 'RawPix_HSV2037'\n",
      " 'RawPix_HSV2038' 'RawPix_HSV2040' 'RawPix_HSV2041' 'RawPix_HSV2043'\n",
      " 'RawPix_HSV2044' 'RawPix_HSV2046' 'RawPix_HSV2047' 'RawPix_HSV2049'\n",
      " 'RawPix_HSV2050' 'RawPix_HSV2052' 'RawPix_HSV2053' 'RawPix_HSV2055'\n",
      " 'RawPix_HSV2056' 'RawPix_HSV2058' 'RawPix_HSV2059' 'RawPix_HSV2061'\n",
      " 'RawPix_HSV2062' 'RawPix_HSV2064' 'RawPix_HSV2065' 'RawPix_HSV2067'\n",
      " 'RawPix_HSV2068' 'RawPix_HSV2070' 'RawPix_HSV2071' 'RawPix_HSV2073'\n",
      " 'RawPix_HSV2074' 'RawPix_HSV2076' 'RawPix_HSV2077' 'RawPix_HSV2079'\n",
      " 'RawPix_HSV2080' 'RawPix_HSV2082' 'RawPix_HSV2083' 'RawPix_HSV2085'\n",
      " 'RawPix_HSV2086' 'RawPix_HSV2088' 'RawPix_HSV2089' 'RawPix_HSV2091'\n",
      " 'RawPix_HSV2092' 'RawPix_HSV2094' 'RawPix_HSV2095' 'RawPix_HSV2097'\n",
      " 'RawPix_HSV2098' 'RawPix_HSV2100' 'RawPix_HSV2101' 'RawPix_HSV2103'\n",
      " 'RawPix_HSV2104' 'RawPix_HSV2106' 'RawPix_HSV2107' 'RawPix_HSV2109'\n",
      " 'RawPix_HSV2110' 'RawPix_HSV2112' 'RawPix_HSV2113' 'RawPix_HSV2115'\n",
      " 'RawPix_HSV2116' 'RawPix_HSV2118' 'RawPix_HSV2119' 'RawPix_HSV2121'\n",
      " 'RawPix_HSV2122' 'RawPix_HSV2124' 'RawPix_HSV2125' 'RawPix_HSV2127'\n",
      " 'RawPix_HSV2128' 'RawPix_HSV2130' 'RawPix_HSV2131' 'RawPix_HSV2133'\n",
      " 'RawPix_HSV2134' 'RawPix_HSV2136' 'RawPix_HSV2137' 'RawPix_HSV2139'\n",
      " 'RawPix_HSV2140' 'RawPix_HSV2142' 'RawPix_HSV2143' 'RawPix_HSV2145'\n",
      " 'RawPix_HSV2146' 'RawPix_HSV2148' 'RawPix_HSV2149' 'RawPix_HSV2151'\n",
      " 'RawPix_HSV2152' 'RawPix_HSV2154' 'RawPix_HSV2155' 'RawPix_HSV2157'\n",
      " 'RawPix_HSV2158' 'RawPix_HSV2160' 'RawPix_HSV2161' 'RawPix_HSV2163'\n",
      " 'RawPix_HSV2164' 'RawPix_HSV2166' 'RawPix_HSV2167' 'RawPix_HSV2169'\n",
      " 'RawPix_HSV2170' 'RawPix_HSV2172' 'RawPix_HSV2173' 'RawPix_HSV2175'\n",
      " 'RawPix_HSV2176' 'RawPix_HSV2178' 'RawPix_HSV2179' 'RawPix_HSV2181'\n",
      " 'RawPix_HSV2182' 'RawPix_HSV2184' 'RawPix_HSV2185' 'RawPix_HSV2187'\n",
      " 'RawPix_HSV2188' 'RawPix_HSV2190' 'RawPix_HSV2191' 'RawPix_HSV2193'\n",
      " 'RawPix_HSV2194' 'RawPix_HSV2196' 'RawPix_HSV2197' 'RawPix_HSV2199'\n",
      " 'RawPix_HSV2200' 'RawPix_HSV2202' 'RawPix_HSV2203' 'RawPix_HSV2205'\n",
      " 'RawPix_HSV2206' 'RawPix_HSV2208' 'RawPix_HSV2209' 'RawPix_HSV2211'\n",
      " 'RawPix_HSV2212' 'RawPix_HSV2214' 'RawPix_HSV2215' 'RawPix_HSV2217'\n",
      " 'RawPix_HSV2218' 'RawPix_HSV2220' 'RawPix_HSV2221' 'RawPix_HSV2223'\n",
      " 'RawPix_HSV2224' 'RawPix_HSV2226' 'RawPix_HSV2227' 'RawPix_HSV2229'\n",
      " 'RawPix_HSV2230' 'RawPix_HSV2232' 'RawPix_HSV2233' 'RawPix_HSV2235'\n",
      " 'RawPix_HSV2236' 'RawPix_HSV2238' 'RawPix_HSV2239' 'RawPix_HSV2241'\n",
      " 'RawPix_HSV2242' 'RawPix_HSV2244' 'RawPix_HSV2245' 'RawPix_HSV2247'\n",
      " 'RawPix_HSV2248' 'RawPix_HSV2250' 'RawPix_HSV2251' 'RawPix_HSV2253'\n",
      " 'RawPix_HSV2254' 'RawPix_HSV2256' 'RawPix_HSV2257' 'RawPix_HSV2259'\n",
      " 'RawPix_HSV2260' 'RawPix_HSV2262' 'RawPix_HSV2263' 'RawPix_HSV2265'\n",
      " 'RawPix_HSV2266' 'RawPix_HSV2268' 'RawPix_HSV2269' 'RawPix_HSV2271'\n",
      " 'RawPix_HSV2272' 'RawPix_HSV2274' 'RawPix_HSV2275' 'RawPix_HSV2277'\n",
      " 'RawPix_HSV2278' 'RawPix_HSV2280' 'RawPix_HSV2281' 'RawPix_HSV2283'\n",
      " 'RawPix_HSV2284' 'RawPix_HSV2286' 'RawPix_HSV2287' 'RawPix_HSV2289'\n",
      " 'RawPix_HSV2290' 'RawPix_HSV2292' 'RawPix_HSV2293' 'RawPix_HSV2295'\n",
      " 'RawPix_HSV2296' 'RawPix_HSV2298' 'RawPix_HSV2299' 'RawPix_HSV2301'\n",
      " 'RawPix_HSV2302' 'RawPix_HSV2304' 'RawPix_HSV2305' 'RawPix_HSV2307'\n",
      " 'RawPix_HSV2308' 'RawPix_HSV2310' 'RawPix_HSV2311' 'RawPix_HSV2313'\n",
      " 'RawPix_HSV2314' 'RawPix_HSV2316' 'RawPix_HSV2317' 'RawPix_HSV2319'\n",
      " 'RawPix_HSV2320' 'RawPix_HSV2322' 'RawPix_HSV2323' 'RawPix_HSV2325'\n",
      " 'RawPix_HSV2326' 'RawPix_HSV2328' 'RawPix_HSV2329' 'RawPix_HSV2331'\n",
      " 'RawPix_HSV2332' 'RawPix_HSV2334' 'RawPix_HSV2335' 'RawPix_HSV2337'\n",
      " 'RawPix_HSV2338' 'RawPix_HSV2340' 'RawPix_HSV2341' 'RawPix_HSV2343'\n",
      " 'RawPix_HSV2344' 'RawPix_HSV2346' 'RawPix_HSV2347' 'RawPix_HSV2349'\n",
      " 'RawPix_HSV2350' 'RawPix_HSV2352' 'RawPix_HSV2353' 'RawPix_HSV2355'\n",
      " 'RawPix_HSV2356' 'RawPix_HSV2358' 'RawPix_HSV2359' 'RawPix_HSV2361'\n",
      " 'RawPix_HSV2362' 'RawPix_HSV2364' 'RawPix_HSV2365' 'RawPix_HSV2367'\n",
      " 'RawPix_HSV2368' 'RawPix_HSV2370' 'RawPix_HSV2371' 'RawPix_HSV2373'\n",
      " 'RawPix_HSV2374' 'RawPix_HSV2376' 'RawPix_HSV2377' 'RawPix_HSV2379'\n",
      " 'RawPix_HSV2380' 'RawPix_HSV2382' 'RawPix_HSV2383' 'RawPix_HSV2385'\n",
      " 'RawPix_HSV2386' 'RawPix_HSV2388' 'RawPix_HSV2389' 'RawPix_HSV2391'\n",
      " 'RawPix_HSV2392' 'RawPix_HSV2394' 'RawPix_HSV2395' 'RawPix_HSV2397'\n",
      " 'RawPix_HSV2398' 'RawPix_HSV2400' 'RawPix_HSV2401' 'RawPix_HSV2403'\n",
      " 'RawPix_HSV2404' 'RawPix_HSV2406' 'RawPix_HSV2407' 'RawPix_HSV2409'\n",
      " 'RawPix_HSV2410' 'RawPix_HSV2412' 'RawPix_HSV2413' 'RawPix_HSV2415'\n",
      " 'RawPix_HSV2416' 'RawPix_HSV2418' 'RawPix_HSV2419' 'RawPix_HSV2421'\n",
      " 'RawPix_HSV2422' 'RawPix_HSV2424' 'RawPix_HSV2425' 'RawPix_HSV2427'\n",
      " 'RawPix_HSV2428' 'RawPix_HSV2430' 'RawPix_HSV2431' 'RawPix_HSV2433'\n",
      " 'RawPix_HSV2434' 'RawPix_HSV2436' 'RawPix_HSV2437' 'RawPix_HSV2439'\n",
      " 'RawPix_HSV2440' 'RawPix_HSV2442' 'RawPix_HSV2443' 'RawPix_HSV2445'\n",
      " 'RawPix_HSV2446' 'RawPix_HSV2448' 'RawPix_HSV2449' 'RawPix_HSV2451'\n",
      " 'RawPix_HSV2452' 'RawPix_HSV2454' 'RawPix_HSV2455' 'RawPix_HSV2457'\n",
      " 'RawPix_HSV2458' 'RawPix_HSV2460' 'RawPix_HSV2461' 'RawPix_HSV2463'\n",
      " 'RawPix_HSV2464' 'RawPix_HSV2466' 'RawPix_HSV2467' 'RawPix_HSV2469'\n",
      " 'RawPix_HSV2470' 'RawPix_HSV2472' 'RawPix_HSV2473' 'RawPix_HSV2475'\n",
      " 'RawPix_HSV2476' 'RawPix_HSV2478' 'RawPix_HSV2479' 'RawPix_HSV2481'\n",
      " 'RawPix_HSV2482' 'RawPix_HSV2484' 'RawPix_HSV2485' 'RawPix_HSV2487'\n",
      " 'RawPix_HSV2488' 'RawPix_HSV2490' 'RawPix_HSV2491' 'RawPix_HSV2493'\n",
      " 'RawPix_HSV2494' 'RawPix_HSV2496' 'RawPix_HSV2497' 'RawPix_HSV2499'\n",
      " 'RawPix_HSV2500' 'RawPix_HSV2502' 'RawPix_HSV2503' 'RawPix_HSV2505'\n",
      " 'RawPix_HSV2506' 'RawPix_HSV2508' 'RawPix_HSV2509' 'RawPix_HSV2511'\n",
      " 'RawPix_HSV2512' 'RawPix_HSV2514' 'RawPix_HSV2515' 'RawPix_HSV2517'\n",
      " 'RawPix_HSV2518' 'RawPix_HSV2520' 'RawPix_HSV2521' 'RawPix_HSV2523'\n",
      " 'RawPix_HSV2524' 'RawPix_HSV2526' 'RawPix_HSV2527' 'RawPix_HSV2529'\n",
      " 'RawPix_HSV2530' 'RawPix_HSV2532' 'RawPix_HSV2533' 'RawPix_HSV2535'\n",
      " 'RawPix_HSV2536' 'RawPix_HSV2538' 'RawPix_HSV2539' 'RawPix_HSV2541'\n",
      " 'RawPix_HSV2542' 'RawPix_HSV2544' 'RawPix_HSV2545' 'RawPix_HSV2547'\n",
      " 'RawPix_HSV2548' 'RawPix_HSV2550' 'RawPix_HSV2551' 'RawPix_HSV2553'\n",
      " 'RawPix_HSV2554' 'RawPix_HSV2556' 'RawPix_HSV2557' 'RawPix_HSV2559'\n",
      " 'RawPix_HSV2560' 'RawPix_HSV2562' 'RawPix_HSV2563' 'RawPix_HSV2565'\n",
      " 'RawPix_HSV2566' 'RawPix_HSV2568' 'RawPix_HSV2569' 'RawPix_HSV2571'\n",
      " 'RawPix_HSV2572' 'RawPix_HSV2574' 'RawPix_HSV2575' 'RawPix_HSV2577'\n",
      " 'RawPix_HSV2578' 'RawPix_HSV2580' 'RawPix_HSV2581' 'RawPix_HSV2583'\n",
      " 'RawPix_HSV2584' 'RawPix_HSV2586' 'RawPix_HSV2587' 'RawPix_HSV2589'\n",
      " 'RawPix_HSV2590' 'RawPix_HSV2592' 'RawPix_HSV2593' 'RawPix_HSV2595'\n",
      " 'RawPix_HSV2596' 'RawPix_HSV2598' 'RawPix_HSV2599' 'RawPix_HSV2601'\n",
      " 'RawPix_HSV2602' 'RawPix_HSV2604' 'RawPix_HSV2605' 'RawPix_HSV2607'\n",
      " 'RawPix_HSV2608' 'RawPix_HSV2610' 'RawPix_HSV2611' 'RawPix_HSV2613'\n",
      " 'RawPix_HSV2614' 'RawPix_HSV2616' 'RawPix_HSV2617' 'RawPix_HSV2619'\n",
      " 'RawPix_HSV2620' 'RawPix_HSV2622' 'RawPix_HSV2623' 'RawPix_HSV2625'\n",
      " 'RawPix_HSV2626' 'RawPix_HSV2628' 'RawPix_HSV2629' 'RawPix_HSV2631'\n",
      " 'RawPix_HSV2632' 'RawPix_HSV2634' 'RawPix_HSV2635' 'RawPix_HSV2637'\n",
      " 'RawPix_HSV2638' 'RawPix_HSV2640' 'RawPix_HSV2641' 'RawPix_HSV2643'\n",
      " 'RawPix_HSV2644' 'RawPix_HSV2646' 'RawPix_HSV2647' 'RawPix_HSV2649'\n",
      " 'RawPix_HSV2650' 'RawPix_HSV2652' 'RawPix_HSV2653' 'RawPix_HSV2655'\n",
      " 'RawPix_HSV2656' 'RawPix_HSV2658' 'RawPix_HSV2659' 'RawPix_HSV2661'\n",
      " 'RawPix_HSV2662' 'RawPix_HSV2664' 'RawPix_HSV2665' 'RawPix_HSV2667'\n",
      " 'RawPix_HSV2668' 'RawPix_HSV2670' 'RawPix_HSV2671' 'RawPix_HSV2673'\n",
      " 'RawPix_HSV2674' 'RawPix_HSV2676' 'RawPix_HSV2677' 'RawPix_HSV2679'\n",
      " 'RawPix_HSV2680' 'RawPix_HSV2682' 'RawPix_HSV2683' 'RawPix_HSV2685'\n",
      " 'RawPix_HSV2686' 'RawPix_HSV2688' 'RawPix_HSV2689' 'RawPix_HSV2691'\n",
      " 'RawPix_HSV2692' 'RawPix_HSV2694' 'RawPix_HSV2695' 'RawPix_HSV2697'\n",
      " 'RawPix_HSV2698' 'RawPix_HSV2700' 'RawPix_HSV2701' 'RawPix_HSV2703'\n",
      " 'RawPix_HSV2704' 'RawPix_HSV2706' 'RawPix_HSV2707' 'RawPix_HSV2709'\n",
      " 'RawPix_HSV2710' 'RawPix_HSV2712' 'RawPix_HSV2713' 'RawPix_HSV2715'\n",
      " 'RawPix_HSV2716' 'RawPix_HSV2718' 'RawPix_HSV2719' 'RawPix_HSV2721'\n",
      " 'RawPix_HSV2722' 'RawPix_HSV2724' 'RawPix_HSV2725' 'RawPix_HSV2727'\n",
      " 'RawPix_HSV2728' 'RawPix_HSV2730' 'RawPix_HSV2731' 'RawPix_HSV2733'\n",
      " 'RawPix_HSV2734' 'RawPix_HSV2736' 'RawPix_HSV2737' 'RawPix_HSV2739'\n",
      " 'RawPix_HSV2740' 'RawPix_HSV2742' 'RawPix_HSV2743' 'RawPix_HSV2745'\n",
      " 'RawPix_HSV2746' 'RawPix_HSV2748' 'RawPix_HSV2749' 'RawPix_HSV2751'\n",
      " 'RawPix_HSV2752' 'RawPix_HSV2754' 'RawPix_HSV2755' 'RawPix_HSV2757'\n",
      " 'RawPix_HSV2758' 'RawPix_HSV2760' 'RawPix_HSV2761' 'RawPix_HSV2763'\n",
      " 'RawPix_HSV2764' 'RawPix_HSV2766' 'RawPix_HSV2767' 'RawPix_HSV2769'\n",
      " 'RawPix_HSV2770' 'RawPix_HSV2772' 'RawPix_HSV2773' 'RawPix_HSV2775'\n",
      " 'RawPix_HSV2776' 'RawPix_HSV2778' 'RawPix_HSV2779' 'RawPix_HSV2781'\n",
      " 'RawPix_HSV2782' 'RawPix_HSV2784' 'RawPix_HSV2785' 'RawPix_HSV2787'\n",
      " 'RawPix_HSV2788' 'RawPix_HSV2790' 'RawPix_HSV2791' 'RawPix_HSV2793'\n",
      " 'RawPix_HSV2794' 'RawPix_HSV2796' 'RawPix_HSV2797' 'RawPix_HSV2799'\n",
      " 'RawPix_HSV2800' 'RawPix_HSV2802' 'RawPix_HSV2803' 'RawPix_HSV2805'\n",
      " 'RawPix_HSV2806' 'RawPix_HSV2808' 'RawPix_HSV2809' 'RawPix_HSV2811'\n",
      " 'RawPix_HSV2812' 'RawPix_HSV2814' 'RawPix_HSV2815' 'RawPix_HSV2817'\n",
      " 'RawPix_HSV2818' 'RawPix_HSV2820' 'RawPix_HSV2821' 'RawPix_HSV2823'\n",
      " 'RawPix_HSV2824' 'RawPix_HSV2826' 'RawPix_HSV2827' 'RawPix_HSV2829'\n",
      " 'RawPix_HSV2830' 'RawPix_HSV2832' 'RawPix_HSV2833' 'RawPix_HSV2835'\n",
      " 'RawPix_HSV2836' 'RawPix_HSV2838' 'RawPix_HSV2839' 'RawPix_HSV2841'\n",
      " 'RawPix_HSV2842' 'RawPix_HSV2844' 'RawPix_HSV2845' 'RawPix_HSV2847'\n",
      " 'RawPix_HSV2848' 'RawPix_HSV2850' 'RawPix_HSV2851' 'RawPix_HSV2853'\n",
      " 'RawPix_HSV2854' 'RawPix_HSV2856' 'RawPix_HSV2857' 'RawPix_HSV2859'\n",
      " 'RawPix_HSV2860' 'RawPix_HSV2862' 'RawPix_HSV2863' 'RawPix_HSV2865'\n",
      " 'RawPix_HSV2866' 'RawPix_HSV2868' 'RawPix_HSV2869' 'RawPix_HSV2871'\n",
      " 'RawPix_HSV2872' 'RawPix_HSV2874' 'RawPix_HSV2875' 'RawPix_HSV2877'\n",
      " 'RawPix_HSV2878' 'RawPix_HSV2880' 'RawPix_HSV2881' 'RawPix_HSV2883'\n",
      " 'RawPix_HSV2884' 'RawPix_HSV2886' 'RawPix_HSV2887' 'RawPix_HSV2889'\n",
      " 'RawPix_HSV2890' 'RawPix_HSV2892' 'RawPix_HSV2893' 'RawPix_HSV2895'\n",
      " 'RawPix_HSV2896' 'RawPix_HSV2898' 'RawPix_HSV2899' 'RawPix_HSV2901'\n",
      " 'RawPix_HSV2902' 'RawPix_HSV2904' 'RawPix_HSV2905' 'RawPix_HSV2907'\n",
      " 'RawPix_HSV2908' 'RawPix_HSV2910' 'RawPix_HSV2911' 'RawPix_HSV2913'\n",
      " 'RawPix_HSV2914' 'RawPix_HSV2916' 'RawPix_HSV2917' 'RawPix_HSV2919'\n",
      " 'RawPix_HSV2920' 'RawPix_HSV2922' 'RawPix_HSV2923' 'RawPix_HSV2925'\n",
      " 'RawPix_HSV2926' 'RawPix_HSV2928' 'RawPix_HSV2929' 'RawPix_HSV2931'\n",
      " 'RawPix_HSV2932' 'RawPix_HSV2934' 'RawPix_HSV2935' 'RawPix_HSV2937'\n",
      " 'RawPix_HSV2938' 'RawPix_HSV2940' 'RawPix_HSV2941' 'RawPix_HSV2943'\n",
      " 'RawPix_HSV2944' 'RawPix_HSV2946' 'RawPix_HSV2947' 'RawPix_HSV2949'\n",
      " 'RawPix_HSV2950' 'RawPix_HSV2952' 'RawPix_HSV2953' 'RawPix_HSV2955'\n",
      " 'RawPix_HSV2956' 'RawPix_HSV2958' 'RawPix_HSV2959' 'RawPix_HSV2961'\n",
      " 'RawPix_HSV2962' 'RawPix_HSV2964' 'RawPix_HSV2965' 'RawPix_HSV2967'\n",
      " 'RawPix_HSV2968' 'RawPix_HSV2970' 'RawPix_HSV2971' 'RawPix_HSV2973'\n",
      " 'RawPix_HSV2974' 'RawPix_HSV2976' 'RawPix_HSV2977' 'RawPix_HSV2979'\n",
      " 'RawPix_HSV2980' 'RawPix_HSV2982' 'RawPix_HSV2983' 'RawPix_HSV2985'\n",
      " 'RawPix_HSV2986' 'RawPix_HSV2988' 'RawPix_HSV2989' 'RawPix_HSV2991'\n",
      " 'RawPix_HSV2992' 'RawPix_HSV2994' 'RawPix_HSV2995' 'RawPix_HSV2997'\n",
      " 'RawPix_HSV2998' 'RawPix_HSV3000' 'RawPix_HSV3001' 'RawPix_HSV3003'\n",
      " 'RawPix_HSV3004' 'RawPix_HSV3006' 'RawPix_HSV3007' 'RawPix_HSV3009'\n",
      " 'RawPix_HSV3010' 'RawPix_HSV3012' 'RawPix_HSV3013' 'RawPix_HSV3015'\n",
      " 'RawPix_HSV3016' 'RawPix_HSV3018' 'RawPix_HSV3019' 'RawPix_HSV3021'\n",
      " 'RawPix_HSV3022' 'RawPix_HSV3024' 'RawPix_HSV3025' 'RawPix_HSV3027'\n",
      " 'RawPix_HSV3028' 'RawPix_HSV3030' 'RawPix_HSV3031' 'RawPix_HSV3033'\n",
      " 'RawPix_HSV3034' 'RawPix_HSV3036' 'RawPix_HSV3037' 'RawPix_HSV3039'\n",
      " 'RawPix_HSV3040' 'RawPix_HSV3042' 'RawPix_HSV3043' 'RawPix_HSV3045'\n",
      " 'RawPix_HSV3046' 'RawPix_HSV3048' 'RawPix_HSV3049' 'RawPix_HSV3051'\n",
      " 'RawPix_HSV3052' 'RawPix_HSV3054' 'RawPix_HSV3055' 'RawPix_HSV3057'\n",
      " 'RawPix_HSV3058' 'RawPix_HSV3060' 'RawPix_HSV3061' 'RawPix_HSV3063'\n",
      " 'RawPix_HSV3064' 'RawPix_HSV3066' 'RawPix_HSV3067' 'RawPix_HSV3069'\n",
      " 'RawPix_HSV3070' 'CIE-CH1-0' 'CIE-CH1-1' 'CIE-CH1-2' 'CIE-CH1-3'\n",
      " 'CIE-CH1-4' 'CIE-CH1-5' 'CIE-CH1-6' 'CIE-CH1-7' 'CIE-CH1-8' 'CIE-CH1-9'\n",
      " 'CIE-CH1-10' 'CIE-CH1-11' 'CIE-CH1-12' 'CIE-CH1-13' 'CIE-CH1-14'\n",
      " 'CIE-CH1-15' 'CIE-CH1-16' 'CIE-CH1-17' 'CIE-CH1-18' 'CIE-CH1-19'\n",
      " 'CIE-CH1-20' 'CIE-CH1-21' 'CIE-CH1-22' 'CIE-CH1-23' 'CIE-CH1-24'\n",
      " 'CIE-CH1-25' 'CIE-CH1-26' 'CIE-CH1-27' 'CIE-CH1-28' 'CIE-CH1-29'\n",
      " 'CIE-CH1-30' 'CIE-CH1-31' 'CIE-CH1-32' 'CIE-CH1-33' 'CIE-CH1-34'\n",
      " 'CIE-CH1-35' 'CIE-CH1-36' 'CIE-CH1-37' 'CIE-CH1-38' 'CIE-CH1-39'\n",
      " 'CIE-CH1-40' 'CIE-CH1-41' 'CIE-CH1-42' 'CIE-CH1-43' 'CIE-CH1-44'\n",
      " 'CIE-CH1-45' 'CIE-CH1-46' 'CIE-CH1-47' 'CIE-CH1-48' 'CIE-CH1-49'\n",
      " 'CIE-CH2-0' 'CIE-CH2-1' 'CIE-CH2-2' 'CIE-CH2-3' 'CIE-CH2-4' 'CIE-CH2-5'\n",
      " 'CIE-CH2-6' 'CIE-CH2-7' 'CIE-CH2-8' 'CIE-CH2-9' 'CIE-CH2-10' 'CIE-CH2-11'\n",
      " 'CIE-CH2-12' 'CIE-CH2-13' 'CIE-CH2-14' 'CIE-CH2-15' 'CIE-CH2-16'\n",
      " 'CIE-CH2-17' 'CIE-CH2-18' 'CIE-CH2-19' 'CIE-CH2-20' 'CIE-CH2-21'\n",
      " 'CIE-CH2-22' 'CIE-CH2-23' 'CIE-CH2-24' 'CIE-CH2-25' 'CIE-CH2-26'\n",
      " 'CIE-CH2-27' 'CIE-CH2-28' 'CIE-CH2-29' 'CIE-CH2-30' 'CIE-CH2-31'\n",
      " 'CIE-CH2-32' 'CIE-CH2-33' 'CIE-CH2-34' 'CIE-CH2-35' 'CIE-CH2-36'\n",
      " 'CIE-CH2-37' 'CIE-CH2-38' 'CIE-CH2-39' 'CIE-CH2-40' 'CIE-CH2-41'\n",
      " 'CIE-CH2-42' 'CIE-CH2-43' 'CIE-CH2-44' 'CIE-CH2-45' 'CIE-CH2-46'\n",
      " 'CIE-CH2-47' 'CIE-CH2-48' 'CIE-CH2-49' 'CIE-CH3-0' 'CIE-CH3-1'\n",
      " 'CIE-CH3-2' 'CIE-CH3-3' 'CIE-CH3-4' 'CIE-CH3-5' 'CIE-CH3-6' 'CIE-CH3-7'\n",
      " 'CIE-CH3-8' 'CIE-CH3-9' 'CIE-CH3-10' 'CIE-CH3-11' 'CIE-CH3-12'\n",
      " 'CIE-CH3-13' 'CIE-CH3-14' 'CIE-CH3-15' 'CIE-CH3-16' 'CIE-CH3-17'\n",
      " 'CIE-CH3-18' 'CIE-CH3-19' 'CIE-CH3-20' 'CIE-CH3-21' 'CIE-CH3-22'\n",
      " 'CIE-CH3-23' 'CIE-CH3-24' 'CIE-CH3-25' 'CIE-CH3-26' 'CIE-CH3-27'\n",
      " 'CIE-CH3-28' 'CIE-CH3-29' 'CIE-CH3-30' 'CIE-CH3-31' 'CIE-CH3-32'\n",
      " 'CIE-CH3-33' 'CIE-CH3-34' 'CIE-CH3-35' 'CIE-CH3-36' 'CIE-CH3-37'\n",
      " 'CIE-CH3-38' 'CIE-CH3-39' 'CIE-CH3-40' 'CIE-CH3-41' 'CIE-CH3-42'\n",
      " 'CIE-CH3-43' 'CIE-CH3-44' 'CIE-CH3-45' 'CIE-CH3-46' 'CIE-CH3-47'\n",
      " 'CIE-CH3-48' 'CIE-CH3-49' 'Cluster: 0 cspace: CIE; sortCH1; X'\n",
      " 'Cluster: 0 cspace: CIE; sortCH1; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortCH1; SIZE'\n",
      " 'Cluster: 0 cspace: CIE; sortCH2; X' 'Cluster: 0 cspace: CIE; sortCH2; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortCH2; SIZE'\n",
      " 'Cluster: 0 cspace: CIE; sortCH3; X' 'Cluster: 0 cspace: CIE; sortCH3; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortCH3; SIZE'\n",
      " 'Cluster: 0 cspace: CIE; sortX; X' 'Cluster: 0 cspace: CIE; sortX; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortY; X' 'Cluster: 0 cspace: CIE; sortY; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortY; SIZE'\n",
      " 'Cluster: 0 cspace: CIE; sortSize; X'\n",
      " 'Cluster: 0 cspace: CIE; sortSize; Y'\n",
      " 'Cluster: 0 cspace: CIE; sortSize; SIZE'\n",
      " 'Cluster: 1 cspace: CIE; sortCH1; X' 'Cluster: 1 cspace: CIE; sortCH1; Y'\n",
      " 'Cluster: 1 cspace: CIE; sortCH1; SIZE'\n",
      " 'Cluster: 1 cspace: CIE; sortCH2; X' 'Cluster: 1 cspace: CIE; sortCH2; Y'\n",
      " 'Cluster: 1 cspace: CIE; sortCH2; SIZE'\n",
      " 'Cluster: 1 cspace: CIE; sortCH3; X' 'Cluster: 1 cspace: CIE; sortCH3; Y'\n",
      " 'Cluster: 1 cspace: CIE; sortCH3; SIZE'\n",
      " 'Cluster: 1 cspace: CIE; sortX; X' 'Cluster: 1 cspace: CIE; sortX; Y'\n",
      " 'Cluster: 1 cspace: CIE; sortX; SIZE' 'Cluster: 1 cspace: CIE; sortY; X'\n",
      " 'Cluster: 1 cspace: CIE; sortY; Y' 'Cluster: 1 cspace: CIE; sortY; SIZE'\n",
      " 'Cluster: 1 cspace: CIE; sortSize; X'\n",
      " 'Cluster: 1 cspace: CIE; sortSize; Y'\n",
      " 'Cluster: 1 cspace: CIE; sortSize; SIZE'\n",
      " 'Cluster: 2 cspace: CIE; sortCH1; X' 'Cluster: 2 cspace: CIE; sortCH1; Y'\n",
      " 'Cluster: 2 cspace: CIE; sortCH1; SIZE'\n",
      " 'Cluster: 2 cspace: CIE; sortCH2; X' 'Cluster: 2 cspace: CIE; sortCH2; Y'\n",
      " 'Cluster: 2 cspace: CIE; sortCH2; SIZE'\n",
      " 'Cluster: 2 cspace: CIE; sortCH3; X' 'Cluster: 2 cspace: CIE; sortCH3; Y'\n",
      " 'Cluster: 2 cspace: CIE; sortCH3; SIZE'\n",
      " 'Cluster: 2 cspace: CIE; sortX; X' 'Cluster: 2 cspace: CIE; sortX; Y'\n",
      " 'Cluster: 2 cspace: CIE; sortX; SIZE' 'Cluster: 2 cspace: CIE; sortY; X'\n",
      " 'Cluster: 2 cspace: CIE; sortY; Y' 'Cluster: 2 cspace: CIE; sortY; SIZE'\n",
      " 'Cluster: 2 cspace: CIE; sortSize; X'\n",
      " 'Cluster: 2 cspace: CIE; sortSize; Y'\n",
      " 'Cluster: 2 cspace: CIE; sortSize; SIZE'\n",
      " 'Cluster: 3 cspace: CIE; sortCH1; X' 'Cluster: 3 cspace: CIE; sortCH1; Y'\n",
      " 'Cluster: 3 cspace: CIE; sortCH1; SIZE'\n",
      " 'Cluster: 3 cspace: CIE; sortCH2; X' 'Cluster: 3 cspace: CIE; sortCH2; Y'\n",
      " 'Cluster: 3 cspace: CIE; sortCH3; X' 'Cluster: 3 cspace: CIE; sortX; X'\n",
      " 'Cluster: 3 cspace: CIE; sortX; Y' 'Cluster: 3 cspace: CIE; sortX; SIZE'\n",
      " 'Cluster: 3 cspace: CIE; sortY; X' 'Cluster: 3 cspace: CIE; sortY; Y'\n",
      " 'Cluster: 3 cspace: CIE; sortY; SIZE'\n",
      " 'Cluster: 3 cspace: CIE; sortSize; X'\n",
      " 'Cluster: 3 cspace: CIE; sortSize; Y'\n",
      " 'Cluster: 3 cspace: CIE; sortSize; SIZE'\n",
      " 'Cluster: 4 cspace: CIE; sortCH1; X' 'Cluster: 4 cspace: CIE; sortCH1; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortCH1; SIZE'\n",
      " 'Cluster: 4 cspace: CIE; sortCH2; X' 'Cluster: 4 cspace: CIE; sortCH2; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortCH3; X' 'Cluster: 4 cspace: CIE; sortCH3; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortX; X' 'Cluster: 4 cspace: CIE; sortX; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortY; X' 'Cluster: 4 cspace: CIE; sortY; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortSize; X'\n",
      " 'Cluster: 4 cspace: CIE; sortSize; Y'\n",
      " 'Cluster: 4 cspace: CIE; sortSize; SIZE' 'YDBDR-CH1-0' 'YDBDR-CH1-1'\n",
      " 'YDBDR-CH1-2' 'YDBDR-CH1-3' 'YDBDR-CH1-4' 'YDBDR-CH1-5' 'YDBDR-CH1-6'\n",
      " 'YDBDR-CH1-7' 'YDBDR-CH1-8' 'YDBDR-CH1-9' 'YDBDR-CH1-10' 'YDBDR-CH1-11'\n",
      " 'YDBDR-CH1-12' 'YDBDR-CH1-13' 'YDBDR-CH1-14' 'YDBDR-CH1-15'\n",
      " 'YDBDR-CH1-16' 'YDBDR-CH1-17' 'YDBDR-CH1-18' 'YDBDR-CH1-19'\n",
      " 'YDBDR-CH1-20' 'YDBDR-CH1-21' 'YDBDR-CH1-22' 'YDBDR-CH1-23'\n",
      " 'YDBDR-CH1-24' 'YDBDR-CH1-25' 'YDBDR-CH1-26' 'YDBDR-CH1-27'\n",
      " 'YDBDR-CH1-28' 'YDBDR-CH1-29' 'YDBDR-CH1-30' 'YDBDR-CH1-31'\n",
      " 'YDBDR-CH1-32' 'YDBDR-CH1-33' 'YDBDR-CH1-34' 'YDBDR-CH1-35'\n",
      " 'YDBDR-CH1-36' 'YDBDR-CH1-37' 'YDBDR-CH1-38' 'YDBDR-CH1-39'\n",
      " 'YDBDR-CH1-40' 'YDBDR-CH1-41' 'YDBDR-CH1-42' 'YDBDR-CH1-43'\n",
      " 'YDBDR-CH1-44' 'YDBDR-CH1-45' 'YDBDR-CH1-46' 'YDBDR-CH1-47'\n",
      " 'YDBDR-CH1-48' 'YDBDR-CH1-49' 'YDBDR-CH2-0' 'YDBDR-CH2-1' 'YDBDR-CH2-2'\n",
      " 'YDBDR-CH2-3' 'YDBDR-CH2-4' 'YDBDR-CH2-5' 'YDBDR-CH2-6' 'YDBDR-CH2-7'\n",
      " 'YDBDR-CH2-8' 'YDBDR-CH2-9' 'YDBDR-CH2-10' 'YDBDR-CH2-11' 'YDBDR-CH2-12'\n",
      " 'YDBDR-CH2-13' 'YDBDR-CH2-14' 'YDBDR-CH2-15' 'YDBDR-CH2-16'\n",
      " 'YDBDR-CH2-17' 'YDBDR-CH2-18' 'YDBDR-CH2-19' 'YDBDR-CH2-20'\n",
      " 'YDBDR-CH2-21' 'YDBDR-CH2-22' 'YDBDR-CH2-23' 'YDBDR-CH2-24'\n",
      " 'YDBDR-CH2-25' 'YDBDR-CH2-26' 'YDBDR-CH2-27' 'YDBDR-CH2-28'\n",
      " 'YDBDR-CH2-29' 'YDBDR-CH2-30' 'YDBDR-CH2-31' 'YDBDR-CH2-32'\n",
      " 'YDBDR-CH2-33' 'YDBDR-CH2-34' 'YDBDR-CH2-35' 'YDBDR-CH2-36'\n",
      " 'YDBDR-CH2-37' 'YDBDR-CH2-38' 'YDBDR-CH2-39' 'YDBDR-CH2-40'\n",
      " 'YDBDR-CH2-41' 'YDBDR-CH2-42' 'YDBDR-CH2-43' 'YDBDR-CH2-44'\n",
      " 'YDBDR-CH2-45' 'YDBDR-CH2-46' 'YDBDR-CH2-47' 'YDBDR-CH2-48'\n",
      " 'YDBDR-CH2-49' 'YDBDR-CH3-0' 'YDBDR-CH3-1' 'YDBDR-CH3-2' 'YDBDR-CH3-3'\n",
      " 'YDBDR-CH3-4' 'YDBDR-CH3-5' 'YDBDR-CH3-6' 'YDBDR-CH3-7' 'YDBDR-CH3-8'\n",
      " 'YDBDR-CH3-9' 'YDBDR-CH3-10' 'YDBDR-CH3-11' 'YDBDR-CH3-12' 'YDBDR-CH3-13'\n",
      " 'YDBDR-CH3-14' 'YDBDR-CH3-15' 'YDBDR-CH3-16' 'YDBDR-CH3-17'\n",
      " 'YDBDR-CH3-18' 'YDBDR-CH3-19' 'YDBDR-CH3-20' 'YDBDR-CH3-21'\n",
      " 'YDBDR-CH3-22' 'YDBDR-CH3-23' 'YDBDR-CH3-24' 'YDBDR-CH3-25'\n",
      " 'YDBDR-CH3-26' 'YDBDR-CH3-27' 'YDBDR-CH3-28' 'YDBDR-CH3-29'\n",
      " 'YDBDR-CH3-30' 'YDBDR-CH3-31' 'YDBDR-CH3-32' 'YDBDR-CH3-33'\n",
      " 'YDBDR-CH3-34' 'YDBDR-CH3-35' 'YDBDR-CH3-36' 'YDBDR-CH3-37'\n",
      " 'YDBDR-CH3-38' 'YDBDR-CH3-39' 'YDBDR-CH3-40' 'YDBDR-CH3-41'\n",
      " 'YDBDR-CH3-42' 'YDBDR-CH3-43' 'YDBDR-CH3-44' 'YDBDR-CH3-45'\n",
      " 'YDBDR-CH3-46' 'YDBDR-CH3-47' 'YDBDR-CH3-48' 'YDBDR-CH3-49'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH1; X'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH1; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH1; SIZE'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH2; X'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH2; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH2; SIZE'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH3; X'\n",
      " 'Cluster: 0 cspace: YDBDR; sortCH3; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortX; X' 'Cluster: 0 cspace: YDBDR; sortX; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortX; SIZE'\n",
      " 'Cluster: 0 cspace: YDBDR; sortY; X' 'Cluster: 0 cspace: YDBDR; sortY; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortY; SIZE'\n",
      " 'Cluster: 0 cspace: YDBDR; sortSize; X'\n",
      " 'Cluster: 0 cspace: YDBDR; sortSize; Y'\n",
      " 'Cluster: 0 cspace: YDBDR; sortSize; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH1; X'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH1; Y'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH1; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH2; X'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH2; Y'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH2; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH3; X'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH3; Y'\n",
      " 'Cluster: 1 cspace: YDBDR; sortCH3; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortX; X' 'Cluster: 1 cspace: YDBDR; sortX; Y'\n",
      " 'Cluster: 1 cspace: YDBDR; sortX; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortY; X' 'Cluster: 1 cspace: YDBDR; sortY; Y'\n",
      " 'Cluster: 1 cspace: YDBDR; sortY; SIZE'\n",
      " 'Cluster: 1 cspace: YDBDR; sortSize; X'\n",
      " 'Cluster: 1 cspace: YDBDR; sortSize; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH1; X'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH1; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH1; SIZE'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH2; X'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH2; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH2; SIZE'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH3; X'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH3; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortCH3; SIZE'\n",
      " 'Cluster: 2 cspace: YDBDR; sortX; X' 'Cluster: 2 cspace: YDBDR; sortX; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortX; SIZE'\n",
      " 'Cluster: 2 cspace: YDBDR; sortY; X' 'Cluster: 2 cspace: YDBDR; sortY; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortY; SIZE'\n",
      " 'Cluster: 2 cspace: YDBDR; sortSize; X'\n",
      " 'Cluster: 2 cspace: YDBDR; sortSize; Y'\n",
      " 'Cluster: 2 cspace: YDBDR; sortSize; SIZE'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH1; X'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH1; Y'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH1; SIZE'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH2; X'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH2; Y'\n",
      " 'Cluster: 3 cspace: YDBDR; sortCH3; X'\n",
      " 'Cluster: 3 cspace: YDBDR; sortX; X' 'Cluster: 3 cspace: YDBDR; sortX; Y'\n",
      " 'Cluster: 3 cspace: YDBDR; sortX; SIZE'\n",
      " 'Cluster: 3 cspace: YDBDR; sortY; X' 'Cluster: 3 cspace: YDBDR; sortY; Y'\n",
      " 'Cluster: 3 cspace: YDBDR; sortY; SIZE'\n",
      " 'Cluster: 3 cspace: YDBDR; sortSize; X'\n",
      " 'Cluster: 3 cspace: YDBDR; sortSize; Y'\n",
      " 'Cluster: 3 cspace: YDBDR; sortSize; SIZE'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH1; X'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH1; Y'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH2; X'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH2; Y'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH3; X'\n",
      " 'Cluster: 4 cspace: YDBDR; sortCH3; Y'\n",
      " 'Cluster: 4 cspace: YDBDR; sortX; X' 'Cluster: 4 cspace: YDBDR; sortX; Y'\n",
      " 'Cluster: 4 cspace: YDBDR; sortY; X' 'Cluster: 4 cspace: YDBDR; sortY; Y'\n",
      " 'Cluster: 4 cspace: YDBDR; sortSize; X'\n",
      " 'Cluster: 4 cspace: YDBDR; sortSize; Y'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'Cluster: 4 cspace: YDBDR; sortSize; SIZE']\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(np.array(X_train.columns[selector.variances_>0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('variancethreshold', VarianceThreshold(threshold=0.01)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=0.7, random_state=None,\n",
       "  svd_solver='full', tol=0.0, whiten=True))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes[0].fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_names = [#'V0001_PCA_80','V0001_PCA_70','V0001_PCA_5components',\n",
    "              #'V001_PCA_80',\n",
    "              'V001_PCA_70',\n",
    "              'V001_PCA_5components',\n",
    "              #'V01_PCA_90',\n",
    "              'V01_PCA_85',\n",
    "              'V01_PCA_80',\n",
    "              'V01_PCA_5components',\n",
    "              #'V09_PCA_95',\n",
    "              'V09_PCA_90',\n",
    "              'V09_PCA_80',\n",
    "              'V09_PCA_5components'\n",
    "            ]\n",
    "pipes = [\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 0.70, whiten = True, svd_solver = 'full')),\n",
    "    #make_pipeline(VarianceThreshold(0.001), StandardScaler(),\n",
    "    #              PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "    #              PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "                  PCA(n_components = 0.70, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.01), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "    #              PCA(n_components = 0.90, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 0.85, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.1), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "    \n",
    "    #make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "    #              PCA(n_components = 0.95, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 0.90, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 0.80, whiten = True, svd_solver = 'full')),\n",
    "    make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "                  PCA(n_components = 5, whiten = True, svd_solver = 'full')),\n",
    "       ]\n",
    "\n",
    "\n",
    "#pipe_names = ['V09_PCA_5components']\n",
    "#pipes = [make_pipeline(VarianceThreshold(0.9), StandardScaler(),\n",
    "#                  PCA(n_components = 5, whiten = True, svd_solver = 'full'))]\n",
    "model_names_xgb = ['SVC', 'XGBClassifier_tree', 'XGBClassifier_dart']\n",
    "\n",
    "\n",
    "models_xgb = [SVC(probability=True),\n",
    "               XGBClassifier()]#,XGBClassifier(booster='dart')]\n",
    "\n",
    "xgb_tree_dict = {'n_estimators': [50, 100, 200, 250], 'learning_rate': np.arange(0,1,0.01),'gamma': np.arange(0,10,0.1),\n",
    "                'max_depth': np.arange(5,25,5), 'min_child_weight': [1, 2, 5, 8, 10],\n",
    "                'max_delta_step': [0, 1, 5], 'subsample': np.arange(0.1,1,0.1),\n",
    "                 'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0]}\n",
    "#xgb_dart_dict = {'sample_type': ['uniform','weighted'], 'normalize_type': ['tree','forest'],\n",
    "#                'rate_drop': np.arange(0,0.9,0.1), 'skip_drop': np.arange(0,0.5,0.1), 'one_drop': [0,1]}\n",
    "#xgb_dart_dict = xgb_dart_dict.update(xgb_tree_dict)\n",
    "#xgb_linear_dict = {'lambda': np.arange(0,2,0.1), 'alpha': np.arange(0,2,0.1)}\n",
    "##{'C': expon(scale=0.2), 'degree': [2,3,4,5,6,7,8], 'kernel': ['rbf', 'poly', 'linear', 'sigmoid'],\n",
    "##    'coef0': [0.0, 0.5, 0.75, 1.0], 'shrinking': [True, False], 'tol': np.arange(1e-5,0.7,0.00001)},\n",
    "models_params_xgb = [\n",
    "    {'C': expon(scale=0.2), 'degree': [2,3,4,5,6,7,8], 'kernel': ['rbf', 'poly', 'linear', 'sigmoid'],\n",
    "    'coef0': [0.0, 0.5, 0.75, 1.0], 'shrinking': [True, False], 'tol': np.arange(1e-2,0.7,0.01)},\n",
    "    xgb_tree_dict#, xgb_dart_dict\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bench = classmod.ModelsBenchmark(model_names_xgb, models_xgb, models_params_xgb)\n",
    "xgb_bench.fitTransformators(names=pipe_names,\n",
    "                             transformators=pipes,\n",
    "                             X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier(booster='dart').get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 89\n",
      "Finding best parameters for SVC_V001_PCA_70:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V001_PCA_70...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V001_PCA_70:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V001_PCA_70...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for SVC_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V001_PCA_5components...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V001_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V001_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 90\n",
      "Finding best parameters for SVC_V01_PCA_85:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V01_PCA_85...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for XGBClassifier_tree_V01_PCA_85:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V01_PCA_85...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 66\n",
      "Finding best parameters for SVC_V01_PCA_80:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V01_PCA_80...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V01_PCA_80:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V01_PCA_80...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for SVC_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V01_PCA_5components...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V01_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V01_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 79\n",
      "Finding best parameters for SVC_V09_PCA_90:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V09_PCA_90...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V09_PCA_90:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V09_PCA_90...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 38\n",
      "Finding best parameters for SVC_V09_PCA_80:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V09_PCA_80...\n",
      "\n",
      "Finding best parameters for XGBClassifier_tree_V09_PCA_80:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V09_PCA_80...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PCA, x: 8322; y: 16680\n",
      "After PCA, x: 8322; y: 5\n",
      "Finding best parameters for SVC_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVC_V09_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters for XGBClassifier_tree_V09_PCA_5components:\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBClassifier_tree_V09_PCA_5components...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamT\\Anaconda3\\envs\\foodmlenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_labels = np.unique(y_train)\n",
    "score_dict = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='weighted'),\n",
    "             'Log_Loss': make_scorer(log_loss,normalize=True,greater_is_better=False, needs_proba=True)} \n",
    "xgb_bench.runBenchmarkOnLoaded(X_train, y_train,  prio_score='Log_Loss', folds=3, iters=5, randomized=True,\n",
    "                                    verbosity=3, print_shapes=True,\n",
    "                               scoring=score_dict)\n",
    "rootDir = '''D:/PROGRAMMING_PROJS/FoodMachineLearning/FoodMLrepo/FoodML/foodml_src/'''\n",
    "xgb_bench.saveToPickles(rootDir,'randomized_results_svc_xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC_V001_PCA_70': (0.9858207161739966,\n",
       "  0.9858756077124561,\n",
       "  0.18143819205810097,\n",
       "  array([[458,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   3,   0,   0,   0,   3,   1,   0,   0,   1,   0],\n",
       "         [  0, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 198,   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 208,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 195,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 220,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 204,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0, 198,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   4,   0, 192,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   2,   0,   1,   0,   0,   0,   0,   0, 187,\n",
       "            0,   0,   0,   0,   0,   3,   0,   3,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          264,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0, 196,   0,   0,   0,   0,   0,   3,   3,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0,   0,   0,   1,   4,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 212,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 184,   0,   4,   1,   0,   0,   2,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   4,   0, 190,   2,   0,   0,   2,   0,\n",
       "            0,   0,   2,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   2,   0,   4, 193,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 279,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0, 402,   0,\n",
       "            0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   3,   0,   0,   0,   0,\n",
       "            0, 191,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   3,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0, 185,   0,   0,   0,   0,   2,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 186,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0, 207,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 205,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   4,   3,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 191,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "            0,   1,   1,   0,   0,   0,   0, 197,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 195,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 208,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   2,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 263,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 200]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.99      0.98      0.99       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      0.99      0.99       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       0.97      0.98      0.97       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       0.98      0.99      0.99       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       0.98      0.98      0.98       196\\n      DATES       0.99      1.00      1.00       223\\n   DOUGHNUT       0.99      0.95      0.97       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       0.99      0.94      0.97       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       0.99      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       0.94      0.95      0.95       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       0.89      0.94      0.91       203\\n   MOONCAKE       0.93      0.96      0.95       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       0.99      0.99      0.99       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       0.99      1.00      1.00       193\\n      PEACH       0.98      0.97      0.98       196\\n       PEAR       0.94      0.95      0.94       195\\n     PEPPER       1.00      0.98      0.99       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       0.97      0.95      0.96       200\\n    SACHIMA       0.97      0.98      0.97       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       0.99      0.99      0.99       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       0.99      0.99      0.99      8322\\n'),\n",
       " 'SVC_V001_PCA_5components': (0.4834174477289113,\n",
       "  0.478459771352596,\n",
       "  1.5651195035150418,\n",
       "  array([[196,  10,   1,   2,   6,   9,   4,   0,   4,   1,   2,   0,   1,\n",
       "            0,   0,   4,   1,   1,  10,   5,  12,   2,   0,  52,  24,   3,\n",
       "            0,   1,  29,   3,  13,   1,  49,   9,   0,   2,   9,   0],\n",
       "         [  0, 134,   0,   7,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,  21,  15,   0,   0,   0,   0,   4,   0,  11,   7,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "         [  1,   0, 152,   0,   0,   0,   0,   0,   8,   0,   6,  13,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,  10,   2,   0,   0,   0,   0,   0,   0,   7],\n",
       "         [  0,   5,   0, 146,   0,   0,   0,   0,   0,  12,   0,  15,   1,\n",
       "            0,   0,   0,   3,   6,   0,   0,   0,   0,   6,   2,   2,   8,\n",
       "            0,   0,   0,   2,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "         [ 32,   0,   0,   0,  44,   0,   0,   0,   2,   0,   1,   0,   3,\n",
       "            0,   0,   4,   0,   0,   0,   5,  22,   0,   0,   0,  35,   0,\n",
       "            0,   2,  33,   0,   1,   0,  19,   6,   0,   0,   0,   4],\n",
       "         [  0,   0,   0,   0,   0, 151,   6,   0,   0,   2,   0,   0,   0,\n",
       "            8,   0,   0,   0,   0,   0,   7,   0,   0,   0,   2,  11,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   7,   6,  97,   0,   0,   2,   1,   0,   0,\n",
       "            8,   0,   1,   0,   0,   0,  13,  13,   0,   0,   0,  30,   0,\n",
       "            4,   0,   0,   1,   0,   0,  11,   0,  19,   0,   0,   5],\n",
       "         [  5,   0,   0,   0,   1,   0,   0, 105,   0,   0,   0,  13,   0,\n",
       "            0,   8,   0,   0,   0,   3,   0,  24,   0,   0,   0,  10,   0,\n",
       "            0,   9,  15,   0,   1,   0,   5,   2,   0,   0,   4,   0],\n",
       "         [  0,   6,   0,   0,   2,   0,   2,   2,  87,   1,  39,  16,   0,\n",
       "            1,   0,   0,   9,   3,   0,   0,   0,   1,   0,   1,   1,   1,\n",
       "            0,   0,   0,   8,   0,   0,   2,   0,   0,   4,   1,  12],\n",
       "         [  0,   0,   0,   3,   0,   0,  13,   0,   0, 149,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            9,   0,   0,   0,   0,   0,   0,   0,  15,   2,   0,   1],\n",
       "         [  0,   0,   0,   5,   0,   0,   0,   0,   7,  10, 143,   0,   0,\n",
       "            3,   0,   1,   0,   0,   0,   0,   0,   0,   4,   0,   1,   0,\n",
       "            0,   0,   0,   1,   0,   0,  10,   0,   0,   0,   0,  11],\n",
       "         [  2,   3,   0,  11,   0,   1,   0,   1,  11,   7,  12, 127,   1,\n",
       "            0,   0,   0,   4,   3,   0,   0,   1,   0,   4,   1,   1,   6,\n",
       "            3,   0,   0,   0,   0,  21,   0,   0,   0,   2,   1,   0],\n",
       "         [ 27,   0,   0,   0,   7,   0,   0,   0,   0,   0,   0,   0,  33,\n",
       "            0,   0,   0,   0,   0,   3,  10,  30,   0,   0,   2,  63,   0,\n",
       "            0,   5,   3,   0,   2,   0,   4,   5,   0,   0,   3,   0],\n",
       "         [  0,   2,   0,   0,   3,   8,   2,   0,   4,   1,   0,   0,   6,\n",
       "          163,   0,   0,   0,   0,   4,   0,  34,   2,   0,   0,  12,   0,\n",
       "            0,   0,   5,   0,   0,   0,   1,   0,   9,   0,   7,   2],\n",
       "         [ 14,   0,   0,   0,   5,   0,   0,  24,   1,   0,   0,   2,   1,\n",
       "            1,  66,   0,   0,   0,   8,   6,  25,   8,   5,   0,   4,   0,\n",
       "            0,   3,   4,  13,   4,   0,   9,   2,   0,   0,   4,   0],\n",
       "         [ 40,   1,   2,   0,   4,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,  30,   0,   0,   0,   0,   0,   4,   0,  10,  16,   1,\n",
       "           43,   1,   6,   0,   7,   0,   8,   0,   7,   0,   8,   2],\n",
       "         [  0,  40,   0,   1,   0,   0,   0,   1,   1,   2,   0,   1,   0,\n",
       "            0,   4,   0,  84,  17,   1,   0,   0,   0,   2,   0,  16,   4,\n",
       "            4,   0,   0,   0,   0,   4,   0,   0,   2,  12,   0,   0],\n",
       "         [ 13,  40,   0,  11,   0,   0,   0,   1,   0,  10,   0,   0,   0,\n",
       "            0,   0,   0,  11, 111,   0,   0,   0,   0,   3,   0,   6,   1,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0],\n",
       "         [  3,   2,   0,   5,   7,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   3,  59,   0,  48,   4,   1,   0,  24,   4,\n",
       "            0,  10,  11,   0,   1,   0,   1,   2,   0,   0,   7,   0],\n",
       "         [  0,   0,   0,   0,   0,   1,   3,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 183,   0,   0,   0,   0,   5,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   2,   0,   0,  15,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   3,   0,   0,  16,   4,  84,   5,   0,   0,  23,   2,\n",
       "            0,   4,  19,   0,   2,   0,  12,   6,   0,   0,   6,   0],\n",
       "         [  2,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   9,\n",
       "            0,   0,   0,   0,   0,  11,  18,  23,  81,   0,   0,  27,   0,\n",
       "            0,   5,   7,   0,   5,   0,   0,   1,   0,   0,   4,   0],\n",
       "         [  0,   0,   4,   7,   0,   1,   2,   6,   2,   3,  17,  13,   0,\n",
       "            0,   4,   0,   6,   5,   0,   1,   0,   0,  99,   0,  13,   5,\n",
       "            1,   0,   0,   1,   0,   0,   0,   0,   1,   0,   0,   5],\n",
       "         [ 21,   4,   0,   0,   0,  24,   2,   0,   0,   1,   0,   2,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   1, 206,   4,   0,\n",
       "            4,   0,   0,   0,   0,   0,   0,   0,   6,   1,   0,   0],\n",
       "         [ 19,  16,   0,   0,  10,  16,   4,   1,   0,   3,   0,   0,   0,\n",
       "            0,   0,   1,   1,   3,   1,   4,  46,   1,   1,   1, 178,   2,\n",
       "           51,   0,   7,   0,   1,   0,  14,   6,  17,   1,   1,   0],\n",
       "         [  0,  18,   0,  11,   0,   1,   0,   7,   2,   4,   0,   9,   0,\n",
       "            0,   2,   0,   5,  28,   0,   0,   5,   0,  14,   0,  10,  59,\n",
       "            3,   0,   2,   0,   0,   0,   0,   0,   0,  12,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   0,  18,   0,\n",
       "          162,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0],\n",
       "         [ 19,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "            2,   0,   0,   0,   0,  16,   1,  33,  12,   0,   0,  25,   1,\n",
       "            0,  28,  18,   0,   9,   0,   0,   5,   0,   0,  13,   0],\n",
       "         [ 11,   1,   0,   8,  13,   0,   1,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   2,   1,   0,   0,  35,   0,   4,   0,  28,   1,\n",
       "            0,   0,  59,   0,   0,   0,  14,  14,   0,   0,   2,   0],\n",
       "         [ 20,   1,   6,   5,   2,   0,   0,   4,  15,   0,  19,  15,   1,\n",
       "            0,   4,   2,   0,   0,   0,   0,   0,   0,   1,   0,   0,   3,\n",
       "            1,   0,   0,  60,   0,   5,   8,   0,   0,   1,   2,  14],\n",
       "         [ 46,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "            0,   0,   1,   0,   0,   1,   0,   1,   8,   0,   0,   6,   0,\n",
       "            0,  17,   2,   0, 110,   0,   0,   0,   0,   0,   9,   0],\n",
       "         [  0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,  33,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   1,   0, 168,   0,   0,   0,   0,   0,   0],\n",
       "         [  8,   0,   0,   0,  14,   0,   0,   1,   2,   0,  12,   0,   0,\n",
       "            3,   0,   1,   0,   0,   3,   3,   8,   1,   0,   0,  23,   0,\n",
       "            0,   2,  17,   2,   0,   0,  90,   1,   0,   0,   2,   7],\n",
       "         [ 22,   0,   0,   0,   5,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "            0,   0,   0,   0,   0,   8,   1,  51,   2,   0,   0,  26,   0,\n",
       "            0,   8,  35,   0,   5,   0,   1,  23,   0,   0,  12,   0],\n",
       "         [  0,   0,   0,   0,   0,  13,   6,   0,   1,   8,   0,   0,   0,\n",
       "           14,   0,   0,   0,   0,   0,   7,   0,   1,   0,   1,   7,   1,\n",
       "           10,   0,   0,   0,   0,   0,   0,   0, 125,   1,   0,   0],\n",
       "         [  0,  38,   0,   3,   0,   0,   0,   0,   0,   9,   0,   4,   0,\n",
       "            0,   0,   0,  42,  34,   0,   0,   0,   0,   3,   0,  14,   9,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,  49,   0,   0],\n",
       "         [ 66,   1,   0,   0,   3,   9,   8,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,  11,   8,   1,   2,   0,   5,  22,   0,\n",
       "           10,   4,  18,   1,   2,   0,   1,   3,   9,   0,  77,   3],\n",
       "         [  0,   0,   2,   7,   4,   0,   0,   0,  35,   1,   8,   4,   0,\n",
       "            0,   1,   4,   0,   0,   0,   0,   0,   1,   0,   0,   2,   0,\n",
       "            0,   0,   0,  12,   1,   0,   2,   0,   1,   0,  10, 105]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.34      0.42      0.38       466\\n    APRICOT       0.40      0.66      0.50       202\\n  AUBERGINE       0.91      0.76      0.83       200\\n    AVOCADO       0.62      0.70      0.66       209\\n     BANANA       0.27      0.21      0.23       213\\n       BEAN       0.59      0.77      0.67       195\\n      BREAD       0.65      0.44      0.52       220\\n        BUN       0.69      0.51      0.59       205\\n     CARROT       0.48      0.44      0.46       199\\n     CHEESE       0.66      0.77      0.71       194\\n   CUCUMBER       0.55      0.73      0.63       196\\n      DATES       0.47      0.57      0.52       223\\n   DOUGHNUT       0.49      0.17      0.25       197\\n        EGG       0.79      0.62      0.69       265\\n      FIRED       0.74      0.32      0.44       209\\n      GRAPE       0.49      0.15      0.23       201\\n GRAPEFRUIT       0.44      0.43      0.44       196\\n       KIWI       0.48      0.52      0.50       212\\n      LEMON       0.38      0.31      0.34       193\\n     LITCHI       0.66      0.95      0.78       192\\n      MANGO       0.17      0.41      0.24       203\\n   MOONCAKE       0.60      0.40      0.48       201\\n      OLIVE       0.65      0.51      0.57       196\\n      ONION       0.73      0.74      0.73       279\\n     ORANGE       0.25      0.44      0.32       406\\n     PAPAYA       0.50      0.31      0.38       192\\n      PASTA       0.52      0.84      0.64       193\\n      PEACH       0.28      0.14      0.19       196\\n       PEAR       0.20      0.30      0.24       195\\n     PEPPER       0.52      0.32      0.39       189\\n       PLUM       0.66      0.53      0.59       208\\nPOMEGRANATE       0.84      0.82      0.83       206\\n       QIWI       0.34      0.45      0.39       200\\n    SACHIMA       0.27      0.11      0.16       202\\n      SAUCE       0.57      0.64      0.60       195\\n      SWEET       0.52      0.24      0.32       208\\n     TOMATO       0.42      0.29      0.34       266\\n WATERMELON       0.59      0.53      0.56       200\\n\\navg / total       0.51      0.48      0.48      8322\\n'),\n",
       " 'SVC_V01_PCA_85': (0.4337899543378995,\n",
       "  0.4193502730988126,\n",
       "  1.4455457481538057,\n",
       "  array([[433,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            8,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,  20,   0,\n",
       "            0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [ 57, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,\n",
       "            4,   6,   0,   4,   0,   0,   0,   0,   0,   0,   0,  10,  11,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "         [  7,   0, 114,   0,   0,   1,   0,   0,   5,   0,   2,  36,   0,\n",
       "           32,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 26,   0,   0, 149,   0,   0,   0,   0,   1,   0,   0,   6,   0,\n",
       "           10,  10,   0,   0,   4,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [175,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  34,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 70,   0,   3,   0,   0, 112,   0,   0,   0,   0,   0,   0,   0,\n",
       "            8,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [118,   0,   0,   0,   0,   0,  22,   0,   0,   2,   0,   0,   0,\n",
       "           35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  42,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 61,   0,   0,   0,   0,   0,   0,  90,   0,   0,   0,  16,   0,\n",
       "            6,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 36,   3,   1,   0,   0,   0,   0,   0,  67,   0,  23,  23,   0,\n",
       "           11,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8,  11,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,  12],\n",
       "         [ 18,   0,   0,   0,   0,   0,   0,   0,   0, 147,   0,   0,   0,\n",
       "           23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 40,   0,   0,   0,   0,   0,   0,   0,  18,   0, 105,   0,   0,\n",
       "           16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  13],\n",
       "         [  9,   0,   9,   0,   0,   0,   0,   0,   0,   0,   0, 203,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "         [139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  53,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 43,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          182,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  34,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0],\n",
       "         [ 74,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   2,   0,\n",
       "            3, 105,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [165,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "           14,   0,   0,   0,   0,   0,   5,   0,   0,   0,   3,   8,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0],\n",
       "         [ 53,   4,   0,   0,   0,   0,   0,   3,   0,   0,   0,  14,   0,\n",
       "           21,   3,   0,  68,   6,   0,   0,   0,   0,   0,   0,  12,   5,\n",
       "            0,   0,   0,   0,   0,   4,   0,   0,   0,   3,   0,   0],\n",
       "         [ 12,   0,   0,  15,   0,   0,   0,   3,   0,   0,   0,   3,   0,\n",
       "            6,  16,   0,   0, 155,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "         [ 99,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           27,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  65,   0,\n",
       "            0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 190,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [111,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            7,   0,   0,   0,   2,   0,   1,   0,   0,   0,   0,  81,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            4,   0,   0,   0,   0,   0,   0,   0,  18,   0,   0,  33,   0,\n",
       "            0,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 14,   0,  16,   0,   0,   1,   0,   0,   4,   0,   2,   7,   0,\n",
       "           36,   9,   0,   0,   5,   0,   0,   0,   0,  99,   0,   1,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "         [ 50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   0,   0, 216,   1,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "         [112,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "           18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 271,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "         [ 21,   0,   1,   3,   0,   1,   0,   1,   2,   0,   1,  16,   0,\n",
       "            7,   8,   0,   1,   0,   0,   0,   0,   0,   2,   0,   7, 117,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   3,   0,   0],\n",
       "         [158,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            4,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   4,   0,\n",
       "           25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [152,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   6,   6,\n",
       "            0,  21,   0,   0,   0,   0,   0,   0,   1,   2,   1,   0],\n",
       "         [139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           14,   0,   0,   0,   2,   0,   2,   0,   0,   0,   0,  36,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "         [ 62,   0,   0,   0,   0,   0,   0,   1,  17,   0,  24,  19,   0,\n",
       "            7,  12,   0,   0,   2,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  39,   0,   0,   0,   0,   0,   0,   0,   5],\n",
       "         [193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   2,   0,   0,  10,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "            5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 198,   0,   0,   0,   0,   0,   0],\n",
       "         [130,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           22,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  47,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [137,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "            4,   0,   0,   0,   1,   0,   9,   0,   1,   0,   0,  37,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,  10,   0,   0,   0,   0],\n",
       "         [ 28,   0,   0,   1,   0,   6,   0,   0,   0,   0,   0,   0,   0,\n",
       "            9,   0,   0,   0,   1,   0,   0,   0,   0,   0,   2,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 146,   0,   0,   2],\n",
       "         [ 20,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,  11,   0,\n",
       "           34,   8,   0,   0,   1,   0,   0,   0,   0,   0,   0,  18,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 111,   0,   0],\n",
       "         [232,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  11,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   7,   0],\n",
       "         [ 55,   0,   0,   0,   0,   0,   0,   0,  31,   0,  17,   4,   0,\n",
       "            7,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  76]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.13      0.93      0.22       466\\n    APRICOT       0.94      0.51      0.66       202\\n  AUBERGINE       0.79      0.57      0.66       200\\n    AVOCADO       0.89      0.71      0.79       209\\n     BANANA       0.00      0.00      0.00       213\\n       BEAN       0.89      0.57      0.70       195\\n      BREAD       1.00      0.10      0.18       220\\n        BUN       0.82      0.44      0.57       205\\n     CARROT       0.46      0.34      0.39       199\\n     CHEESE       0.98      0.76      0.85       194\\n   CUCUMBER       0.60      0.54      0.57       196\\n      DATES       0.55      0.91      0.69       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.30      0.69      0.41       265\\n      FIRED       0.51      0.50      0.51       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.93      0.35      0.51       196\\n       KIWI       0.86      0.73      0.79       212\\n      LEMON       0.00      0.00      0.00       193\\n     LITCHI       0.88      0.99      0.93       192\\n      MANGO       0.00      0.00      0.00       203\\n   MOONCAKE       0.95      0.09      0.16       201\\n      OLIVE       0.98      0.51      0.67       196\\n      ONION       0.95      0.77      0.85       279\\n     ORANGE       0.31      0.67      0.42       406\\n     PAPAYA       0.74      0.61      0.67       192\\n      PASTA       0.96      0.13      0.23       193\\n      PEACH       0.64      0.11      0.18       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       1.00      0.21      0.34       189\\n       PLUM       1.00      0.05      0.09       208\\nPOMEGRANATE       0.96      0.96      0.96       206\\n       QIWI       0.00      0.00      0.00       200\\n    SACHIMA       0.91      0.05      0.09       202\\n      SAUCE       0.94      0.75      0.83       195\\n      SWEET       0.88      0.53      0.66       208\\n     TOMATO       0.88      0.03      0.05       266\\n WATERMELON       0.70      0.38      0.49       200\\n\\navg / total       0.62      0.43      0.42      8322\\n'),\n",
       " 'XGBClassifier_tree_V001_PCA_70': (0.8791155972122086,\n",
       "  0.8789979754481593,\n",
       "  0.6387673838291281,\n",
       "  array([[406,   0,   0,   0,   7,   1,   1,   0,   0,   2,   0,   0,   1,\n",
       "            0,   2,   2,   0,   3,   3,   0,   3,   0,   0,   1,   2,   2,\n",
       "            2,   3,   3,   1,   2,   2,   7,   1,   0,   1,   7,   1],\n",
       "         [  1, 179,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   8,   1,   0,   0,   0,   0,   0,   0,   1,   2,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   1,   0],\n",
       "         [  0,   0, 187,   0,   0,   0,   0,   0,   1,   0,   3,   2,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   2,   1,   0,   1,\n",
       "            0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   1, 199,   0,   0,   1,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   1,   1,   0,   0,   0,   0,   2,   1,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,   0,   0,   0, 172,   1,   4,   1,   0,   0,   1,   0,   4,\n",
       "            1,   0,   0,   0,   0,   0,   0,   5,   1,   0,   0,   8,   0,\n",
       "            0,   0,   1,   0,   0,   0,   5,   3,   0,   0,   0,   0],\n",
       "         [  1,   0,   1,   0,   0, 186,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0],\n",
       "         [  3,   0,   0,   0,   3,   1, 192,   1,   0,   1,   0,   0,   1,\n",
       "            3,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
       "            0,   0,   1,   1,   0,   0,   4,   0,   1,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   1,   0,   0, 186,   0,   0,   0,   3,   0,\n",
       "            2,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   3,   1,   0,   0,   0,   0,   6,   0,   0,   0,   0],\n",
       "         [  1,   6,   2,   0,   1,   2,   0,   0, 155,   0,   5,   3,   0,\n",
       "            1,   0,   1,   2,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "            0,   0,   0,   1,   0,   1,   2,   0,   0,   2,   0,  11],\n",
       "         [  0,   0,   0,   0,   1,   1,   0,   0,   0, 190,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  0,   0,   1,   2,   0,   0,   0,   0,   7,   0, 171,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   5,   0,   0,   0,   1,   6],\n",
       "         [  0,   2,   0,   0,   0,   0,   0,   0,   3,   0,   1, 202,   0,\n",
       "            0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   2,   1,   2,\n",
       "            1,   0,   0,   2,   0,   0,   0,   0,   0,   3,   0,   0],\n",
       "         [  5,   0,   0,   0,   2,   0,   2,   0,   0,   0,   0,   0, 159,\n",
       "            1,   5,   0,   0,   0,   1,   0,   6,   6,   0,   0,   4,   0,\n",
       "            0,   1,   2,   0,   0,   0,   2,   1,   0,   0,   0,   0],\n",
       "         [  3,   1,   1,   1,   1,   0,   3,   2,   1,   0,   0,   0,   1,\n",
       "          238,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   1,   0,   2,   4,   1,   0,   1,   2],\n",
       "         [  3,   0,   0,   0,   2,   0,   1,   2,   0,   0,   0,   0,   4,\n",
       "            0, 180,   0,   0,   0,   0,   0,   2,   4,   0,   0,   2,   0,\n",
       "            0,   2,   2,   0,   2,   0,   0,   1,   0,   0,   1,   1],\n",
       "         [  7,   1,   2,   0,   4,   0,   2,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0, 159,   0,   0,   0,   0,   0,   1,   0,   0,   5,   1,\n",
       "            5,   0,   0,   0,   5,   0,   2,   0,   4,   0,   2,   0],\n",
       "         [  2,   4,   0,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,\n",
       "            0,   1,   3, 166,   2,   1,   0,   0,   1,   1,   1,   2,   2,\n",
       "            0,   0,   0,   1,   0,   0,   0,   0,   1,   3,   2,   0],\n",
       "         [  0,   1,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  10, 192,   1,   0,   0,   0,   0,   1,   0,   4,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   2,   0,   2,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   3, 153,   0,   4,   7,   2,   0,   3,   1,\n",
       "            0,   4,   4,   0,   1,   0,   2,   2,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0, 191,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2,   2,   0,   0,   2,   0,   1,   1,   0,   0,   0,   0,   2,\n",
       "            2,   0,   0,   0,   0,   2,   0, 170,   5,   0,   0,   3,   0,\n",
       "            0,   3,   1,   0,   0,   0,   5,   1,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   2,\n",
       "            1,   2,   0,   0,   0,   4,   1,   4, 173,   0,   0,   0,   0,\n",
       "            0,   4,   0,   0,   0,   0,   3,   3,   0,   0,   1,   0],\n",
       "         [  0,   0,   2,   6,   0,   1,   0,   0,   1,   0,   0,   2,   0,\n",
       "            1,   0,   0,   1,   3,   0,   0,   0,   0, 179,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,   0,   1,   0,   0,   3,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   1,   0,   0,   0,   0,   2, 262,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0],\n",
       "         [  6,   0,   0,   0,   6,   1,   0,   0,   0,   1,   0,   0,   2,\n",
       "            0,   0,   0,   2,   1,   4,   0,   5,   0,   0,   0, 360,   0,\n",
       "            2,   1,   4,   1,   0,   0,   3,   0,   2,   0,   5,   0],\n",
       "         [  0,   3,   0,   5,   0,   1,   0,   0,   1,   0,   0,   1,   0,\n",
       "            0,   2,   1,   4,   1,   0,   0,   0,   0,   3,   0,   4, 164,\n",
       "            0,   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          183,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,   0],\n",
       "         [  4,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   1,   6,   3,   3,   8,   0,   0,   1,   6,\n",
       "            0, 154,   0,   0,   4,   0,   1,   2,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   3,   5,   0,   0,   2,   0,   0,   0,   0,   5,\n",
       "            0,   0,   0,   1,   0,   4,   0,   4,   1,   2,   1,   3,   0,\n",
       "            0,   1, 150,   0,   1,   0,   0,   9,   0,   1,   0,   0],\n",
       "         [  4,   0,   1,   3,   1,   0,   0,   0,   3,   0,   3,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   0,\n",
       "            0,   0,   0, 157,   0,   5,   0,   0,   0,   0,   2,   6],\n",
       "         [  3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   1,   0,   0,   1,   0,   1,   1,   0,   1,   0,   0,\n",
       "            0,   7,   0,   1, 186,   0,   1,   0,   0,   0,   4,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0, 191,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   4,   1,   0,\n",
       "            1,   1,   0,   0,   0,   4,   0,   4,   3,   0,   0,   1,   0,\n",
       "            0,   1,   5,   1,   1,   0, 166,   0,   2,   0,   0,   3],\n",
       "         [  7,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "            2,   2,   1,   0,   0,   1,   0,   1,   2,   0,   0,   0,   0,\n",
       "            0,   5,   5,   0,   0,   0,   1, 171,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   4,   0,   0,   0,   2,   0,   0,   0,\n",
       "            1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   2,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 183,   0,   0,   0],\n",
       "         [  0,   2,   0,   0,   0,   0,   0,   0,   1,   0,   0,   2,   0,\n",
       "            1,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0, 196,   0,   0],\n",
       "         [  3,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   4,   0,   0,   1,   0,   3,   1,   0,   1,   8,   1,\n",
       "            0,   0,   0,   1,   2,   0,   0,   0,   4,   0, 234,   0],\n",
       "         [  2,   0,   1,   3,   1,   0,   1,   0,   5,   0,   1,   1,   0,\n",
       "            0,   0,   2,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,\n",
       "            0,   0,   0,   4,   0,   0,   3,   0,   0,   0,   0, 174]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.84      0.87      0.85       466\\n    APRICOT       0.88      0.89      0.88       202\\n  AUBERGINE       0.94      0.94      0.94       200\\n    AVOCADO       0.88      0.95      0.92       209\\n     BANANA       0.81      0.81      0.81       213\\n       BEAN       0.91      0.95      0.93       195\\n      BREAD       0.91      0.87      0.89       220\\n        BUN       0.94      0.91      0.92       205\\n     CARROT       0.87      0.78      0.82       199\\n     CHEESE       0.96      0.98      0.97       194\\n   CUCUMBER       0.90      0.87      0.89       196\\n      DATES       0.87      0.91      0.89       223\\n   DOUGHNUT       0.86      0.81      0.83       197\\n        EGG       0.92      0.90      0.91       265\\n      FIRED       0.91      0.86      0.89       209\\n      GRAPE       0.89      0.79      0.84       201\\n GRAPEFRUIT       0.81      0.85      0.83       196\\n       KIWI       0.92      0.91      0.91       212\\n      LEMON       0.82      0.79      0.81       193\\n     LITCHI       0.98      0.99      0.99       192\\n      MANGO       0.79      0.84      0.81       203\\n   MOONCAKE       0.80      0.86      0.83       201\\n      OLIVE       0.91      0.91      0.91       196\\n      ONION       0.95      0.94      0.95       279\\n     ORANGE       0.85      0.89      0.87       406\\n     PAPAYA       0.87      0.85      0.86       192\\n      PASTA       0.94      0.95      0.95       193\\n      PEACH       0.81      0.79      0.80       196\\n       PEAR       0.83      0.77      0.80       195\\n     PEPPER       0.91      0.83      0.87       189\\n       PLUM       0.90      0.89      0.90       208\\nPOMEGRANATE       0.95      0.93      0.94       206\\n       QIWI       0.77      0.83      0.80       200\\n    SACHIMA       0.84      0.85      0.84       202\\n      SAUCE       0.91      0.94      0.92       195\\n      SWEET       0.90      0.94      0.92       208\\n     TOMATO       0.86      0.88      0.87       266\\n WATERMELON       0.85      0.87      0.86       200\\n\\navg / total       0.88      0.88      0.88      8322\\n'),\n",
       " 'XGBClassifier_tree_V001_PCA_5components': (0.6967075222302331,\n",
       "  0.6933937028516342,\n",
       "  1.1821470390571063,\n",
       "  array([[267,   5,   1,   1,  12,  10,   2,   2,   0,   1,   3,   0,   2,\n",
       "            2,   0,   4,   1,   3,   3,   6,   2,   4,   1,  33,  12,   2,\n",
       "            2,   1,  15,   2,   4,   6,  28,   8,   0,   2,  14,   5],\n",
       "         [  0, 169,   0,   5,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   9,   5,   0,   0,   0,   0,   3,   0,   1,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0],\n",
       "         [  1,   0, 179,   1,   0,   0,   0,   0,   2,   0,   3,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,\n",
       "            0,   0,   0,   6,   3,   0,   0,   0,   0,   0,   0,   2],\n",
       "         [  0,   4,   0, 162,   0,   0,   1,   2,   0,   2,   0,   8,   4,\n",
       "            0,   1,   0,   0,   4,   0,   0,   0,   0,   2,   2,   3,  11,\n",
       "            0,   0,   0,   2,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "         [  9,   0,   1,   0, 109,   0,   5,   2,   3,   0,   0,   0,   9,\n",
       "            2,   0,   4,   0,   0,   0,   8,   5,   5,   0,   0,  12,   0,\n",
       "            0,   2,  11,   0,   2,   0,  10,   8,   0,   0,   2,   4],\n",
       "         [  0,   0,   0,   0,   0, 157,   7,   0,   0,   1,   0,   0,   0,\n",
       "            6,   0,   0,   0,   0,   0,   6,   0,   0,   0,   4,   5,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   6,   0,   2,   0],\n",
       "         [  6,   0,   0,   0,   2,   6, 141,   1,   1,   6,   0,   0,   2,\n",
       "            7,   1,   0,   0,   0,   0,   5,   1,   2,   1,   0,  14,   0,\n",
       "            3,   0,   0,   0,   0,   0,   6,   0,   6,   2,   0,   7],\n",
       "         [  3,   0,   0,   0,   2,   0,   1, 124,   0,   0,   0,   2,   7,\n",
       "            1,  10,   1,   1,   0,   1,   0,   5,   7,   0,   0,   2,   0,\n",
       "            0,  10,  11,   1,   1,   3,   5,   4,   0,   0,   3,   0],\n",
       "         [  2,   4,   0,   0,   0,   0,   3,   2, 119,   1,  16,   7,   0,\n",
       "            2,   0,   2,   6,   2,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "            0,   0,   0,   3,   0,   1,   1,   0,   0,   6,   1,  18],\n",
       "         [  0,   0,   0,   5,   0,   0,   4,   0,   0, 165,   0,   0,   1,\n",
       "            1,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "            5,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   2],\n",
       "         [  0,   0,   0,   5,   0,   0,   0,   0,   3,   2, 163,   0,   0,\n",
       "            2,   2,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   3,   0,   0,   2,   0,   0,   0,   0,  12],\n",
       "         [  2,   2,   0,   6,   0,   1,   0,   4,   1,   6,   0, 173,   0,\n",
       "            0,   0,   0,   3,   2,   1,   0,   0,   0,   2,   1,   2,   5,\n",
       "            2,   0,   1,   0,   0,   8,   0,   0,   0,   1,   0,   0],\n",
       "         [ 13,   0,   2,   0,   8,   0,   2,   0,   0,   0,   1,   0, 108,\n",
       "            1,   1,   0,   0,   0,   3,   7,   6,   5,   0,   3,  20,   0,\n",
       "            0,   0,   2,   0,   0,   0,   8,   6,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   0,   2,   0,   3,   0,   1,   0,   0,   0,   6,\n",
       "          205,   2,   0,   0,   0,   2,   0,   6,   1,   0,   0,   7,   0,\n",
       "            0,   1,   1,   0,   1,   0,   1,   9,   6,   2,   3,   4],\n",
       "         [  6,   0,   0,   0,   5,   0,   0,   8,   1,   0,   0,   1,   5,\n",
       "            3, 104,   0,   0,   0,   9,   1,   5,  12,   0,   0,   5,   1,\n",
       "            0,   7,   3,  10,   3,   0,  10,   7,   0,   0,   2,   1],\n",
       "         [ 10,   1,   4,   0,   0,   4,   1,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0, 116,   0,   0,   0,   1,   0,   4,   0,   6,  13,   1,\n",
       "           16,   0,   0,   0,   5,   0,   5,   2,   6,   0,   2,   3],\n",
       "         [  1,  24,   0,   2,   0,   0,   1,   1,   2,   3,   0,   3,   0,\n",
       "            0,   0,   0, 104,  22,   1,   0,   0,   0,   0,   0,   9,   2,\n",
       "            4,   0,   0,   0,   0,   3,   0,   0,   1,  12,   1,   0],\n",
       "         [  0,   9,   0,   2,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   3, 188,   0,   0,   0,   0,   1,   0,   2,   2,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "         [  0,   3,   0,   3,   3,   0,   0,   0,   0,   0,   0,   1,   2,\n",
       "            0,   0,   0,   2,   2, 117,   0,   9,   4,   1,   0,   9,   2,\n",
       "            1,  17,   8,   1,   0,   0,   2,   0,   0,   0,   6,   0],\n",
       "         [  0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0, 187,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "         [  9,   2,   0,   0,   9,   0,   0,   1,   0,   0,   0,   0,   4,\n",
       "            2,   2,   2,   0,   0,  14,   4, 102,   5,   0,   0,   7,   1,\n",
       "            0,   5,  16,   0,   0,   0,   6,   9,   0,   0,   3,   0],\n",
       "         [  4,   0,   0,   0,   2,   0,   1,   0,   0,   0,   0,   0,   5,\n",
       "            0,   0,   0,   0,   0,  11,   4,   7, 146,   0,   0,   7,   0,\n",
       "            0,   6,   2,   0,   0,   0,   4,   1,   0,   0,   1,   0],\n",
       "         [  0,   4,   4,   8,   0,   0,   2,  13,   2,   3,   3,   3,   0,\n",
       "            0,   3,   0,   1,   3,   0,   0,   0,   0, 134,   1,   3,   2,\n",
       "            0,   0,   1,   1,   0,   0,   0,   0,   1,   3,   0,   1],\n",
       "         [  9,   0,   3,   0,   0,  10,   3,   0,   0,   1,   0,   0,   0,\n",
       "            2,   0,   2,   0,   0,   0,   1,   0,   0,   1, 230,   2,   0,\n",
       "            5,   0,   0,   0,   0,   1,   0,   0,   5,   4,   0,   0],\n",
       "         [ 11,   6,   0,   1,   6,  17,  10,   2,   0,   2,   0,   2,   4,\n",
       "            2,   0,   4,   5,   1,  11,   5,   6,   1,   1,   0, 229,   3,\n",
       "           36,   3,   6,   2,   1,   0,  10,   5,   9,   3,   2,   0],\n",
       "         [  0,  12,   0,   1,   0,   0,   0,   5,   0,   4,   0,   4,   0,\n",
       "            0,   2,   0,   2,   7,   0,   0,   0,   0,   1,   0,   8, 139,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   1,   6,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   1,   0,   0,   0,   3,   0,   0,   0,\n",
       "            0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,\n",
       "          178,   0,   0,   0,   0,   0,   0,   0,   1,   2,   1,   0],\n",
       "         [  7,   2,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "            2,   0,   1,   5,   1,   4,   0,   2,   7,   0,   1,   5,   2,\n",
       "            0, 119,   5,   0,   8,   0,   2,   8,   0,   1,   9,   0],\n",
       "         [  6,   0,   0,   5,   5,   0,   2,   1,   0,   1,   0,   0,   0,\n",
       "            0,   1,   1,   1,   1,   3,   0,  11,   1,   2,   0,   9,   3,\n",
       "            0,   3, 110,   2,   0,   0,  12,  13,   0,   0,   1,   1],\n",
       "         [  4,   0,  11,   1,   1,   0,   0,   1,  10,   0,  11,   8,   1,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   5,   4,\n",
       "            0,   0,   1,  95,   1,   5,   3,   1,   0,   0,   3,  21],\n",
       "         [ 11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "            0,   0,   0,   0,   0,   1,   1,   0,   4,   0,   0,   1,   0,\n",
       "            0,   4,   0,   0, 179,   1,   0,   0,   0,   0,   4,   0],\n",
       "         [  1,   0,   2,   2,   0,   0,   0,   0,   0,   0,   0,  15,   0,\n",
       "            0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0, 184,   0,   0,   0,   0,   0,   0],\n",
       "         [  5,   0,   0,   0,   6,   0,   3,   1,   3,   0,   9,   0,   0,\n",
       "            4,   0,   2,   0,   0,   7,   2,   4,   2,   0,   0,   4,   0,\n",
       "            0,   4,   3,   1,   0,   0, 127,   3,   0,   0,   4,   6],\n",
       "         [  3,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "            8,   0,   3,   0,   0,   8,   0,   8,   3,   0,   0,   7,   0,\n",
       "            0,   9,  11,   0,   3,   0,   2, 123,   0,   0,   4,   0],\n",
       "         [  0,   0,   0,   0,   1,   4,   7,   0,   0,   5,   0,   0,   1,\n",
       "            6,   0,   1,   0,   0,   0,   2,   0,   0,   1,   0,   4,   0,\n",
       "            6,   0,   0,   0,   0,   0,   0,   0, 156,   0,   1,   0],\n",
       "         [  0,   2,   0,   3,   0,   0,   0,   4,   0,   7,   0,   3,   0,\n",
       "            0,   0,   0,  14,   3,   0,   0,   0,   0,   3,   0,   4,   2,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   0, 161,   0,   0],\n",
       "         [  6,   0,   0,   0,   2,  12,   5,   1,   1,   1,   0,   0,   1,\n",
       "            0,   0,   8,   1,   0,   6,   3,   4,   1,   0,   6,   6,   0,\n",
       "            5,   2,   6,   2,   1,   0,   2,   1,   5,   0, 173,   5],\n",
       "         [  1,   0,   0,   3,   0,   0,   0,   0,  11,   1,   7,   3,   0,\n",
       "            0,   1,   5,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,\n",
       "            0,   0,   0,   5,   0,   0,   0,   0,   1,   0,   3, 156]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.67      0.57      0.62       466\\n    APRICOT       0.68      0.84      0.75       202\\n  AUBERGINE       0.86      0.90      0.88       200\\n    AVOCADO       0.75      0.78      0.76       209\\n     BANANA       0.59      0.51      0.55       213\\n       BEAN       0.70      0.81      0.75       195\\n      BREAD       0.69      0.64      0.67       220\\n        BUN       0.70      0.60      0.65       205\\n     CARROT       0.74      0.60      0.66       199\\n     CHEESE       0.76      0.85      0.80       194\\n   CUCUMBER       0.75      0.83      0.79       196\\n      DATES       0.74      0.78      0.76       223\\n   DOUGHNUT       0.64      0.55      0.59       197\\n        EGG       0.79      0.77      0.78       265\\n      FIRED       0.80      0.50      0.61       209\\n      GRAPE       0.71      0.58      0.64       201\\n GRAPEFRUIT       0.66      0.53      0.59       196\\n       KIWI       0.77      0.89      0.82       212\\n      LEMON       0.58      0.61      0.59       193\\n     LITCHI       0.77      0.97      0.86       192\\n      MANGO       0.56      0.50      0.53       203\\n   MOONCAKE       0.68      0.73      0.70       201\\n      OLIVE       0.85      0.68      0.76       196\\n      ONION       0.80      0.82      0.81       279\\n     ORANGE       0.54      0.56      0.55       406\\n     PAPAYA       0.75      0.72      0.74       192\\n      PASTA       0.67      0.92      0.77       193\\n      PEACH       0.62      0.61      0.61       196\\n       PEAR       0.52      0.56      0.54       195\\n     PEPPER       0.70      0.50      0.58       189\\n       PLUM       0.84      0.86      0.85       208\\nPOMEGRANATE       0.87      0.89      0.88       206\\n       QIWI       0.52      0.64      0.57       200\\n    SACHIMA       0.59      0.61      0.60       202\\n      SAUCE       0.75      0.80      0.77       195\\n      SWEET       0.75      0.77      0.76       208\\n     TOMATO       0.70      0.65      0.68       266\\n WATERMELON       0.63      0.78      0.70       200\\n\\navg / total       0.70      0.70      0.69      8322\\n'),\n",
       " 'XGBClassifier_tree_V01_PCA_85': (0.9997596731554914,\n",
       "  0.9997596984722297,\n",
       "  0.03860649823844127,\n",
       "  array([[466,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 202,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 213,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 195,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 220,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 205,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0, 199,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 197,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          265,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 195,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 212,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 193,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 203,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 201,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 278,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 406,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 195,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 189,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 208,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 200,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 202,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 195,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 208,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 266,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 200]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      0.99      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'SVC_V01_PCA_80': (0.8123047344388368,\n",
       "  0.8116927050402059,\n",
       "  0.5515768927659934,\n",
       "  array([[392,   0,   0,   1,   4,   1,   0,   0,   0,   0,   0,   0,   3,\n",
       "            2,   0,   1,   2,   0,   3,   0,   7,   0,   0,   0,  19,   0,\n",
       "            0,   1,   3,   0,  10,   2,   5,   3,   0,   0,   7,   0],\n",
       "         [  4, 189,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   4,   0,   0,   0,   3,   0,   0,   0,   0,   2,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 190,   0,   0,   2,   0,   0,   0,   0,   0,   7,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0, 206,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 27,   0,   0,   0, 117,   1,   1,   2,   1,   0,   1,   0,   1,\n",
       "            1,   1,   1,   0,   0,   1,   1,  11,   3,   0,   0,  10,   0,\n",
       "            0,   4,   5,   1,   1,   0,  11,   6,   0,   0,   4,   1],\n",
       "         [  0,   0,   1,   0,   0, 191,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 15,   0,   0,   0,   5,   0, 174,   0,   0,   0,   0,   0,   6,\n",
       "            1,   0,   2,   0,   0,   0,   0,   2,   0,   0,   0,   7,   0,\n",
       "            0,   0,   1,   0,   0,   0,   5,   0,   0,   0,   2,   0],\n",
       "         [  8,   0,   0,   0,   1,   0,   0, 165,   0,   0,   0,   0,   3,\n",
       "            4,   2,   0,   0,   0,   0,   0,   8,   0,   0,   0,   1,   0,\n",
       "            0,   1,   0,   0,   1,   0,   0,  11,   0,   0,   0,   0],\n",
       "         [  1,   1,   0,   0,   0,   0,   0,   0, 142,   0,  15,   7,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  14,\n",
       "            0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,  10],\n",
       "         [  1,   0,   0,   0,   0,   0,   1,   0,   0, 191,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,  21,   0, 156,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "            0,   0,   0,   0,   0,   0,   5,   0,   0,   0,   1,   8],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 24,   0,   0,   0,   3,   0,   1,   1,   0,   0,   0,   0,  97,\n",
       "            1,   0,   1,   0,   0,  10,   0,  17,   4,   0,   1,   7,   0,\n",
       "            0,   6,   1,   0,  10,   0,   4,   6,   0,   0,   3,   0],\n",
       "         [  7,   0,   0,   0,   1,   1,   0,   0,   2,   0,   0,   0,   3,\n",
       "          225,   0,   0,   0,   0,   0,   0,   6,   0,   0,   1,   8,   0,\n",
       "            0,   0,   0,   0,   2,   0,   0,   5,   3,   0,   0,   1],\n",
       "         [  7,   0,   0,   0,   3,   0,   3,   3,   0,   0,   0,   1,   2,\n",
       "            2, 114,   0,   0,   0,   1,   0,  17,   8,   0,   0,  22,   0,\n",
       "            0,   1,   0,   0,  16,   0,   2,   4,   0,   0,   3,   0],\n",
       "         [ 14,   0,   0,   0,   0,   2,   1,   0,   0,   0,   0,   1,   0,\n",
       "            2,   0, 150,   0,   1,   0,   0,   0,   1,   0,   0,   3,   0,\n",
       "            3,   2,   0,   1,  11,   0,   0,   0,   3,   0,   6,   0],\n",
       "         [  2,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0, 170,  11,   0,   0,   1,   0,   0,   0,   3,   0,\n",
       "            0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   1,   0],\n",
       "         [  4,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "            0,   4,   0,   1, 200,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "         [  7,   0,   0,   0,   2,   0,   0,   2,   0,   0,   0,   0,   1,\n",
       "            1,   0,   0,   0,   0, 128,   0,  16,   4,   0,   0,   4,   0,\n",
       "            0,  12,   5,   0,   0,   0,   1,   3,   0,   0,   7,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 14,   0,   0,   0,   1,   0,   0,   3,   0,   0,   0,   0,   7,\n",
       "            1,   0,   0,   0,   0,   9,   1, 138,   1,   0,   0,   3,   0,\n",
       "            0,   5,   0,   0,   6,   0,   2,   8,   0,   0,   4,   0],\n",
       "         [  8,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "            2,   0,   0,   0,   0,   7,   0,  15, 130,   0,   0,   0,   0,\n",
       "            0,  15,   2,   0,  11,   0,   5,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   2,   0,   0,   1,   0,   0,   0,   0,   0,   5,   0,\n",
       "            0,   3,   0,   0,   0,   0,   0,   0,   0, 182,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   1,   2,   0,   0,   0,   0,   0,   1,\n",
       "            5,   0,   0,   0,   0,   0,   0,   0,   0,   0, 266,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   0],\n",
       "         [ 14,   0,   0,   0,   2,   1,   3,   0,   0,   0,   0,   0,   2,\n",
       "            0,   0,   1,   1,   0,   3,   0,  13,   0,   0,   0, 353,   1,\n",
       "            1,   0,   0,   0,   0,   0,   2,   0,   1,   0,   8,   0],\n",
       "         [  2,   1,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   2,   2,   0,   0,   0,   0,   5,   0,   0, 178,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          189,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  9,   0,   0,   0,   1,   0,   0,   4,   0,   0,   0,   0,   4,\n",
       "            0,   0,   0,   1,   0,   5,   4,   5,  16,   0,   0,   1,   4,\n",
       "            0, 107,   1,   0,  17,   0,   0,   4,   0,   1,  12,   0],\n",
       "         [ 20,   0,   0,   0,   6,   0,   2,   2,   0,   0,   0,   0,   5,\n",
       "            4,   0,   0,   0,   1,   5,   2,   8,   0,   0,   0,  21,   0,\n",
       "            0,   6,  94,   0,   0,   0,   3,  12,   0,   0,   4,   0],\n",
       "         [  7,   0,   0,   1,   0,   0,   0,   1,  19,   0,  13,   4,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 131,   0,   1,   1,   0,   0,   0,   3,   8],\n",
       "         [ 11,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   1,   0,   0,   2,   0,   4,  15,   0,   0,   1,   0,\n",
       "            0,   7,   0,   0, 151,   0,   1,   0,   0,   0,  13,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0],\n",
       "         [ 15,   0,   0,   0,   1,   0,   0,   2,   0,   0,   5,   0,   3,\n",
       "            1,   0,   0,   0,   0,   3,   0,  11,   3,   0,   0,   5,   0,\n",
       "            0,   7,   1,   1,   2,   0, 139,   1,   0,   0,   0,   0],\n",
       "         [ 10,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   8,\n",
       "            4,   0,   4,   0,   0,   3,   7,   9,   4,   0,   0,   1,   0,\n",
       "            0,   9,   4,   0,   3,   0,   0, 131,   0,   0,   2,   0],\n",
       "         [  1,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,\n",
       "            2,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0, 185,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 205,   0,   0],\n",
       "         [  9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "            5,   0,   6,   0,   0,   0,   0,   2,   3,   0,   1,   3,   0,\n",
       "            1,   0,   0,   0,   3,   0,   0,   0,   2,   0, 229,   0],\n",
       "         [  4,   0,   0,   0,   0,   0,   0,   0,  42,   0,  11,   1,   0,\n",
       "            2,   0,   1,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   1, 134]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.61      0.84      0.71       466\\n    APRICOT       0.96      0.94      0.95       202\\n  AUBERGINE       0.98      0.95      0.97       200\\n    AVOCADO       0.99      0.99      0.99       209\\n     BANANA       0.76      0.55      0.64       213\\n       BEAN       0.93      0.98      0.95       195\\n      BREAD       0.93      0.79      0.85       220\\n        BUN       0.89      0.80      0.84       205\\n     CARROT       0.63      0.71      0.67       199\\n     CHEESE       1.00      0.98      0.99       194\\n   CUCUMBER       0.78      0.80      0.79       196\\n      DATES       0.88      1.00      0.94       223\\n   DOUGHNUT       0.64      0.49      0.56       197\\n        EGG       0.84      0.85      0.84       265\\n      FIRED       0.92      0.55      0.68       209\\n      GRAPE       0.86      0.75      0.80       201\\n GRAPEFRUIT       0.93      0.87      0.90       196\\n       KIWI       0.93      0.94      0.93       212\\n      LEMON       0.71      0.66      0.69       193\\n     LITCHI       0.92      1.00      0.96       192\\n      MANGO       0.47      0.68      0.56       203\\n   MOONCAKE       0.68      0.65      0.66       201\\n      OLIVE       0.97      0.93      0.95       196\\n      ONION       0.99      0.95      0.97       279\\n     ORANGE       0.74      0.87      0.80       406\\n     PAPAYA       0.87      0.93      0.90       192\\n      PASTA       0.96      0.98      0.97       193\\n      PEACH       0.58      0.55      0.56       196\\n       PEAR       0.80      0.48      0.60       195\\n     PEPPER       0.96      0.69      0.81       189\\n       PLUM       0.62      0.73      0.67       208\\nPOMEGRANATE       0.97      1.00      0.99       206\\n       QIWI       0.73      0.69      0.71       200\\n    SACHIMA       0.67      0.65      0.66       202\\n      SAUCE       0.95      0.95      0.95       195\\n      SWEET       1.00      0.99      0.99       208\\n     TOMATO       0.74      0.86      0.80       266\\n WATERMELON       0.83      0.67      0.74       200\\n\\navg / total       0.82      0.81      0.81      8322\\n'),\n",
       " 'XGBClassifier_tree_V01_PCA_80': (0.9137226628214371,\n",
       "  0.9135756666700537,\n",
       "  0.649716582977296,\n",
       "  array([[433,   0,   0,   0,   1,   1,   0,   0,   2,   0,   1,   1,   2,\n",
       "            3,   0,   1,   0,   0,   1,   0,   3,   0,   0,   3,   4,   0,\n",
       "            0,   0,   0,   1,   0,   1,   5,   1,   1,   0,   1,   0],\n",
       "         [  3, 194,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 195,   0,   0,   2,   0,   0,   1,   0,   0,   1,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   1, 198,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   3,   0,   0,   0,   0,   2,   0,   1,   1,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,   0,   0,   1, 182,   1,   1,   1,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   1,   0,   5,   2,   0,   0,   1,   0,\n",
       "            0,   1,   1,   0,   1,   0,   3,   2,   0,   0,   1,   2],\n",
       "         [  1,   0,   2,   0,   0, 190,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  5,   0,   0,   0,   1,   0, 198,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   2,   7,   0,\n",
       "            0,   0,   1,   0,   0,   0,   2,   1,   0,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0, 190,   0,   0,   1,   0,   1,\n",
       "            2,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   1,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   5,   0,   0,   0,   0],\n",
       "         [  1,   2,   0,   0,   1,   0,   0,   0, 171,   0,   4,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   2,   3,\n",
       "            0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,  11],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0, 192,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   4,   0, 183,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   3,   0,   0,   1,   0,   0,   0,   0,   3],\n",
       "         [  0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0, 219,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  6,   0,   0,   0,   2,   0,   4,   1,   0,   0,   0,   0, 168,\n",
       "            1,   1,   0,   0,   1,   3,   0,   1,   0,   0,   0,   1,   0,\n",
       "            1,   1,   2,   0,   2,   0,   0,   2,   0,   0,   0,   0],\n",
       "         [  5,   0,   0,   0,   1,   1,   3,   0,   1,   0,   0,   0,   1,\n",
       "          236,   0,   0,   0,   0,   0,   0,   2,   0,   0,   1,   5,   0,\n",
       "            0,   0,   1,   0,   0,   0,   1,   4,   2,   0,   0,   1],\n",
       "         [  5,   0,   0,   0,   0,   0,   1,   3,   0,   0,   0,   0,   3,\n",
       "            1, 172,   2,   0,   0,   1,   0,   4,   1,   0,   1,   3,   0,\n",
       "            0,   2,   1,   0,   6,   0,   2,   1,   0,   0,   0,   0],\n",
       "         [  3,   0,   0,   0,   1,   0,   1,   0,   1,   1,   0,   1,   0,\n",
       "            1,   0, 168,   0,   0,   0,   1,   0,   0,   1,   1,   5,   0,\n",
       "            8,   0,   1,   2,   1,   0,   0,   0,   2,   0,   2,   0],\n",
       "         [  1,   1,   0,   0,   1,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 181,   3,   1,   0,   0,   0,   1,   0,   1,   1,\n",
       "            0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "            0,   0,   0,   1, 202,   1,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   0,   1,   0,   0,   2,   0,   0,   0,   0,   2,\n",
       "            0,   0,   0,   2,   0, 162,   0,   4,   0,   2,   0,   3,   0,\n",
       "            0,   3,   1,   1,   2,   0,   1,   1,   0,   0,   4,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  4,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "            0,   1,   0,   1,   0,   8,   0, 161,   3,   0,   0,   3,   0,\n",
       "            0,   1,   2,   0,   5,   0,   0,   3,   0,   1,   4,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   4,\n",
       "            0,   0,   0,   0,   0,   2,   1,   2, 181,   0,   0,   2,   0,\n",
       "            0,   2,   1,   0,   4,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 195,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   0,   2, 271,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0],\n",
       "         [  4,   0,   0,   1,   0,   0,   2,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   2,   0,   0,   0,   6,   0,   3,   0, 375,   0,\n",
       "            1,   0,   0,   0,   1,   0,   3,   0,   3,   0,   4,   0],\n",
       "         [  3,   0,   0,   2,   0,   0,   0,   0,   0,   0,   3,   0,   0,\n",
       "            0,   0,   0,   2,   0,   0,   0,   0,   0,   1,   0,   3, 178,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          190,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0],\n",
       "         [  4,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   5,\n",
       "            0,   2,   0,   3,   0,   2,   3,   3,   7,   0,   0,   1,   4,\n",
       "            0, 152,   1,   0,   1,   0,   1,   1,   1,   1,   2,   0],\n",
       "         [  3,   0,   0,   0,   1,   0,   3,   1,   0,   0,   0,   0,   2,\n",
       "            0,   0,   0,   2,   1,   1,   0,   6,   0,   0,   0,   4,   0,\n",
       "            0,   1, 162,   0,   0,   0,   2,   5,   0,   0,   1,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   7,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0, 170,   0,   0,   0,   0,   0,   0,   2,   5],\n",
       "         [  3,   1,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   2,   0,   1,   5,   0,   0,   3,   0,\n",
       "            0,   2,   0,   0, 183,   0,   1,   0,   0,   0,   5,   0],\n",
       "         [  3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 201,   0,   0,   1,   0,   0,   0],\n",
       "         [  4,   0,   0,   0,   3,   1,   1,   1,   0,   0,   3,   0,   0,\n",
       "            1,   1,   0,   0,   0,   0,   0,   4,   3,   0,   0,   2,   0,\n",
       "            0,   0,   0,   0,   0,   0, 175,   1,   0,   0,   0,   0],\n",
       "         [  9,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   3,\n",
       "            1,   0,   0,   0,   0,   1,   0,   3,   2,   0,   1,   0,   0,\n",
       "            0,   3,   1,   0,   0,   0,   0, 176,   0,   0,   0,   0],\n",
       "         [  3,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0, 184,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   1,   2,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 201,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   2,\n",
       "            1,   0,   3,   1,   0,   1,   0,   2,   1,   1,   0,   4,   0,\n",
       "            1,   0,   0,   1,   2,   0,   0,   0,   3,   0, 238,   1],\n",
       "         [  2,   0,   0,   0,   0,   1,   0,   0,   2,   0,   1,   0,   0,\n",
       "            2,   0,   1,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   0,   0,   0,   0,   1,   0,   1, 185]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.83      0.93      0.87       466\\n    APRICOT       0.98      0.96      0.97       202\\n  AUBERGINE       0.98      0.97      0.98       200\\n    AVOCADO       0.98      0.95      0.96       209\\n     BANANA       0.90      0.85      0.88       213\\n       BEAN       0.93      0.97      0.95       195\\n      BREAD       0.92      0.90      0.91       220\\n        BUN       0.93      0.93      0.93       205\\n     CARROT       0.90      0.86      0.88       199\\n     CHEESE       0.99      0.99      0.99       194\\n   CUCUMBER       0.93      0.93      0.93       196\\n      DATES       0.96      0.98      0.97       223\\n   DOUGHNUT       0.86      0.85      0.85       197\\n        EGG       0.93      0.89      0.91       265\\n      FIRED       0.97      0.82      0.89       209\\n      GRAPE       0.93      0.84      0.88       201\\n GRAPEFRUIT       0.90      0.92      0.91       196\\n       KIWI       0.95      0.95      0.95       212\\n      LEMON       0.87      0.84      0.85       193\\n     LITCHI       0.97      1.00      0.99       192\\n      MANGO       0.77      0.79      0.78       203\\n   MOONCAKE       0.88      0.90      0.89       201\\n      OLIVE       0.93      0.99      0.96       196\\n      ONION       0.96      0.97      0.97       279\\n     ORANGE       0.86      0.92      0.89       406\\n     PAPAYA       0.95      0.93      0.94       192\\n      PASTA       0.94      0.98      0.96       193\\n      PEACH       0.89      0.78      0.83       196\\n       PEAR       0.92      0.83      0.87       195\\n     PEPPER       0.93      0.90      0.92       189\\n       PLUM       0.88      0.88      0.88       208\\nPOMEGRANATE       0.99      0.98      0.98       206\\n       QIWI       0.88      0.88      0.88       200\\n    SACHIMA       0.86      0.87      0.86       202\\n      SAUCE       0.92      0.94      0.93       195\\n      SWEET       0.99      0.97      0.98       208\\n     TOMATO       0.88      0.89      0.89       266\\n WATERMELON       0.89      0.93      0.91       200\\n\\navg / total       0.91      0.91      0.91      8322\\n'),\n",
       " 'SVC_V01_PCA_5components': (0.39762076423936554,\n",
       "  0.36666102891952995,\n",
       "  1.908143057108833,\n",
       "  array([[236,  18,   3,   0,   0,   8,   8,   0,   2,   2,   1,   1,   0,\n",
       "            4,   1,   0,  12,   0,   0,   2,  27,   0,   0,  41,  56,   0,\n",
       "            7,   0,   0,   0,   0,   5,   2,   0,  14,   0,  16,   0],\n",
       "         [  7, 129,   0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  25,  10,   0,   0,   3,   0,   0,   0,  11,   0,\n",
       "            0,   0,   0,   0,   0,   4,   0,   0,   0,  10,   0,   0],\n",
       "         [  0,   0, 155,   0,   0,   0,   0,   0,  13,   4,   7,   7,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   7],\n",
       "         [ 16,   2,   0, 129,   0,   0,   0,   9,   1,   1,   0,  15,   0,\n",
       "            0,   0,   0,   4,  12,   0,   0,   3,   0,   0,   2,   0,   7,\n",
       "            0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4],\n",
       "         [ 92,   1,   0,   4,   4,   3,   3,   0,   1,   3,   0,   0,   0,\n",
       "           10,   0,   0,   2,   5,   0,   1,  25,   9,   2,   0,  24,   0,\n",
       "            0,   8,   0,   0,   0,   0,   3,   3,   0,   1,   6,   3],\n",
       "         [  6,   0,   3,   0,   0,  42,   0,   0,   0,  14,   0,   0,   1,\n",
       "            1,   0,   3,   0,   0,   0,   3,   0,   1,   0,  98,   0,   0,\n",
       "           17,   0,   0,   0,   3,   0,   0,   0,   2,   0,   1,   0],\n",
       "         [ 40,   0,   1,   0,   0,   3, 109,   0,   0,   0,   0,   0,   0,\n",
       "           11,   0,   0,   1,   0,   0,   3,  19,   0,   0,   9,  18,   0,\n",
       "            1,   0,   0,   0,   1,   0,   1,   0,   0,   0,   3,   0],\n",
       "         [ 38,   0,   0,   2,   0,   0,   0,  75,   0,   0,   0,  21,   0,\n",
       "            0,  13,   0,   1,   8,   0,   0,   9,   5,   1,   0,  19,   1,\n",
       "            0,   5,   0,   0,   0,   0,   0,   5,   0,   0,   2,   0],\n",
       "         [  5,   1,   2,   0,   0,   0,   8,   0,  20,   1,  81,  20,   0,\n",
       "            1,   0,   0,   8,   1,   3,   0,   0,   0,   1,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,  21,   8,   0,   0,   0,   0,  17],\n",
       "         [  6,   0,   2,   1,   0,   0,   0,   0,   0,  81,   0,   1,   0,\n",
       "           19,   0,   0,   0,   0,   0,   0,   1,   0,   0,  35,  19,   0,\n",
       "            4,   0,   0,   0,   0,   0,   6,   0,  18,   0,   0,   1],\n",
       "         [  8,   0,   2,   3,   0,   0,   7,   0,   3,   0, 100,   0,   0,\n",
       "            5,   2,   0,   0,   0,   0,   0,   0,   4,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   3,   4,  11,   0,   0,   0,   0,  43],\n",
       "         [  4,   0,  21,  19,   0,   0,   0,  12,   9,   4,   0, 100,   0,\n",
       "            0,   6,   0,   0,   3,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "            0,   0,   0,   0,   0,  41,   0,   0,   0,   0,   0,   2],\n",
       "         [ 67,   0,   0,   1,   0,   5,   3,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   4,   0,   0,  39,  14,   0,   4,  33,   0,\n",
       "            1,   9,   0,   0,   1,   0,   0,   0,   0,   0,  14,   2],\n",
       "         [ 36,   0,   6,   0,   1,   3,  17,   0,   2,   4,   0,   0,   0,\n",
       "           94,   0,   0,   0,   0,   0,   0,  30,   0,   1,  30,  27,   0,\n",
       "            5,   0,   0,   0,   0,   0,   2,   0,   4,   0,   2,   1],\n",
       "         [ 47,   0,   0,   0,   0,   2,   3,  22,   1,   0,   2,  11,   0,\n",
       "            1,  58,   0,   9,   1,   0,   0,  28,   1,   1,   3,   7,   4,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   6,   0],\n",
       "         [ 72,   0,   1,   5,   0,   1,   3,   0,   0,   1,   0,   1,   0,\n",
       "            0,   0,   3,   0,   0,   0,  13,   0,   6,   1,   5,   7,   3,\n",
       "           62,   4,   0,   0,   0,   2,   1,   1,   8,   0,   1,   0],\n",
       "         [ 12,  33,   1,   1,   0,   0,   0,  11,   2,   1,   0,   0,   0,\n",
       "            0,   5,   0,  51,  10,   5,   0,   0,   0,   1,   0,  10,   2,\n",
       "            1,   5,   0,   0,   2,  39,   0,   3,   1,   0,   0,   0],\n",
       "         [  8,   3,   0,  13,   0,   0,   0,   9,   0,   0,   0,   3,   0,\n",
       "            0,   2,   0,  11, 132,   0,   0,   1,  15,   0,   0,   0,  11,\n",
       "            0,   2,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [ 44,   1,   1,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0,\n",
       "            0,   0,   0,   1,   3,  15,   0,  33,  14,   2,   0,  36,   2,\n",
       "            0,  26,   0,   0,   0,   5,   0,   1,   0,   2,   5,   0],\n",
       "         [  8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            4,   0,   0,   0,   0,   0, 179,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 46,   2,   0,   3,   1,   2,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   3,   0,   1,  96,   4,   2,   0,  31,   0,\n",
       "            1,   4,   0,   0,   0,   0,   0,   1,   0,   0,   5,   0],\n",
       "         [ 40,   0,   0,   1,   0,  15,   0,   0,   0,   1,   0,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,  16,  36,  48,   0,   2,   2,   0,\n",
       "            0,  26,   0,   0,   8,   0,   0,   1,   0,   0,   3,   0],\n",
       "         [  3,   5,  20,   8,   0,   0,   0,  20,   2,   1,   8,   7,   0,\n",
       "            0,  11,   0,   0,   3,   0,   0,   2,   0,  91,   0,   2,   0,\n",
       "            0,   0,   3,   2,   0,   7,   0,   0,   0,   1,   0,   0],\n",
       "         [  5,   6,   3,   0,   0,   3,   0,   0,   0,   1,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   1,   0,   0,   1, 255,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   2,   0,   0,   0],\n",
       "         [ 96,   4,   1,   0,   0,   1,   1,   0,   0,   2,   0,   0,   0,\n",
       "            0,   0,   8,   2,   0,   4,   1,  13,   0,   1,  29, 216,   0,\n",
       "            1,   0,   0,   0,   0,   5,   0,   0,   8,   0,  13,   0],\n",
       "         [ 11,  15,   5,   6,   0,   0,   0,   1,   3,   3,   0,  10,   0,\n",
       "            0,   5,   0,   8,  15,   4,   0,   1,   8,   0,   0,   4,  56,\n",
       "            0,  10,   0,   0,   0,  19,   0,   0,   0,   8,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   5,   0,   1,   0,   6,   0,   0,\n",
       "          170,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "         [ 60,   3,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   1,   5,   1,   6,  23,  28,   6,   1,   2,   0,\n",
       "            0,  47,   0,   0,   0,   0,   0,   2,   0,   0,   6,   0],\n",
       "         [ 77,   7,   0,   6,   0,   0,   2,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,  16,   0,   1,  24,   6,   3,   0,  18,   0,\n",
       "            0,  17,   0,   0,   0,   3,   1,   2,   0,   0,  11,   0],\n",
       "         [ 10,   0,   0,   3,   0,   2,  24,   0,   9,   2,  40,  12,   0,\n",
       "            4,  11,   0,   0,   1,   0,   0,   0,   6,   0,   2,   1,   0,\n",
       "            0,   0,   0,  39,   0,   8,   0,   0,   0,   0,   1,  14],\n",
       "         [ 79,   0,   0,   0,   0,  10,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   1,   0,  13,  22,  15,   1,   5,  10,   0,\n",
       "            1,  24,   0,   0,   7,   0,   0,   0,   0,   0,  19,   0],\n",
       "         [  2,   0,   2,   0,   0,   0,   0,   5,   1,   2,   0,  13,   0,\n",
       "            0,   3,   0,   1,   2,   0,   0,   0,   0,   0,   0,   8,   0,\n",
       "            0,   0,   0,   0,   0, 167,   0,   0,   0,   0,   0,   0],\n",
       "         [ 52,   1,   1,   8,   0,   0,   5,   0,   2,   1,  12,   0,   0,\n",
       "            0,   0,   0,   0,  24,   1,   1,  26,  14,   0,   1,   7,   0,\n",
       "            1,   7,   0,   0,   0,   0,  19,   2,   2,   0,   7,   6],\n",
       "         [ 57,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,  20,   0,  11,  41,  15,   2,   1,  13,   0,\n",
       "            0,  11,   0,   0,   0,   0,   0,  29,   0,   0,   1,   0],\n",
       "         [  3,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            2,   0,   1,   0,   0,   1,   0,   0,   2,   0,  14,   1,   0,\n",
       "           10,   0,   0,   0,   0,   1,   0,   0, 159,   0,   0,   0],\n",
       "         [  5,   4,   0,   9,   0,   0,   0,  10,   0,   0,   0,   6,   0,\n",
       "            0,   0,   0,   5,  43,   0,   0,   0,   0,   0,   0,  13,   9,\n",
       "            0,   2,   0,   0,   0,  31,  10,   0,   0,  61,   0,   0],\n",
       "         [117,   0,   0,   0,   0,  10,  17,   0,   2,   3,   0,   0,   0,\n",
       "            9,   0,   0,   2,   0,   0,   0,   7,   0,   2,  28,   7,   0,\n",
       "            8,   0,   0,   0,   0,   1,   0,   0,   6,   0,  47,   0],\n",
       "         [ 11,   0,   4,   0,   0,   2,   6,   0,  18,   0,  45,   1,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "            0,   4,   0,   0,   0,   4,   6,   0,   3,   0,   1,  90]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.17      0.51      0.25       466\\n    APRICOT       0.55      0.64      0.59       202\\n  AUBERGINE       0.66      0.78      0.71       200\\n    AVOCADO       0.57      0.62      0.59       209\\n     BANANA       0.57      0.02      0.04       213\\n       BEAN       0.34      0.22      0.26       195\\n      BREAD       0.50      0.50      0.50       220\\n        BUN       0.43      0.37      0.40       205\\n     CARROT       0.22      0.10      0.14       199\\n     CHEESE       0.60      0.42      0.49       194\\n   CUCUMBER       0.34      0.51      0.41       196\\n      DATES       0.43      0.45      0.44       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.54      0.35      0.43       265\\n      FIRED       0.50      0.28      0.36       209\\n      GRAPE       0.19      0.01      0.03       201\\n GRAPEFRUIT       0.35      0.26      0.30       196\\n       KIWI       0.41      0.62      0.49       212\\n      LEMON       0.44      0.08      0.13       193\\n     LITCHI       0.70      0.93      0.80       192\\n      MANGO       0.19      0.47      0.27       203\\n   MOONCAKE       0.22      0.24      0.23       201\\n      OLIVE       0.76      0.46      0.58       196\\n      ONION       0.45      0.91      0.60       279\\n     ORANGE       0.36      0.53      0.43       406\\n     PAPAYA       0.58      0.29      0.39       192\\n      PASTA       0.58      0.88      0.70       193\\n      PEACH       0.22      0.24      0.23       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.95      0.21      0.34       189\\n       PLUM       0.28      0.03      0.06       208\\nPOMEGRANATE       0.45      0.81      0.58       206\\n       QIWI       0.27      0.10      0.14       200\\n    SACHIMA       0.58      0.14      0.23       202\\n      SAUCE       0.70      0.82      0.75       195\\n      SWEET       0.73      0.29      0.42       208\\n     TOMATO       0.28      0.18      0.22       266\\n WATERMELON       0.47      0.45      0.46       200\\n\\navg / total       0.42      0.40      0.37      8322\\n'),\n",
       " 'XGBClassifier_tree_V01_PCA_5components': (0.9974765681326604,\n",
       "  0.9974782886175115,\n",
       "  0.17970487978331712,\n",
       "  array([[466,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 202,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0, 212,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 195,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 219,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 204,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0, 198,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 193,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 197,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          264,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 199,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 194,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 211,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 193,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 191,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 203,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 201,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 278,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 405,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 193,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 189,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 207,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 205,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 199,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 202,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 208,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 265,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 200]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.99      1.00      0.99       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      0.99      1.00       199\\n     CHEESE       0.99      0.99      0.99       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       0.99      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      0.99      0.99       201\\n GRAPEFRUIT       1.00      0.99      0.99       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      0.99      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       0.99      1.00      0.99       196\\n      ONION       0.99      1.00      0.99       279\\n     ORANGE       0.99      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       0.99      0.99      0.99       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      0.99      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      0.99      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'SVC_V09_PCA_90': (0.6986301369863014,\n",
       "  0.6952460025389041,\n",
       "  0.8457822856599567,\n",
       "  array([[375,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "           17,   0,   0,   2,   1,   1,   0,   8,   0,   0,  11,  28,   0,\n",
       "            2,   3,   1,   0,   0,   1,   1,   0,   0,   0,  12,   0],\n",
       "         [  9, 181,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   2,   0,   0,   0,   5,   0,   0,   0,   3,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0],\n",
       "         [  2,   0, 178,   0,   0,   3,   0,   0,   1,   0,   0,  12,   0,\n",
       "            4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  2,   0,   0, 190,   0,   0,   0,   0,   1,   0,   0,   4,   0,\n",
       "            1,   6,   0,   0,   1,   0,   0,   0,   0,   3,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 53,   0,   0,   0,  66,   0,   3,   4,   6,   0,   1,   0,   3,\n",
       "            6,   0,   1,   0,   0,   1,   1,  12,   0,   0,   0,  21,   0,\n",
       "            0,   8,   4,   0,   2,   0,  11,   4,   0,   0,   4,   2],\n",
       "         [  7,   0,   4,   0,   0, 167,   1,   0,   0,   0,   0,   0,   0,\n",
       "            2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   1,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 16,   0,   0,   0,   5,   0, 156,   0,   0,   6,   0,   0,   8,\n",
       "            7,   0,   0,   0,   0,   0,   0,   5,   0,   0,   1,  10,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   1,   0,   0,   4,   0],\n",
       "         [ 10,   0,   0,   0,   0,   0,   0, 155,   0,   0,   0,   1,   3,\n",
       "            4,   1,   0,   0,   0,   0,   0,   8,   0,   0,   0,   0,   0,\n",
       "            0,   3,   0,   3,   0,   0,   1,  15,   0,   0,   1,   0],\n",
       "         [  0,   4,   0,   0,   3,   0,   0,   0, 120,   0,  15,   7,   0,\n",
       "            4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   8,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  27],\n",
       "         [  3,   0,   0,   0,   1,   0,   1,   0,   0, 177,   0,   0,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  7,   0,   0,   0,   0,   0,   0,   0,  19,   0, 141,   0,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,\n",
       "            0,   0,   0,   0,   0,   0,   6,   0,   0,   0,   0,  16],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 222,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 65,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,  43,\n",
       "            5,   0,   0,   0,   0,  10,   0,  16,   8,   0,   0,  17,   0,\n",
       "            0,   7,   2,   0,   8,   0,   5,   2,   0,   0,   8,   0],\n",
       "         [  7,   0,   0,   0,   2,   1,   0,   0,   1,   0,   0,   0,   2,\n",
       "          221,   0,   0,   0,   0,   1,   0,   8,   0,   0,   1,  13,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   5,   1,   0,   1,   1],\n",
       "         [ 28,   0,   0,   0,   4,   0,   0,   8,   1,   0,   0,   0,   1,\n",
       "            8, 101,   0,   0,   0,   1,   1,  11,   6,   0,   0,  28,   0,\n",
       "            2,   0,   0,   0,   4,   0,   1,   2,   0,   0,   2,   0],\n",
       "         [ 45,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "           23,   0,  74,   0,   0,   0,   1,   0,   3,   0,   3,   5,   0,\n",
       "           13,   8,   0,   3,   2,   0,   0,   0,   2,   0,  16,   0],\n",
       "         [  8,   4,   0,   0,   1,   0,   0,   0,   0,   0,   0,   6,   0,\n",
       "           10,   1,   0, 140,   9,   0,   0,   0,   0,   0,   0,   7,   5,\n",
       "            0,   0,   0,   0,   0,   4,   0,   0,   1,   0,   0,   0],\n",
       "         [  0,   0,   0,   2,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "            1,   7,   0,   0, 196,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "            0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 21,   0,   0,   0,   5,   0,   0,   2,   0,   0,   0,   0,   2,\n",
       "           20,   0,   0,   0,   0,  90,   0,  10,   3,   0,   0,   7,   0,\n",
       "            0,  17,   3,   0,   0,   0,   1,   4,   0,   0,   8,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 190,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 32,   0,   0,   0,   2,   0,   0,   3,   0,   2,   0,   0,   2,\n",
       "            4,   0,   1,   0,   0,   8,   0,  93,   0,   0,   0,  30,   0,\n",
       "            0,   6,   2,   0,   3,   0,   5,   6,   0,   0,   4,   0],\n",
       "         [ 28,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   9,\n",
       "            5,   0,   0,   0,   0,  11,   0,  14,  91,   0,   0,  11,   0,\n",
       "            0,  18,   0,   0,   4,   0,   4,   2,   0,   0,   3,   0],\n",
       "         [  3,   0,   5,   0,   4,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "           24,   7,   0,   0,   0,   0,   0,   0,   0, 152,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   1,   0,   0, 254,   0,   0,\n",
       "            1,   0,   0,   0,   0,   1,   0,   4,   0,   0,   0,   0],\n",
       "         [ 27,   0,   0,   0,   1,   4,   0,   0,   0,   0,   0,   0,   0,\n",
       "           17,   0,   0,   0,   0,   3,   0,   5,   0,   0,   4, 322,   1,\n",
       "            3,   2,   0,   0,   0,   0,   1,   0,   6,   0,  10,   0],\n",
       "         [  3,   4,   1,   0,   0,   2,   0,   1,   1,   0,   0,   2,   0,\n",
       "            8,   2,   0,   0,   0,   0,   0,   0,   0,   4,   0,   3, 158,\n",
       "            0,   2,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            7,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "          183,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [ 26,   0,   0,   0,   1,   1,   0,   3,   0,   0,   0,   0,   3,\n",
       "            0,   0,   0,   1,   0,   7,   4,   4,  14,   0,   0,   3,   4,\n",
       "            1,  72,   1,   0,  10,   0,   1,  17,   1,   1,  21,   0],\n",
       "         [ 42,   0,   0,   0,   4,   0,   1,   1,   0,   0,   0,   0,   3,\n",
       "           10,   0,   0,   0,   0,  11,   2,  18,   1,   0,   0,  35,   0,\n",
       "            0,  14,  31,   0,   0,   0,   3,  11,   0,   0,   8,   0],\n",
       "         [  4,   0,   0,   1,   0,   0,   0,   0,  30,   0,  11,  11,   0,\n",
       "            7,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  99,   0,   0,   0,   0,   0,   0,  11,  12],\n",
       "         [ 48,   0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,   1,\n",
       "            5,   0,   1,   0,   0,   5,   1,   5,  16,   0,   0,   1,   0,\n",
       "            0,  10,   0,   0,  92,   0,   2,   1,   0,   0,  18,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 202,   0,   0,   0,   0,   0,   0],\n",
       "         [ 20,   0,   0,   0,   5,   0,   1,   2,   0,   0,   5,   0,   2,\n",
       "           13,   0,   0,   0,   0,   6,   0,   7,   2,   0,   0,  20,   0,\n",
       "            0,  12,   6,   0,   1,   0,  81,   2,   0,   0,   2,  13],\n",
       "         [ 21,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "            2,   0,   1,   0,   0,   4,  10,  24,   5,   0,   0,   5,   0,\n",
       "            0,  16,   3,   0,   1,   0,   1,  98,   0,   0,   2,   0],\n",
       "         [  1,   0,   0,   0,   0,   5,   0,   0,   0,   0,   0,   0,   0,\n",
       "            7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   1, 178,   0,   0,   0],\n",
       "         [  2,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   5,   0,\n",
       "            5,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 192,   0,   0],\n",
       "         [ 21,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,\n",
       "            8,   0,   2,   0,   0,   0,   0,   4,   1,   0,   3,   9,   0,\n",
       "            1,   3,   0,   1,   0,   0,   0,   0,   2,   0, 209,   0],\n",
       "         [  9,   0,   0,   0,   0,   0,   0,   0,  44,   0,  15,   1,   0,\n",
       "            4,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 124]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.39      0.80      0.53       466\\n    APRICOT       0.94      0.90      0.92       202\\n  AUBERGINE       0.95      0.89      0.92       200\\n    AVOCADO       0.98      0.91      0.94       209\\n     BANANA       0.59      0.31      0.41       213\\n       BEAN       0.91      0.86      0.88       195\\n      BREAD       0.94      0.71      0.81       220\\n        BUN       0.86      0.76      0.80       205\\n     CARROT       0.53      0.60      0.57       199\\n     CHEESE       0.96      0.91      0.93       194\\n   CUCUMBER       0.75      0.72      0.73       196\\n      DATES       0.80      1.00      0.89       223\\n   DOUGHNUT       0.48      0.22      0.30       197\\n        EGG       0.46      0.83      0.59       265\\n      FIRED       0.77      0.48      0.59       209\\n      GRAPE       0.93      0.37      0.53       201\\n GRAPEFRUIT       0.97      0.71      0.82       196\\n       KIWI       0.95      0.92      0.94       212\\n      LEMON       0.57      0.47      0.51       193\\n     LITCHI       0.90      0.99      0.94       192\\n      MANGO       0.36      0.46      0.40       203\\n   MOONCAKE       0.61      0.45      0.52       201\\n      OLIVE       0.96      0.78      0.86       196\\n      ONION       0.91      0.91      0.91       279\\n     ORANGE       0.55      0.79      0.65       406\\n     PAPAYA       0.88      0.82      0.85       192\\n      PASTA       0.84      0.95      0.89       193\\n      PEACH       0.35      0.37      0.36       196\\n       PEAR       0.58      0.16      0.25       195\\n     PEPPER       0.93      0.52      0.67       189\\n       PLUM       0.72      0.44      0.55       208\\nPOMEGRANATE       0.97      0.98      0.98       206\\n       QIWI       0.65      0.41      0.50       200\\n    SACHIMA       0.56      0.49      0.52       202\\n      SAUCE       0.93      0.91      0.92       195\\n      SWEET       0.96      0.92      0.94       208\\n     TOMATO       0.60      0.79      0.68       266\\n WATERMELON       0.64      0.62      0.63       200\\n\\navg / total       0.73      0.70      0.70      8322\\n'),\n",
       " 'XGBClassifier_tree_V09_PCA_90': (0.9989185291997116,\n",
       "  0.9989172121443446,\n",
       "  0.05642888196607992,\n",
       "  array([[466,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 202,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 197,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 213,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 195,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 220,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 205,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0, 199,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 222,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 197,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          265,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 212,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 193,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 203,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 201,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 276,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 406,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 195,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 189,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 208,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 200,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 202,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 193,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 208,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 266,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 200]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      0.98      0.99       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       0.99      1.00      0.99       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       0.99      1.00      1.00       196\\n      ONION       0.99      0.99      0.99       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       0.99      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      0.99      0.99       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'SVC_V09_PCA_80': (0.768565248738284,\n",
       "  0.7666776369650055,\n",
       "  0.9164292492759663,\n",
       "  array([[350,   2,   0,   1,   8,   1,   0,   2,   0,   0,   0,   0,   7,\n",
       "            1,   1,   7,   2,   0,   5,   0,   6,   2,   0,   8,  16,   0,\n",
       "            0,   5,   3,   1,   4,   1,   5,   9,   1,   0,  17,   1],\n",
       "         [  3, 184,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  15,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 197,   0,   0,   0,   0,   0,   2,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  5,   0,   0, 204,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 28,   0,   0,   0,  99,   0,   7,   2,   3,   0,   0,   0,   4,\n",
       "            5,   0,   3,   0,   0,   2,   0,  10,   2,   0,   0,  12,   0,\n",
       "            0,   6,  13,   0,   0,   0,  10,   2,   0,   0,   3,   2],\n",
       "         [  3,   0,   0,   0,   0, 191,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  5,   0,   0,   0,  11,   0, 149,   0,   0,   2,   0,   0,   2,\n",
       "           13,   0,   1,   0,   0,   0,   0,   7,   0,   0,   3,  12,   0,\n",
       "            0,   0,   1,   1,   0,   0,   4,   2,   0,   0,   7,   0],\n",
       "         [  7,   0,   0,   0,   1,   0,   0, 174,   0,   0,   0,   0,   1,\n",
       "            6,   3,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "            0,   2,   0,   0,   0,   0,   0,   9,   0,   0,   0,   0],\n",
       "         [  0,   5,   0,   0,   1,   0,   0,   0, 170,   0,   3,   0,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,  15],\n",
       "         [  0,   0,   0,   0,   0,   0,   2,   0,   0, 190,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   0,   0,   0,  20,   0, 167,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   1,   0,   0,   3,   0,   0,   0,   0,   4],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 40,   0,   0,   0,  10,   0,   2,   0,   0,   0,   0,   0,  54,\n",
       "            3,   1,   2,   0,   0,  12,   0,  16,  13,   0,   0,   2,   0,\n",
       "            0,  15,   5,   0,   7,   0,   5,   8,   0,   0,   2,   0],\n",
       "         [  7,   0,   0,   0,   1,   4,  10,   0,   0,   0,   0,   0,   6,\n",
       "          192,   3,   0,   0,   0,   2,   0,   6,   0,   0,   3,  11,   0,\n",
       "            0,   0,   2,   0,   0,   0,   0,  13,   1,   0,   2,   2],\n",
       "         [ 11,   0,   0,   0,   4,   2,   0,   8,   0,   0,   0,   0,  10,\n",
       "            3, 135,   2,   0,   0,   1,   1,   5,   4,   0,   0,   4,   0,\n",
       "            0,   1,   2,   0,   3,   0,   5,   4,   0,   0,   4,   0],\n",
       "         [ 16,   0,   0,   0,   2,   1,   0,   4,   0,   1,   0,   1,   0,\n",
       "            0,   2, 124,   1,   0,   0,   0,   0,   1,   0,   1,   5,   0,\n",
       "            0,   6,   0,   2,  18,   0,   1,   1,   2,   0,  12,   0],\n",
       "         [  3,   7,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   2, 173,   3,   0,   0,   1,   0,   0,   0,   3,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  5,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 11,   0,   0,   0,   3,   0,   0,   2,   0,   0,   0,   0,   6,\n",
       "            1,   0,   0,   3,   0, 122,   0,   3,   6,   0,   0,   3,   0,\n",
       "            0,  11,   7,   0,   1,   0,   6,   0,   0,   0,   8,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 191,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 15,   0,   0,   0,  11,   0,   1,   5,   0,   0,   0,   0,  21,\n",
       "            3,   0,   0,   0,   0,  15,   0,  93,   4,   0,   0,   7,   0,\n",
       "            0,   6,   4,   0,   2,   0,   7,   6,   0,   0,   3,   0],\n",
       "         [  8,   0,   0,   1,   2,   1,   0,   1,   0,   0,   0,   0,  12,\n",
       "            3,   0,   1,   0,   0,  11,   1,   4, 120,   0,   0,   0,   0,\n",
       "            0,  16,   3,   0,   2,   0,  10,   4,   0,   0,   1,   0],\n",
       "         [  1,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   1,   0,   0, 261,   3,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   3,   0],\n",
       "         [ 19,   3,   0,   0,  11,   3,   2,   0,   0,   0,   0,   0,   5,\n",
       "            1,   1,   2,   3,   0,  17,   0,  10,   0,   0,   0, 303,   1,\n",
       "            0,   1,   2,   0,   1,   0,   4,   2,   0,   1,  14,   0],\n",
       "         [  0,   1,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0, 182,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          191,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 17,   0,   0,   0,   2,   0,   0,   6,   0,   0,   0,   0,   8,\n",
       "            0,   0,   2,   4,   0,   3,   4,   3,  17,   0,   1,   0,   1,\n",
       "            1,  85,   6,   0,   7,   0,   1,   6,   0,   1,  21,   0],\n",
       "         [ 24,   0,   0,   1,  17,   0,   4,   6,   0,   0,   0,   0,   4,\n",
       "            0,   0,   0,   3,   3,  18,   1,   7,   0,   0,   0,  11,   0,\n",
       "            0,  13,  56,   0,   0,   0,   8,  14,   0,   0,   5,   0],\n",
       "         [  5,   0,   0,   1,   0,   0,   0,   0,  26,   0,   1,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 145,   0,   0,   0,   0,   0,   0,   3,   8],\n",
       "         [ 26,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,   5,\n",
       "            3,   0,   4,   0,   0,   3,   0,   2,  18,   0,   1,   5,   0,\n",
       "            0,  17,   1,   0, 106,   0,   3,   2,   0,   0,   8,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0],\n",
       "         [  7,   0,   0,   0,   5,   1,   2,   2,   0,   0,  11,   0,   8,\n",
       "            1,   2,   0,   0,   0,   4,   0,   8,   9,   0,   0,   5,   0,\n",
       "            0,  11,   9,   1,   1,   0, 109,   2,   1,   0,   0,   1],\n",
       "         [ 13,   0,   0,   0,   3,   0,   1,   3,   0,   0,   0,   0,   5,\n",
       "            5,   3,   4,   0,   0,   0,   2,   7,   7,   0,   0,   1,   0,\n",
       "            0,   8,   6,   0,   2,   0,   6, 122,   0,   0,   4,   0],\n",
       "         [  1,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0, 189,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 206,   0,   0],\n",
       "         [ 19,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   2,   0,\n",
       "            3,   0,  10,   0,   0,   0,   0,   0,   4,   0,   1,  10,   0,\n",
       "            2,   4,   0,   2,   3,   0,   0,   0,   2,   0, 203,   0],\n",
       "         [  5,   0,   0,   0,   0,   0,   0,   0,  49,   0,   3,   0,   0,\n",
       "            5,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   5,   0,   0,   0,   0,   0,   0,   1, 130]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.53      0.75      0.62       466\\n    APRICOT       0.91      0.91      0.91       202\\n  AUBERGINE       0.99      0.98      0.99       200\\n    AVOCADO       0.98      0.98      0.98       209\\n     BANANA       0.50      0.46      0.48       213\\n       BEAN       0.93      0.98      0.95       195\\n      BREAD       0.82      0.68      0.74       220\\n        BUN       0.81      0.85      0.83       205\\n     CARROT       0.62      0.85      0.72       199\\n     CHEESE       0.98      0.98      0.98       194\\n   CUCUMBER       0.90      0.85      0.88       196\\n      DATES       0.98      1.00      0.99       223\\n   DOUGHNUT       0.34      0.27      0.30       197\\n        EGG       0.76      0.72      0.74       265\\n      FIRED       0.89      0.65      0.75       209\\n      GRAPE       0.73      0.62      0.67       201\\n GRAPEFRUIT       0.84      0.88      0.86       196\\n       KIWI       0.97      0.97      0.97       212\\n      LEMON       0.57      0.63      0.60       193\\n     LITCHI       0.95      0.99      0.97       192\\n      MANGO       0.49      0.46      0.47       203\\n   MOONCAKE       0.58      0.60      0.59       201\\n      OLIVE       0.97      0.99      0.98       196\\n      ONION       0.93      0.94      0.93       279\\n     ORANGE       0.73      0.75      0.74       406\\n     PAPAYA       0.99      0.95      0.97       192\\n      PASTA       0.98      0.99      0.98       193\\n      PEACH       0.41      0.43      0.42       196\\n       PEAR       0.47      0.29      0.36       195\\n     PEPPER       0.91      0.77      0.83       189\\n       PLUM       0.68      0.51      0.58       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       0.58      0.55      0.56       200\\n    SACHIMA       0.58      0.60      0.59       202\\n      SAUCE       0.96      0.97      0.97       195\\n      SWEET       0.99      0.99      0.99       208\\n     TOMATO       0.63      0.76      0.69       266\\n WATERMELON       0.80      0.65      0.72       200\\n\\navg / total       0.77      0.77      0.77      8322\\n'),\n",
       " 'XGBClassifier_tree_V09_PCA_80': (1.0,\n",
       "  1.0,\n",
       "  0.022685754121015905,\n",
       "  array([[466,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 202,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0, 200,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0, 213,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 195,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 220,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0, 205,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0, 199,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0, 194,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 223,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 197,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          265,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 209,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 201,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 212,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 193,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 192,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 203,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 201,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 196,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 279,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 406,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          193,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0, 196,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0, 195,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0, 189,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0, 208,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0, 206,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0, 200,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0, 202,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0, 195,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0, 208,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 266,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 200]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       1.00      1.00      1.00       466\\n    APRICOT       1.00      1.00      1.00       202\\n  AUBERGINE       1.00      1.00      1.00       200\\n    AVOCADO       1.00      1.00      1.00       209\\n     BANANA       1.00      1.00      1.00       213\\n       BEAN       1.00      1.00      1.00       195\\n      BREAD       1.00      1.00      1.00       220\\n        BUN       1.00      1.00      1.00       205\\n     CARROT       1.00      1.00      1.00       199\\n     CHEESE       1.00      1.00      1.00       194\\n   CUCUMBER       1.00      1.00      1.00       196\\n      DATES       1.00      1.00      1.00       223\\n   DOUGHNUT       1.00      1.00      1.00       197\\n        EGG       1.00      1.00      1.00       265\\n      FIRED       1.00      1.00      1.00       209\\n      GRAPE       1.00      1.00      1.00       201\\n GRAPEFRUIT       1.00      1.00      1.00       196\\n       KIWI       1.00      1.00      1.00       212\\n      LEMON       1.00      1.00      1.00       193\\n     LITCHI       1.00      1.00      1.00       192\\n      MANGO       1.00      1.00      1.00       203\\n   MOONCAKE       1.00      1.00      1.00       201\\n      OLIVE       1.00      1.00      1.00       196\\n      ONION       1.00      1.00      1.00       279\\n     ORANGE       1.00      1.00      1.00       406\\n     PAPAYA       1.00      1.00      1.00       192\\n      PASTA       1.00      1.00      1.00       193\\n      PEACH       1.00      1.00      1.00       196\\n       PEAR       1.00      1.00      1.00       195\\n     PEPPER       1.00      1.00      1.00       189\\n       PLUM       1.00      1.00      1.00       208\\nPOMEGRANATE       1.00      1.00      1.00       206\\n       QIWI       1.00      1.00      1.00       200\\n    SACHIMA       1.00      1.00      1.00       202\\n      SAUCE       1.00      1.00      1.00       195\\n      SWEET       1.00      1.00      1.00       208\\n     TOMATO       1.00      1.00      1.00       266\\n WATERMELON       1.00      1.00      1.00       200\\n\\navg / total       1.00      1.00      1.00      8322\\n'),\n",
       " 'SVC_V09_PCA_5components': (0.3818793559240567,\n",
       "  0.3434308346035542,\n",
       "  1.8985966598401576,\n",
       "  array([[265,   5,   3,   0,   0,   5,   8,   0,   4,   6,   0,   0,   0,\n",
       "            1,   0,   0,   6,   0,   0,   2,  35,   0,   0,  33,  47,   0,\n",
       "            1,   0,   0,   0,   0,   5,   1,   0,  20,   0,  19,   0],\n",
       "         [ 39,  71,   0,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,  43,   9,   0,   0,   4,   0,   0,   0,   3,   9,\n",
       "            0,   0,   0,   0,   0,   2,   0,   0,   0,  10,   0,   0],\n",
       "         [  0,   0, 149,   0,   0,   0,   0,   0,  16,   3,   9,   7,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0,   0,   3,   2,   0,   0,\n",
       "            0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   0,   5],\n",
       "         [ 12,   0,   0, 134,   0,   0,   0,   3,   1,   5,   0,  15,   0,\n",
       "            0,   0,   0,   1,  24,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "            0,   3,   0,   0,   0,   0,   0,   0,   0,   4,   0,   4],\n",
       "         [ 83,   0,   0,   2,   1,   3,   8,   0,   0,   3,   0,   0,   0,\n",
       "            6,   0,   0,   0,   6,   0,   1,  27,   8,   0,   0,  33,   1,\n",
       "            0,  10,   0,   1,   0,   0,   4,   4,   0,   0,   9,   3],\n",
       "         [  5,   0,   5,   0,   0,  50,   1,   0,   0,  24,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   2,   0,   4,   0,  82,   1,   0,\n",
       "           11,   0,   0,   0,   0,   0,   0,   0,   7,   0,   3,   0],\n",
       "         [ 18,   1,   0,   0,   1,   2, 123,   0,   0,   0,   0,   0,   0,\n",
       "            9,   0,   0,   0,   0,   1,   4,  22,   0,   0,  12,  23,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0],\n",
       "         [ 32,   1,   0,   2,   0,   0,   0,  83,   0,   0,   0,  17,   0,\n",
       "            0,   8,   0,   0,  10,   0,   0,  15,   4,   0,   0,  18,   3,\n",
       "            0,   7,   0,   0,   0,   0,   0,   3,   0,   0,   2,   0],\n",
       "         [  5,   2,   0,   1,   0,   0,   9,   0,   9,   1,  82,  20,   0,\n",
       "            0,   0,   0,  12,   0,   2,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,  19,  10,   0,   0,   1,   0,  25],\n",
       "         [ 16,   2,   0,   0,   0,   0,   0,   0,   0,  74,   0,   0,   0,\n",
       "           24,   0,   0,   0,   0,   1,   0,   0,   0,   0,  33,  23,   0,\n",
       "            5,   0,   0,   0,   0,   0,   3,   0,  10,   0,   0,   3],\n",
       "         [ 10,   0,   4,   3,   0,   0,   8,   0,   1,   1,  83,   0,   0,\n",
       "            5,   6,   0,   0,   0,   0,   0,   0,   3,   0,   0,   1,   0,\n",
       "            0,   0,   0,   9,   0,   4,   8,   0,   0,   0,   0,  50],\n",
       "         [  3,   0,  12,  20,   0,   0,   0,  21,  22,   4,   0,  75,   0,\n",
       "            0,   2,   0,   2,   3,   0,   0,   0,   0,   0,   0,   5,   0,\n",
       "            0,   0,   0,   0,   0,  54,   0,   0,   0,   0,   0,   0],\n",
       "         [ 47,   0,   0,   1,   0,   9,   3,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   5,   0,   0,  41,  15,   0,   2,  52,   0,\n",
       "            1,   8,   0,   1,   0,   0,   0,   0,   0,   0,  12,   0],\n",
       "         [ 24,   0,   0,   0,   0,   4,  34,   0,   0,   4,   0,   0,   0,\n",
       "           92,   0,   0,   2,   0,   0,   2,  35,   0,   0,  23,  30,   0,\n",
       "            0,   0,   0,   1,   0,   0,   2,   0,   9,   0,   2,   1],\n",
       "         [ 38,   0,   0,   0,   0,   5,   4,  25,   1,   0,   3,  12,   0,\n",
       "            0,  52,   0,   3,   0,   0,   0,  30,   1,   0,   0,  15,  14,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0],\n",
       "         [ 66,   0,   1,   8,   1,   0,   6,   0,   0,   2,   0,   1,   0,\n",
       "            1,   0,   0,   0,   0,   0,  17,   0,   6,   1,   5,  11,   3,\n",
       "           52,   1,   0,   0,   0,   2,   0,   2,  14,   0,   1,   0],\n",
       "         [ 12,  23,   1,   1,   0,   0,   0,  10,   0,   1,   0,   0,   0,\n",
       "            0,   6,   0,  53,  10,   5,   0,   6,   0,   1,   0,  15,   7,\n",
       "            2,   3,   0,   2,   2,  32,   0,   2,   0,   2,   0,   0],\n",
       "         [ 10,   1,   0,  19,   0,   0,   0,  10,   0,   0,   0,   2,   0,\n",
       "            0,   1,   0,   5, 133,   0,   0,   1,   8,   0,   0,   0,   5,\n",
       "            0,   4,   0,   0,   0,   3,   0,   0,   0,  10,   0,   0],\n",
       "         [ 44,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,   0,   0,\n",
       "            0,   0,   0,   2,   6,  14,   0,  35,  17,   1,   0,  32,   1,\n",
       "            0,  23,   0,   0,   0,   5,   0,   2,   0,   2,   6,   0],\n",
       "         [  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            5,   0,   0,   0,   0,   0, 181,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [ 37,   1,   0,   3,   0,   4,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   2,   4,   0,   1, 108,   5,   1,   0,  25,   0,\n",
       "            1,   3,   0,   0,   0,   0,   0,   1,   0,   0,   6,   0],\n",
       "         [ 38,   0,   0,   0,   0,  12,   1,   0,   0,   1,   0,   0,   0,\n",
       "            1,   0,   0,   0,   1,   4,  16,  36,  52,   0,   0,  12,   0,\n",
       "            0,  20,   0,   0,   6,   0,   0,   0,   0,   0,   1,   0],\n",
       "         [  7,   5,  27,   8,   0,   0,   0,  18,   2,   1,   7,   9,   0,\n",
       "            0,  13,   0,   0,  10,   0,   0,   1,   0,  79,   0,   1,   0,\n",
       "            0,   0,   0,   1,   0,   7,   0,   0,   0,   0,   0,   0],\n",
       "         [  6,   0,   2,   0,   0,   3,   1,   0,   1,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   1,   3,   0,   1, 248,   2,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   9,   0,   0,   0],\n",
       "         [108,   3,   1,   0,   0,   1,   2,   0,   0,   5,   0,   0,   0,\n",
       "            1,   0,   0,   5,   0,   5,   3,  19,   0,   1,  30, 199,   0,\n",
       "            4,   0,   0,   0,   0,   4,   0,   0,   2,   0,  13,   0],\n",
       "         [ 12,  11,   5,  13,   0,   0,   0,   4,   3,   2,   0,  12,   0,\n",
       "            0,   7,   0,  11,  28,   4,   0,   1,   2,   0,   0,   4,  49,\n",
       "            0,   7,   0,   0,   0,  13,   0,   0,   1,   3,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,  10,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   1,   6,   0,   1,   0,   1,   0,   0,\n",
       "          168,   0,   0,   0,   0,   0,   0,   0,   5,   0,   0,   0],\n",
       "         [ 58,   0,   0,   3,   0,   5,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   7,   2,   6,  23,  32,   1,   0,   7,   0,\n",
       "            0,  42,   0,   0,   0,   0,   0,   3,   0,   0,   7,   0],\n",
       "         [ 70,   1,   0,   6,   0,   0,   1,   1,   0,   1,   0,   0,   0,\n",
       "            0,   0,   0,   0,  15,   0,   1,  32,   6,   2,   0,  22,   1,\n",
       "            0,  18,   0,   1,   1,   3,   0,   1,   0,   0,  12,   0],\n",
       "         [ 12,   0,   0,   1,   0,   0,  18,   0,   0,   7,  44,  11,   0,\n",
       "            0,  14,   0,   2,   1,   0,   0,   0,   5,   0,   0,   4,   0,\n",
       "            0,   0,   0,  48,   0,   5,   0,   0,   0,   0,   0,  17],\n",
       "         [ 54,   0,   0,   0,   0,  11,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,  15,  20,  14,   0,   3,  35,   0,\n",
       "            4,  27,   0,   0,   6,   0,   0,   1,   0,   0,  18,   0],\n",
       "         [  0,   0,   2,   0,   0,   0,   0,   6,   2,   1,   0,  14,   0,\n",
       "            0,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,   0,\n",
       "            0,   0,   0,   2,   0, 164,   0,   0,   0,   0,   0,   0],\n",
       "         [ 50,   0,   0,   9,   0,   0,   5,   0,   3,   1,   1,   0,   0,\n",
       "            0,   0,   0,   0,  18,   2,   1,  35,  14,   0,   1,   2,   1,\n",
       "            1,  13,   0,   1,   0,   0,  16,   0,   2,   0,   7,  17],\n",
       "         [ 34,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,  27,   0,  14,  55,  16,   1,   0,  19,   0,\n",
       "            0,  10,   0,   0,   0,   0,   0,  23,   0,   0,   3,   0],\n",
       "         [  0,   0,   1,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,\n",
       "            5,   0,   0,   0,   0,   0,   0,   0,   1,   0,  15,   0,   0,\n",
       "            3,   0,   0,   0,   0,   0,   0,   0, 167,   0,   1,   0],\n",
       "         [  3,  15,   0,  17,   0,   0,   0,  13,   0,   0,   0,   9,   0,\n",
       "            0,  25,   0,   2,  56,   0,   0,   0,   1,   0,   0,   8,  12,\n",
       "            0,   2,   0,   0,   0,  32,   0,   0,   0,  13,   0,   0],\n",
       "         [107,   0,   0,   0,   0,  13,  20,   0,   0,   3,   0,   0,   0,\n",
       "            9,   0,   0,   0,   0,   0,   0,   6,   0,   2,  22,  14,   0,\n",
       "           11,   0,   0,   0,   0,   1,   1,   0,   3,   0,  54,   0],\n",
       "         [  9,   0,   0,   0,   0,   0,  10,   0,   4,   0,  53,   0,   0,\n",
       "            1,   0,   0,   1,   0,   0,   0,   0,   0,   0,   3,   0,   6,\n",
       "            0,   0,   0,   0,   0,   3,   7,   0,   3,   0,   0, 100]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.20      0.57      0.29       466\\n    APRICOT       0.50      0.35      0.41       202\\n  AUBERGINE       0.70      0.74      0.72       200\\n    AVOCADO       0.51      0.64      0.57       209\\n     BANANA       0.33      0.00      0.01       213\\n       BEAN       0.36      0.26      0.30       195\\n      BREAD       0.47      0.56      0.51       220\\n        BUN       0.43      0.40      0.42       205\\n     CARROT       0.13      0.05      0.07       199\\n     CHEESE       0.48      0.38      0.43       194\\n   CUCUMBER       0.29      0.42      0.35       196\\n      DATES       0.37      0.34      0.35       223\\n   DOUGHNUT       0.00      0.00      0.00       197\\n        EGG       0.57      0.35      0.43       265\\n      FIRED       0.37      0.25      0.30       209\\n      GRAPE       0.00      0.00      0.00       201\\n GRAPEFRUIT       0.35      0.27      0.30       196\\n       KIWI       0.36      0.63      0.45       212\\n      LEMON       0.34      0.07      0.12       193\\n     LITCHI       0.66      0.94      0.78       192\\n      MANGO       0.18      0.53      0.27       203\\n   MOONCAKE       0.24      0.26      0.25       201\\n      OLIVE       0.83      0.40      0.54       196\\n      ONION       0.48      0.89      0.62       279\\n     ORANGE       0.29      0.49      0.37       406\\n     PAPAYA       0.44      0.26      0.32       192\\n      PASTA       0.63      0.87      0.73       193\\n      PEACH       0.21      0.21      0.21       196\\n       PEAR       0.00      0.00      0.00       195\\n     PEPPER       0.72      0.25      0.37       189\\n       PLUM       0.40      0.03      0.05       208\\nPOMEGRANATE       0.45      0.80      0.58       206\\n       QIWI       0.31      0.08      0.13       200\\n    SACHIMA       0.55      0.11      0.19       202\\n      SAUCE       0.66      0.86      0.75       195\\n      SWEET       0.29      0.06      0.10       208\\n     TOMATO       0.29      0.20      0.24       266\\n WATERMELON       0.44      0.50      0.47       200\\n\\navg / total       0.38      0.38      0.34      8322\\n'),\n",
       " 'XGBClassifier_tree_V09_PCA_5components': (0.804253785147801,\n",
       "  0.803308476648813,\n",
       "  0.7676484146967563,\n",
       "  array([[376,   3,   0,   0,   5,   3,   2,   4,   0,   3,   1,   0,   3,\n",
       "            1,   0,   3,   2,   0,   4,   0,   6,   2,   2,   1,  15,   0,\n",
       "            0,   3,   3,   1,   3,   0,   5,   2,   6,   0,   6,   1],\n",
       "         [  0, 186,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   2,   2,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "            0,   0,   1,   0,   0,   1,   0,   0,   0,   5,   0,   0],\n",
       "         [  0,   0, 183,   0,   0,   0,   0,   0,   3,   3,   2,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   2,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4],\n",
       "         [  1,   2,   0, 194,   0,   0,   0,   0,   0,   3,   0,   0,   0,\n",
       "            0,   1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   2,   2,\n",
       "            0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0],\n",
       "         [  9,   0,   0,   0, 124,   3,   0,   4,   3,   1,   3,   0,   2,\n",
       "            2,   0,   3,   3,   1,   5,   0,   5,   4,   0,   0,  10,   1,\n",
       "            0,   4,   5,   1,   0,   0,  10,   3,   0,   3,   3,   1],\n",
       "         [  3,   0,   1,   0,   0, 168,   2,   0,   0,   2,   0,   0,   2,\n",
       "            0,   0,   3,   0,   0,   0,   0,   0,   0,   0,   7,   1,   0,\n",
       "            0,   1,   0,   0,   0,   0,   0,   0,   2,   0,   2,   1],\n",
       "         [  5,   1,   0,   0,   1,   0, 179,   1,   0,   1,   0,   0,   2,\n",
       "            5,   2,   1,   0,   0,   0,   2,   3,   0,   0,   1,   6,   1,\n",
       "            0,   1,   1,   1,   0,   0,   0,   4,   0,   0,   1,   1],\n",
       "         [  5,   2,   0,   0,   2,   0,   1, 159,   0,   0,   0,   2,   3,\n",
       "            2,   3,   0,   1,   0,   0,   0,   3,   0,   2,   0,   2,   0,\n",
       "            0,   4,   5,   0,   1,   0,   1,   5,   0,   1,   1,   0],\n",
       "         [  0,   1,   2,   0,   0,   0,   0,   0, 166,   1,   3,   2,   0,\n",
       "            1,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   3,   0,   2,   2,   0,   0,   2,   2,  11],\n",
       "         [  2,   0,   0,   2,   1,   3,   0,   0,   1, 167,   1,   0,   0,\n",
       "            1,   0,   1,   0,   0,   0,   0,   0,   1,   0,   1,   4,   0,\n",
       "            1,   0,   0,   0,   0,   0,   0,   0,   5,   0,   2,   1],\n",
       "         [  1,   0,   2,   1,   0,   0,   1,   0,   6,   2, 172,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,   7],\n",
       "         [  1,   0,   1,   0,   0,   0,   0,   4,   2,   3,   0, 204,   1,\n",
       "            0,   1,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   1,\n",
       "            0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0],\n",
       "         [ 11,   0,   0,   0,   2,   1,   2,   2,   0,   1,   0,   0, 122,\n",
       "            4,   0,   1,   0,   1,   3,   0,   2,   8,   0,   0,   9,   0,\n",
       "            1,   6,   3,   1,  11,   0,   0,   1,   0,   2,   3,   0],\n",
       "         [  6,   0,   0,   0,   2,   2,   3,   1,   1,   5,   4,   0,   2,\n",
       "          198,   1,   0,   0,   0,   2,   2,   5,   2,   0,   5,   6,   0,\n",
       "            2,   1,   5,   0,   0,   0,   0,   4,   1,   0,   5,   0],\n",
       "         [  4,   0,   0,   0,   2,   0,   3,   2,   1,   0,   0,   0,   4,\n",
       "            0, 155,   2,   0,   0,   1,   1,   7,   5,   0,   0,   5,   0,\n",
       "            1,   1,   2,   0,   5,   0,   2,   2,   0,   0,   4,   0],\n",
       "         [  6,   0,   1,   1,   4,   1,   2,   1,   0,   3,   0,   0,   2,\n",
       "            2,   0, 128,   2,   0,   0,   2,   0,   2,   1,   2,   5,   1,\n",
       "           17,   0,   0,   1,   3,   1,   1,   2,   5,   0,   4,   1],\n",
       "         [  2,   6,   0,   0,   0,   0,   0,   3,   1,   0,   0,   0,   0,\n",
       "            2,   1,   3, 157,   0,   2,   0,   0,   0,   0,   0,   6,   6,\n",
       "            0,   0,   1,   1,   2,   0,   0,   1,   0,   2,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   2,   1,\n",
       "            0,   1,   0,   5, 188,   2,   0,   0,   1,   0,   0,   0,   2,\n",
       "            0,   1,   1,   0,   0,   1,   2,   0,   0,   3,   0,   0],\n",
       "         [  2,   1,   2,   1,   4,   0,   0,   1,   0,   0,   0,   0,   3,\n",
       "            1,   0,   1,   1,   0, 141,   0,   4,   4,   1,   0,   3,   0,\n",
       "            0,   5,   3,   0,   4,   1,   2,   3,   0,   0,   5,   0],\n",
       "         [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            3,   0,   0,   0,   0,   0, 188,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  5,   1,   0,   1,   4,   0,   0,   2,   0,   0,   0,   0,   5,\n",
       "            2,   1,   2,   2,   0,   6,   0, 135,   7,   1,   0,   5,   1,\n",
       "            0,   1,   4,   0,   4,   0,   5,   5,   0,   1,   3,   0],\n",
       "         [  3,   0,   0,   0,   1,   0,   2,   0,   0,   0,   0,   0,   8,\n",
       "            3,   2,   0,   0,   0,   5,   3,   2, 154,   0,   0,   2,   1,\n",
       "            0,   3,   0,   0,   4,   0,   4,   2,   0,   0,   2,   0],\n",
       "         [  1,   2,   1,   0,   0,   0,   0,   1,   0,   1,   0,   5,   0,\n",
       "            0,   0,   1,   1,   1,   0,   0,   0,   0, 179,   0,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0],\n",
       "         [  1,   1,   2,   0,   0,   7,   0,   1,   0,   2,   1,   0,   0,\n",
       "            2,   0,   1,   2,   0,   0,   1,   0,   0,   0, 247,   4,   0,\n",
       "            1,   0,   1,   0,   0,   1,   0,   0,   1,   0,   3,   0],\n",
       "         [ 16,   0,   0,   0,   3,   2,   1,   0,   0,   4,   0,   2,   2,\n",
       "            1,   3,   2,   2,   1,   7,   0,   4,   0,   3,   7, 325,   0,\n",
       "            0,   2,   8,   0,   0,   0,   1,   1,   2,   0,   7,   0],\n",
       "         [  3,   4,   1,   3,   0,   0,   0,   1,   0,   2,   0,   2,   1,\n",
       "            0,   0,   0,   4,   0,   1,   0,   0,   0,   0,   0,   4, 158,\n",
       "            0,   0,   4,   0,   0,   1,   0,   0,   0,   3,   0,   0],\n",
       "         [  1,   0,   0,   0,   0,   3,   0,   0,   0,   1,   0,   0,   0,\n",
       "            0,   0,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          177,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "         [  8,   1,   0,   2,   0,   1,   1,   3,   0,   0,   0,   0,   4,\n",
       "            2,   0,   1,   0,   0,   5,   1,   3,  12,   0,   0,   2,   1,\n",
       "            0, 135,   3,   0,   4,   0,   4,   1,   0,   0,   2,   0],\n",
       "         [  5,   4,   0,   1,   1,   0,   1,   1,   0,   1,   1,   0,   2,\n",
       "            2,   1,   4,   1,   1,   5,   1,   7,   2,   0,   0,   8,   0,\n",
       "            0,   4, 130,   0,   0,   1,   1,   6,   0,   0,   4,   0],\n",
       "         [  1,   0,   2,   0,   0,   0,   2,   0,  13,   2,   4,   5,   1,\n",
       "            0,   0,   0,   2,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0, 143,   0,   4,   0,   0,   0,   0,   3,   5],\n",
       "         [  4,   0,   0,   0,   3,   2,   1,   0,   0,   0,   0,   0,   3,\n",
       "            0,   3,   0,   0,   0,   1,   0,   3,   7,   0,   0,   3,   0,\n",
       "            2,   7,   0,   0, 158,   1,   0,   1,   0,   0,   9,   0],\n",
       "         [  1,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   5,   1,\n",
       "            0,   1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,   0,   0,   1,   0, 193,   0,   0,   0,   0,   0,   0],\n",
       "         [  3,   1,   0,   0,   7,   1,   2,   3,   1,   0,   4,   0,   2,\n",
       "            1,   2,   1,   0,   0,   2,   0,   7,   4,   0,   0,   5,   0,\n",
       "            1,   2,   7,   1,   2,   0, 128,   2,   2,   2,   5,   2],\n",
       "         [  4,   0,   0,   0,   3,   0,   2,   1,   0,   1,   0,   0,   5,\n",
       "            2,   0,   0,   1,   1,   3,   2,   7,   2,   0,   0,   7,   0,\n",
       "            1,   4,   5,   1,   5,   0,   3, 139,   0,   1,   2,   0],\n",
       "         [  3,   0,   0,   0,   0,   4,   0,   0,   0,   1,   0,   0,   0,\n",
       "            2,   0,   2,   0,   0,   1,   0,   0,   0,   0,   3,   1,   0,\n",
       "            2,   0,   0,   0,   0,   0,   0,   0, 176,   0,   0,   0],\n",
       "         [  1,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "            0,   0,   0,   2,   3,   0,   0,   0,   0,   1,   0,   6,   1,\n",
       "            0,   0,   0,   0,   0,   2,   1,   0,   0, 189,   0,   0],\n",
       "         [  6,   0,   0,   0,   3,   3,   0,   0,   1,   2,   0,   0,   5,\n",
       "            4,   0,   4,   0,   0,   2,   0,   2,   1,   1,   7,   6,   0,\n",
       "            4,   2,   0,   1,   3,   0,   1,   1,   2,   0, 202,   3],\n",
       "         [  2,   0,   0,   0,   0,   1,   2,   0,   7,   1,   3,   0,   0,\n",
       "            2,   0,   0,   3,   0,   0,   0,   0,   0,   0,   1,   1,   0,\n",
       "            0,   0,   0,   4,   0,   0,   2,   0,   1,   0,   0, 170]],\n",
       "        dtype=int64),\n",
       "  '             precision    recall  f1-score   support\\n\\n      APPLE       0.75      0.81      0.78       466\\n    APRICOT       0.86      0.92      0.89       202\\n  AUBERGINE       0.92      0.92      0.92       200\\n    AVOCADO       0.94      0.93      0.93       209\\n     BANANA       0.71      0.58      0.64       213\\n       BEAN       0.82      0.86      0.84       195\\n      BREAD       0.85      0.81      0.83       220\\n        BUN       0.82      0.78      0.79       205\\n     CARROT       0.80      0.83      0.82       199\\n     CHEESE       0.78      0.86      0.82       194\\n   CUCUMBER       0.86      0.88      0.87       196\\n      DATES       0.89      0.91      0.90       223\\n   DOUGHNUT       0.66      0.62      0.64       197\\n        EGG       0.81      0.75      0.78       265\\n      FIRED       0.87      0.74      0.80       209\\n      GRAPE       0.74      0.64      0.68       201\\n GRAPEFRUIT       0.79      0.80      0.80       196\\n       KIWI       0.94      0.89      0.91       212\\n      LEMON       0.71      0.73      0.72       193\\n     LITCHI       0.93      0.98      0.95       192\\n      MANGO       0.66      0.67      0.66       203\\n   MOONCAKE       0.71      0.77      0.74       201\\n      OLIVE       0.93      0.91      0.92       196\\n      ONION       0.87      0.89      0.88       279\\n     ORANGE       0.71      0.80      0.75       406\\n     PAPAYA       0.90      0.82      0.86       192\\n      PASTA       0.84      0.92      0.88       193\\n      PEACH       0.72      0.69      0.70       196\\n       PEAR       0.67      0.67      0.67       195\\n     PEPPER       0.89      0.76      0.82       189\\n       PLUM       0.76      0.76      0.76       208\\nPOMEGRANATE       0.91      0.94      0.92       206\\n       QIWI       0.72      0.64      0.68       200\\n    SACHIMA       0.75      0.69      0.72       202\\n      SAUCE       0.86      0.90      0.88       195\\n      SWEET       0.87      0.91      0.89       208\\n     TOMATO       0.72      0.76      0.74       266\\n WATERMELON       0.82      0.85      0.83       200\\n\\navg / total       0.80      0.80      0.80      8322\\n')}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bench.best_models_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
